{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hp_optimization_without_stratified_K_Fold",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/Hp_optimization_without_stratified_K_Fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZpyLcr_wktZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U keras-tuner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11sCznT-2mmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tAAGti39qMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r my_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "541652cb-9624-42c2-c985-d1bc871749d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-87QSVhqhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSbeCedhuxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbcwLGg3iNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQdR4izXiT0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5wIylYmsQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = df_test.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data_stand = train_data - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVOoNOvm0Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_stand = test_data - mean\n",
        "test_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00VohsAyokpq",
        "colab_type": "text"
      },
      "source": [
        "##Vettorizzare i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvS_9ISpxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={'adenocarcinoma':0, 'large cell':1, 'squamous cell carcinoma':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPW9U0XrWY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_dec = [word_index[label] for label in train_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4SBiKFQsKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels_dec = [word_index[label] for label in test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMbTYR7okJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "9bf9f8a5-2dcf-473f-f441-72bace966396"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Frv4FDNn6Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels_dec)\n",
        "one_hot_test_labels = to_categorical(test_labels_dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn0tkOGc3LKN",
        "colab_type": "text"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS76u6iu3Seg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjC4zqJ3bui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.85, svd_solver='full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLUCf9qX4p_e",
        "colab_type": "code",
        "outputId": "f1d98658-182d-4ad3-cf0f-47616ceca818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pca.fit(train_data_stand)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.85, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyaKgNZ44o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_pca = pca.transform(train_data_stand)\n",
        "test_data_stand_pca = pca.transform(test_data_stand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9C4nl05b_g",
        "colab_type": "code",
        "outputId": "bb924ef1-5fbb-497d-bd21-6bc75f561393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_stand_pca.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSKvSu4s5ip",
        "colab_type": "text"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osgm8ZvLpZh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTbHiq0D-4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAzbu7P1VylY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqbUCK5wOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KutkQ9Noj5mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hp):\n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "#  model.add(layers.Dense(units=(hp.Int('units', min_value=3, max_value=8, step=1)), \n",
        "#                         activation='relu', input_shape=(9,)))\n",
        " \n",
        "  drop_rate = hp.Choice('drop_rate', [0.0, 0.1, 0.2, 0.3,\n",
        "                              0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "\n",
        "  model.add(layers.Dense(4, activation='relu', input_shape=(7,)))\n",
        "  model.add(layers.Dropout(rate=drop_rate))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "#  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "#  lr = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "#  decay = hp.Choice('decay', [1e-4, 1e-5, 1e-6, 1e-7, 1e-8])\n",
        "#  momentum = hp.Choice('momentum', [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
        "  model.compile(optimizer=SGD(learning_rate=1e-3, momentum=0.5, decay=1e-6, nesterov=True), \n",
        "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1ZG40_dJtke",
        "colab_type": "text"
      },
      "source": [
        "##Prova Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABYrxmZxJdlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFCCTjE6JrQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_data_stand_pca, train_labels_dec,\n",
        "                                                    stratify=train_labels_dec,\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pus4JhTKWWB",
        "colab_type": "code",
        "outputId": "bddcfc50-628b-41d7-83d2-fe03a1c74189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.count(2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yP9-PE1Wjz-",
        "colab_type": "text"
      },
      "source": [
        "#Keras tuner RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "78f7dc1d-2aed-4198-a62c-c5ce0a877a87",
        "id": "oHDM8LE39gTU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 50\n",
        "  \n",
        "one_hot_partial_train_targets = to_categorical(y_train)\n",
        "one_hot_val_targets = to_categorical(y_val)\n",
        "\n",
        "tuner = RandomSearch(build_model, objective='val_acc', max_trials=10, \n",
        "                       executions_per_trial=5, directory='/content/my_dir', project_name='RandomSearch')\n",
        "  \n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(X_train, one_hot_partial_train_targets, validation_data=(X_val, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=5)\n",
        "  \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">drop_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 2ms/sample - loss: 1.6270 - acc: 0.4615 - val_loss: 2.1536 - val_acc: 0.4074\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.5215 - acc: 0.4615 - val_loss: 1.9634 - val_acc: 0.4074\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.4337 - acc: 0.4615 - val_loss: 1.8087 - val_acc: 0.4074\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.3613 - acc: 0.4423 - val_loss: 1.6704 - val_acc: 0.4074\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.3016 - acc: 0.4519 - val_loss: 1.5604 - val_acc: 0.4074\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.2530 - acc: 0.4615 - val_loss: 1.4682 - val_acc: 0.4074\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.2157 - acc: 0.4519 - val_loss: 1.3960 - val_acc: 0.4074\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1831 - acc: 0.4519 - val_loss: 1.3348 - val_acc: 0.4074\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1578 - acc: 0.4615 - val_loss: 1.2859 - val_acc: 0.4074\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1364 - acc: 0.4423 - val_loss: 1.2455 - val_acc: 0.4074\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1190 - acc: 0.4615 - val_loss: 1.2096 - val_acc: 0.4074\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1029 - acc: 0.4615 - val_loss: 1.1818 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0908 - acc: 0.4615 - val_loss: 1.1583 - val_acc: 0.4074\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0796 - acc: 0.4808 - val_loss: 1.1374 - val_acc: 0.4074\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0704 - acc: 0.4808 - val_loss: 1.1211 - val_acc: 0.4074\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0617 - acc: 0.4808 - val_loss: 1.1057 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 1.0538 - acc: 0.4808 - val_loss: 1.0938 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0474 - acc: 0.4615 - val_loss: 1.0818 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0403 - acc: 0.4808 - val_loss: 1.0709 - val_acc: 0.4074\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0351 - acc: 0.4904 - val_loss: 1.0621 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0304 - acc: 0.5000 - val_loss: 1.0533 - val_acc: 0.4074\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0259 - acc: 0.5000 - val_loss: 1.0463 - val_acc: 0.4074\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0208 - acc: 0.5000 - val_loss: 1.0399 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0169 - acc: 0.4904 - val_loss: 1.0350 - val_acc: 0.4074\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0127 - acc: 0.4904 - val_loss: 1.0295 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0090 - acc: 0.4904 - val_loss: 1.0245 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0061 - acc: 0.4808 - val_loss: 1.0206 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0032 - acc: 0.4615 - val_loss: 1.0176 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0000 - acc: 0.4808 - val_loss: 1.0135 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9968 - acc: 0.4712 - val_loss: 1.0106 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9950 - acc: 0.4712 - val_loss: 1.0071 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9924 - acc: 0.4712 - val_loss: 1.0054 - val_acc: 0.4074\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9905 - acc: 0.4808 - val_loss: 1.0042 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 448us/sample - loss: 0.9874 - acc: 0.4712 - val_loss: 1.0015 - val_acc: 0.4444\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9851 - acc: 0.4712 - val_loss: 0.9985 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9834 - acc: 0.4712 - val_loss: 0.9970 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9821 - acc: 0.4712 - val_loss: 0.9957 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9793 - acc: 0.4712 - val_loss: 0.9935 - val_acc: 0.4444\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9769 - acc: 0.4808 - val_loss: 0.9929 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9749 - acc: 0.4808 - val_loss: 0.9926 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 0.9735 - acc: 0.4808 - val_loss: 0.9923 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9719 - acc: 0.4712 - val_loss: 0.9919 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9703 - acc: 0.4808 - val_loss: 0.9919 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9694 - acc: 0.4712 - val_loss: 0.9909 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9663 - acc: 0.4712 - val_loss: 0.9897 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9652 - acc: 0.4808 - val_loss: 0.9893 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9641 - acc: 0.4712 - val_loss: 0.9886 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9623 - acc: 0.4712 - val_loss: 0.9874 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9604 - acc: 0.4712 - val_loss: 0.9866 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9596 - acc: 0.4712 - val_loss: 0.9867 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 843us/sample - loss: 1.3795 - acc: 0.3942 - val_loss: 1.6230 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.3153 - acc: 0.4038 - val_loss: 1.5539 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2640 - acc: 0.4038 - val_loss: 1.4947 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2235 - acc: 0.4038 - val_loss: 1.4477 - val_acc: 0.3704\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1883 - acc: 0.3942 - val_loss: 1.4086 - val_acc: 0.3704\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.1612 - acc: 0.4135 - val_loss: 1.3770 - val_acc: 0.3704\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.1366 - acc: 0.4231 - val_loss: 1.3513 - val_acc: 0.3704\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1164 - acc: 0.4135 - val_loss: 1.3290 - val_acc: 0.3704\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0978 - acc: 0.4135 - val_loss: 1.3077 - val_acc: 0.3704\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0832 - acc: 0.4327 - val_loss: 1.2910 - val_acc: 0.3704\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0700 - acc: 0.4423 - val_loss: 1.2750 - val_acc: 0.3704\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.0571 - acc: 0.4519 - val_loss: 1.2609 - val_acc: 0.3704\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0468 - acc: 0.4519 - val_loss: 1.2504 - val_acc: 0.3704\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0374 - acc: 0.4519 - val_loss: 1.2401 - val_acc: 0.3704\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0277 - acc: 0.4519 - val_loss: 1.2303 - val_acc: 0.3704\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0211 - acc: 0.5000 - val_loss: 1.2212 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0138 - acc: 0.5192 - val_loss: 1.2124 - val_acc: 0.4444\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0068 - acc: 0.5000 - val_loss: 1.2055 - val_acc: 0.4444\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0020 - acc: 0.5096 - val_loss: 1.1987 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9961 - acc: 0.5096 - val_loss: 1.1923 - val_acc: 0.4444\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 0.9906 - acc: 0.5000 - val_loss: 1.1857 - val_acc: 0.4444\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9865 - acc: 0.5288 - val_loss: 1.1803 - val_acc: 0.4444\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9825 - acc: 0.5192 - val_loss: 1.1754 - val_acc: 0.4444\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9781 - acc: 0.5288 - val_loss: 1.1709 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9747 - acc: 0.5096 - val_loss: 1.1671 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9715 - acc: 0.5288 - val_loss: 1.1630 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9683 - acc: 0.5192 - val_loss: 1.1586 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9646 - acc: 0.5192 - val_loss: 1.1551 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 686us/sample - loss: 0.9626 - acc: 0.5385 - val_loss: 1.1524 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9601 - acc: 0.5577 - val_loss: 1.1489 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 0.9567 - acc: 0.5769 - val_loss: 1.1451 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9542 - acc: 0.5769 - val_loss: 1.1422 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9524 - acc: 0.5769 - val_loss: 1.1396 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9511 - acc: 0.5962 - val_loss: 1.1384 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9478 - acc: 0.5962 - val_loss: 1.1352 - val_acc: 0.4074\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9461 - acc: 0.5962 - val_loss: 1.1325 - val_acc: 0.4074\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 0.9442 - acc: 0.5865 - val_loss: 1.1305 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9429 - acc: 0.6154 - val_loss: 1.1290 - val_acc: 0.4444\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9410 - acc: 0.5962 - val_loss: 1.1281 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9389 - acc: 0.6154 - val_loss: 1.1256 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 485us/sample - loss: 0.9387 - acc: 0.5962 - val_loss: 1.1241 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9362 - acc: 0.5962 - val_loss: 1.1221 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 0.9350 - acc: 0.5962 - val_loss: 1.1205 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9335 - acc: 0.5962 - val_loss: 1.1183 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 0.9330 - acc: 0.5962 - val_loss: 1.1170 - val_acc: 0.5185\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9307 - acc: 0.5962 - val_loss: 1.1152 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9296 - acc: 0.5962 - val_loss: 1.1140 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9284 - acc: 0.5865 - val_loss: 1.1126 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 283us/sample - loss: 0.9269 - acc: 0.5865 - val_loss: 1.1118 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9271 - acc: 0.5865 - val_loss: 1.1118 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 980us/sample - loss: 3.0253 - acc: 0.3558 - val_loss: 2.5641 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 2.5781 - acc: 0.3558 - val_loss: 2.2434 - val_acc: 0.4074\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 2.2297 - acc: 0.3558 - val_loss: 2.0041 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.9582 - acc: 0.3558 - val_loss: 1.8309 - val_acc: 0.2963\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.7501 - acc: 0.3654 - val_loss: 1.7254 - val_acc: 0.2963\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.6040 - acc: 0.3654 - val_loss: 1.6560 - val_acc: 0.2963\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.4966 - acc: 0.3558 - val_loss: 1.5968 - val_acc: 0.2963\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.4211 - acc: 0.3558 - val_loss: 1.5412 - val_acc: 0.2963\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.3610 - acc: 0.3269 - val_loss: 1.4987 - val_acc: 0.2593\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 431us/sample - loss: 1.3164 - acc: 0.3173 - val_loss: 1.4532 - val_acc: 0.2963\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2733 - acc: 0.3750 - val_loss: 1.4155 - val_acc: 0.2963\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.2440 - acc: 0.3558 - val_loss: 1.3856 - val_acc: 0.2963\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.2168 - acc: 0.4038 - val_loss: 1.3621 - val_acc: 0.3333\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1922 - acc: 0.3846 - val_loss: 1.3414 - val_acc: 0.3333\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1724 - acc: 0.3750 - val_loss: 1.3243 - val_acc: 0.3333\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1533 - acc: 0.3750 - val_loss: 1.3080 - val_acc: 0.2963\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1350 - acc: 0.4038 - val_loss: 1.2930 - val_acc: 0.3704\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.1233 - acc: 0.4135 - val_loss: 1.2758 - val_acc: 0.3704\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.1118 - acc: 0.4135 - val_loss: 1.2587 - val_acc: 0.4074\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0997 - acc: 0.4231 - val_loss: 1.2437 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0899 - acc: 0.3846 - val_loss: 1.2328 - val_acc: 0.4444\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0799 - acc: 0.4038 - val_loss: 1.2240 - val_acc: 0.4444\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0721 - acc: 0.4038 - val_loss: 1.2137 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0646 - acc: 0.4231 - val_loss: 1.2078 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0591 - acc: 0.4231 - val_loss: 1.2042 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0499 - acc: 0.4327 - val_loss: 1.1970 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0428 - acc: 0.4519 - val_loss: 1.1885 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0386 - acc: 0.4231 - val_loss: 1.1848 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 389us/sample - loss: 1.0348 - acc: 0.4135 - val_loss: 1.1829 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 1.0287 - acc: 0.4327 - val_loss: 1.1703 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0243 - acc: 0.4135 - val_loss: 1.1642 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0196 - acc: 0.4423 - val_loss: 1.1535 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0157 - acc: 0.3942 - val_loss: 1.1491 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0111 - acc: 0.4423 - val_loss: 1.1432 - val_acc: 0.4444\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0086 - acc: 0.4135 - val_loss: 1.1392 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0037 - acc: 0.4423 - val_loss: 1.1349 - val_acc: 0.4074\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0016 - acc: 0.4327 - val_loss: 1.1327 - val_acc: 0.4074\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9970 - acc: 0.4615 - val_loss: 1.1280 - val_acc: 0.4074\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9959 - acc: 0.4327 - val_loss: 1.1248 - val_acc: 0.3704\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9943 - acc: 0.4519 - val_loss: 1.1185 - val_acc: 0.4074\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9901 - acc: 0.4808 - val_loss: 1.1128 - val_acc: 0.4074\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9883 - acc: 0.4904 - val_loss: 1.1107 - val_acc: 0.4074\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9862 - acc: 0.4808 - val_loss: 1.1112 - val_acc: 0.4074\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9829 - acc: 0.4904 - val_loss: 1.1108 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9813 - acc: 0.5096 - val_loss: 1.1091 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9783 - acc: 0.5192 - val_loss: 1.1047 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9768 - acc: 0.5192 - val_loss: 1.1016 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9756 - acc: 0.5000 - val_loss: 1.1014 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9753 - acc: 0.5192 - val_loss: 1.0998 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9742 - acc: 0.5000 - val_loss: 1.1017 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 973us/sample - loss: 2.8641 - acc: 0.2019 - val_loss: 2.5327 - val_acc: 0.2222\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 2.3588 - acc: 0.2308 - val_loss: 2.1547 - val_acc: 0.2222\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.9901 - acc: 0.2404 - val_loss: 1.8777 - val_acc: 0.2963\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.7239 - acc: 0.2500 - val_loss: 1.6801 - val_acc: 0.3333\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.5188 - acc: 0.3077 - val_loss: 1.5401 - val_acc: 0.3704\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.3787 - acc: 0.3173 - val_loss: 1.4393 - val_acc: 0.3704\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2810 - acc: 0.3558 - val_loss: 1.3646 - val_acc: 0.4074\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2149 - acc: 0.3750 - val_loss: 1.3077 - val_acc: 0.4444\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1648 - acc: 0.3846 - val_loss: 1.2627 - val_acc: 0.4815\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.1273 - acc: 0.4423 - val_loss: 1.2269 - val_acc: 0.5185\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0986 - acc: 0.4519 - val_loss: 1.1975 - val_acc: 0.5185\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0752 - acc: 0.4615 - val_loss: 1.1734 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0588 - acc: 0.5000 - val_loss: 1.1537 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0434 - acc: 0.5000 - val_loss: 1.1368 - val_acc: 0.5185\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0311 - acc: 0.5000 - val_loss: 1.1223 - val_acc: 0.5185\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0210 - acc: 0.5192 - val_loss: 1.1101 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 654us/sample - loss: 1.0129 - acc: 0.5192 - val_loss: 1.0995 - val_acc: 0.5556\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0052 - acc: 0.5192 - val_loss: 1.0913 - val_acc: 0.5556\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9999 - acc: 0.5192 - val_loss: 1.0834 - val_acc: 0.5556\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 290us/sample - loss: 0.9944 - acc: 0.5192 - val_loss: 1.0765 - val_acc: 0.5556\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9896 - acc: 0.5192 - val_loss: 1.0711 - val_acc: 0.5556\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9851 - acc: 0.5385 - val_loss: 1.0661 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9818 - acc: 0.5385 - val_loss: 1.0620 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9787 - acc: 0.5288 - val_loss: 1.0581 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9750 - acc: 0.5481 - val_loss: 1.0551 - val_acc: 0.5185\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9723 - acc: 0.5385 - val_loss: 1.0527 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9705 - acc: 0.5673 - val_loss: 1.0505 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9676 - acc: 0.5673 - val_loss: 1.0477 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9664 - acc: 0.5577 - val_loss: 1.0458 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9639 - acc: 0.5673 - val_loss: 1.0439 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9621 - acc: 0.5481 - val_loss: 1.0425 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9607 - acc: 0.5577 - val_loss: 1.0404 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9592 - acc: 0.5481 - val_loss: 1.0396 - val_acc: 0.5556\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9566 - acc: 0.5577 - val_loss: 1.0384 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 0.9558 - acc: 0.5577 - val_loss: 1.0376 - val_acc: 0.5556\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9546 - acc: 0.5769 - val_loss: 1.0370 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9526 - acc: 0.5769 - val_loss: 1.0364 - val_acc: 0.5556\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9524 - acc: 0.5865 - val_loss: 1.0353 - val_acc: 0.5556\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9508 - acc: 0.5769 - val_loss: 1.0355 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 285us/sample - loss: 0.9503 - acc: 0.5673 - val_loss: 1.0343 - val_acc: 0.5556\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9482 - acc: 0.5673 - val_loss: 1.0343 - val_acc: 0.5556\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9475 - acc: 0.5769 - val_loss: 1.0333 - val_acc: 0.5556\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9464 - acc: 0.5673 - val_loss: 1.0329 - val_acc: 0.5556\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9455 - acc: 0.5769 - val_loss: 1.0322 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9444 - acc: 0.5769 - val_loss: 1.0320 - val_acc: 0.5556\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9442 - acc: 0.5769 - val_loss: 1.0320 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9425 - acc: 0.5769 - val_loss: 1.0315 - val_acc: 0.5556\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9421 - acc: 0.5673 - val_loss: 1.0313 - val_acc: 0.5556\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9417 - acc: 0.5769 - val_loss: 1.0309 - val_acc: 0.5556\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9413 - acc: 0.5865 - val_loss: 1.0307 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 944us/sample - loss: 1.7070 - acc: 0.5288 - val_loss: 2.7615 - val_acc: 0.4074\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 1.6015 - acc: 0.5288 - val_loss: 2.5672 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.5092 - acc: 0.5192 - val_loss: 2.4075 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.4362 - acc: 0.5192 - val_loss: 2.2776 - val_acc: 0.3704\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.3755 - acc: 0.5096 - val_loss: 2.1709 - val_acc: 0.3704\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.3260 - acc: 0.5192 - val_loss: 2.0728 - val_acc: 0.3704\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.2833 - acc: 0.5192 - val_loss: 1.9839 - val_acc: 0.4074\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2492 - acc: 0.5000 - val_loss: 1.9153 - val_acc: 0.4074\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.2184 - acc: 0.5096 - val_loss: 1.8552 - val_acc: 0.4074\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1936 - acc: 0.5000 - val_loss: 1.8044 - val_acc: 0.4074\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.1713 - acc: 0.5192 - val_loss: 1.7538 - val_acc: 0.4074\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.1538 - acc: 0.5096 - val_loss: 1.7088 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.1375 - acc: 0.5096 - val_loss: 1.6730 - val_acc: 0.4074\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.1230 - acc: 0.5096 - val_loss: 1.6416 - val_acc: 0.4074\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 285us/sample - loss: 1.1119 - acc: 0.5096 - val_loss: 1.6144 - val_acc: 0.4074\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1001 - acc: 0.5096 - val_loss: 1.5897 - val_acc: 0.3704\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 1.0868 - acc: 0.5096 - val_loss: 1.5634 - val_acc: 0.3704\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.0754 - acc: 0.5096 - val_loss: 1.5355 - val_acc: 0.3704\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0646 - acc: 0.5096 - val_loss: 1.5054 - val_acc: 0.3704\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0523 - acc: 0.5096 - val_loss: 1.4805 - val_acc: 0.3704\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0416 - acc: 0.5288 - val_loss: 1.4587 - val_acc: 0.3704\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0318 - acc: 0.5288 - val_loss: 1.4351 - val_acc: 0.3704\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0255 - acc: 0.5288 - val_loss: 1.4133 - val_acc: 0.3704\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0179 - acc: 0.5096 - val_loss: 1.4031 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0097 - acc: 0.5288 - val_loss: 1.3875 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 1.0024 - acc: 0.5385 - val_loss: 1.3721 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9966 - acc: 0.5481 - val_loss: 1.3609 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9913 - acc: 0.5577 - val_loss: 1.3538 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9856 - acc: 0.5481 - val_loss: 1.3491 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9803 - acc: 0.5481 - val_loss: 1.3391 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9760 - acc: 0.5673 - val_loss: 1.3258 - val_acc: 0.5185\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9709 - acc: 0.5481 - val_loss: 1.3146 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9671 - acc: 0.5577 - val_loss: 1.3080 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9628 - acc: 0.5673 - val_loss: 1.2973 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9583 - acc: 0.5673 - val_loss: 1.2883 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9569 - acc: 0.5577 - val_loss: 1.2856 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9524 - acc: 0.5673 - val_loss: 1.2711 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9475 - acc: 0.5673 - val_loss: 1.2610 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9443 - acc: 0.5673 - val_loss: 1.2581 - val_acc: 0.5185\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9414 - acc: 0.5673 - val_loss: 1.2485 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 0.9393 - acc: 0.5673 - val_loss: 1.2408 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9361 - acc: 0.5673 - val_loss: 1.2374 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 281us/sample - loss: 0.9336 - acc: 0.5673 - val_loss: 1.2344 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9310 - acc: 0.5769 - val_loss: 1.2338 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9297 - acc: 0.5673 - val_loss: 1.2285 - val_acc: 0.5185\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 0.9276 - acc: 0.5673 - val_loss: 1.2245 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9260 - acc: 0.5673 - val_loss: 1.2221 - val_acc: 0.5556\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9251 - acc: 0.5769 - val_loss: 1.2182 - val_acc: 0.5556\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 286us/sample - loss: 0.9228 - acc: 0.5769 - val_loss: 1.2159 - val_acc: 0.5556\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9225 - acc: 0.5769 - val_loss: 1.2092 - val_acc: 0.5556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9009ac92b32ab7f939a324b675bfb380</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5037037134170532</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 2ms/sample - loss: 2.8552 - acc: 0.2788 - val_loss: 1.7182 - val_acc: 0.1852\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.9003 - acc: 0.3269 - val_loss: 1.6228 - val_acc: 0.1852\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 2.1885 - acc: 0.2981 - val_loss: 1.5146 - val_acc: 0.1852\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.6226 - acc: 0.4135 - val_loss: 1.4659 - val_acc: 0.2222\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.6797 - acc: 0.4231 - val_loss: 1.4268 - val_acc: 0.2222\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.7799 - acc: 0.4038 - val_loss: 1.3727 - val_acc: 0.2593\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 1.7203 - acc: 0.4038 - val_loss: 1.3378 - val_acc: 0.3333\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.9137 - acc: 0.4038 - val_loss: 1.3005 - val_acc: 0.3333\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.9175 - acc: 0.4327 - val_loss: 1.2751 - val_acc: 0.3333\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.4243 - acc: 0.4615 - val_loss: 1.2572 - val_acc: 0.2963\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.5510 - acc: 0.4519 - val_loss: 1.2274 - val_acc: 0.2963\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.2763 - acc: 0.4904 - val_loss: 1.2114 - val_acc: 0.2963\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.3133 - acc: 0.5000 - val_loss: 1.1983 - val_acc: 0.2963\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.4963 - acc: 0.5192 - val_loss: 1.1806 - val_acc: 0.3333\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.2582 - acc: 0.4519 - val_loss: 1.1637 - val_acc: 0.3333\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.4371 - acc: 0.4231 - val_loss: 1.1543 - val_acc: 0.3704\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.2659 - acc: 0.4519 - val_loss: 1.1542 - val_acc: 0.3704\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.2420 - acc: 0.5000 - val_loss: 1.1433 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.3022 - acc: 0.4808 - val_loss: 1.1291 - val_acc: 0.3704\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.3480 - acc: 0.4904 - val_loss: 1.1181 - val_acc: 0.4444\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1215 - acc: 0.4712 - val_loss: 1.0989 - val_acc: 0.4074\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 1.3185 - acc: 0.4038 - val_loss: 1.0834 - val_acc: 0.3704\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.3429 - acc: 0.5000 - val_loss: 1.0730 - val_acc: 0.4444\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.2986 - acc: 0.5481 - val_loss: 1.0707 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 416us/sample - loss: 1.1383 - acc: 0.4808 - val_loss: 1.0703 - val_acc: 0.4815\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.0382 - acc: 0.5192 - val_loss: 1.0672 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.3268 - acc: 0.4615 - val_loss: 1.0468 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.3593 - acc: 0.4423 - val_loss: 1.0322 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0819 - acc: 0.4904 - val_loss: 1.0206 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.1020 - acc: 0.4808 - val_loss: 1.0178 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.2074 - acc: 0.4519 - val_loss: 1.0202 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1579 - acc: 0.4712 - val_loss: 1.0137 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0538 - acc: 0.4808 - val_loss: 1.0095 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1508 - acc: 0.4808 - val_loss: 1.0019 - val_acc: 0.4444\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.0548 - acc: 0.4904 - val_loss: 0.9950 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2422 - acc: 0.4904 - val_loss: 0.9959 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0890 - acc: 0.5096 - val_loss: 0.9919 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 1.0735 - acc: 0.4904 - val_loss: 0.9898 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 1.0246 - acc: 0.5000 - val_loss: 0.9891 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 422us/sample - loss: 1.1380 - acc: 0.4423 - val_loss: 0.9895 - val_acc: 0.5556\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 484us/sample - loss: 0.9894 - acc: 0.5096 - val_loss: 0.9840 - val_acc: 0.5556\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 1.1031 - acc: 0.5096 - val_loss: 0.9875 - val_acc: 0.5556\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0203 - acc: 0.5000 - val_loss: 0.9818 - val_acc: 0.5556\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0788 - acc: 0.5288 - val_loss: 0.9758 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0264 - acc: 0.4519 - val_loss: 0.9783 - val_acc: 0.5926\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.2286 - acc: 0.4231 - val_loss: 0.9831 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0273 - acc: 0.4808 - val_loss: 0.9833 - val_acc: 0.5556\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0272 - acc: 0.4327 - val_loss: 0.9845 - val_acc: 0.5556\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9673 - acc: 0.4904 - val_loss: 0.9786 - val_acc: 0.5926\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0962 - acc: 0.5000 - val_loss: 0.9749 - val_acc: 0.5926\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.4915 - acc: 0.3654 - val_loss: 2.3351 - val_acc: 0.2222\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 3.2013 - acc: 0.2500 - val_loss: 2.0340 - val_acc: 0.2222\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 2.5174 - acc: 0.3654 - val_loss: 1.8391 - val_acc: 0.2222\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 2.2112 - acc: 0.3077 - val_loss: 1.6958 - val_acc: 0.2222\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 2.1622 - acc: 0.3365 - val_loss: 1.5358 - val_acc: 0.2222\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.8374 - acc: 0.3558 - val_loss: 1.4393 - val_acc: 0.1852\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.5504 - acc: 0.4615 - val_loss: 1.3949 - val_acc: 0.1852\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.5960 - acc: 0.4519 - val_loss: 1.3264 - val_acc: 0.2222\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.7480 - acc: 0.3942 - val_loss: 1.2705 - val_acc: 0.2222\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.6518 - acc: 0.3942 - val_loss: 1.2289 - val_acc: 0.2222\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.7668 - acc: 0.3173 - val_loss: 1.2072 - val_acc: 0.2593\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.4141 - acc: 0.4038 - val_loss: 1.2079 - val_acc: 0.2593\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 1.6174 - acc: 0.4327 - val_loss: 1.1893 - val_acc: 0.2963\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.4944 - acc: 0.4615 - val_loss: 1.1804 - val_acc: 0.3704\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.3912 - acc: 0.4423 - val_loss: 1.1694 - val_acc: 0.3704\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.4066 - acc: 0.3942 - val_loss: 1.1390 - val_acc: 0.3704\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.5541 - acc: 0.4231 - val_loss: 1.1278 - val_acc: 0.3704\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.3534 - acc: 0.4423 - val_loss: 1.1060 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 1.2269 - acc: 0.5288 - val_loss: 1.0924 - val_acc: 0.4074\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.3434 - acc: 0.4423 - val_loss: 1.0905 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.4075 - acc: 0.4615 - val_loss: 1.0883 - val_acc: 0.4074\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.2208 - acc: 0.4904 - val_loss: 1.0907 - val_acc: 0.4074\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.1448 - acc: 0.4519 - val_loss: 1.0987 - val_acc: 0.3704\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0972 - acc: 0.4615 - val_loss: 1.0905 - val_acc: 0.4815\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.2048 - acc: 0.3750 - val_loss: 1.0816 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.4651 - acc: 0.4423 - val_loss: 1.0705 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1058 - acc: 0.5000 - val_loss: 1.0713 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.1225 - acc: 0.5673 - val_loss: 1.0662 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.2031 - acc: 0.4808 - val_loss: 1.0719 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0683 - acc: 0.5481 - val_loss: 1.0773 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.2082 - acc: 0.4423 - val_loss: 1.0721 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1586 - acc: 0.4712 - val_loss: 1.0758 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9912 - acc: 0.5288 - val_loss: 1.0734 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1281 - acc: 0.4904 - val_loss: 1.0675 - val_acc: 0.4444\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0078 - acc: 0.5192 - val_loss: 1.0652 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2050 - acc: 0.5000 - val_loss: 1.0570 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0443 - acc: 0.5288 - val_loss: 1.0533 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0794 - acc: 0.4519 - val_loss: 1.0422 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0125 - acc: 0.5481 - val_loss: 1.0390 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1062 - acc: 0.5385 - val_loss: 1.0426 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1151 - acc: 0.5288 - val_loss: 1.0384 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0620 - acc: 0.5288 - val_loss: 1.0385 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0727 - acc: 0.5192 - val_loss: 1.0336 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9606 - acc: 0.5577 - val_loss: 1.0336 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0036 - acc: 0.4519 - val_loss: 1.0327 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1098 - acc: 0.4904 - val_loss: 1.0358 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1504 - acc: 0.4712 - val_loss: 1.0459 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0983 - acc: 0.4327 - val_loss: 1.0442 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0384 - acc: 0.5000 - val_loss: 1.0353 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9844 - acc: 0.5865 - val_loss: 1.0326 - val_acc: 0.4815\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 989us/sample - loss: 2.9556 - acc: 0.4519 - val_loss: 1.5593 - val_acc: 0.5926\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 2.0316 - acc: 0.5288 - val_loss: 1.4889 - val_acc: 0.5926\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.9758 - acc: 0.4615 - val_loss: 1.3564 - val_acc: 0.5926\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 2.4251 - acc: 0.4808 - val_loss: 1.2483 - val_acc: 0.5926\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.8964 - acc: 0.5000 - val_loss: 1.1219 - val_acc: 0.5185\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.9839 - acc: 0.5000 - val_loss: 1.1081 - val_acc: 0.5556\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 2.1078 - acc: 0.4615 - val_loss: 1.0291 - val_acc: 0.5926\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 738us/sample - loss: 1.5772 - acc: 0.4231 - val_loss: 0.9996 - val_acc: 0.6296\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.5226 - acc: 0.4615 - val_loss: 0.9828 - val_acc: 0.5926\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.7139 - acc: 0.4423 - val_loss: 0.9717 - val_acc: 0.6296\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.6173 - acc: 0.4808 - val_loss: 0.9486 - val_acc: 0.6296\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.2384 - acc: 0.4904 - val_loss: 0.9504 - val_acc: 0.6296\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 420us/sample - loss: 1.2004 - acc: 0.4808 - val_loss: 0.9450 - val_acc: 0.6667\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.2528 - acc: 0.5577 - val_loss: 0.9487 - val_acc: 0.6296\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 389us/sample - loss: 1.2491 - acc: 0.5288 - val_loss: 0.9475 - val_acc: 0.6667\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.3521 - acc: 0.5096 - val_loss: 0.9540 - val_acc: 0.6296\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.2643 - acc: 0.4808 - val_loss: 0.9509 - val_acc: 0.6296\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.1914 - acc: 0.4904 - val_loss: 0.9720 - val_acc: 0.5926\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.1830 - acc: 0.5288 - val_loss: 0.9695 - val_acc: 0.6296\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1999 - acc: 0.5192 - val_loss: 0.9702 - val_acc: 0.6296\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 1.3923 - acc: 0.5000 - val_loss: 0.9641 - val_acc: 0.6296\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0545 - acc: 0.5000 - val_loss: 0.9698 - val_acc: 0.6296\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.1767 - acc: 0.5192 - val_loss: 0.9714 - val_acc: 0.5926\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1886 - acc: 0.4808 - val_loss: 0.9827 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.2164 - acc: 0.4615 - val_loss: 0.9850 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0730 - acc: 0.5096 - val_loss: 0.9846 - val_acc: 0.5556\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.1929 - acc: 0.4904 - val_loss: 0.9850 - val_acc: 0.5556\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.1743 - acc: 0.4712 - val_loss: 0.9959 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0282 - acc: 0.5192 - val_loss: 1.0032 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0802 - acc: 0.4808 - val_loss: 1.0100 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0789 - acc: 0.5288 - val_loss: 1.0061 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.1777 - acc: 0.5000 - val_loss: 1.0035 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0007 - acc: 0.4615 - val_loss: 1.0021 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0645 - acc: 0.5192 - val_loss: 1.0027 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0072 - acc: 0.5481 - val_loss: 0.9998 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0355 - acc: 0.5385 - val_loss: 1.0040 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0830 - acc: 0.5096 - val_loss: 1.0057 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.1271 - acc: 0.4904 - val_loss: 0.9984 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0988 - acc: 0.5288 - val_loss: 0.9992 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0966 - acc: 0.4519 - val_loss: 0.9921 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0148 - acc: 0.5096 - val_loss: 0.9982 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0113 - acc: 0.4904 - val_loss: 0.9964 - val_acc: 0.5556\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.1348 - acc: 0.5096 - val_loss: 0.9997 - val_acc: 0.5556\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0854 - acc: 0.5481 - val_loss: 0.9967 - val_acc: 0.5926\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0503 - acc: 0.5192 - val_loss: 0.9943 - val_acc: 0.5926\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0053 - acc: 0.4327 - val_loss: 0.9958 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0172 - acc: 0.5000 - val_loss: 0.9977 - val_acc: 0.5556\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1025 - acc: 0.4808 - val_loss: 0.9957 - val_acc: 0.5556\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0870 - acc: 0.4808 - val_loss: 0.9940 - val_acc: 0.5926\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0598 - acc: 0.4423 - val_loss: 0.9985 - val_acc: 0.5556\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.4454 - acc: 0.3173 - val_loss: 2.2790 - val_acc: 0.2593\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 3.0785 - acc: 0.3750 - val_loss: 1.9825 - val_acc: 0.2963\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 2.5713 - acc: 0.3558 - val_loss: 1.7666 - val_acc: 0.2963\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 2.0785 - acc: 0.2885 - val_loss: 1.6227 - val_acc: 0.2963\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 2.1251 - acc: 0.3558 - val_loss: 1.4803 - val_acc: 0.2963\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.7677 - acc: 0.3750 - val_loss: 1.4061 - val_acc: 0.2963\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.5156 - acc: 0.4423 - val_loss: 1.3535 - val_acc: 0.2963\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.7335 - acc: 0.3462 - val_loss: 1.2655 - val_acc: 0.2963\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.5013 - acc: 0.3654 - val_loss: 1.2165 - val_acc: 0.2963\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.5841 - acc: 0.3846 - val_loss: 1.1676 - val_acc: 0.2963\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.3366 - acc: 0.4231 - val_loss: 1.1447 - val_acc: 0.2963\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.3158 - acc: 0.3654 - val_loss: 1.1134 - val_acc: 0.2963\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.2533 - acc: 0.4231 - val_loss: 1.0948 - val_acc: 0.3333\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.2225 - acc: 0.4519 - val_loss: 1.0814 - val_acc: 0.3333\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.2823 - acc: 0.4231 - val_loss: 1.0734 - val_acc: 0.3704\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.2424 - acc: 0.2885 - val_loss: 1.0615 - val_acc: 0.3704\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.2968 - acc: 0.3077 - val_loss: 1.0522 - val_acc: 0.3333\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1587 - acc: 0.4231 - val_loss: 1.0453 - val_acc: 0.3333\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1418 - acc: 0.3942 - val_loss: 1.0377 - val_acc: 0.3333\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.1344 - acc: 0.4327 - val_loss: 1.0346 - val_acc: 0.3704\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.1563 - acc: 0.4231 - val_loss: 1.0296 - val_acc: 0.3704\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.0744 - acc: 0.4615 - val_loss: 1.0320 - val_acc: 0.3333\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1599 - acc: 0.3365 - val_loss: 1.0250 - val_acc: 0.3333\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0593 - acc: 0.4615 - val_loss: 1.0240 - val_acc: 0.3333\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0819 - acc: 0.4808 - val_loss: 1.0207 - val_acc: 0.3333\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0634 - acc: 0.4327 - val_loss: 1.0136 - val_acc: 0.3333\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0802 - acc: 0.4327 - val_loss: 1.0111 - val_acc: 0.4074\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0374 - acc: 0.4519 - val_loss: 1.0093 - val_acc: 0.3333\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0544 - acc: 0.4327 - val_loss: 1.0088 - val_acc: 0.4074\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0370 - acc: 0.4519 - val_loss: 1.0077 - val_acc: 0.3704\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0680 - acc: 0.3558 - val_loss: 1.0032 - val_acc: 0.3704\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0135 - acc: 0.4712 - val_loss: 1.0050 - val_acc: 0.3704\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0072 - acc: 0.4519 - val_loss: 1.0066 - val_acc: 0.3704\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0299 - acc: 0.4712 - val_loss: 1.0018 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9920 - acc: 0.4808 - val_loss: 1.0018 - val_acc: 0.4074\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.0210 - acc: 0.4038 - val_loss: 0.9996 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.0226 - acc: 0.4615 - val_loss: 0.9986 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0071 - acc: 0.4712 - val_loss: 0.9961 - val_acc: 0.4444\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0091 - acc: 0.4519 - val_loss: 0.9955 - val_acc: 0.4074\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0469 - acc: 0.3654 - val_loss: 0.9898 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9922 - acc: 0.5000 - val_loss: 0.9921 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0222 - acc: 0.3942 - val_loss: 0.9892 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0246 - acc: 0.3750 - val_loss: 0.9867 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0234 - acc: 0.3750 - val_loss: 0.9854 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9868 - acc: 0.4327 - val_loss: 0.9861 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0164 - acc: 0.4231 - val_loss: 0.9841 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0066 - acc: 0.4615 - val_loss: 0.9863 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0054 - acc: 0.4423 - val_loss: 0.9822 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9657 - acc: 0.5577 - val_loss: 0.9833 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9737 - acc: 0.4231 - val_loss: 0.9837 - val_acc: 0.4815\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.7373 - acc: 0.3654 - val_loss: 1.5849 - val_acc: 0.4444\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 2.8521 - acc: 0.3365 - val_loss: 1.3976 - val_acc: 0.4444\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 2.4387 - acc: 0.3750 - val_loss: 1.2893 - val_acc: 0.4074\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 2.0635 - acc: 0.4327 - val_loss: 1.1923 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.6382 - acc: 0.4327 - val_loss: 1.1481 - val_acc: 0.4815\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.7281 - acc: 0.4519 - val_loss: 1.1159 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.6275 - acc: 0.3654 - val_loss: 1.1072 - val_acc: 0.5185\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.6278 - acc: 0.4231 - val_loss: 1.1121 - val_acc: 0.5185\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.6110 - acc: 0.4135 - val_loss: 1.1072 - val_acc: 0.5185\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.4931 - acc: 0.4231 - val_loss: 1.0982 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.4653 - acc: 0.4423 - val_loss: 1.0858 - val_acc: 0.5185\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.2425 - acc: 0.4423 - val_loss: 1.0965 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.4062 - acc: 0.4519 - val_loss: 1.1046 - val_acc: 0.5185\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.4903 - acc: 0.4423 - val_loss: 1.1100 - val_acc: 0.5185\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.2791 - acc: 0.4519 - val_loss: 1.1068 - val_acc: 0.5185\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.4517 - acc: 0.4615 - val_loss: 1.0973 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0941 - acc: 0.4904 - val_loss: 1.1115 - val_acc: 0.5556\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.2865 - acc: 0.5096 - val_loss: 1.1175 - val_acc: 0.5185\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 429us/sample - loss: 1.4102 - acc: 0.4615 - val_loss: 1.1139 - val_acc: 0.5556\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.2984 - acc: 0.5000 - val_loss: 1.0995 - val_acc: 0.5556\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.2356 - acc: 0.4712 - val_loss: 1.0991 - val_acc: 0.5185\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1537 - acc: 0.4904 - val_loss: 1.1066 - val_acc: 0.5185\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.0836 - acc: 0.4615 - val_loss: 1.1130 - val_acc: 0.4815\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0933 - acc: 0.5096 - val_loss: 1.1089 - val_acc: 0.5185\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.2306 - acc: 0.4712 - val_loss: 1.1014 - val_acc: 0.4815\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.2199 - acc: 0.4231 - val_loss: 1.1002 - val_acc: 0.4815\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.1184 - acc: 0.4904 - val_loss: 1.0999 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.0730 - acc: 0.5000 - val_loss: 1.0987 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1676 - acc: 0.4712 - val_loss: 1.0835 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0522 - acc: 0.5096 - val_loss: 1.0854 - val_acc: 0.5556\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.1311 - acc: 0.4808 - val_loss: 1.0895 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0689 - acc: 0.5000 - val_loss: 1.0862 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 430us/sample - loss: 1.1369 - acc: 0.4519 - val_loss: 1.0961 - val_acc: 0.5556\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 499us/sample - loss: 1.0208 - acc: 0.5192 - val_loss: 1.0897 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1535 - acc: 0.4712 - val_loss: 1.0804 - val_acc: 0.5556\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0272 - acc: 0.5096 - val_loss: 1.0765 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1248 - acc: 0.4904 - val_loss: 1.0760 - val_acc: 0.5556\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 1.0776 - acc: 0.4712 - val_loss: 1.0852 - val_acc: 0.5556\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0467 - acc: 0.4904 - val_loss: 1.0791 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0844 - acc: 0.4808 - val_loss: 1.0843 - val_acc: 0.5556\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0403 - acc: 0.5288 - val_loss: 1.0813 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.1050 - acc: 0.5000 - val_loss: 1.0817 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1458 - acc: 0.3942 - val_loss: 1.0776 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0566 - acc: 0.4519 - val_loss: 1.0816 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0500 - acc: 0.4808 - val_loss: 1.0809 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0170 - acc: 0.4904 - val_loss: 1.0849 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0198 - acc: 0.4904 - val_loss: 1.0816 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0634 - acc: 0.4904 - val_loss: 1.0753 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0340 - acc: 0.4615 - val_loss: 1.0707 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0352 - acc: 0.4808 - val_loss: 1.0729 - val_acc: 0.4444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: fa0f3144dfb3afb61cf07370dfad5da3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5703703761100769</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.6</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.7877 - acc: 0.2981 - val_loss: 2.1142 - val_acc: 0.4074\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 2.3549 - acc: 0.2692 - val_loss: 1.8464 - val_acc: 0.4074\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 2.0866 - acc: 0.2788 - val_loss: 1.6605 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.8476 - acc: 0.3269 - val_loss: 1.5151 - val_acc: 0.3333\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.5360 - acc: 0.3365 - val_loss: 1.4311 - val_acc: 0.3333\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.4877 - acc: 0.2692 - val_loss: 1.3598 - val_acc: 0.3333\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.3766 - acc: 0.3750 - val_loss: 1.2817 - val_acc: 0.3333\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.3017 - acc: 0.3462 - val_loss: 1.2468 - val_acc: 0.3333\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.2571 - acc: 0.3077 - val_loss: 1.2104 - val_acc: 0.3333\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1935 - acc: 0.3654 - val_loss: 1.1851 - val_acc: 0.3704\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1329 - acc: 0.4231 - val_loss: 1.1929 - val_acc: 0.3704\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1004 - acc: 0.4808 - val_loss: 1.1870 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1262 - acc: 0.4327 - val_loss: 1.1844 - val_acc: 0.4074\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0903 - acc: 0.4904 - val_loss: 1.1861 - val_acc: 0.4074\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0233 - acc: 0.5385 - val_loss: 1.1944 - val_acc: 0.3704\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0722 - acc: 0.4519 - val_loss: 1.1704 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0709 - acc: 0.4615 - val_loss: 1.1582 - val_acc: 0.3704\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0000 - acc: 0.4808 - val_loss: 1.1494 - val_acc: 0.3704\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0326 - acc: 0.4712 - val_loss: 1.1216 - val_acc: 0.4074\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0108 - acc: 0.5385 - val_loss: 1.1329 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9969 - acc: 0.5192 - val_loss: 1.1448 - val_acc: 0.4074\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0761 - acc: 0.4519 - val_loss: 1.1496 - val_acc: 0.4074\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0151 - acc: 0.4423 - val_loss: 1.1543 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0131 - acc: 0.4519 - val_loss: 1.1338 - val_acc: 0.4074\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0073 - acc: 0.4808 - val_loss: 1.1172 - val_acc: 0.4074\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0339 - acc: 0.4423 - val_loss: 1.1078 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0036 - acc: 0.5288 - val_loss: 1.1165 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9788 - acc: 0.5096 - val_loss: 1.1232 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0079 - acc: 0.5000 - val_loss: 1.1117 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9717 - acc: 0.5577 - val_loss: 1.1116 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9993 - acc: 0.4808 - val_loss: 1.1035 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9578 - acc: 0.5481 - val_loss: 1.1020 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9327 - acc: 0.5577 - val_loss: 1.1190 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9746 - acc: 0.5096 - val_loss: 1.1144 - val_acc: 0.4444\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9306 - acc: 0.5385 - val_loss: 1.1216 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9708 - acc: 0.5192 - val_loss: 1.1046 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9835 - acc: 0.4615 - val_loss: 1.1072 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9339 - acc: 0.5385 - val_loss: 1.1021 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9923 - acc: 0.4615 - val_loss: 1.1056 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9574 - acc: 0.4904 - val_loss: 1.0913 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0234 - acc: 0.4423 - val_loss: 1.0941 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9057 - acc: 0.5769 - val_loss: 1.1001 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9478 - acc: 0.5288 - val_loss: 1.1027 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.8850 - acc: 0.5865 - val_loss: 1.1099 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9303 - acc: 0.5481 - val_loss: 1.1139 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9596 - acc: 0.5288 - val_loss: 1.1021 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0277 - acc: 0.4519 - val_loss: 1.0922 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9675 - acc: 0.5385 - val_loss: 1.0946 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9589 - acc: 0.5577 - val_loss: 1.1017 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9576 - acc: 0.5192 - val_loss: 1.1049 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 974us/sample - loss: 2.9119 - acc: 0.3365 - val_loss: 2.5701 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 2.5944 - acc: 0.3654 - val_loss: 2.4259 - val_acc: 0.3333\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 2.4268 - acc: 0.3750 - val_loss: 2.2473 - val_acc: 0.2963\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 2.1495 - acc: 0.3558 - val_loss: 2.1467 - val_acc: 0.2963\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 2.1535 - acc: 0.3269 - val_loss: 2.0435 - val_acc: 0.2963\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.8905 - acc: 0.4327 - val_loss: 1.9524 - val_acc: 0.3704\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 2.0929 - acc: 0.3750 - val_loss: 1.8656 - val_acc: 0.3704\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.9534 - acc: 0.3750 - val_loss: 1.7854 - val_acc: 0.3704\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.7655 - acc: 0.3654 - val_loss: 1.7390 - val_acc: 0.3704\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.6811 - acc: 0.4423 - val_loss: 1.6772 - val_acc: 0.3704\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.6597 - acc: 0.3942 - val_loss: 1.6205 - val_acc: 0.3704\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.5969 - acc: 0.3846 - val_loss: 1.5638 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.4923 - acc: 0.3558 - val_loss: 1.5195 - val_acc: 0.4074\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.4925 - acc: 0.3942 - val_loss: 1.4798 - val_acc: 0.4074\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.3589 - acc: 0.4519 - val_loss: 1.4459 - val_acc: 0.4074\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.3543 - acc: 0.4519 - val_loss: 1.4076 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 282us/sample - loss: 1.3875 - acc: 0.4038 - val_loss: 1.3839 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.3144 - acc: 0.4038 - val_loss: 1.3630 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.2681 - acc: 0.4135 - val_loss: 1.3419 - val_acc: 0.4074\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.3076 - acc: 0.4423 - val_loss: 1.3142 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.2763 - acc: 0.4135 - val_loss: 1.2862 - val_acc: 0.4074\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.2576 - acc: 0.5000 - val_loss: 1.2640 - val_acc: 0.4074\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1923 - acc: 0.4904 - val_loss: 1.2621 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1885 - acc: 0.4519 - val_loss: 1.2488 - val_acc: 0.4074\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0557 - acc: 0.4904 - val_loss: 1.2551 - val_acc: 0.4074\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1083 - acc: 0.4519 - val_loss: 1.2589 - val_acc: 0.4074\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1013 - acc: 0.5481 - val_loss: 1.2431 - val_acc: 0.4074\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1088 - acc: 0.5096 - val_loss: 1.2270 - val_acc: 0.4074\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1635 - acc: 0.4327 - val_loss: 1.2190 - val_acc: 0.4074\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1413 - acc: 0.4519 - val_loss: 1.2079 - val_acc: 0.4074\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1358 - acc: 0.5000 - val_loss: 1.2053 - val_acc: 0.4074\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0768 - acc: 0.5481 - val_loss: 1.1979 - val_acc: 0.4074\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0871 - acc: 0.5385 - val_loss: 1.1942 - val_acc: 0.4074\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0569 - acc: 0.5385 - val_loss: 1.1995 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0971 - acc: 0.5096 - val_loss: 1.1886 - val_acc: 0.4074\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0644 - acc: 0.5673 - val_loss: 1.1671 - val_acc: 0.4074\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.1044 - acc: 0.5192 - val_loss: 1.1552 - val_acc: 0.4074\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9967 - acc: 0.5962 - val_loss: 1.1500 - val_acc: 0.4074\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.0853 - acc: 0.5192 - val_loss: 1.1387 - val_acc: 0.4074\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0377 - acc: 0.5481 - val_loss: 1.1306 - val_acc: 0.4074\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0627 - acc: 0.5096 - val_loss: 1.1273 - val_acc: 0.4074\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0759 - acc: 0.5000 - val_loss: 1.1258 - val_acc: 0.4074\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0398 - acc: 0.5288 - val_loss: 1.1224 - val_acc: 0.4074\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0745 - acc: 0.5192 - val_loss: 1.1138 - val_acc: 0.4074\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0152 - acc: 0.5865 - val_loss: 1.1123 - val_acc: 0.4074\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 1.0498 - acc: 0.5096 - val_loss: 1.1080 - val_acc: 0.4074\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0392 - acc: 0.5577 - val_loss: 1.1009 - val_acc: 0.4074\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0439 - acc: 0.5288 - val_loss: 1.0983 - val_acc: 0.4074\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0075 - acc: 0.5673 - val_loss: 1.0929 - val_acc: 0.4074\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.0061 - acc: 0.5577 - val_loss: 1.0922 - val_acc: 0.4074\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.9749 - acc: 0.3365 - val_loss: 1.9141 - val_acc: 0.5556\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 434us/sample - loss: 1.7507 - acc: 0.4231 - val_loss: 1.8316 - val_acc: 0.5926\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 1.4270 - acc: 0.4423 - val_loss: 1.7879 - val_acc: 0.5926\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.6165 - acc: 0.4231 - val_loss: 1.7329 - val_acc: 0.5556\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.5359 - acc: 0.3942 - val_loss: 1.6873 - val_acc: 0.5556\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.5420 - acc: 0.3942 - val_loss: 1.6181 - val_acc: 0.5556\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.4242 - acc: 0.3654 - val_loss: 1.5855 - val_acc: 0.5556\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.3186 - acc: 0.4904 - val_loss: 1.5406 - val_acc: 0.5556\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.3971 - acc: 0.4712 - val_loss: 1.4997 - val_acc: 0.5556\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.2294 - acc: 0.4712 - val_loss: 1.4832 - val_acc: 0.5926\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.3079 - acc: 0.4615 - val_loss: 1.4680 - val_acc: 0.5926\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.1836 - acc: 0.4231 - val_loss: 1.4355 - val_acc: 0.5556\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 1.1407 - acc: 0.4712 - val_loss: 1.4286 - val_acc: 0.5556\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1284 - acc: 0.4327 - val_loss: 1.4104 - val_acc: 0.5556\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.2416 - acc: 0.3365 - val_loss: 1.4011 - val_acc: 0.5556\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1374 - acc: 0.4423 - val_loss: 1.3887 - val_acc: 0.5556\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2150 - acc: 0.4423 - val_loss: 1.3634 - val_acc: 0.5556\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0459 - acc: 0.4808 - val_loss: 1.3554 - val_acc: 0.5556\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1034 - acc: 0.4904 - val_loss: 1.3367 - val_acc: 0.5556\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1734 - acc: 0.3654 - val_loss: 1.3230 - val_acc: 0.5556\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0363 - acc: 0.4423 - val_loss: 1.3257 - val_acc: 0.5556\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1767 - acc: 0.3942 - val_loss: 1.3087 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0782 - acc: 0.4904 - val_loss: 1.2940 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0617 - acc: 0.4423 - val_loss: 1.2886 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0308 - acc: 0.4519 - val_loss: 1.2839 - val_acc: 0.5185\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0203 - acc: 0.4615 - val_loss: 1.2781 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0853 - acc: 0.4712 - val_loss: 1.2567 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0358 - acc: 0.4904 - val_loss: 1.2475 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0210 - acc: 0.4519 - val_loss: 1.2437 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0040 - acc: 0.5192 - val_loss: 1.2378 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0032 - acc: 0.5000 - val_loss: 1.2361 - val_acc: 0.5185\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0302 - acc: 0.5000 - val_loss: 1.2314 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0201 - acc: 0.4615 - val_loss: 1.2229 - val_acc: 0.5556\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9703 - acc: 0.5096 - val_loss: 1.2249 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9588 - acc: 0.5096 - val_loss: 1.2190 - val_acc: 0.5556\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9948 - acc: 0.4712 - val_loss: 1.2184 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 0.9277 - acc: 0.5288 - val_loss: 1.2140 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9685 - acc: 0.4904 - val_loss: 1.2147 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9684 - acc: 0.4615 - val_loss: 1.2117 - val_acc: 0.5185\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9579 - acc: 0.4808 - val_loss: 1.2017 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.8871 - acc: 0.5577 - val_loss: 1.2039 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9381 - acc: 0.5096 - val_loss: 1.1998 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0137 - acc: 0.5096 - val_loss: 1.1946 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9734 - acc: 0.4519 - val_loss: 1.1911 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0282 - acc: 0.4808 - val_loss: 1.1844 - val_acc: 0.5556\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9540 - acc: 0.5000 - val_loss: 1.1851 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9515 - acc: 0.5192 - val_loss: 1.1797 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0248 - acc: 0.5096 - val_loss: 1.1703 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9467 - acc: 0.5288 - val_loss: 1.1724 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0157 - acc: 0.4327 - val_loss: 1.1700 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 992us/sample - loss: 2.5264 - acc: 0.3365 - val_loss: 1.9586 - val_acc: 0.4074\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 2.1984 - acc: 0.3462 - val_loss: 1.7389 - val_acc: 0.4074\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 2.0205 - acc: 0.3173 - val_loss: 1.5593 - val_acc: 0.4815\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.6672 - acc: 0.3654 - val_loss: 1.4366 - val_acc: 0.4815\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.5310 - acc: 0.4038 - val_loss: 1.3847 - val_acc: 0.4815\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.4577 - acc: 0.3942 - val_loss: 1.3263 - val_acc: 0.4815\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.3058 - acc: 0.3654 - val_loss: 1.3086 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.3554 - acc: 0.3846 - val_loss: 1.2931 - val_acc: 0.5185\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.3581 - acc: 0.3365 - val_loss: 1.2705 - val_acc: 0.5185\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.2360 - acc: 0.3462 - val_loss: 1.2792 - val_acc: 0.5185\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.2906 - acc: 0.3558 - val_loss: 1.2666 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.2186 - acc: 0.4712 - val_loss: 1.2817 - val_acc: 0.4444\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.2060 - acc: 0.5000 - val_loss: 1.2795 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0837 - acc: 0.4615 - val_loss: 1.2681 - val_acc: 0.4444\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0818 - acc: 0.5096 - val_loss: 1.2630 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.2205 - acc: 0.5000 - val_loss: 1.2536 - val_acc: 0.4444\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1168 - acc: 0.4904 - val_loss: 1.2360 - val_acc: 0.4444\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1899 - acc: 0.4712 - val_loss: 1.2198 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0565 - acc: 0.4808 - val_loss: 1.2342 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0357 - acc: 0.5000 - val_loss: 1.2307 - val_acc: 0.4815\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1142 - acc: 0.4808 - val_loss: 1.2194 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1457 - acc: 0.4904 - val_loss: 1.2092 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1234 - acc: 0.4615 - val_loss: 1.2036 - val_acc: 0.5185\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.1440 - acc: 0.4712 - val_loss: 1.1913 - val_acc: 0.5185\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0788 - acc: 0.5096 - val_loss: 1.1862 - val_acc: 0.5185\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0847 - acc: 0.4808 - val_loss: 1.1781 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1057 - acc: 0.4808 - val_loss: 1.1651 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0301 - acc: 0.4519 - val_loss: 1.1693 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9892 - acc: 0.4904 - val_loss: 1.1763 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 597us/sample - loss: 1.1297 - acc: 0.4904 - val_loss: 1.1766 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0449 - acc: 0.4808 - val_loss: 1.1772 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0748 - acc: 0.4519 - val_loss: 1.1759 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0800 - acc: 0.4423 - val_loss: 1.1685 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0395 - acc: 0.5192 - val_loss: 1.1629 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0063 - acc: 0.5096 - val_loss: 1.1700 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0162 - acc: 0.5192 - val_loss: 1.1530 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0016 - acc: 0.4904 - val_loss: 1.1508 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9949 - acc: 0.5192 - val_loss: 1.1437 - val_acc: 0.4444\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0098 - acc: 0.5000 - val_loss: 1.1505 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0113 - acc: 0.4712 - val_loss: 1.1482 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9728 - acc: 0.4904 - val_loss: 1.1475 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9706 - acc: 0.4423 - val_loss: 1.1567 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0618 - acc: 0.4904 - val_loss: 1.1613 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9873 - acc: 0.5192 - val_loss: 1.1708 - val_acc: 0.4074\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.8988 - acc: 0.5096 - val_loss: 1.1672 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9873 - acc: 0.5288 - val_loss: 1.1529 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0129 - acc: 0.4808 - val_loss: 1.1500 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9553 - acc: 0.5000 - val_loss: 1.1405 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0490 - acc: 0.4519 - val_loss: 1.1488 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9500 - acc: 0.5192 - val_loss: 1.1565 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.3769 - acc: 0.4423 - val_loss: 2.3184 - val_acc: 0.5185\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 2.3839 - acc: 0.5385 - val_loss: 2.0677 - val_acc: 0.4815\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 2.3301 - acc: 0.4808 - val_loss: 1.9764 - val_acc: 0.5185\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 2.0787 - acc: 0.5288 - val_loss: 1.9208 - val_acc: 0.4815\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 2.1967 - acc: 0.4904 - val_loss: 1.7825 - val_acc: 0.4815\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 2.2146 - acc: 0.4904 - val_loss: 1.6778 - val_acc: 0.4815\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 2.0033 - acc: 0.5577 - val_loss: 1.6000 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 2.1836 - acc: 0.5000 - val_loss: 1.5363 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.9200 - acc: 0.5096 - val_loss: 1.5476 - val_acc: 0.4815\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.5771 - acc: 0.5865 - val_loss: 1.4844 - val_acc: 0.5185\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.5169 - acc: 0.5769 - val_loss: 1.4285 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.7785 - acc: 0.5192 - val_loss: 1.4311 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.5190 - acc: 0.5481 - val_loss: 1.3958 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.4326 - acc: 0.5577 - val_loss: 1.3725 - val_acc: 0.4444\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.3317 - acc: 0.5577 - val_loss: 1.4061 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.4091 - acc: 0.5000 - val_loss: 1.4097 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.4075 - acc: 0.5096 - val_loss: 1.4213 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1279 - acc: 0.5769 - val_loss: 1.4090 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.4908 - acc: 0.5288 - val_loss: 1.4223 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.2715 - acc: 0.5962 - val_loss: 1.3838 - val_acc: 0.4815\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.2421 - acc: 0.5673 - val_loss: 1.3769 - val_acc: 0.5556\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.2708 - acc: 0.5481 - val_loss: 1.3964 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.3028 - acc: 0.5481 - val_loss: 1.3826 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.4390 - acc: 0.5192 - val_loss: 1.3438 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.2145 - acc: 0.5577 - val_loss: 1.3268 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1809 - acc: 0.4904 - val_loss: 1.3165 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.3034 - acc: 0.5288 - val_loss: 1.3084 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.2706 - acc: 0.5192 - val_loss: 1.2954 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0834 - acc: 0.5673 - val_loss: 1.2858 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.3760 - acc: 0.5096 - val_loss: 1.2740 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0388 - acc: 0.5481 - val_loss: 1.3144 - val_acc: 0.5185\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.2655 - acc: 0.4712 - val_loss: 1.2998 - val_acc: 0.5185\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1617 - acc: 0.5673 - val_loss: 1.2912 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1943 - acc: 0.5385 - val_loss: 1.3020 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0724 - acc: 0.5865 - val_loss: 1.2660 - val_acc: 0.5556\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.2555 - acc: 0.5192 - val_loss: 1.2718 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1628 - acc: 0.5481 - val_loss: 1.2848 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0610 - acc: 0.5577 - val_loss: 1.2649 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1083 - acc: 0.5865 - val_loss: 1.2574 - val_acc: 0.5185\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1435 - acc: 0.5192 - val_loss: 1.2548 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9702 - acc: 0.5673 - val_loss: 1.2690 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1069 - acc: 0.5192 - val_loss: 1.2589 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0092 - acc: 0.5192 - val_loss: 1.2907 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0592 - acc: 0.5769 - val_loss: 1.2703 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.0442 - acc: 0.5769 - val_loss: 1.2596 - val_acc: 0.5185\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0525 - acc: 0.5481 - val_loss: 1.2524 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0701 - acc: 0.5481 - val_loss: 1.2483 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0583 - acc: 0.5577 - val_loss: 1.2395 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1594 - acc: 0.5096 - val_loss: 1.2369 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0737 - acc: 0.5288 - val_loss: 1.2299 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 74c5af08aaf0d8acef3c011f2ad29b5a</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5111111402511597</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 5.0810 - acc: 0.3846 - val_loss: 1.7048 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 2.2647 - acc: 0.4231 - val_loss: 1.6027 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 3.4171 - acc: 0.4135 - val_loss: 1.4327 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 1.8484 - acc: 0.4808 - val_loss: 1.3275 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 2.3632 - acc: 0.4423 - val_loss: 1.2917 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 2.6089 - acc: 0.4615 - val_loss: 1.2420 - val_acc: 0.4815\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.6775 - acc: 0.4712 - val_loss: 1.2009 - val_acc: 0.4444\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.7058 - acc: 0.4423 - val_loss: 1.1585 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 2.0730 - acc: 0.4615 - val_loss: 1.1246 - val_acc: 0.5926\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.8124 - acc: 0.4712 - val_loss: 1.1309 - val_acc: 0.5185\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.2436 - acc: 0.5192 - val_loss: 1.1206 - val_acc: 0.5185\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.6604 - acc: 0.4904 - val_loss: 1.1134 - val_acc: 0.5185\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.4083 - acc: 0.4038 - val_loss: 1.0832 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.3653 - acc: 0.4423 - val_loss: 1.0808 - val_acc: 0.4444\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.4988 - acc: 0.5000 - val_loss: 1.0721 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.4598 - acc: 0.4423 - val_loss: 1.0490 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.3530 - acc: 0.4712 - val_loss: 1.0486 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.7505 - acc: 0.3942 - val_loss: 1.0449 - val_acc: 0.5185\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1957 - acc: 0.4904 - val_loss: 1.0367 - val_acc: 0.5185\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.2952 - acc: 0.5000 - val_loss: 1.0351 - val_acc: 0.5185\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.2673 - acc: 0.4231 - val_loss: 1.0188 - val_acc: 0.5556\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.2945 - acc: 0.4135 - val_loss: 1.0130 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0793 - acc: 0.5096 - val_loss: 1.0197 - val_acc: 0.5185\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1664 - acc: 0.4327 - val_loss: 1.0025 - val_acc: 0.5185\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.2119 - acc: 0.5096 - val_loss: 1.0068 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1874 - acc: 0.4808 - val_loss: 1.0079 - val_acc: 0.5556\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0805 - acc: 0.4904 - val_loss: 1.0081 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0910 - acc: 0.4423 - val_loss: 0.9999 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.1278 - acc: 0.4615 - val_loss: 0.9931 - val_acc: 0.5556\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0663 - acc: 0.4808 - val_loss: 0.9911 - val_acc: 0.5556\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0806 - acc: 0.4615 - val_loss: 0.9876 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 466us/sample - loss: 1.0798 - acc: 0.4904 - val_loss: 0.9856 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 283us/sample - loss: 1.1385 - acc: 0.4615 - val_loss: 0.9761 - val_acc: 0.5556\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1551 - acc: 0.4519 - val_loss: 0.9734 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0794 - acc: 0.4712 - val_loss: 0.9802 - val_acc: 0.5556\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0925 - acc: 0.4904 - val_loss: 0.9809 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0340 - acc: 0.5000 - val_loss: 0.9798 - val_acc: 0.5556\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0696 - acc: 0.4615 - val_loss: 0.9752 - val_acc: 0.5556\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0885 - acc: 0.4808 - val_loss: 0.9846 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0121 - acc: 0.5192 - val_loss: 0.9955 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1493 - acc: 0.4615 - val_loss: 0.9913 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.1045 - acc: 0.4615 - val_loss: 0.9911 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0746 - acc: 0.4712 - val_loss: 0.9941 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0759 - acc: 0.4712 - val_loss: 0.9901 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0315 - acc: 0.4808 - val_loss: 0.9854 - val_acc: 0.5926\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0988 - acc: 0.4712 - val_loss: 0.9946 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0297 - acc: 0.5096 - val_loss: 0.9906 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0209 - acc: 0.5000 - val_loss: 0.9849 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0236 - acc: 0.4808 - val_loss: 0.9887 - val_acc: 0.5556\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0755 - acc: 0.5000 - val_loss: 0.9923 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 987us/sample - loss: 2.1313 - acc: 0.3365 - val_loss: 1.4464 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 2.1558 - acc: 0.4519 - val_loss: 1.3809 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 2.0616 - acc: 0.4327 - val_loss: 1.3134 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.8929 - acc: 0.4712 - val_loss: 1.2312 - val_acc: 0.3704\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.7823 - acc: 0.5000 - val_loss: 1.1864 - val_acc: 0.3704\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.3652 - acc: 0.4231 - val_loss: 1.1676 - val_acc: 0.4074\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.4832 - acc: 0.5000 - val_loss: 1.1317 - val_acc: 0.4444\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.3247 - acc: 0.4519 - val_loss: 1.1131 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.3158 - acc: 0.5577 - val_loss: 1.0897 - val_acc: 0.4074\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.4003 - acc: 0.3942 - val_loss: 1.0636 - val_acc: 0.4074\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1849 - acc: 0.4519 - val_loss: 1.0404 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 470us/sample - loss: 1.3980 - acc: 0.4808 - val_loss: 1.0373 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.3786 - acc: 0.4712 - val_loss: 1.0249 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.4335 - acc: 0.4519 - val_loss: 1.0131 - val_acc: 0.5556\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0977 - acc: 0.4712 - val_loss: 1.0144 - val_acc: 0.5556\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.3141 - acc: 0.4519 - val_loss: 1.0073 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0650 - acc: 0.4712 - val_loss: 1.0028 - val_acc: 0.5556\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1091 - acc: 0.4712 - val_loss: 0.9990 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.2461 - acc: 0.4615 - val_loss: 0.9982 - val_acc: 0.5926\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.2993 - acc: 0.4712 - val_loss: 0.9987 - val_acc: 0.5926\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1406 - acc: 0.4808 - val_loss: 0.9983 - val_acc: 0.5926\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0307 - acc: 0.5192 - val_loss: 0.9907 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0237 - acc: 0.4615 - val_loss: 0.9862 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.2346 - acc: 0.4231 - val_loss: 0.9873 - val_acc: 0.5926\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0680 - acc: 0.5000 - val_loss: 0.9846 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1743 - acc: 0.4231 - val_loss: 0.9851 - val_acc: 0.5556\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0628 - acc: 0.4615 - val_loss: 0.9870 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.2207 - acc: 0.4615 - val_loss: 0.9901 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0935 - acc: 0.4615 - val_loss: 0.9897 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0958 - acc: 0.4808 - val_loss: 0.9912 - val_acc: 0.5926\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0566 - acc: 0.4519 - val_loss: 0.9888 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0142 - acc: 0.4808 - val_loss: 0.9865 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0487 - acc: 0.4712 - val_loss: 0.9880 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0265 - acc: 0.5000 - val_loss: 0.9890 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0797 - acc: 0.4712 - val_loss: 0.9889 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0208 - acc: 0.4904 - val_loss: 0.9897 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0260 - acc: 0.4423 - val_loss: 0.9853 - val_acc: 0.5556\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0297 - acc: 0.5000 - val_loss: 0.9863 - val_acc: 0.5556\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 447us/sample - loss: 1.0282 - acc: 0.5385 - val_loss: 0.9897 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9789 - acc: 0.5288 - val_loss: 0.9887 - val_acc: 0.5556\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0672 - acc: 0.4808 - val_loss: 0.9908 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0251 - acc: 0.4712 - val_loss: 0.9911 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0002 - acc: 0.4904 - val_loss: 0.9912 - val_acc: 0.5556\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9937 - acc: 0.4712 - val_loss: 0.9908 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0001 - acc: 0.4904 - val_loss: 0.9902 - val_acc: 0.5556\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0171 - acc: 0.4904 - val_loss: 0.9893 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0212 - acc: 0.4327 - val_loss: 0.9872 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9895 - acc: 0.5192 - val_loss: 0.9895 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0396 - acc: 0.4712 - val_loss: 0.9895 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9960 - acc: 0.5192 - val_loss: 0.9874 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.9841 - acc: 0.3846 - val_loss: 1.4088 - val_acc: 0.4815\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.5263 - acc: 0.4327 - val_loss: 1.4210 - val_acc: 0.5185\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.3297 - acc: 0.4904 - val_loss: 1.4333 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.4887 - acc: 0.4519 - val_loss: 1.4689 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1355 - acc: 0.4615 - val_loss: 1.4683 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.3366 - acc: 0.4135 - val_loss: 1.4331 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.4214 - acc: 0.4808 - val_loss: 1.4084 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.4772 - acc: 0.4712 - val_loss: 1.3702 - val_acc: 0.4444\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0503 - acc: 0.5096 - val_loss: 1.3634 - val_acc: 0.4815\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0088 - acc: 0.4808 - val_loss: 1.3788 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0615 - acc: 0.5673 - val_loss: 1.3759 - val_acc: 0.4815\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1400 - acc: 0.4423 - val_loss: 1.3376 - val_acc: 0.4444\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.3030 - acc: 0.4519 - val_loss: 1.2959 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.3819 - acc: 0.4712 - val_loss: 1.2706 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 434us/sample - loss: 1.1815 - acc: 0.4712 - val_loss: 1.2406 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.2637 - acc: 0.4423 - val_loss: 1.2108 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.3435 - acc: 0.5577 - val_loss: 1.1631 - val_acc: 0.5185\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0413 - acc: 0.4904 - val_loss: 1.1530 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.2270 - acc: 0.4904 - val_loss: 1.1193 - val_acc: 0.5185\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0899 - acc: 0.5000 - val_loss: 1.1201 - val_acc: 0.4444\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.2399 - acc: 0.4423 - val_loss: 1.1203 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0580 - acc: 0.4519 - val_loss: 1.1240 - val_acc: 0.4444\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 1.0392 - acc: 0.4904 - val_loss: 1.1299 - val_acc: 0.4444\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 1.0931 - acc: 0.4904 - val_loss: 1.1188 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0683 - acc: 0.4615 - val_loss: 1.0949 - val_acc: 0.4815\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0702 - acc: 0.4615 - val_loss: 1.0861 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0488 - acc: 0.4808 - val_loss: 1.0842 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0864 - acc: 0.4423 - val_loss: 1.0738 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0791 - acc: 0.4519 - val_loss: 1.0639 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.1381 - acc: 0.4423 - val_loss: 1.0557 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0756 - acc: 0.4712 - val_loss: 1.0508 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0809 - acc: 0.4423 - val_loss: 1.0422 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0101 - acc: 0.4808 - val_loss: 1.0489 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0088 - acc: 0.4712 - val_loss: 1.0433 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0974 - acc: 0.4327 - val_loss: 1.0383 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0521 - acc: 0.4615 - val_loss: 1.0367 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0790 - acc: 0.4519 - val_loss: 1.0475 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0283 - acc: 0.5192 - val_loss: 1.0463 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0569 - acc: 0.4904 - val_loss: 1.0591 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0243 - acc: 0.4808 - val_loss: 1.0497 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1005 - acc: 0.4423 - val_loss: 1.0476 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9795 - acc: 0.5096 - val_loss: 1.0404 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0871 - acc: 0.4519 - val_loss: 1.0351 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0687 - acc: 0.4038 - val_loss: 1.0221 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0408 - acc: 0.4712 - val_loss: 1.0165 - val_acc: 0.5556\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0115 - acc: 0.5096 - val_loss: 1.0279 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9945 - acc: 0.5192 - val_loss: 1.0231 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0112 - acc: 0.4615 - val_loss: 1.0231 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0092 - acc: 0.4808 - val_loss: 1.0264 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0295 - acc: 0.4423 - val_loss: 1.0188 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.3218 - acc: 0.4327 - val_loss: 1.8952 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 2.0638 - acc: 0.4423 - val_loss: 1.6429 - val_acc: 0.3333\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.9392 - acc: 0.4519 - val_loss: 1.4986 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 2.1431 - acc: 0.4038 - val_loss: 1.2783 - val_acc: 0.4815\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.3322 - acc: 0.3558 - val_loss: 1.2365 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.3417 - acc: 0.3846 - val_loss: 1.2072 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.4076 - acc: 0.3750 - val_loss: 1.1851 - val_acc: 0.5556\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.2165 - acc: 0.4712 - val_loss: 1.1835 - val_acc: 0.4444\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1545 - acc: 0.3750 - val_loss: 1.1672 - val_acc: 0.4074\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.2030 - acc: 0.3750 - val_loss: 1.1570 - val_acc: 0.4074\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 414us/sample - loss: 1.1025 - acc: 0.5192 - val_loss: 1.1486 - val_acc: 0.4074\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1241 - acc: 0.4327 - val_loss: 1.1353 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1289 - acc: 0.4231 - val_loss: 1.1264 - val_acc: 0.4074\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0819 - acc: 0.4135 - val_loss: 1.1134 - val_acc: 0.3704\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1418 - acc: 0.4231 - val_loss: 1.0972 - val_acc: 0.5185\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0548 - acc: 0.4615 - val_loss: 1.0884 - val_acc: 0.4444\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1083 - acc: 0.4423 - val_loss: 1.0731 - val_acc: 0.4444\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1124 - acc: 0.3942 - val_loss: 1.0659 - val_acc: 0.4444\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0546 - acc: 0.4231 - val_loss: 1.0601 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 1.0327 - acc: 0.4327 - val_loss: 1.0559 - val_acc: 0.5185\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0617 - acc: 0.4423 - val_loss: 1.0539 - val_acc: 0.5185\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0269 - acc: 0.4519 - val_loss: 1.0555 - val_acc: 0.4444\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9866 - acc: 0.4808 - val_loss: 1.0580 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0629 - acc: 0.3942 - val_loss: 1.0515 - val_acc: 0.4074\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0557 - acc: 0.4327 - val_loss: 1.0442 - val_acc: 0.4074\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 410us/sample - loss: 1.0199 - acc: 0.4519 - val_loss: 1.0389 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 416us/sample - loss: 1.0567 - acc: 0.4519 - val_loss: 1.0421 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0060 - acc: 0.5000 - val_loss: 1.0414 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0194 - acc: 0.4135 - val_loss: 1.0376 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0405 - acc: 0.4423 - val_loss: 1.0393 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.0061 - acc: 0.4904 - val_loss: 1.0366 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0569 - acc: 0.3942 - val_loss: 1.0350 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0408 - acc: 0.4038 - val_loss: 1.0348 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0068 - acc: 0.3846 - val_loss: 1.0424 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0216 - acc: 0.4231 - val_loss: 1.0396 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0183 - acc: 0.4904 - val_loss: 1.0369 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 478us/sample - loss: 1.0107 - acc: 0.4808 - val_loss: 1.0373 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0085 - acc: 0.4808 - val_loss: 1.0394 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0309 - acc: 0.4615 - val_loss: 1.0373 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0599 - acc: 0.3654 - val_loss: 1.0366 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9877 - acc: 0.5192 - val_loss: 1.0357 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0313 - acc: 0.4231 - val_loss: 1.0374 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0291 - acc: 0.3462 - val_loss: 1.0377 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0383 - acc: 0.4327 - val_loss: 1.0362 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0661 - acc: 0.4615 - val_loss: 1.0347 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0371 - acc: 0.4519 - val_loss: 1.0299 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0320 - acc: 0.4231 - val_loss: 1.0315 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0298 - acc: 0.4231 - val_loss: 1.0312 - val_acc: 0.3333\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0025 - acc: 0.4712 - val_loss: 1.0281 - val_acc: 0.5556\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9954 - acc: 0.4231 - val_loss: 1.0306 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.4034 - acc: 0.3654 - val_loss: 2.0120 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 2.0272 - acc: 0.4327 - val_loss: 1.8741 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 2.7261 - acc: 0.4038 - val_loss: 1.7309 - val_acc: 0.4074\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 425us/sample - loss: 1.9365 - acc: 0.3654 - val_loss: 1.6575 - val_acc: 0.5185\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 2.5187 - acc: 0.3750 - val_loss: 1.4488 - val_acc: 0.5185\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.8451 - acc: 0.4615 - val_loss: 1.3905 - val_acc: 0.5556\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.8179 - acc: 0.3654 - val_loss: 1.3737 - val_acc: 0.5556\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.6629 - acc: 0.3654 - val_loss: 1.3215 - val_acc: 0.5556\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.6831 - acc: 0.3942 - val_loss: 1.2636 - val_acc: 0.5556\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.5575 - acc: 0.4327 - val_loss: 1.1989 - val_acc: 0.5926\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.5627 - acc: 0.4135 - val_loss: 1.1881 - val_acc: 0.5926\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.5590 - acc: 0.3365 - val_loss: 1.1484 - val_acc: 0.5185\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 430us/sample - loss: 1.3885 - acc: 0.3365 - val_loss: 1.1663 - val_acc: 0.5556\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.5258 - acc: 0.4231 - val_loss: 1.1819 - val_acc: 0.5556\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.4065 - acc: 0.4231 - val_loss: 1.1763 - val_acc: 0.5556\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 1.3424 - acc: 0.3942 - val_loss: 1.1610 - val_acc: 0.5556\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.2512 - acc: 0.3942 - val_loss: 1.1427 - val_acc: 0.5556\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.4454 - acc: 0.3846 - val_loss: 1.1203 - val_acc: 0.5556\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1189 - acc: 0.4519 - val_loss: 1.0978 - val_acc: 0.5185\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.3110 - acc: 0.4712 - val_loss: 1.0875 - val_acc: 0.5185\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0495 - acc: 0.5000 - val_loss: 1.0833 - val_acc: 0.5185\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.2148 - acc: 0.4904 - val_loss: 1.0706 - val_acc: 0.5185\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1651 - acc: 0.4327 - val_loss: 1.0767 - val_acc: 0.5185\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.2241 - acc: 0.4038 - val_loss: 1.0681 - val_acc: 0.5926\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0894 - acc: 0.4904 - val_loss: 1.0725 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0635 - acc: 0.4327 - val_loss: 1.0836 - val_acc: 0.5926\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.1256 - acc: 0.4808 - val_loss: 1.0876 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1538 - acc: 0.4423 - val_loss: 1.0897 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.1432 - acc: 0.4519 - val_loss: 1.0857 - val_acc: 0.5556\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.1530 - acc: 0.4231 - val_loss: 1.0511 - val_acc: 0.5926\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1269 - acc: 0.4327 - val_loss: 1.0367 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0748 - acc: 0.4327 - val_loss: 1.0375 - val_acc: 0.5926\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0315 - acc: 0.4904 - val_loss: 1.0484 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.2058 - acc: 0.4327 - val_loss: 1.0387 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0498 - acc: 0.4712 - val_loss: 1.0399 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 1.0002 - acc: 0.4615 - val_loss: 1.0384 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0465 - acc: 0.4615 - val_loss: 1.0301 - val_acc: 0.5926\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.1572 - acc: 0.4327 - val_loss: 1.0332 - val_acc: 0.5926\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1970 - acc: 0.4038 - val_loss: 1.0366 - val_acc: 0.5926\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0438 - acc: 0.4423 - val_loss: 1.0315 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.1280 - acc: 0.4231 - val_loss: 1.0360 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.1030 - acc: 0.4038 - val_loss: 1.0351 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1033 - acc: 0.4519 - val_loss: 1.0298 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0055 - acc: 0.4519 - val_loss: 1.0330 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0639 - acc: 0.4904 - val_loss: 1.0427 - val_acc: 0.5926\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0568 - acc: 0.3654 - val_loss: 1.0381 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0325 - acc: 0.4712 - val_loss: 1.0282 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0845 - acc: 0.3654 - val_loss: 1.0175 - val_acc: 0.5556\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9926 - acc: 0.4615 - val_loss: 1.0218 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0315 - acc: 0.4423 - val_loss: 1.0235 - val_acc: 0.5926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9cedb2f1274012558626680e8cf304fe</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5777777433395386</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.9230 - acc: 0.3558 - val_loss: 1.5688 - val_acc: 0.4444\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.9669 - acc: 0.4135 - val_loss: 1.4285 - val_acc: 0.4444\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.5667 - acc: 0.4135 - val_loss: 1.3448 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.4915 - acc: 0.4231 - val_loss: 1.2855 - val_acc: 0.4815\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.4789 - acc: 0.3654 - val_loss: 1.2354 - val_acc: 0.4815\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.3222 - acc: 0.3750 - val_loss: 1.1993 - val_acc: 0.4815\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2618 - acc: 0.3942 - val_loss: 1.1739 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2144 - acc: 0.4519 - val_loss: 1.1516 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.2343 - acc: 0.4038 - val_loss: 1.1538 - val_acc: 0.4815\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1976 - acc: 0.3654 - val_loss: 1.1493 - val_acc: 0.4074\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.2714 - acc: 0.3846 - val_loss: 1.1256 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1506 - acc: 0.3942 - val_loss: 1.1144 - val_acc: 0.4444\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.2407 - acc: 0.3846 - val_loss: 1.0976 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1640 - acc: 0.4135 - val_loss: 1.0838 - val_acc: 0.4444\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1205 - acc: 0.3654 - val_loss: 1.0775 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0887 - acc: 0.4231 - val_loss: 1.0750 - val_acc: 0.4444\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0126 - acc: 0.4423 - val_loss: 1.0708 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.2311 - acc: 0.4231 - val_loss: 1.0750 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0835 - acc: 0.4135 - val_loss: 1.0733 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1096 - acc: 0.4327 - val_loss: 1.0770 - val_acc: 0.4815\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.1181 - acc: 0.4231 - val_loss: 1.0706 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1014 - acc: 0.4327 - val_loss: 1.0640 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1320 - acc: 0.4327 - val_loss: 1.0709 - val_acc: 0.4815\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0140 - acc: 0.4615 - val_loss: 1.0647 - val_acc: 0.4815\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0600 - acc: 0.3846 - val_loss: 1.0551 - val_acc: 0.4815\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0802 - acc: 0.4519 - val_loss: 1.0508 - val_acc: 0.4815\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0538 - acc: 0.4519 - val_loss: 1.0515 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 1.0822 - acc: 0.4135 - val_loss: 1.0504 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0820 - acc: 0.3750 - val_loss: 1.0462 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0555 - acc: 0.4135 - val_loss: 1.0421 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9826 - acc: 0.4327 - val_loss: 1.0385 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9953 - acc: 0.4423 - val_loss: 1.0352 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9977 - acc: 0.4904 - val_loss: 1.0399 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0313 - acc: 0.4423 - val_loss: 1.0382 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9933 - acc: 0.4519 - val_loss: 1.0368 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9727 - acc: 0.5192 - val_loss: 1.0342 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9796 - acc: 0.4808 - val_loss: 1.0381 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 0.9597 - acc: 0.5385 - val_loss: 1.0447 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9447 - acc: 0.5096 - val_loss: 1.0467 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9912 - acc: 0.5481 - val_loss: 1.0464 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9735 - acc: 0.4712 - val_loss: 1.0423 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9843 - acc: 0.4808 - val_loss: 1.0413 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0078 - acc: 0.5096 - val_loss: 1.0413 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0184 - acc: 0.4615 - val_loss: 1.0410 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0305 - acc: 0.5192 - val_loss: 1.0388 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9921 - acc: 0.5481 - val_loss: 1.0332 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9742 - acc: 0.5096 - val_loss: 1.0435 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 0.9757 - acc: 0.5000 - val_loss: 1.0451 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9419 - acc: 0.5769 - val_loss: 1.0493 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9455 - acc: 0.5481 - val_loss: 1.0491 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.1056 - acc: 0.3462 - val_loss: 3.6487 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 3.0044 - acc: 0.3558 - val_loss: 3.3515 - val_acc: 0.4444\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 2.5934 - acc: 0.3750 - val_loss: 3.0733 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 2.3257 - acc: 0.3654 - val_loss: 2.8861 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 2.1064 - acc: 0.4135 - val_loss: 2.6524 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 2.1038 - acc: 0.4423 - val_loss: 2.5639 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.8614 - acc: 0.4423 - val_loss: 2.3922 - val_acc: 0.4444\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 2.0548 - acc: 0.4615 - val_loss: 2.1967 - val_acc: 0.4444\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.8023 - acc: 0.4615 - val_loss: 2.0771 - val_acc: 0.4444\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.6650 - acc: 0.4327 - val_loss: 1.9974 - val_acc: 0.4444\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.4009 - acc: 0.4519 - val_loss: 1.9571 - val_acc: 0.4815\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 287us/sample - loss: 1.7714 - acc: 0.4038 - val_loss: 1.8174 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.6446 - acc: 0.4615 - val_loss: 1.6926 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.4090 - acc: 0.4231 - val_loss: 1.6248 - val_acc: 0.4444\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.5027 - acc: 0.4038 - val_loss: 1.5646 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.4694 - acc: 0.3942 - val_loss: 1.4875 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.4130 - acc: 0.4712 - val_loss: 1.3934 - val_acc: 0.5185\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.3320 - acc: 0.4327 - val_loss: 1.3421 - val_acc: 0.5185\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.2697 - acc: 0.4519 - val_loss: 1.3472 - val_acc: 0.5185\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.2591 - acc: 0.4423 - val_loss: 1.3518 - val_acc: 0.5185\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.2393 - acc: 0.5096 - val_loss: 1.2957 - val_acc: 0.5185\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.2339 - acc: 0.4519 - val_loss: 1.2692 - val_acc: 0.5185\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 728us/sample - loss: 1.1483 - acc: 0.5385 - val_loss: 1.2584 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.2435 - acc: 0.4808 - val_loss: 1.2140 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0984 - acc: 0.5288 - val_loss: 1.1998 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1497 - acc: 0.4519 - val_loss: 1.1875 - val_acc: 0.5556\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.1466 - acc: 0.4231 - val_loss: 1.1714 - val_acc: 0.5556\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1371 - acc: 0.4615 - val_loss: 1.1602 - val_acc: 0.5556\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.0998 - acc: 0.4808 - val_loss: 1.1228 - val_acc: 0.5556\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9900 - acc: 0.5000 - val_loss: 1.1041 - val_acc: 0.5556\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0941 - acc: 0.5192 - val_loss: 1.1132 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9811 - acc: 0.5288 - val_loss: 1.1221 - val_acc: 0.5185\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1151 - acc: 0.5288 - val_loss: 1.1012 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9957 - acc: 0.5481 - val_loss: 1.0816 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9942 - acc: 0.4904 - val_loss: 1.0964 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0439 - acc: 0.5000 - val_loss: 1.0878 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0445 - acc: 0.5192 - val_loss: 1.0735 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0475 - acc: 0.4712 - val_loss: 1.0632 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0670 - acc: 0.4615 - val_loss: 1.0690 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0666 - acc: 0.4423 - val_loss: 1.0469 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 415us/sample - loss: 1.0222 - acc: 0.4904 - val_loss: 1.0373 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0300 - acc: 0.4904 - val_loss: 1.0457 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0575 - acc: 0.4712 - val_loss: 1.0394 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9520 - acc: 0.5096 - val_loss: 1.0425 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9790 - acc: 0.5096 - val_loss: 1.0451 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0373 - acc: 0.4808 - val_loss: 1.0393 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9765 - acc: 0.4904 - val_loss: 1.0535 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9937 - acc: 0.5000 - val_loss: 1.0517 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9699 - acc: 0.5000 - val_loss: 1.0407 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0194 - acc: 0.4904 - val_loss: 1.0483 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.1622 - acc: 0.4135 - val_loss: 1.6775 - val_acc: 0.4444\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 2.1563 - acc: 0.3654 - val_loss: 1.5594 - val_acc: 0.4074\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.7997 - acc: 0.3942 - val_loss: 1.4848 - val_acc: 0.3333\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.7162 - acc: 0.4519 - val_loss: 1.4210 - val_acc: 0.2963\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.8680 - acc: 0.3173 - val_loss: 1.3569 - val_acc: 0.2222\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.4552 - acc: 0.3269 - val_loss: 1.3215 - val_acc: 0.2222\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.5685 - acc: 0.3942 - val_loss: 1.2793 - val_acc: 0.2593\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.4663 - acc: 0.3269 - val_loss: 1.2453 - val_acc: 0.2593\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.3886 - acc: 0.3846 - val_loss: 1.2171 - val_acc: 0.2593\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.3400 - acc: 0.3462 - val_loss: 1.2041 - val_acc: 0.2593\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.3010 - acc: 0.3558 - val_loss: 1.1790 - val_acc: 0.2222\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.2394 - acc: 0.3750 - val_loss: 1.1696 - val_acc: 0.2222\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.2341 - acc: 0.3654 - val_loss: 1.1526 - val_acc: 0.2222\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1429 - acc: 0.4135 - val_loss: 1.1427 - val_acc: 0.2222\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1965 - acc: 0.2981 - val_loss: 1.1333 - val_acc: 0.2222\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.1835 - acc: 0.3942 - val_loss: 1.1325 - val_acc: 0.1481\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1701 - acc: 0.3558 - val_loss: 1.1276 - val_acc: 0.1852\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.1552 - acc: 0.4231 - val_loss: 1.1218 - val_acc: 0.1481\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1213 - acc: 0.3365 - val_loss: 1.1185 - val_acc: 0.1481\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0641 - acc: 0.4038 - val_loss: 1.1107 - val_acc: 0.1481\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9955 - acc: 0.4231 - val_loss: 1.1116 - val_acc: 0.1852\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.1570 - acc: 0.3462 - val_loss: 1.1072 - val_acc: 0.1852\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0850 - acc: 0.3846 - val_loss: 1.0996 - val_acc: 0.1852\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1296 - acc: 0.4135 - val_loss: 1.0969 - val_acc: 0.2222\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0656 - acc: 0.4615 - val_loss: 1.0953 - val_acc: 0.2963\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0977 - acc: 0.4135 - val_loss: 1.0910 - val_acc: 0.3333\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0582 - acc: 0.4327 - val_loss: 1.0846 - val_acc: 0.3704\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0354 - acc: 0.5096 - val_loss: 1.0858 - val_acc: 0.3704\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0526 - acc: 0.4519 - val_loss: 1.0839 - val_acc: 0.3704\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0150 - acc: 0.4712 - val_loss: 1.0792 - val_acc: 0.3704\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0578 - acc: 0.4038 - val_loss: 1.0781 - val_acc: 0.3704\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0173 - acc: 0.4808 - val_loss: 1.0763 - val_acc: 0.3704\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0557 - acc: 0.4519 - val_loss: 1.0753 - val_acc: 0.3704\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0186 - acc: 0.5000 - val_loss: 1.0803 - val_acc: 0.3704\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0465 - acc: 0.4904 - val_loss: 1.0808 - val_acc: 0.3704\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0260 - acc: 0.4519 - val_loss: 1.0818 - val_acc: 0.3704\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 1.0374 - acc: 0.4712 - val_loss: 1.0811 - val_acc: 0.3704\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9602 - acc: 0.5096 - val_loss: 1.0843 - val_acc: 0.3704\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9975 - acc: 0.5096 - val_loss: 1.0815 - val_acc: 0.3704\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9872 - acc: 0.5288 - val_loss: 1.0832 - val_acc: 0.3704\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0369 - acc: 0.4423 - val_loss: 1.0783 - val_acc: 0.3704\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0749 - acc: 0.4712 - val_loss: 1.0800 - val_acc: 0.4074\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0112 - acc: 0.4808 - val_loss: 1.0780 - val_acc: 0.3704\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0685 - acc: 0.4135 - val_loss: 1.0735 - val_acc: 0.3704\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0041 - acc: 0.4808 - val_loss: 1.0727 - val_acc: 0.3704\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9843 - acc: 0.4904 - val_loss: 1.0727 - val_acc: 0.2963\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0492 - acc: 0.4423 - val_loss: 1.0691 - val_acc: 0.2963\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0439 - acc: 0.4519 - val_loss: 1.0686 - val_acc: 0.2963\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 1.0017 - acc: 0.4327 - val_loss: 1.0700 - val_acc: 0.3704\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0178 - acc: 0.5000 - val_loss: 1.0673 - val_acc: 0.3704\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.3407 - acc: 0.2788 - val_loss: 1.7091 - val_acc: 0.2222\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.9535 - acc: 0.2981 - val_loss: 1.5760 - val_acc: 0.2222\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.8041 - acc: 0.2981 - val_loss: 1.4724 - val_acc: 0.2222\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.6309 - acc: 0.3173 - val_loss: 1.4088 - val_acc: 0.2222\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.5490 - acc: 0.2981 - val_loss: 1.3616 - val_acc: 0.1852\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.3429 - acc: 0.3750 - val_loss: 1.3272 - val_acc: 0.2593\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.3397 - acc: 0.3365 - val_loss: 1.3025 - val_acc: 0.2593\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.3697 - acc: 0.2981 - val_loss: 1.2696 - val_acc: 0.2593\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2745 - acc: 0.3654 - val_loss: 1.2565 - val_acc: 0.2593\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.3474 - acc: 0.2788 - val_loss: 1.2382 - val_acc: 0.2593\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1234 - acc: 0.3846 - val_loss: 1.2253 - val_acc: 0.2593\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.2000 - acc: 0.4038 - val_loss: 1.2090 - val_acc: 0.2963\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.1918 - acc: 0.3654 - val_loss: 1.1837 - val_acc: 0.3333\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2023 - acc: 0.3846 - val_loss: 1.1675 - val_acc: 0.3333\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1684 - acc: 0.3558 - val_loss: 1.1470 - val_acc: 0.3704\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1322 - acc: 0.3942 - val_loss: 1.1400 - val_acc: 0.3704\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.1025 - acc: 0.4038 - val_loss: 1.1194 - val_acc: 0.3704\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1434 - acc: 0.3654 - val_loss: 1.1055 - val_acc: 0.3704\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0655 - acc: 0.3846 - val_loss: 1.0956 - val_acc: 0.3704\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.1008 - acc: 0.3846 - val_loss: 1.0826 - val_acc: 0.3704\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1185 - acc: 0.3846 - val_loss: 1.0732 - val_acc: 0.3704\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0592 - acc: 0.4327 - val_loss: 1.0682 - val_acc: 0.3704\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1045 - acc: 0.3654 - val_loss: 1.0607 - val_acc: 0.3704\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0478 - acc: 0.4135 - val_loss: 1.0528 - val_acc: 0.3704\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0199 - acc: 0.4712 - val_loss: 1.0499 - val_acc: 0.3704\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0605 - acc: 0.4135 - val_loss: 1.0401 - val_acc: 0.3704\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.0652 - acc: 0.4038 - val_loss: 1.0320 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0611 - acc: 0.4327 - val_loss: 1.0292 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0403 - acc: 0.4038 - val_loss: 1.0310 - val_acc: 0.4074\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0365 - acc: 0.4038 - val_loss: 1.0294 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0393 - acc: 0.3750 - val_loss: 1.0233 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0568 - acc: 0.4135 - val_loss: 1.0243 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0397 - acc: 0.4231 - val_loss: 1.0201 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0478 - acc: 0.4231 - val_loss: 1.0180 - val_acc: 0.4444\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0100 - acc: 0.3942 - val_loss: 1.0090 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0396 - acc: 0.4231 - val_loss: 1.0042 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0180 - acc: 0.4615 - val_loss: 1.0004 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0326 - acc: 0.4423 - val_loss: 0.9998 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0130 - acc: 0.4135 - val_loss: 0.9951 - val_acc: 0.5185\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0596 - acc: 0.4327 - val_loss: 0.9955 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9942 - acc: 0.4808 - val_loss: 0.9932 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0363 - acc: 0.4808 - val_loss: 0.9919 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0351 - acc: 0.4038 - val_loss: 0.9894 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 0.9681 - acc: 0.4615 - val_loss: 0.9902 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0384 - acc: 0.4038 - val_loss: 0.9901 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0273 - acc: 0.4231 - val_loss: 0.9886 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0044 - acc: 0.4423 - val_loss: 0.9863 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0223 - acc: 0.4712 - val_loss: 0.9861 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0142 - acc: 0.4423 - val_loss: 0.9865 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0148 - acc: 0.4519 - val_loss: 0.9859 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.0911 - acc: 0.3462 - val_loss: 2.9847 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 446us/sample - loss: 3.1560 - acc: 0.3365 - val_loss: 2.4354 - val_acc: 0.4074\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 2.6194 - acc: 0.4231 - val_loss: 2.1025 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 2.2987 - acc: 0.3846 - val_loss: 1.8291 - val_acc: 0.4074\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.8559 - acc: 0.3846 - val_loss: 1.7105 - val_acc: 0.4074\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.8933 - acc: 0.3462 - val_loss: 1.5136 - val_acc: 0.4815\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.6080 - acc: 0.3942 - val_loss: 1.3976 - val_acc: 0.5185\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.5120 - acc: 0.3269 - val_loss: 1.3088 - val_acc: 0.5185\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.3834 - acc: 0.4038 - val_loss: 1.2483 - val_acc: 0.5185\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.2749 - acc: 0.4135 - val_loss: 1.2098 - val_acc: 0.5185\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.3565 - acc: 0.4423 - val_loss: 1.1699 - val_acc: 0.5185\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1242 - acc: 0.4615 - val_loss: 1.1648 - val_acc: 0.5556\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.2361 - acc: 0.4038 - val_loss: 1.1305 - val_acc: 0.5185\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.2526 - acc: 0.4135 - val_loss: 1.1369 - val_acc: 0.5185\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.2353 - acc: 0.4712 - val_loss: 1.1265 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.3035 - acc: 0.3750 - val_loss: 1.1126 - val_acc: 0.4444\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0889 - acc: 0.3942 - val_loss: 1.1009 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1512 - acc: 0.4712 - val_loss: 1.0972 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0597 - acc: 0.4519 - val_loss: 1.1043 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0693 - acc: 0.5673 - val_loss: 1.0981 - val_acc: 0.5185\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0291 - acc: 0.5769 - val_loss: 1.0930 - val_acc: 0.5185\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1386 - acc: 0.4327 - val_loss: 1.0859 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0956 - acc: 0.5096 - val_loss: 1.0803 - val_acc: 0.5185\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0604 - acc: 0.5192 - val_loss: 1.0728 - val_acc: 0.5185\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0289 - acc: 0.5288 - val_loss: 1.0700 - val_acc: 0.5185\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0584 - acc: 0.5192 - val_loss: 1.0617 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.1042 - acc: 0.4712 - val_loss: 1.0617 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1138 - acc: 0.4519 - val_loss: 1.0645 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0529 - acc: 0.5192 - val_loss: 1.0602 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0349 - acc: 0.5577 - val_loss: 1.0590 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1267 - acc: 0.3942 - val_loss: 1.0589 - val_acc: 0.5185\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0020 - acc: 0.5000 - val_loss: 1.0479 - val_acc: 0.5185\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0472 - acc: 0.4808 - val_loss: 1.0481 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0275 - acc: 0.4423 - val_loss: 1.0400 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0411 - acc: 0.4615 - val_loss: 1.0455 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0527 - acc: 0.5096 - val_loss: 1.0467 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0694 - acc: 0.4135 - val_loss: 1.0382 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0229 - acc: 0.5577 - val_loss: 1.0403 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0336 - acc: 0.5000 - val_loss: 1.0479 - val_acc: 0.5185\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0183 - acc: 0.5000 - val_loss: 1.0454 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0987 - acc: 0.5000 - val_loss: 1.0465 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9959 - acc: 0.5192 - val_loss: 1.0405 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9828 - acc: 0.5288 - val_loss: 1.0357 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9778 - acc: 0.5192 - val_loss: 1.0296 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0289 - acc: 0.4615 - val_loss: 1.0281 - val_acc: 0.5185\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9745 - acc: 0.5865 - val_loss: 1.0294 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9892 - acc: 0.4519 - val_loss: 1.0193 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9382 - acc: 0.5577 - val_loss: 1.0245 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0171 - acc: 0.4808 - val_loss: 1.0222 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9873 - acc: 0.4904 - val_loss: 1.0253 - val_acc: 0.4815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: f4bec78767a26245564eb9510036295d</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5185185074806213</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.3178 - acc: 0.2308 - val_loss: 3.0328 - val_acc: 0.1111\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 2.3567 - acc: 0.3558 - val_loss: 2.7350 - val_acc: 0.1111\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 2.6303 - acc: 0.2500 - val_loss: 2.4494 - val_acc: 0.1481\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 2.8959 - acc: 0.3846 - val_loss: 2.0767 - val_acc: 0.1481\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 2.1937 - acc: 0.3654 - val_loss: 1.8021 - val_acc: 0.1481\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 477us/sample - loss: 1.9496 - acc: 0.3942 - val_loss: 1.6244 - val_acc: 0.2593\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.8044 - acc: 0.3750 - val_loss: 1.4503 - val_acc: 0.3333\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.6226 - acc: 0.3942 - val_loss: 1.3655 - val_acc: 0.2593\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.5204 - acc: 0.3750 - val_loss: 1.2918 - val_acc: 0.3333\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.4119 - acc: 0.3846 - val_loss: 1.2235 - val_acc: 0.3704\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1772 - acc: 0.4135 - val_loss: 1.2179 - val_acc: 0.3704\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.3617 - acc: 0.3942 - val_loss: 1.1848 - val_acc: 0.3704\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.4303 - acc: 0.3846 - val_loss: 1.1596 - val_acc: 0.4074\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.4185 - acc: 0.4327 - val_loss: 1.1316 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.2354 - acc: 0.4423 - val_loss: 1.1216 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0926 - acc: 0.4615 - val_loss: 1.1077 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.2208 - acc: 0.4519 - val_loss: 1.0942 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1771 - acc: 0.4231 - val_loss: 1.0800 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1550 - acc: 0.4519 - val_loss: 1.0600 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1353 - acc: 0.4038 - val_loss: 1.0564 - val_acc: 0.4444\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 1.0575 - acc: 0.4712 - val_loss: 1.0457 - val_acc: 0.4444\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1073 - acc: 0.4808 - val_loss: 1.0420 - val_acc: 0.4444\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.1490 - acc: 0.4904 - val_loss: 1.0335 - val_acc: 0.4444\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1136 - acc: 0.4808 - val_loss: 1.0325 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0481 - acc: 0.4904 - val_loss: 1.0250 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1229 - acc: 0.4327 - val_loss: 1.0176 - val_acc: 0.4815\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0861 - acc: 0.4327 - val_loss: 1.0195 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0348 - acc: 0.4423 - val_loss: 1.0124 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0301 - acc: 0.5096 - val_loss: 1.0169 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0461 - acc: 0.4519 - val_loss: 1.0265 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9744 - acc: 0.5192 - val_loss: 1.0216 - val_acc: 0.5185\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0061 - acc: 0.4904 - val_loss: 1.0035 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0317 - acc: 0.4808 - val_loss: 1.0010 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0584 - acc: 0.4904 - val_loss: 0.9971 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9655 - acc: 0.5288 - val_loss: 0.9960 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9648 - acc: 0.5481 - val_loss: 0.9969 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0838 - acc: 0.4615 - val_loss: 1.0022 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0226 - acc: 0.5000 - val_loss: 1.0022 - val_acc: 0.4444\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9985 - acc: 0.5288 - val_loss: 0.9936 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0086 - acc: 0.5192 - val_loss: 1.0001 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0083 - acc: 0.4808 - val_loss: 0.9932 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0135 - acc: 0.4904 - val_loss: 0.9904 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9664 - acc: 0.5481 - val_loss: 0.9944 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9957 - acc: 0.4712 - val_loss: 0.9988 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9840 - acc: 0.5577 - val_loss: 0.9871 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0044 - acc: 0.5192 - val_loss: 0.9894 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 410us/sample - loss: 1.0514 - acc: 0.4327 - val_loss: 0.9939 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9774 - acc: 0.5000 - val_loss: 0.9844 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0113 - acc: 0.4712 - val_loss: 0.9813 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0064 - acc: 0.4615 - val_loss: 0.9879 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 995us/sample - loss: 2.1682 - acc: 0.3558 - val_loss: 3.0637 - val_acc: 0.5185\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 670us/sample - loss: 1.8642 - acc: 0.4327 - val_loss: 2.8862 - val_acc: 0.5556\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 2.3913 - acc: 0.3942 - val_loss: 2.7051 - val_acc: 0.5185\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 2.2653 - acc: 0.4808 - val_loss: 2.4586 - val_acc: 0.4815\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 2.0076 - acc: 0.4423 - val_loss: 2.3479 - val_acc: 0.4815\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 2.4830 - acc: 0.3942 - val_loss: 2.1633 - val_acc: 0.4815\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.7137 - acc: 0.5288 - val_loss: 2.0852 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 2.1929 - acc: 0.4519 - val_loss: 1.9244 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.6750 - acc: 0.4327 - val_loss: 1.8823 - val_acc: 0.5185\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.4053 - acc: 0.4519 - val_loss: 1.8998 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.4118 - acc: 0.3846 - val_loss: 1.8714 - val_acc: 0.5185\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.3567 - acc: 0.5288 - val_loss: 1.7691 - val_acc: 0.5556\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.5671 - acc: 0.4423 - val_loss: 1.7510 - val_acc: 0.5926\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.4249 - acc: 0.4135 - val_loss: 1.7706 - val_acc: 0.5556\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.5494 - acc: 0.4519 - val_loss: 1.7103 - val_acc: 0.5556\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.1989 - acc: 0.5385 - val_loss: 1.7082 - val_acc: 0.5556\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.7134 - acc: 0.4327 - val_loss: 1.5904 - val_acc: 0.5926\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.5056 - acc: 0.4135 - val_loss: 1.5906 - val_acc: 0.5556\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.7613 - acc: 0.4423 - val_loss: 1.5363 - val_acc: 0.5556\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.2003 - acc: 0.4519 - val_loss: 1.5223 - val_acc: 0.5926\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1626 - acc: 0.4808 - val_loss: 1.5243 - val_acc: 0.5556\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.2178 - acc: 0.4904 - val_loss: 1.4747 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1411 - acc: 0.4327 - val_loss: 1.4802 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.6921 - acc: 0.4808 - val_loss: 1.3896 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1707 - acc: 0.4327 - val_loss: 1.4111 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0775 - acc: 0.5000 - val_loss: 1.3827 - val_acc: 0.5556\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.1617 - acc: 0.5000 - val_loss: 1.3542 - val_acc: 0.5556\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.2449 - acc: 0.4231 - val_loss: 1.3374 - val_acc: 0.5556\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1430 - acc: 0.4904 - val_loss: 1.3154 - val_acc: 0.5556\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1905 - acc: 0.4808 - val_loss: 1.3152 - val_acc: 0.5556\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0292 - acc: 0.4615 - val_loss: 1.3140 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0938 - acc: 0.5000 - val_loss: 1.2976 - val_acc: 0.5185\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.4485 - acc: 0.4904 - val_loss: 1.2315 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0482 - acc: 0.5192 - val_loss: 1.2266 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0688 - acc: 0.5000 - val_loss: 1.2439 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0616 - acc: 0.4519 - val_loss: 1.2416 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.4333 - acc: 0.4904 - val_loss: 1.2023 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.3584 - acc: 0.4327 - val_loss: 1.1566 - val_acc: 0.5556\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0605 - acc: 0.4615 - val_loss: 1.1506 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1150 - acc: 0.4519 - val_loss: 1.1400 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9864 - acc: 0.4904 - val_loss: 1.1515 - val_acc: 0.5556\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 288us/sample - loss: 1.0062 - acc: 0.5192 - val_loss: 1.1445 - val_acc: 0.5556\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.1941 - acc: 0.4135 - val_loss: 1.1388 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0561 - acc: 0.4519 - val_loss: 1.1184 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0796 - acc: 0.5192 - val_loss: 1.1241 - val_acc: 0.5556\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9576 - acc: 0.5288 - val_loss: 1.1220 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9990 - acc: 0.4519 - val_loss: 1.1182 - val_acc: 0.5556\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0986 - acc: 0.4808 - val_loss: 1.0954 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9888 - acc: 0.4712 - val_loss: 1.0922 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0354 - acc: 0.4712 - val_loss: 1.1017 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.5394 - acc: 0.3846 - val_loss: 2.0134 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 2.4749 - acc: 0.4038 - val_loss: 1.8419 - val_acc: 0.3333\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.8069 - acc: 0.5000 - val_loss: 1.7759 - val_acc: 0.3333\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.8720 - acc: 0.4615 - val_loss: 1.6234 - val_acc: 0.4074\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.9591 - acc: 0.4904 - val_loss: 1.5315 - val_acc: 0.4074\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.6931 - acc: 0.4904 - val_loss: 1.4280 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.4839 - acc: 0.5288 - val_loss: 1.3751 - val_acc: 0.4444\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.4015 - acc: 0.4615 - val_loss: 1.3365 - val_acc: 0.4074\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.4674 - acc: 0.4904 - val_loss: 1.3141 - val_acc: 0.4074\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.2211 - acc: 0.4712 - val_loss: 1.2863 - val_acc: 0.4444\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1967 - acc: 0.5481 - val_loss: 1.2740 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.2148 - acc: 0.4712 - val_loss: 1.2488 - val_acc: 0.4444\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2017 - acc: 0.4808 - val_loss: 1.1951 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1424 - acc: 0.4808 - val_loss: 1.1608 - val_acc: 0.4074\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0322 - acc: 0.5000 - val_loss: 1.1557 - val_acc: 0.4074\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0429 - acc: 0.4904 - val_loss: 1.1483 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.1905 - acc: 0.4712 - val_loss: 1.1380 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1510 - acc: 0.4904 - val_loss: 1.1211 - val_acc: 0.4444\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0107 - acc: 0.5000 - val_loss: 1.0924 - val_acc: 0.4074\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0925 - acc: 0.5577 - val_loss: 1.0877 - val_acc: 0.4444\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0990 - acc: 0.4904 - val_loss: 1.0746 - val_acc: 0.4444\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1346 - acc: 0.4615 - val_loss: 1.0645 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0783 - acc: 0.4712 - val_loss: 1.0623 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0451 - acc: 0.5000 - val_loss: 1.0503 - val_acc: 0.4815\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0220 - acc: 0.4423 - val_loss: 1.0379 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0543 - acc: 0.4423 - val_loss: 1.0563 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9996 - acc: 0.5385 - val_loss: 1.0630 - val_acc: 0.4074\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0934 - acc: 0.5288 - val_loss: 1.0739 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0515 - acc: 0.5000 - val_loss: 1.0659 - val_acc: 0.4074\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0193 - acc: 0.4519 - val_loss: 1.0424 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0224 - acc: 0.5481 - val_loss: 1.0444 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0413 - acc: 0.5096 - val_loss: 1.0565 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0412 - acc: 0.4904 - val_loss: 1.0359 - val_acc: 0.4074\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9855 - acc: 0.5096 - val_loss: 1.0426 - val_acc: 0.4444\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9769 - acc: 0.4808 - val_loss: 1.0352 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0412 - acc: 0.4712 - val_loss: 1.0446 - val_acc: 0.4074\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9420 - acc: 0.4808 - val_loss: 1.0453 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9768 - acc: 0.4712 - val_loss: 1.0551 - val_acc: 0.4074\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0887 - acc: 0.5096 - val_loss: 1.0251 - val_acc: 0.4074\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0452 - acc: 0.5096 - val_loss: 1.0233 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0300 - acc: 0.4135 - val_loss: 1.0279 - val_acc: 0.4074\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0577 - acc: 0.4615 - val_loss: 1.0327 - val_acc: 0.4074\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9767 - acc: 0.4904 - val_loss: 1.0233 - val_acc: 0.3704\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0252 - acc: 0.5385 - val_loss: 1.0237 - val_acc: 0.4074\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0853 - acc: 0.5000 - val_loss: 1.0284 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0867 - acc: 0.4615 - val_loss: 1.0188 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9956 - acc: 0.5096 - val_loss: 1.0339 - val_acc: 0.4074\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9508 - acc: 0.5000 - val_loss: 1.0271 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0013 - acc: 0.5192 - val_loss: 1.0281 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0369 - acc: 0.4808 - val_loss: 1.0276 - val_acc: 0.4074\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 992us/sample - loss: 3.3080 - acc: 0.4038 - val_loss: 2.2187 - val_acc: 0.5185\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 3.4741 - acc: 0.4615 - val_loss: 1.9722 - val_acc: 0.4815\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 2.6029 - acc: 0.3462 - val_loss: 1.8401 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 2.2464 - acc: 0.4423 - val_loss: 1.7379 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 2.1562 - acc: 0.4327 - val_loss: 1.6179 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.7965 - acc: 0.4423 - val_loss: 1.5373 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 2.3020 - acc: 0.4519 - val_loss: 1.4352 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.6153 - acc: 0.4231 - val_loss: 1.3846 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.5150 - acc: 0.4423 - val_loss: 1.3413 - val_acc: 0.4444\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.5136 - acc: 0.4327 - val_loss: 1.3081 - val_acc: 0.4444\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.6629 - acc: 0.4712 - val_loss: 1.2471 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.4645 - acc: 0.4038 - val_loss: 1.2146 - val_acc: 0.4444\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.3837 - acc: 0.4712 - val_loss: 1.1943 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.6849 - acc: 0.4038 - val_loss: 1.1534 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.3887 - acc: 0.4519 - val_loss: 1.1131 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.2808 - acc: 0.4712 - val_loss: 1.1110 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.2145 - acc: 0.4615 - val_loss: 1.1049 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.3832 - acc: 0.4904 - val_loss: 1.0838 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2350 - acc: 0.4231 - val_loss: 1.0716 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.1359 - acc: 0.4904 - val_loss: 1.0641 - val_acc: 0.5185\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.3603 - acc: 0.4519 - val_loss: 1.0382 - val_acc: 0.5926\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1386 - acc: 0.4904 - val_loss: 1.0384 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1351 - acc: 0.5096 - val_loss: 1.0412 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0488 - acc: 0.5000 - val_loss: 1.0376 - val_acc: 0.5185\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1147 - acc: 0.4615 - val_loss: 1.0347 - val_acc: 0.5185\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1282 - acc: 0.4712 - val_loss: 1.0351 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0751 - acc: 0.4712 - val_loss: 1.0246 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.1518 - acc: 0.4519 - val_loss: 1.0173 - val_acc: 0.5556\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0813 - acc: 0.4808 - val_loss: 1.0095 - val_acc: 0.5556\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0632 - acc: 0.4519 - val_loss: 1.0052 - val_acc: 0.5556\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0843 - acc: 0.4615 - val_loss: 0.9944 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0833 - acc: 0.4712 - val_loss: 0.9926 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0758 - acc: 0.4904 - val_loss: 1.0034 - val_acc: 0.5556\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1388 - acc: 0.4615 - val_loss: 1.0018 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0627 - acc: 0.4808 - val_loss: 0.9871 - val_acc: 0.5926\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 746us/sample - loss: 1.1519 - acc: 0.4712 - val_loss: 0.9776 - val_acc: 0.6296\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0785 - acc: 0.4615 - val_loss: 0.9850 - val_acc: 0.5926\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1015 - acc: 0.4423 - val_loss: 0.9938 - val_acc: 0.5556\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0685 - acc: 0.4808 - val_loss: 0.9972 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.0938 - acc: 0.4904 - val_loss: 1.0082 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1167 - acc: 0.4231 - val_loss: 1.0015 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 410us/sample - loss: 1.0792 - acc: 0.4712 - val_loss: 0.9961 - val_acc: 0.5556\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0080 - acc: 0.4615 - val_loss: 0.9931 - val_acc: 0.5926\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0133 - acc: 0.4904 - val_loss: 0.9945 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0238 - acc: 0.4423 - val_loss: 1.0045 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0594 - acc: 0.4327 - val_loss: 0.9967 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1157 - acc: 0.4231 - val_loss: 1.0016 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9783 - acc: 0.5000 - val_loss: 0.9949 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0554 - acc: 0.4712 - val_loss: 0.9850 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9954 - acc: 0.4712 - val_loss: 0.9818 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.0724 - acc: 0.3462 - val_loss: 2.8807 - val_acc: 0.1481\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 2.9903 - acc: 0.4423 - val_loss: 2.4730 - val_acc: 0.1852\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 2.5575 - acc: 0.3365 - val_loss: 2.1220 - val_acc: 0.1852\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 453us/sample - loss: 2.2640 - acc: 0.3654 - val_loss: 1.8389 - val_acc: 0.1852\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 2.0902 - acc: 0.4135 - val_loss: 1.6441 - val_acc: 0.1852\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 2.3532 - acc: 0.3077 - val_loss: 1.4632 - val_acc: 0.2222\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.9192 - acc: 0.4231 - val_loss: 1.3760 - val_acc: 0.2593\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.6816 - acc: 0.3750 - val_loss: 1.3266 - val_acc: 0.2963\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.4182 - acc: 0.4135 - val_loss: 1.2782 - val_acc: 0.2963\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.3847 - acc: 0.4423 - val_loss: 1.2349 - val_acc: 0.3333\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.2957 - acc: 0.4615 - val_loss: 1.2220 - val_acc: 0.3333\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.4891 - acc: 0.3654 - val_loss: 1.1971 - val_acc: 0.3333\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2279 - acc: 0.4904 - val_loss: 1.1917 - val_acc: 0.2963\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1768 - acc: 0.3654 - val_loss: 1.1761 - val_acc: 0.3333\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.2695 - acc: 0.4712 - val_loss: 1.1585 - val_acc: 0.3704\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.2268 - acc: 0.4231 - val_loss: 1.1519 - val_acc: 0.3333\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.2232 - acc: 0.4038 - val_loss: 1.1411 - val_acc: 0.3333\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 483us/sample - loss: 1.2206 - acc: 0.3942 - val_loss: 1.1300 - val_acc: 0.3333\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1990 - acc: 0.3750 - val_loss: 1.1249 - val_acc: 0.3333\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.1876 - acc: 0.3558 - val_loss: 1.1070 - val_acc: 0.3333\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0544 - acc: 0.5000 - val_loss: 1.0942 - val_acc: 0.4074\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0559 - acc: 0.4615 - val_loss: 1.0910 - val_acc: 0.4074\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1270 - acc: 0.4038 - val_loss: 1.0914 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0889 - acc: 0.4038 - val_loss: 1.0810 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9836 - acc: 0.5288 - val_loss: 1.0785 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0883 - acc: 0.3846 - val_loss: 1.0768 - val_acc: 0.4074\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0545 - acc: 0.4135 - val_loss: 1.0719 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0571 - acc: 0.4231 - val_loss: 1.0667 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0354 - acc: 0.4327 - val_loss: 1.0647 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0171 - acc: 0.4712 - val_loss: 1.0617 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0311 - acc: 0.4423 - val_loss: 1.0589 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0680 - acc: 0.4231 - val_loss: 1.0578 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0212 - acc: 0.4904 - val_loss: 1.0562 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0236 - acc: 0.4808 - val_loss: 1.0518 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0308 - acc: 0.4038 - val_loss: 1.0481 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0614 - acc: 0.4135 - val_loss: 1.0455 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0330 - acc: 0.4038 - val_loss: 1.0437 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0109 - acc: 0.4615 - val_loss: 1.0428 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0119 - acc: 0.5000 - val_loss: 1.0392 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0413 - acc: 0.4615 - val_loss: 1.0370 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0385 - acc: 0.4038 - val_loss: 1.0333 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9782 - acc: 0.5288 - val_loss: 1.0354 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0482 - acc: 0.4327 - val_loss: 1.0339 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0255 - acc: 0.4808 - val_loss: 1.0308 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0031 - acc: 0.4231 - val_loss: 1.0285 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0202 - acc: 0.4615 - val_loss: 1.0259 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9956 - acc: 0.5000 - val_loss: 1.0212 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9724 - acc: 0.5288 - val_loss: 1.0203 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0185 - acc: 0.5000 - val_loss: 1.0197 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9909 - acc: 0.4904 - val_loss: 1.0196 - val_acc: 0.4444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: f4ca1642017cbb1382d75244b0a9b374</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5407407879829407</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.7</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 2ms/sample - loss: 2.1259 - acc: 0.4038 - val_loss: 2.9114 - val_acc: 0.1481\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 455us/sample - loss: 2.0564 - acc: 0.3942 - val_loss: 2.6897 - val_acc: 0.2963\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 415us/sample - loss: 1.8465 - acc: 0.3942 - val_loss: 2.5466 - val_acc: 0.3333\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 2.7678 - acc: 0.4808 - val_loss: 2.3105 - val_acc: 0.2963\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.5653 - acc: 0.4904 - val_loss: 2.1799 - val_acc: 0.2963\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.6686 - acc: 0.4423 - val_loss: 2.1056 - val_acc: 0.2963\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.5122 - acc: 0.4038 - val_loss: 2.0204 - val_acc: 0.3333\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 1.9069 - acc: 0.4135 - val_loss: 1.8742 - val_acc: 0.2593\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.2762 - acc: 0.4231 - val_loss: 1.8438 - val_acc: 0.2963\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 2.2263 - acc: 0.3558 - val_loss: 1.6669 - val_acc: 0.2963\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 2.2820 - acc: 0.3942 - val_loss: 1.5889 - val_acc: 0.2963\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 1.2050 - acc: 0.3942 - val_loss: 1.5537 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 2.5181 - acc: 0.4327 - val_loss: 1.4624 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.6841 - acc: 0.4423 - val_loss: 1.4333 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.2391 - acc: 0.4038 - val_loss: 1.4067 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.2895 - acc: 0.4615 - val_loss: 1.4096 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1421 - acc: 0.3558 - val_loss: 1.4184 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 1.3788 - acc: 0.3558 - val_loss: 1.3541 - val_acc: 0.5185\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.5572 - acc: 0.4423 - val_loss: 1.3807 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.1405 - acc: 0.4135 - val_loss: 1.3751 - val_acc: 0.3704\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 2.0801 - acc: 0.4038 - val_loss: 1.3160 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.7359 - acc: 0.4519 - val_loss: 1.2957 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.3173 - acc: 0.3654 - val_loss: 1.2813 - val_acc: 0.3704\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.3581 - acc: 0.4135 - val_loss: 1.2885 - val_acc: 0.4815\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.6692 - acc: 0.4038 - val_loss: 1.2800 - val_acc: 0.2963\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.7434 - acc: 0.3942 - val_loss: 1.2190 - val_acc: 0.3704\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.3836 - acc: 0.4231 - val_loss: 1.1819 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1413 - acc: 0.3654 - val_loss: 1.1839 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0370 - acc: 0.4327 - val_loss: 1.1837 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.2143 - acc: 0.4615 - val_loss: 1.2094 - val_acc: 0.3704\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.2350 - acc: 0.3846 - val_loss: 1.1950 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.2644 - acc: 0.4519 - val_loss: 1.2236 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.6759 - acc: 0.3558 - val_loss: 1.1366 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.4694 - acc: 0.3654 - val_loss: 1.1155 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0779 - acc: 0.4615 - val_loss: 1.1140 - val_acc: 0.3704\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0362 - acc: 0.5192 - val_loss: 1.1361 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1426 - acc: 0.3846 - val_loss: 1.1155 - val_acc: 0.4074\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.4119 - acc: 0.4519 - val_loss: 1.1249 - val_acc: 0.5556\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1000 - acc: 0.4519 - val_loss: 1.1153 - val_acc: 0.5185\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0057 - acc: 0.4327 - val_loss: 1.1039 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.3366 - acc: 0.3846 - val_loss: 1.1136 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0832 - acc: 0.4327 - val_loss: 1.0933 - val_acc: 0.4074\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0087 - acc: 0.4519 - val_loss: 1.0915 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.1978 - acc: 0.4231 - val_loss: 1.0909 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1845 - acc: 0.3750 - val_loss: 1.0874 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.1165 - acc: 0.3846 - val_loss: 1.0951 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1867 - acc: 0.4519 - val_loss: 1.1016 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0825 - acc: 0.4423 - val_loss: 1.0908 - val_acc: 0.4074\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0370 - acc: 0.3846 - val_loss: 1.0948 - val_acc: 0.2963\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0224 - acc: 0.4712 - val_loss: 1.0788 - val_acc: 0.3333\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 6.8501 - acc: 0.3269 - val_loss: 2.6673 - val_acc: 0.1111\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 3.4799 - acc: 0.3846 - val_loss: 2.3189 - val_acc: 0.1111\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.7490 - acc: 0.4135 - val_loss: 2.1825 - val_acc: 0.1111\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 2.1938 - acc: 0.4712 - val_loss: 2.0248 - val_acc: 0.0370\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 2.3761 - acc: 0.4038 - val_loss: 1.8692 - val_acc: 0.1481\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.7842 - acc: 0.4135 - val_loss: 1.7740 - val_acc: 0.2963\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 3.6596 - acc: 0.4231 - val_loss: 1.6169 - val_acc: 0.2963\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.7569 - acc: 0.3750 - val_loss: 1.5943 - val_acc: 0.2963\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.6302 - acc: 0.3077 - val_loss: 1.5470 - val_acc: 0.3333\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.8153 - acc: 0.4038 - val_loss: 1.4726 - val_acc: 0.3333\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.7015 - acc: 0.3846 - val_loss: 1.4213 - val_acc: 0.3333\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.4668 - acc: 0.4231 - val_loss: 1.3722 - val_acc: 0.3333\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.3006 - acc: 0.4519 - val_loss: 1.3590 - val_acc: 0.3333\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.1815 - acc: 0.5000 - val_loss: 1.3513 - val_acc: 0.3333\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.5115 - acc: 0.4519 - val_loss: 1.3146 - val_acc: 0.3333\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.5645 - acc: 0.4423 - val_loss: 1.3286 - val_acc: 0.2963\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.7150 - acc: 0.4038 - val_loss: 1.3207 - val_acc: 0.2963\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.4564 - acc: 0.4231 - val_loss: 1.2984 - val_acc: 0.2963\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1639 - acc: 0.4038 - val_loss: 1.2696 - val_acc: 0.3333\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.2362 - acc: 0.4423 - val_loss: 1.2390 - val_acc: 0.3333\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0625 - acc: 0.4615 - val_loss: 1.2260 - val_acc: 0.3333\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1383 - acc: 0.4327 - val_loss: 1.2314 - val_acc: 0.3333\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2096 - acc: 0.4231 - val_loss: 1.2223 - val_acc: 0.3333\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.4495 - acc: 0.4038 - val_loss: 1.2297 - val_acc: 0.3704\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1522 - acc: 0.4038 - val_loss: 1.2297 - val_acc: 0.3704\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.3324 - acc: 0.4327 - val_loss: 1.2209 - val_acc: 0.4074\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.2766 - acc: 0.4327 - val_loss: 1.2103 - val_acc: 0.4074\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.2832 - acc: 0.3846 - val_loss: 1.1906 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.2701 - acc: 0.4423 - val_loss: 1.1643 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.2243 - acc: 0.3942 - val_loss: 1.1453 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1492 - acc: 0.5000 - val_loss: 1.1239 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2506 - acc: 0.4135 - val_loss: 1.1070 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0761 - acc: 0.4423 - val_loss: 1.1011 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.3441 - acc: 0.4231 - val_loss: 1.0809 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1158 - acc: 0.4327 - val_loss: 1.0739 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0155 - acc: 0.5096 - val_loss: 1.0726 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1774 - acc: 0.4423 - val_loss: 1.0660 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0961 - acc: 0.4135 - val_loss: 1.0618 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0201 - acc: 0.4327 - val_loss: 1.0638 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0785 - acc: 0.4712 - val_loss: 1.0661 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1261 - acc: 0.4519 - val_loss: 1.0579 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.1091 - acc: 0.4327 - val_loss: 1.0528 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0549 - acc: 0.4327 - val_loss: 1.0497 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0828 - acc: 0.4327 - val_loss: 1.0439 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 422us/sample - loss: 1.0573 - acc: 0.4135 - val_loss: 1.0407 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0827 - acc: 0.4038 - val_loss: 1.0384 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0057 - acc: 0.4423 - val_loss: 1.0357 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1302 - acc: 0.3942 - val_loss: 1.0301 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 0.9845 - acc: 0.4712 - val_loss: 1.0282 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9828 - acc: 0.4423 - val_loss: 1.0263 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.0341 - acc: 0.4423 - val_loss: 1.8467 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 4.1330 - acc: 0.4423 - val_loss: 1.4334 - val_acc: 0.3333\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 4.2195 - acc: 0.3750 - val_loss: 1.1063 - val_acc: 0.3333\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.5405 - acc: 0.4615 - val_loss: 1.0728 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.9377 - acc: 0.4712 - val_loss: 1.0354 - val_acc: 0.4815\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.6675 - acc: 0.4808 - val_loss: 1.0231 - val_acc: 0.5185\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.5454 - acc: 0.4615 - val_loss: 1.0399 - val_acc: 0.4444\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 2.1159 - acc: 0.4327 - val_loss: 1.0675 - val_acc: 0.4444\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.6825 - acc: 0.4327 - val_loss: 1.0572 - val_acc: 0.4815\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.1771 - acc: 0.5096 - val_loss: 1.0696 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.4945 - acc: 0.4423 - val_loss: 0.9992 - val_acc: 0.5185\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.2837 - acc: 0.4615 - val_loss: 1.0529 - val_acc: 0.5185\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.3946 - acc: 0.4519 - val_loss: 1.0765 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.3215 - acc: 0.4808 - val_loss: 1.0643 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.3355 - acc: 0.4519 - val_loss: 1.0434 - val_acc: 0.5185\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.3379 - acc: 0.4615 - val_loss: 1.0873 - val_acc: 0.3333\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.3322 - acc: 0.4712 - val_loss: 1.0707 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1006 - acc: 0.4423 - val_loss: 1.0852 - val_acc: 0.5185\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0818 - acc: 0.4423 - val_loss: 1.0755 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0115 - acc: 0.4904 - val_loss: 1.1110 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 1.1156 - acc: 0.4423 - val_loss: 1.0755 - val_acc: 0.4444\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0053 - acc: 0.4808 - val_loss: 1.0953 - val_acc: 0.3704\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.2153 - acc: 0.4615 - val_loss: 1.0720 - val_acc: 0.3704\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1635 - acc: 0.4519 - val_loss: 1.0788 - val_acc: 0.3704\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0646 - acc: 0.4135 - val_loss: 1.0757 - val_acc: 0.4815\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0720 - acc: 0.4038 - val_loss: 1.0374 - val_acc: 0.4815\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0802 - acc: 0.4615 - val_loss: 1.0381 - val_acc: 0.4074\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 668us/sample - loss: 1.1569 - acc: 0.4231 - val_loss: 1.0306 - val_acc: 0.5926\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.1164 - acc: 0.4519 - val_loss: 1.0482 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.1185 - acc: 0.4712 - val_loss: 1.0353 - val_acc: 0.4074\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.1119 - acc: 0.4327 - val_loss: 1.0392 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0232 - acc: 0.5096 - val_loss: 1.0321 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.1237 - acc: 0.4519 - val_loss: 1.0092 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0628 - acc: 0.4423 - val_loss: 1.0194 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0645 - acc: 0.4231 - val_loss: 1.0323 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0354 - acc: 0.4904 - val_loss: 1.0269 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0677 - acc: 0.4904 - val_loss: 1.0154 - val_acc: 0.5556\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0771 - acc: 0.5000 - val_loss: 1.0251 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0709 - acc: 0.4712 - val_loss: 1.0134 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.0699 - acc: 0.4423 - val_loss: 1.0067 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1541 - acc: 0.4327 - val_loss: 1.0228 - val_acc: 0.2963\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0743 - acc: 0.4327 - val_loss: 1.0279 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0713 - acc: 0.4712 - val_loss: 1.0342 - val_acc: 0.5556\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9743 - acc: 0.5096 - val_loss: 1.0348 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0514 - acc: 0.4423 - val_loss: 1.0195 - val_acc: 0.5556\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0450 - acc: 0.4808 - val_loss: 1.0263 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0061 - acc: 0.4808 - val_loss: 1.0331 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0383 - acc: 0.4808 - val_loss: 1.0263 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0015 - acc: 0.5000 - val_loss: 1.0368 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0620 - acc: 0.4712 - val_loss: 1.0229 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.9131 - acc: 0.4038 - val_loss: 1.7565 - val_acc: 0.1481\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.8237 - acc: 0.3942 - val_loss: 1.6796 - val_acc: 0.1481\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 508us/sample - loss: 1.4135 - acc: 0.3462 - val_loss: 1.6594 - val_acc: 0.2593\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.6426 - acc: 0.4904 - val_loss: 1.6009 - val_acc: 0.3333\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.8924 - acc: 0.3750 - val_loss: 1.5472 - val_acc: 0.2963\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.7295 - acc: 0.3750 - val_loss: 1.4960 - val_acc: 0.3333\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.6747 - acc: 0.4231 - val_loss: 1.4598 - val_acc: 0.3333\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.5255 - acc: 0.4135 - val_loss: 1.4472 - val_acc: 0.2963\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.4640 - acc: 0.3846 - val_loss: 1.4357 - val_acc: 0.4074\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.6900 - acc: 0.4135 - val_loss: 1.3985 - val_acc: 0.4074\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.3227 - acc: 0.3750 - val_loss: 1.3809 - val_acc: 0.4074\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.7083 - acc: 0.3942 - val_loss: 1.3219 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.4070 - acc: 0.4615 - val_loss: 1.3049 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1159 - acc: 0.4327 - val_loss: 1.2890 - val_acc: 0.4444\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.4781 - acc: 0.4423 - val_loss: 1.2554 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.1915 - acc: 0.4808 - val_loss: 1.2424 - val_acc: 0.4444\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.4112 - acc: 0.5000 - val_loss: 1.2123 - val_acc: 0.4444\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1884 - acc: 0.4423 - val_loss: 1.1974 - val_acc: 0.4444\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.3937 - acc: 0.4904 - val_loss: 1.1894 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.1067 - acc: 0.4423 - val_loss: 1.1872 - val_acc: 0.4444\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 1.1457 - acc: 0.4615 - val_loss: 1.1585 - val_acc: 0.4074\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.6289 - acc: 0.4038 - val_loss: 1.1233 - val_acc: 0.4444\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.3713 - acc: 0.4712 - val_loss: 1.1074 - val_acc: 0.4444\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0816 - acc: 0.4615 - val_loss: 1.0999 - val_acc: 0.3704\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.2117 - acc: 0.4808 - val_loss: 1.0959 - val_acc: 0.3704\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1828 - acc: 0.4519 - val_loss: 1.0836 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1538 - acc: 0.4327 - val_loss: 1.0707 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0971 - acc: 0.4519 - val_loss: 1.0623 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0761 - acc: 0.5192 - val_loss: 1.0627 - val_acc: 0.4074\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9970 - acc: 0.5192 - val_loss: 1.0660 - val_acc: 0.3333\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.2755 - acc: 0.4423 - val_loss: 1.0548 - val_acc: 0.3333\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.2760 - acc: 0.4519 - val_loss: 1.0344 - val_acc: 0.3704\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0299 - acc: 0.4712 - val_loss: 1.0334 - val_acc: 0.3704\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 417us/sample - loss: 1.0583 - acc: 0.4712 - val_loss: 1.0346 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.0153 - acc: 0.4712 - val_loss: 1.0318 - val_acc: 0.3704\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1133 - acc: 0.4615 - val_loss: 1.0203 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0252 - acc: 0.4904 - val_loss: 1.0168 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0459 - acc: 0.4904 - val_loss: 1.0146 - val_acc: 0.4074\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0895 - acc: 0.4615 - val_loss: 1.0046 - val_acc: 0.4074\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0598 - acc: 0.4423 - val_loss: 0.9894 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0227 - acc: 0.4904 - val_loss: 0.9897 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0220 - acc: 0.4135 - val_loss: 1.0118 - val_acc: 0.4074\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0315 - acc: 0.4423 - val_loss: 1.0108 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0877 - acc: 0.4519 - val_loss: 1.0004 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1096 - acc: 0.4712 - val_loss: 0.9854 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0640 - acc: 0.4519 - val_loss: 0.9729 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0398 - acc: 0.4615 - val_loss: 0.9848 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0193 - acc: 0.4712 - val_loss: 0.9853 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0220 - acc: 0.4712 - val_loss: 0.9752 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0114 - acc: 0.4615 - val_loss: 0.9725 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 998us/sample - loss: 1.9565 - acc: 0.3846 - val_loss: 1.1023 - val_acc: 0.5556\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.4816 - acc: 0.4135 - val_loss: 1.1039 - val_acc: 0.5556\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.5438 - acc: 0.4038 - val_loss: 1.0791 - val_acc: 0.5185\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2902 - acc: 0.4327 - val_loss: 1.0764 - val_acc: 0.5926\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.9143 - acc: 0.4135 - val_loss: 1.0742 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1510 - acc: 0.4519 - val_loss: 1.0756 - val_acc: 0.5185\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.5437 - acc: 0.3654 - val_loss: 1.0564 - val_acc: 0.4074\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.3845 - acc: 0.4038 - val_loss: 1.0489 - val_acc: 0.2963\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.6860 - acc: 0.4231 - val_loss: 1.0337 - val_acc: 0.4444\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1806 - acc: 0.4423 - val_loss: 1.0070 - val_acc: 0.5185\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.3472 - acc: 0.3942 - val_loss: 1.0207 - val_acc: 0.5185\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.4572 - acc: 0.3750 - val_loss: 1.0253 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1844 - acc: 0.4135 - val_loss: 1.0127 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.2918 - acc: 0.3846 - val_loss: 1.0128 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.2695 - acc: 0.3462 - val_loss: 1.0063 - val_acc: 0.5185\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.1184 - acc: 0.4519 - val_loss: 1.0075 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 1.3827 - acc: 0.3365 - val_loss: 1.0195 - val_acc: 0.4444\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0527 - acc: 0.4135 - val_loss: 1.0114 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0153 - acc: 0.4519 - val_loss: 1.0133 - val_acc: 0.4074\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.5227 - acc: 0.4231 - val_loss: 1.0412 - val_acc: 0.3333\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.3257 - acc: 0.4712 - val_loss: 1.0374 - val_acc: 0.4444\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1804 - acc: 0.5192 - val_loss: 1.0420 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 2.0287 - acc: 0.4327 - val_loss: 1.0218 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1519 - acc: 0.4519 - val_loss: 1.0308 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.6674 - acc: 0.4423 - val_loss: 1.0190 - val_acc: 0.4815\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 287us/sample - loss: 1.0469 - acc: 0.4423 - val_loss: 1.0191 - val_acc: 0.4815\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0721 - acc: 0.4423 - val_loss: 1.0193 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0631 - acc: 0.4904 - val_loss: 1.0223 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0285 - acc: 0.4423 - val_loss: 1.0200 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0203 - acc: 0.4519 - val_loss: 1.0208 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1549 - acc: 0.4423 - val_loss: 1.0094 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0420 - acc: 0.4519 - val_loss: 1.0082 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.2841 - acc: 0.4904 - val_loss: 1.0008 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1724 - acc: 0.4808 - val_loss: 1.0193 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0439 - acc: 0.4327 - val_loss: 1.0167 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0475 - acc: 0.4519 - val_loss: 1.0160 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.2184 - acc: 0.4231 - val_loss: 1.0172 - val_acc: 0.4074\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0410 - acc: 0.4615 - val_loss: 1.0147 - val_acc: 0.4074\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0371 - acc: 0.4423 - val_loss: 1.0122 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.5156 - acc: 0.4904 - val_loss: 1.0087 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0070 - acc: 0.4808 - val_loss: 1.0112 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.2006 - acc: 0.4615 - val_loss: 1.0072 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.1429 - acc: 0.4712 - val_loss: 0.9982 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.1022 - acc: 0.4808 - val_loss: 0.9983 - val_acc: 0.4074\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0275 - acc: 0.4712 - val_loss: 0.9996 - val_acc: 0.4074\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0003 - acc: 0.4615 - val_loss: 0.9997 - val_acc: 0.4074\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0216 - acc: 0.4808 - val_loss: 1.0072 - val_acc: 0.4074\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.1488 - acc: 0.4808 - val_loss: 1.0088 - val_acc: 0.4074\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.1456 - acc: 0.4808 - val_loss: 1.0025 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0542 - acc: 0.4615 - val_loss: 1.0026 - val_acc: 0.4444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 70a76dc755caa36ef473dad5bf68a996</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5481481552124023</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.9</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.1455 - acc: 0.3365 - val_loss: 3.1898 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 3.0059 - acc: 0.3173 - val_loss: 2.8444 - val_acc: 0.3333\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 2.8434 - acc: 0.3269 - val_loss: 2.5241 - val_acc: 0.3333\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 2.2959 - acc: 0.3269 - val_loss: 2.3109 - val_acc: 0.3333\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 2.3322 - acc: 0.3558 - val_loss: 2.0738 - val_acc: 0.3333\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 2.0165 - acc: 0.3173 - val_loss: 1.9114 - val_acc: 0.3333\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.7680 - acc: 0.2788 - val_loss: 1.7879 - val_acc: 0.2963\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.7999 - acc: 0.2788 - val_loss: 1.6433 - val_acc: 0.2963\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.6247 - acc: 0.3269 - val_loss: 1.5503 - val_acc: 0.4074\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.3528 - acc: 0.3846 - val_loss: 1.5084 - val_acc: 0.4074\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.4746 - acc: 0.3269 - val_loss: 1.4411 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.4789 - acc: 0.3942 - val_loss: 1.3694 - val_acc: 0.4444\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.1961 - acc: 0.5000 - val_loss: 1.3430 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.2177 - acc: 0.4231 - val_loss: 1.3172 - val_acc: 0.4444\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1172 - acc: 0.4808 - val_loss: 1.2894 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1856 - acc: 0.5096 - val_loss: 1.2684 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0899 - acc: 0.4904 - val_loss: 1.2535 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1650 - acc: 0.4904 - val_loss: 1.2416 - val_acc: 0.4444\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0436 - acc: 0.4904 - val_loss: 1.2372 - val_acc: 0.4074\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1698 - acc: 0.4615 - val_loss: 1.2194 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1253 - acc: 0.4712 - val_loss: 1.2092 - val_acc: 0.4074\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0392 - acc: 0.5288 - val_loss: 1.2051 - val_acc: 0.4074\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0027 - acc: 0.5096 - val_loss: 1.2012 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9574 - acc: 0.5577 - val_loss: 1.2000 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0612 - acc: 0.5096 - val_loss: 1.1939 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0373 - acc: 0.5096 - val_loss: 1.1962 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0356 - acc: 0.4712 - val_loss: 1.1902 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9278 - acc: 0.5577 - val_loss: 1.1952 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0136 - acc: 0.5288 - val_loss: 1.1897 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0775 - acc: 0.5000 - val_loss: 1.1799 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9825 - acc: 0.5000 - val_loss: 1.1751 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0296 - acc: 0.5000 - val_loss: 1.1672 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0578 - acc: 0.5000 - val_loss: 1.1582 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9924 - acc: 0.5000 - val_loss: 1.1531 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0840 - acc: 0.4423 - val_loss: 1.1474 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0069 - acc: 0.5000 - val_loss: 1.1485 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0141 - acc: 0.4904 - val_loss: 1.1413 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0449 - acc: 0.4519 - val_loss: 1.1318 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9422 - acc: 0.5481 - val_loss: 1.1168 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9807 - acc: 0.5385 - val_loss: 1.1131 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9862 - acc: 0.5096 - val_loss: 1.1112 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9706 - acc: 0.5192 - val_loss: 1.1056 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0305 - acc: 0.4808 - val_loss: 1.1053 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9362 - acc: 0.5385 - val_loss: 1.1087 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0431 - acc: 0.4615 - val_loss: 1.1012 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0060 - acc: 0.4808 - val_loss: 1.0896 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9785 - acc: 0.5000 - val_loss: 1.0835 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9539 - acc: 0.5096 - val_loss: 1.0903 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9801 - acc: 0.4904 - val_loss: 1.0903 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0249 - acc: 0.5096 - val_loss: 1.0834 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.8644 - acc: 0.5096 - val_loss: 2.0089 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.7143 - acc: 0.4615 - val_loss: 1.8559 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.9048 - acc: 0.3654 - val_loss: 1.7044 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.7028 - acc: 0.4423 - val_loss: 1.6016 - val_acc: 0.3704\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.6956 - acc: 0.4327 - val_loss: 1.5026 - val_acc: 0.3704\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.5889 - acc: 0.4423 - val_loss: 1.4558 - val_acc: 0.3704\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.4012 - acc: 0.4327 - val_loss: 1.3812 - val_acc: 0.3704\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 1.5515 - acc: 0.3654 - val_loss: 1.3101 - val_acc: 0.3704\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.3712 - acc: 0.5000 - val_loss: 1.2588 - val_acc: 0.3704\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.2584 - acc: 0.4423 - val_loss: 1.2173 - val_acc: 0.3704\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.3213 - acc: 0.4423 - val_loss: 1.1857 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1572 - acc: 0.4712 - val_loss: 1.1674 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.2270 - acc: 0.5288 - val_loss: 1.1500 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.2920 - acc: 0.4712 - val_loss: 1.1375 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1071 - acc: 0.4808 - val_loss: 1.1193 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 1.0877 - acc: 0.4519 - val_loss: 1.1075 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.1851 - acc: 0.4712 - val_loss: 1.0956 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1515 - acc: 0.5096 - val_loss: 1.0912 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.1563 - acc: 0.5385 - val_loss: 1.0853 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.1015 - acc: 0.4615 - val_loss: 1.0774 - val_acc: 0.4815\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.1215 - acc: 0.5096 - val_loss: 1.0761 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1014 - acc: 0.4615 - val_loss: 1.0732 - val_acc: 0.5185\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 752us/sample - loss: 1.1652 - acc: 0.4615 - val_loss: 1.0628 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0765 - acc: 0.5000 - val_loss: 1.0581 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.0645 - acc: 0.4327 - val_loss: 1.0544 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1730 - acc: 0.4231 - val_loss: 1.0455 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.1587 - acc: 0.4712 - val_loss: 1.0449 - val_acc: 0.5556\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0982 - acc: 0.4519 - val_loss: 1.0445 - val_acc: 0.5556\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.1628 - acc: 0.4135 - val_loss: 1.0410 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9788 - acc: 0.5096 - val_loss: 1.0408 - val_acc: 0.5556\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.1590 - acc: 0.3846 - val_loss: 1.0361 - val_acc: 0.5926\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0225 - acc: 0.4808 - val_loss: 1.0347 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0741 - acc: 0.5096 - val_loss: 1.0290 - val_acc: 0.5556\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0740 - acc: 0.4712 - val_loss: 1.0302 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0846 - acc: 0.4231 - val_loss: 1.0285 - val_acc: 0.5926\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0363 - acc: 0.4904 - val_loss: 1.0287 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 426us/sample - loss: 1.0411 - acc: 0.4904 - val_loss: 1.0290 - val_acc: 0.5926\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0644 - acc: 0.4519 - val_loss: 1.0243 - val_acc: 0.5926\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1437 - acc: 0.4231 - val_loss: 1.0225 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9953 - acc: 0.4808 - val_loss: 1.0180 - val_acc: 0.5556\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0100 - acc: 0.4519 - val_loss: 1.0184 - val_acc: 0.5926\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0197 - acc: 0.5192 - val_loss: 1.0175 - val_acc: 0.5926\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0391 - acc: 0.5000 - val_loss: 1.0179 - val_acc: 0.5926\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.1247 - acc: 0.4615 - val_loss: 1.0166 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.1138 - acc: 0.5000 - val_loss: 1.0196 - val_acc: 0.5926\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 1.0317 - acc: 0.4904 - val_loss: 1.0246 - val_acc: 0.5926\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0349 - acc: 0.4615 - val_loss: 1.0253 - val_acc: 0.5926\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0197 - acc: 0.5096 - val_loss: 1.0233 - val_acc: 0.5926\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9933 - acc: 0.4904 - val_loss: 1.0239 - val_acc: 0.5926\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 418us/sample - loss: 1.0313 - acc: 0.4327 - val_loss: 1.0199 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 991us/sample - loss: 2.6060 - acc: 0.3942 - val_loss: 1.1443 - val_acc: 0.5926\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.9626 - acc: 0.4327 - val_loss: 1.2154 - val_acc: 0.5185\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 2.0423 - acc: 0.4808 - val_loss: 1.2154 - val_acc: 0.4815\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.9375 - acc: 0.3654 - val_loss: 1.2737 - val_acc: 0.4815\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.7824 - acc: 0.4615 - val_loss: 1.2599 - val_acc: 0.4815\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 2.1720 - acc: 0.4038 - val_loss: 1.2991 - val_acc: 0.5185\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.6908 - acc: 0.4615 - val_loss: 1.2742 - val_acc: 0.5185\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.8838 - acc: 0.3942 - val_loss: 1.2815 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.6698 - acc: 0.4519 - val_loss: 1.2838 - val_acc: 0.5185\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.3107 - acc: 0.4519 - val_loss: 1.3060 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.4538 - acc: 0.4615 - val_loss: 1.2806 - val_acc: 0.4815\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.6853 - acc: 0.4327 - val_loss: 1.2445 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.5678 - acc: 0.3846 - val_loss: 1.2647 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.5179 - acc: 0.4038 - val_loss: 1.2495 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.5188 - acc: 0.3750 - val_loss: 1.2450 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.2027 - acc: 0.4423 - val_loss: 1.2052 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.2947 - acc: 0.4423 - val_loss: 1.2074 - val_acc: 0.5556\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.4341 - acc: 0.4519 - val_loss: 1.2050 - val_acc: 0.5556\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.2979 - acc: 0.4327 - val_loss: 1.2243 - val_acc: 0.5185\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1607 - acc: 0.5000 - val_loss: 1.2024 - val_acc: 0.5556\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.2971 - acc: 0.4712 - val_loss: 1.2213 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1532 - acc: 0.5000 - val_loss: 1.1815 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.1738 - acc: 0.5288 - val_loss: 1.1874 - val_acc: 0.5185\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1475 - acc: 0.4904 - val_loss: 1.1980 - val_acc: 0.5185\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1819 - acc: 0.5288 - val_loss: 1.1759 - val_acc: 0.5185\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1821 - acc: 0.4423 - val_loss: 1.1542 - val_acc: 0.5556\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.2185 - acc: 0.5000 - val_loss: 1.1534 - val_acc: 0.5556\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 1.1896 - acc: 0.4712 - val_loss: 1.1646 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1093 - acc: 0.5673 - val_loss: 1.1554 - val_acc: 0.5556\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1310 - acc: 0.4712 - val_loss: 1.1277 - val_acc: 0.5556\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.2069 - acc: 0.5096 - val_loss: 1.1093 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1453 - acc: 0.4808 - val_loss: 1.1219 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1531 - acc: 0.4808 - val_loss: 1.1094 - val_acc: 0.5556\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0810 - acc: 0.5385 - val_loss: 1.1083 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 1.0197 - acc: 0.5096 - val_loss: 1.1099 - val_acc: 0.5556\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0721 - acc: 0.5192 - val_loss: 1.1004 - val_acc: 0.5556\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.1709 - acc: 0.4615 - val_loss: 1.0949 - val_acc: 0.5556\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1210 - acc: 0.5385 - val_loss: 1.0794 - val_acc: 0.5926\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0737 - acc: 0.5288 - val_loss: 1.0724 - val_acc: 0.5926\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0552 - acc: 0.5192 - val_loss: 1.0754 - val_acc: 0.5556\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 1.1238 - acc: 0.4615 - val_loss: 1.0574 - val_acc: 0.5926\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 732us/sample - loss: 1.0796 - acc: 0.5192 - val_loss: 1.0609 - val_acc: 0.6296\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1597 - acc: 0.4519 - val_loss: 1.0475 - val_acc: 0.6296\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.1382 - acc: 0.4423 - val_loss: 1.0481 - val_acc: 0.6296\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.0402 - acc: 0.5577 - val_loss: 1.0515 - val_acc: 0.5926\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.0242 - acc: 0.5385 - val_loss: 1.0591 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0545 - acc: 0.5481 - val_loss: 1.0566 - val_acc: 0.5926\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0127 - acc: 0.5673 - val_loss: 1.0475 - val_acc: 0.5926\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0160 - acc: 0.5385 - val_loss: 1.0513 - val_acc: 0.5926\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0530 - acc: 0.5192 - val_loss: 1.0469 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.8744 - acc: 0.2885 - val_loss: 2.6966 - val_acc: 0.4444\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 3.9019 - acc: 0.2981 - val_loss: 2.3841 - val_acc: 0.4815\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 3.3472 - acc: 0.3846 - val_loss: 2.1406 - val_acc: 0.4815\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 2.1061 - acc: 0.5000 - val_loss: 2.0351 - val_acc: 0.4815\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 2.7330 - acc: 0.3462 - val_loss: 1.8512 - val_acc: 0.4815\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 2.3976 - acc: 0.3750 - val_loss: 1.7271 - val_acc: 0.4815\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 2.1254 - acc: 0.3846 - val_loss: 1.6272 - val_acc: 0.5185\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.9990 - acc: 0.3654 - val_loss: 1.5337 - val_acc: 0.5185\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 2.0293 - acc: 0.3558 - val_loss: 1.4369 - val_acc: 0.5185\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.7906 - acc: 0.3077 - val_loss: 1.3619 - val_acc: 0.4444\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.5092 - acc: 0.4038 - val_loss: 1.2990 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.6010 - acc: 0.3462 - val_loss: 1.2410 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.4821 - acc: 0.3942 - val_loss: 1.2082 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.3119 - acc: 0.4231 - val_loss: 1.1876 - val_acc: 0.4444\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2517 - acc: 0.4519 - val_loss: 1.1747 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 549us/sample - loss: 1.3029 - acc: 0.4135 - val_loss: 1.1447 - val_acc: 0.4444\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.1944 - acc: 0.4519 - val_loss: 1.1348 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.2354 - acc: 0.5000 - val_loss: 1.1244 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.2432 - acc: 0.4327 - val_loss: 1.1253 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1861 - acc: 0.5288 - val_loss: 1.1257 - val_acc: 0.4444\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.2158 - acc: 0.4712 - val_loss: 1.1144 - val_acc: 0.4444\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 278us/sample - loss: 1.0686 - acc: 0.5192 - val_loss: 1.1042 - val_acc: 0.4444\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.1241 - acc: 0.4712 - val_loss: 1.1077 - val_acc: 0.4444\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.2345 - acc: 0.4327 - val_loss: 1.0939 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0456 - acc: 0.5481 - val_loss: 1.0958 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0740 - acc: 0.4327 - val_loss: 1.0942 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0328 - acc: 0.5385 - val_loss: 1.0896 - val_acc: 0.4444\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9606 - acc: 0.4615 - val_loss: 1.0902 - val_acc: 0.4444\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0567 - acc: 0.4904 - val_loss: 1.0810 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0356 - acc: 0.4615 - val_loss: 1.0809 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9985 - acc: 0.5000 - val_loss: 1.0866 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9833 - acc: 0.5192 - val_loss: 1.0895 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0324 - acc: 0.4808 - val_loss: 1.0901 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0670 - acc: 0.4615 - val_loss: 1.0817 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0656 - acc: 0.5000 - val_loss: 1.0699 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0425 - acc: 0.5385 - val_loss: 1.0768 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0918 - acc: 0.5385 - val_loss: 1.0711 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0794 - acc: 0.5000 - val_loss: 1.0670 - val_acc: 0.4444\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0651 - acc: 0.5288 - val_loss: 1.0686 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0529 - acc: 0.5000 - val_loss: 1.0752 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0085 - acc: 0.4712 - val_loss: 1.0763 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0365 - acc: 0.5673 - val_loss: 1.0763 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9711 - acc: 0.5288 - val_loss: 1.0826 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0122 - acc: 0.4712 - val_loss: 1.0699 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0522 - acc: 0.4615 - val_loss: 1.0679 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0566 - acc: 0.4904 - val_loss: 1.0662 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 413us/sample - loss: 1.0672 - acc: 0.4712 - val_loss: 1.0578 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0265 - acc: 0.4904 - val_loss: 1.0625 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0244 - acc: 0.4712 - val_loss: 1.0561 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9561 - acc: 0.5577 - val_loss: 1.0618 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 991us/sample - loss: 2.4115 - acc: 0.4712 - val_loss: 2.4539 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 2.0173 - acc: 0.4615 - val_loss: 2.2076 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.9711 - acc: 0.4327 - val_loss: 1.9885 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.6123 - acc: 0.4231 - val_loss: 1.8307 - val_acc: 0.3704\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.5502 - acc: 0.4135 - val_loss: 1.6610 - val_acc: 0.3704\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.4686 - acc: 0.4135 - val_loss: 1.5431 - val_acc: 0.3704\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.2784 - acc: 0.4808 - val_loss: 1.4848 - val_acc: 0.4074\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.2754 - acc: 0.5288 - val_loss: 1.4385 - val_acc: 0.4074\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.2563 - acc: 0.4712 - val_loss: 1.4120 - val_acc: 0.4444\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.2268 - acc: 0.4615 - val_loss: 1.3646 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.1166 - acc: 0.4712 - val_loss: 1.3325 - val_acc: 0.4815\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0859 - acc: 0.5096 - val_loss: 1.3092 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0980 - acc: 0.4615 - val_loss: 1.3130 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.2083 - acc: 0.3942 - val_loss: 1.2793 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0594 - acc: 0.4327 - val_loss: 1.2793 - val_acc: 0.4444\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.1182 - acc: 0.4519 - val_loss: 1.2330 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1804 - acc: 0.4135 - val_loss: 1.2171 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.1216 - acc: 0.4615 - val_loss: 1.2104 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0303 - acc: 0.5096 - val_loss: 1.2178 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0888 - acc: 0.4423 - val_loss: 1.2068 - val_acc: 0.4815\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0399 - acc: 0.4231 - val_loss: 1.2068 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.1016 - acc: 0.3750 - val_loss: 1.1909 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0262 - acc: 0.5385 - val_loss: 1.1874 - val_acc: 0.4815\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1330 - acc: 0.4423 - val_loss: 1.1674 - val_acc: 0.4815\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0027 - acc: 0.4808 - val_loss: 1.1849 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0379 - acc: 0.5096 - val_loss: 1.1716 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9846 - acc: 0.5385 - val_loss: 1.1657 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1478 - acc: 0.4231 - val_loss: 1.1441 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0702 - acc: 0.4231 - val_loss: 1.1458 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0204 - acc: 0.5000 - val_loss: 1.1603 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9783 - acc: 0.5288 - val_loss: 1.1560 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.0282 - acc: 0.5288 - val_loss: 1.1426 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0254 - acc: 0.4519 - val_loss: 1.1296 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0587 - acc: 0.4712 - val_loss: 1.1271 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0293 - acc: 0.4423 - val_loss: 1.1212 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0413 - acc: 0.4231 - val_loss: 1.1138 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9817 - acc: 0.5192 - val_loss: 1.1080 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0235 - acc: 0.4519 - val_loss: 1.1012 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0470 - acc: 0.3846 - val_loss: 1.0944 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0021 - acc: 0.5000 - val_loss: 1.0920 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0227 - acc: 0.4423 - val_loss: 1.0935 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 416us/sample - loss: 1.0125 - acc: 0.4519 - val_loss: 1.0952 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9350 - acc: 0.5288 - val_loss: 1.1005 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 0.9936 - acc: 0.4904 - val_loss: 1.1001 - val_acc: 0.4074\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9825 - acc: 0.4712 - val_loss: 1.0849 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0085 - acc: 0.4327 - val_loss: 1.0786 - val_acc: 0.5556\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9941 - acc: 0.4615 - val_loss: 1.0880 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0421 - acc: 0.4615 - val_loss: 1.0801 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.0302 - acc: 0.4712 - val_loss: 1.0722 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9501 - acc: 0.5192 - val_loss: 1.0893 - val_acc: 0.4444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: c1e8e0d1adee9f0a5080f32d0464147c</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5629629492759705</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.5</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.6813 - acc: 0.3750 - val_loss: 1.7853 - val_acc: 0.4444\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 2.5337 - acc: 0.3654 - val_loss: 1.6602 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 2.1974 - acc: 0.3846 - val_loss: 1.5766 - val_acc: 0.3704\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.8205 - acc: 0.3942 - val_loss: 1.5323 - val_acc: 0.4074\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.7184 - acc: 0.3846 - val_loss: 1.4920 - val_acc: 0.5185\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.8654 - acc: 0.3750 - val_loss: 1.4579 - val_acc: 0.5185\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.5050 - acc: 0.4038 - val_loss: 1.4359 - val_acc: 0.5185\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.4541 - acc: 0.4231 - val_loss: 1.4128 - val_acc: 0.5185\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 1.5338 - acc: 0.4327 - val_loss: 1.3940 - val_acc: 0.5185\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.6442 - acc: 0.3942 - val_loss: 1.3626 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.2297 - acc: 0.4615 - val_loss: 1.3642 - val_acc: 0.4815\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 442us/sample - loss: 1.4435 - acc: 0.5000 - val_loss: 1.3404 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 410us/sample - loss: 1.3202 - acc: 0.4808 - val_loss: 1.3228 - val_acc: 0.5185\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.2208 - acc: 0.4615 - val_loss: 1.2954 - val_acc: 0.5185\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1772 - acc: 0.4712 - val_loss: 1.3003 - val_acc: 0.5185\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.2973 - acc: 0.4519 - val_loss: 1.2804 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.2615 - acc: 0.5000 - val_loss: 1.2862 - val_acc: 0.5185\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.2043 - acc: 0.4231 - val_loss: 1.2763 - val_acc: 0.5185\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.2164 - acc: 0.4712 - val_loss: 1.2532 - val_acc: 0.5185\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 457us/sample - loss: 1.1422 - acc: 0.4615 - val_loss: 1.2301 - val_acc: 0.5556\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1056 - acc: 0.5000 - val_loss: 1.2081 - val_acc: 0.5556\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0216 - acc: 0.5000 - val_loss: 1.1890 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0625 - acc: 0.5192 - val_loss: 1.1967 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.2690 - acc: 0.4231 - val_loss: 1.1863 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 290us/sample - loss: 1.0578 - acc: 0.4231 - val_loss: 1.1816 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1456 - acc: 0.4423 - val_loss: 1.1835 - val_acc: 0.5556\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1027 - acc: 0.4615 - val_loss: 1.1815 - val_acc: 0.5556\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.2379 - acc: 0.3846 - val_loss: 1.1720 - val_acc: 0.5556\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.1192 - acc: 0.4135 - val_loss: 1.1661 - val_acc: 0.5926\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1213 - acc: 0.4904 - val_loss: 1.1642 - val_acc: 0.5556\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0567 - acc: 0.4712 - val_loss: 1.1685 - val_acc: 0.5556\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0680 - acc: 0.4423 - val_loss: 1.1725 - val_acc: 0.5926\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9890 - acc: 0.4712 - val_loss: 1.1775 - val_acc: 0.5556\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0628 - acc: 0.5096 - val_loss: 1.1647 - val_acc: 0.5556\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0829 - acc: 0.4712 - val_loss: 1.1535 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9992 - acc: 0.4423 - val_loss: 1.1553 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9921 - acc: 0.5288 - val_loss: 1.1597 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0815 - acc: 0.4904 - val_loss: 1.1727 - val_acc: 0.4444\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 1.0758 - acc: 0.4904 - val_loss: 1.1599 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 437us/sample - loss: 1.0560 - acc: 0.4712 - val_loss: 1.1514 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 421us/sample - loss: 1.0997 - acc: 0.4423 - val_loss: 1.1473 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0540 - acc: 0.4808 - val_loss: 1.1446 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0089 - acc: 0.5288 - val_loss: 1.1429 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0193 - acc: 0.4904 - val_loss: 1.1364 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0947 - acc: 0.3846 - val_loss: 1.1256 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9867 - acc: 0.5096 - val_loss: 1.1322 - val_acc: 0.4074\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9704 - acc: 0.4904 - val_loss: 1.1316 - val_acc: 0.4074\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9230 - acc: 0.5385 - val_loss: 1.1359 - val_acc: 0.4074\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0257 - acc: 0.5385 - val_loss: 1.1324 - val_acc: 0.4074\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9801 - acc: 0.4904 - val_loss: 1.1279 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1000us/sample - loss: 2.3485 - acc: 0.3558 - val_loss: 2.1001 - val_acc: 0.4444\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.9460 - acc: 0.5000 - val_loss: 1.9160 - val_acc: 0.4074\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 2.1964 - acc: 0.4423 - val_loss: 1.7194 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.5963 - acc: 0.4712 - val_loss: 1.6183 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.5715 - acc: 0.5288 - val_loss: 1.5283 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.7857 - acc: 0.4615 - val_loss: 1.4430 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.5735 - acc: 0.5096 - val_loss: 1.3920 - val_acc: 0.4444\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.6461 - acc: 0.4327 - val_loss: 1.3521 - val_acc: 0.4444\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.4945 - acc: 0.4615 - val_loss: 1.3197 - val_acc: 0.4444\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.2481 - acc: 0.5096 - val_loss: 1.2749 - val_acc: 0.4444\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.5753 - acc: 0.4712 - val_loss: 1.2464 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.3928 - acc: 0.4904 - val_loss: 1.2122 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.2972 - acc: 0.5385 - val_loss: 1.1920 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.5089 - acc: 0.4615 - val_loss: 1.1682 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 444us/sample - loss: 1.4799 - acc: 0.5096 - val_loss: 1.1420 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.3575 - acc: 0.4904 - val_loss: 1.1290 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.3728 - acc: 0.5192 - val_loss: 1.0993 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.3872 - acc: 0.4423 - val_loss: 1.0998 - val_acc: 0.5185\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.3087 - acc: 0.5000 - val_loss: 1.0756 - val_acc: 0.5185\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 282us/sample - loss: 1.1779 - acc: 0.4615 - val_loss: 1.0792 - val_acc: 0.5185\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.2450 - acc: 0.5000 - val_loss: 1.0684 - val_acc: 0.5185\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.2069 - acc: 0.5288 - val_loss: 1.0610 - val_acc: 0.5185\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1694 - acc: 0.4904 - val_loss: 1.0565 - val_acc: 0.5185\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1563 - acc: 0.5192 - val_loss: 1.0531 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.2150 - acc: 0.4327 - val_loss: 1.0419 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.1686 - acc: 0.5288 - val_loss: 1.0379 - val_acc: 0.5556\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.2244 - acc: 0.4615 - val_loss: 1.0247 - val_acc: 0.5926\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.2364 - acc: 0.4904 - val_loss: 1.0077 - val_acc: 0.5926\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.1230 - acc: 0.4712 - val_loss: 1.0007 - val_acc: 0.5926\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0865 - acc: 0.5288 - val_loss: 0.9855 - val_acc: 0.5926\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0914 - acc: 0.5000 - val_loss: 0.9819 - val_acc: 0.5926\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0300 - acc: 0.4808 - val_loss: 0.9847 - val_acc: 0.5926\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.1024 - acc: 0.4808 - val_loss: 0.9898 - val_acc: 0.5926\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0055 - acc: 0.4904 - val_loss: 0.9909 - val_acc: 0.5926\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0310 - acc: 0.5096 - val_loss: 0.9898 - val_acc: 0.5926\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9757 - acc: 0.5673 - val_loss: 0.9896 - val_acc: 0.5926\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.1630 - acc: 0.4808 - val_loss: 0.9887 - val_acc: 0.5556\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0018 - acc: 0.5288 - val_loss: 0.9847 - val_acc: 0.5926\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0300 - acc: 0.4808 - val_loss: 0.9826 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9758 - acc: 0.4904 - val_loss: 0.9736 - val_acc: 0.5926\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0719 - acc: 0.4423 - val_loss: 0.9733 - val_acc: 0.5926\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0085 - acc: 0.5000 - val_loss: 0.9783 - val_acc: 0.5926\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0440 - acc: 0.5385 - val_loss: 0.9771 - val_acc: 0.5556\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1089 - acc: 0.4519 - val_loss: 0.9722 - val_acc: 0.5556\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0320 - acc: 0.4808 - val_loss: 0.9736 - val_acc: 0.5556\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9949 - acc: 0.5288 - val_loss: 0.9716 - val_acc: 0.5926\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1033 - acc: 0.4327 - val_loss: 0.9812 - val_acc: 0.5556\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0111 - acc: 0.4904 - val_loss: 0.9793 - val_acc: 0.5556\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0618 - acc: 0.5000 - val_loss: 0.9735 - val_acc: 0.5556\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0365 - acc: 0.5385 - val_loss: 0.9744 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.1725 - acc: 0.3558 - val_loss: 1.9205 - val_acc: 0.2963\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 1.9409 - acc: 0.3654 - val_loss: 1.7686 - val_acc: 0.2963\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 2.1636 - acc: 0.3462 - val_loss: 1.6237 - val_acc: 0.3333\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.4859 - acc: 0.4712 - val_loss: 1.5716 - val_acc: 0.3704\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.5942 - acc: 0.4135 - val_loss: 1.4739 - val_acc: 0.4074\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.6743 - acc: 0.4423 - val_loss: 1.4134 - val_acc: 0.4074\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.6232 - acc: 0.3846 - val_loss: 1.3671 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.6656 - acc: 0.3846 - val_loss: 1.3360 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.6619 - acc: 0.3558 - val_loss: 1.3016 - val_acc: 0.4815\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.5181 - acc: 0.4615 - val_loss: 1.2701 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.4432 - acc: 0.4135 - val_loss: 1.2377 - val_acc: 0.4815\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.2483 - acc: 0.4519 - val_loss: 1.2136 - val_acc: 0.5185\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.4509 - acc: 0.3942 - val_loss: 1.1949 - val_acc: 0.5556\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.4282 - acc: 0.4904 - val_loss: 1.1714 - val_acc: 0.5556\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.2354 - acc: 0.5096 - val_loss: 1.1593 - val_acc: 0.5185\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.4003 - acc: 0.4808 - val_loss: 1.1385 - val_acc: 0.5185\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.3743 - acc: 0.5000 - val_loss: 1.1267 - val_acc: 0.5556\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.2852 - acc: 0.4808 - val_loss: 1.1159 - val_acc: 0.5556\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.2775 - acc: 0.4808 - val_loss: 1.1070 - val_acc: 0.5556\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.2457 - acc: 0.4712 - val_loss: 1.1000 - val_acc: 0.5556\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1472 - acc: 0.4904 - val_loss: 1.0925 - val_acc: 0.5185\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.3078 - acc: 0.4712 - val_loss: 1.0871 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1473 - acc: 0.5000 - val_loss: 1.0774 - val_acc: 0.5185\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1514 - acc: 0.4808 - val_loss: 1.0686 - val_acc: 0.5185\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2101 - acc: 0.5288 - val_loss: 1.0608 - val_acc: 0.5185\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.1603 - acc: 0.5000 - val_loss: 1.0507 - val_acc: 0.5185\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1733 - acc: 0.5096 - val_loss: 1.0427 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1309 - acc: 0.5385 - val_loss: 1.0366 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0808 - acc: 0.4615 - val_loss: 1.0352 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1247 - acc: 0.5192 - val_loss: 1.0319 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1279 - acc: 0.5192 - val_loss: 1.0274 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1153 - acc: 0.5673 - val_loss: 1.0235 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.2412 - acc: 0.4808 - val_loss: 1.0179 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1688 - acc: 0.5096 - val_loss: 1.0136 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.1153 - acc: 0.5673 - val_loss: 1.0108 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1259 - acc: 0.5288 - val_loss: 1.0074 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.1294 - acc: 0.5192 - val_loss: 1.0063 - val_acc: 0.4444\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 432us/sample - loss: 1.0488 - acc: 0.5096 - val_loss: 1.0030 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.1504 - acc: 0.4904 - val_loss: 0.9994 - val_acc: 0.5185\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1277 - acc: 0.5385 - val_loss: 0.9974 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1415 - acc: 0.5769 - val_loss: 0.9964 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.1503 - acc: 0.5288 - val_loss: 0.9946 - val_acc: 0.5556\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0500 - acc: 0.4712 - val_loss: 0.9922 - val_acc: 0.5556\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0483 - acc: 0.5000 - val_loss: 0.9924 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0398 - acc: 0.5192 - val_loss: 0.9910 - val_acc: 0.5185\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0234 - acc: 0.5673 - val_loss: 0.9883 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0465 - acc: 0.5673 - val_loss: 0.9877 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0520 - acc: 0.5096 - val_loss: 0.9868 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.0231 - acc: 0.5673 - val_loss: 0.9861 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.0357 - acc: 0.5288 - val_loss: 0.9837 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 994us/sample - loss: 3.4394 - acc: 0.1827 - val_loss: 2.8508 - val_acc: 0.2222\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 2.5080 - acc: 0.2596 - val_loss: 2.5620 - val_acc: 0.2222\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 2.4581 - acc: 0.2115 - val_loss: 2.2831 - val_acc: 0.2593\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 2.1298 - acc: 0.3077 - val_loss: 2.1116 - val_acc: 0.2963\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 2.0488 - acc: 0.2404 - val_loss: 1.9714 - val_acc: 0.2963\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.9930 - acc: 0.2308 - val_loss: 1.8116 - val_acc: 0.3333\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.7738 - acc: 0.3077 - val_loss: 1.6895 - val_acc: 0.2963\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.8717 - acc: 0.3173 - val_loss: 1.5761 - val_acc: 0.3704\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.5259 - acc: 0.3654 - val_loss: 1.4860 - val_acc: 0.4444\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.4114 - acc: 0.3846 - val_loss: 1.4243 - val_acc: 0.4444\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.5123 - acc: 0.3750 - val_loss: 1.3551 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.3452 - acc: 0.4231 - val_loss: 1.3175 - val_acc: 0.4444\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.4205 - acc: 0.4423 - val_loss: 1.2715 - val_acc: 0.4444\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.2955 - acc: 0.4231 - val_loss: 1.2317 - val_acc: 0.4074\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.3838 - acc: 0.3654 - val_loss: 1.2064 - val_acc: 0.3704\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.2664 - acc: 0.3846 - val_loss: 1.1766 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 417us/sample - loss: 1.2149 - acc: 0.4135 - val_loss: 1.1534 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.2558 - acc: 0.3750 - val_loss: 1.1368 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1973 - acc: 0.4135 - val_loss: 1.1155 - val_acc: 0.3704\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.2434 - acc: 0.3846 - val_loss: 1.0971 - val_acc: 0.3704\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.2355 - acc: 0.4231 - val_loss: 1.0870 - val_acc: 0.3704\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1774 - acc: 0.4423 - val_loss: 1.0773 - val_acc: 0.3704\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.1208 - acc: 0.5096 - val_loss: 1.0643 - val_acc: 0.3704\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0157 - acc: 0.6058 - val_loss: 1.0561 - val_acc: 0.3704\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0934 - acc: 0.5096 - val_loss: 1.0492 - val_acc: 0.3704\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0751 - acc: 0.5096 - val_loss: 1.0406 - val_acc: 0.3704\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.1490 - acc: 0.4519 - val_loss: 1.0358 - val_acc: 0.4074\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0733 - acc: 0.5192 - val_loss: 1.0310 - val_acc: 0.3704\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0438 - acc: 0.4904 - val_loss: 1.0223 - val_acc: 0.4074\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1450 - acc: 0.4327 - val_loss: 1.0224 - val_acc: 0.4074\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0736 - acc: 0.4712 - val_loss: 1.0156 - val_acc: 0.4074\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.1153 - acc: 0.4327 - val_loss: 1.0119 - val_acc: 0.4074\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1279 - acc: 0.4712 - val_loss: 1.0068 - val_acc: 0.3704\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0962 - acc: 0.4904 - val_loss: 1.0076 - val_acc: 0.3704\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0557 - acc: 0.4423 - val_loss: 1.0060 - val_acc: 0.3704\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9850 - acc: 0.5000 - val_loss: 1.0071 - val_acc: 0.4074\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0137 - acc: 0.5000 - val_loss: 1.0047 - val_acc: 0.3704\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0213 - acc: 0.5192 - val_loss: 1.0049 - val_acc: 0.3333\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 1.0293 - acc: 0.5096 - val_loss: 1.0074 - val_acc: 0.4074\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0053 - acc: 0.4808 - val_loss: 1.0014 - val_acc: 0.4074\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0228 - acc: 0.5385 - val_loss: 0.9971 - val_acc: 0.3704\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0759 - acc: 0.4904 - val_loss: 0.9926 - val_acc: 0.3333\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.0282 - acc: 0.5481 - val_loss: 0.9946 - val_acc: 0.3704\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0217 - acc: 0.4808 - val_loss: 0.9928 - val_acc: 0.3704\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0265 - acc: 0.5096 - val_loss: 0.9902 - val_acc: 0.3333\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0191 - acc: 0.5288 - val_loss: 0.9871 - val_acc: 0.3333\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0008 - acc: 0.5096 - val_loss: 0.9863 - val_acc: 0.3333\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0136 - acc: 0.5577 - val_loss: 0.9862 - val_acc: 0.3333\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0466 - acc: 0.5000 - val_loss: 0.9856 - val_acc: 0.3333\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0391 - acc: 0.4615 - val_loss: 0.9878 - val_acc: 0.2963\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 974us/sample - loss: 2.2101 - acc: 0.4712 - val_loss: 2.7665 - val_acc: 0.4815\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 2.1154 - acc: 0.4712 - val_loss: 2.5407 - val_acc: 0.4074\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.8535 - acc: 0.4327 - val_loss: 2.3464 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.8050 - acc: 0.4712 - val_loss: 2.1411 - val_acc: 0.4074\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.7555 - acc: 0.4808 - val_loss: 1.9687 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.3699 - acc: 0.4327 - val_loss: 1.8814 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.5269 - acc: 0.4712 - val_loss: 1.7449 - val_acc: 0.4444\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.2234 - acc: 0.4808 - val_loss: 1.6845 - val_acc: 0.3704\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.1936 - acc: 0.4904 - val_loss: 1.6348 - val_acc: 0.3704\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.3985 - acc: 0.4615 - val_loss: 1.5270 - val_acc: 0.3704\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.3923 - acc: 0.5000 - val_loss: 1.4341 - val_acc: 0.3704\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.2797 - acc: 0.5096 - val_loss: 1.3747 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1693 - acc: 0.5096 - val_loss: 1.3131 - val_acc: 0.4074\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.1722 - acc: 0.5385 - val_loss: 1.2735 - val_acc: 0.4074\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1519 - acc: 0.5000 - val_loss: 1.2386 - val_acc: 0.4074\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1896 - acc: 0.3942 - val_loss: 1.1917 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.1713 - acc: 0.4327 - val_loss: 1.1453 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.1116 - acc: 0.4615 - val_loss: 1.1203 - val_acc: 0.4444\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0203 - acc: 0.5096 - val_loss: 1.1001 - val_acc: 0.4444\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1044 - acc: 0.4423 - val_loss: 1.0807 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0176 - acc: 0.4615 - val_loss: 1.0651 - val_acc: 0.4444\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0860 - acc: 0.4519 - val_loss: 1.0448 - val_acc: 0.4444\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0905 - acc: 0.4327 - val_loss: 1.0258 - val_acc: 0.4444\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0288 - acc: 0.4327 - val_loss: 1.0162 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0309 - acc: 0.4519 - val_loss: 1.0137 - val_acc: 0.4444\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0246 - acc: 0.4615 - val_loss: 1.0139 - val_acc: 0.4444\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0441 - acc: 0.4231 - val_loss: 0.9989 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0290 - acc: 0.5000 - val_loss: 0.9962 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0315 - acc: 0.4423 - val_loss: 0.9960 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9835 - acc: 0.5192 - val_loss: 0.9971 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0172 - acc: 0.4519 - val_loss: 0.9941 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 429us/sample - loss: 1.0055 - acc: 0.4615 - val_loss: 0.9909 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9893 - acc: 0.4615 - val_loss: 0.9900 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0294 - acc: 0.4712 - val_loss: 0.9878 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 411us/sample - loss: 1.0045 - acc: 0.4615 - val_loss: 0.9907 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 0.9840 - acc: 0.4808 - val_loss: 0.9901 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0293 - acc: 0.4712 - val_loss: 0.9896 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9415 - acc: 0.5096 - val_loss: 0.9901 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9883 - acc: 0.4519 - val_loss: 0.9916 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9774 - acc: 0.4712 - val_loss: 0.9948 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 288us/sample - loss: 0.9995 - acc: 0.4519 - val_loss: 0.9937 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0241 - acc: 0.4423 - val_loss: 0.9939 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0570 - acc: 0.4712 - val_loss: 0.9955 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9751 - acc: 0.4135 - val_loss: 0.9928 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9531 - acc: 0.4904 - val_loss: 0.9962 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 0.9926 - acc: 0.4519 - val_loss: 0.9938 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0248 - acc: 0.4519 - val_loss: 0.9949 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0129 - acc: 0.4808 - val_loss: 0.9992 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9990 - acc: 0.5000 - val_loss: 1.0051 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0444 - acc: 0.4808 - val_loss: 1.0037 - val_acc: 0.4815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: cade6f3196f7fe91bd3e1e3ff23cde72</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5481481552124023</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.0055 - acc: 0.4038 - val_loss: 1.9034 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.6259 - acc: 0.4519 - val_loss: 1.7676 - val_acc: 0.3333\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.6222 - acc: 0.4423 - val_loss: 1.6436 - val_acc: 0.3333\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.4996 - acc: 0.4808 - val_loss: 1.5644 - val_acc: 0.3333\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.3451 - acc: 0.4712 - val_loss: 1.5162 - val_acc: 0.3704\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 1.3064 - acc: 0.4808 - val_loss: 1.4859 - val_acc: 0.4074\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 441us/sample - loss: 1.2836 - acc: 0.5577 - val_loss: 1.4560 - val_acc: 0.4444\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.2276 - acc: 0.5481 - val_loss: 1.4329 - val_acc: 0.4444\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1891 - acc: 0.5096 - val_loss: 1.4250 - val_acc: 0.4444\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.1732 - acc: 0.5288 - val_loss: 1.4029 - val_acc: 0.4444\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1591 - acc: 0.5385 - val_loss: 1.3814 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1382 - acc: 0.5192 - val_loss: 1.3601 - val_acc: 0.4444\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.1408 - acc: 0.5192 - val_loss: 1.3460 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0558 - acc: 0.5385 - val_loss: 1.3292 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0717 - acc: 0.5288 - val_loss: 1.3176 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0737 - acc: 0.5577 - val_loss: 1.3037 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0713 - acc: 0.5288 - val_loss: 1.2897 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0717 - acc: 0.5385 - val_loss: 1.2756 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 1.0617 - acc: 0.5288 - val_loss: 1.2649 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0425 - acc: 0.5288 - val_loss: 1.2516 - val_acc: 0.4815\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0405 - acc: 0.5288 - val_loss: 1.2471 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0184 - acc: 0.5673 - val_loss: 1.2378 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0006 - acc: 0.5481 - val_loss: 1.2260 - val_acc: 0.4815\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0765 - acc: 0.5288 - val_loss: 1.2135 - val_acc: 0.4815\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9925 - acc: 0.5385 - val_loss: 1.2070 - val_acc: 0.4815\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0270 - acc: 0.5385 - val_loss: 1.1971 - val_acc: 0.4815\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9855 - acc: 0.5577 - val_loss: 1.1914 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0184 - acc: 0.5385 - val_loss: 1.1845 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9779 - acc: 0.5385 - val_loss: 1.1827 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9764 - acc: 0.5385 - val_loss: 1.1766 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9873 - acc: 0.5577 - val_loss: 1.1687 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9938 - acc: 0.5385 - val_loss: 1.1616 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9935 - acc: 0.5288 - val_loss: 1.1613 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9650 - acc: 0.5577 - val_loss: 1.1643 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9989 - acc: 0.5577 - val_loss: 1.1686 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9693 - acc: 0.5385 - val_loss: 1.1658 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9852 - acc: 0.5385 - val_loss: 1.1571 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9625 - acc: 0.5385 - val_loss: 1.1512 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9880 - acc: 0.5288 - val_loss: 1.1475 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9950 - acc: 0.5192 - val_loss: 1.1540 - val_acc: 0.4074\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9811 - acc: 0.5385 - val_loss: 1.1487 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9867 - acc: 0.5385 - val_loss: 1.1444 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9594 - acc: 0.5577 - val_loss: 1.1397 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9715 - acc: 0.5192 - val_loss: 1.1423 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9763 - acc: 0.5481 - val_loss: 1.1393 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9690 - acc: 0.5385 - val_loss: 1.1350 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 485us/sample - loss: 0.9792 - acc: 0.5192 - val_loss: 1.1319 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9609 - acc: 0.5288 - val_loss: 1.1331 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9836 - acc: 0.5288 - val_loss: 1.1274 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9448 - acc: 0.5673 - val_loss: 1.1227 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 995us/sample - loss: 2.2103 - acc: 0.3462 - val_loss: 2.0836 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.8807 - acc: 0.3462 - val_loss: 1.9607 - val_acc: 0.3704\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 2.2057 - acc: 0.3173 - val_loss: 1.8510 - val_acc: 0.4074\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 2.0310 - acc: 0.3269 - val_loss: 1.7614 - val_acc: 0.4074\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.6947 - acc: 0.4135 - val_loss: 1.6697 - val_acc: 0.4074\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.7362 - acc: 0.3654 - val_loss: 1.5957 - val_acc: 0.4074\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.7602 - acc: 0.3077 - val_loss: 1.5233 - val_acc: 0.4074\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.5811 - acc: 0.4038 - val_loss: 1.4723 - val_acc: 0.4074\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.5408 - acc: 0.3942 - val_loss: 1.4214 - val_acc: 0.3704\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.4662 - acc: 0.3942 - val_loss: 1.3615 - val_acc: 0.4074\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.4780 - acc: 0.3462 - val_loss: 1.3240 - val_acc: 0.4074\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.4761 - acc: 0.3365 - val_loss: 1.3018 - val_acc: 0.4074\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.4157 - acc: 0.3654 - val_loss: 1.2771 - val_acc: 0.4074\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.4019 - acc: 0.3462 - val_loss: 1.2441 - val_acc: 0.4074\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.2310 - acc: 0.4327 - val_loss: 1.2287 - val_acc: 0.4074\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.2346 - acc: 0.3654 - val_loss: 1.2005 - val_acc: 0.4074\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1703 - acc: 0.4231 - val_loss: 1.1840 - val_acc: 0.4074\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2902 - acc: 0.3846 - val_loss: 1.1681 - val_acc: 0.4074\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.2554 - acc: 0.3942 - val_loss: 1.1510 - val_acc: 0.3704\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.2409 - acc: 0.3558 - val_loss: 1.1286 - val_acc: 0.3704\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1444 - acc: 0.4135 - val_loss: 1.1116 - val_acc: 0.3704\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 421us/sample - loss: 1.1583 - acc: 0.4135 - val_loss: 1.1051 - val_acc: 0.4074\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1532 - acc: 0.4519 - val_loss: 1.0922 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1791 - acc: 0.3942 - val_loss: 1.0844 - val_acc: 0.4444\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0815 - acc: 0.4135 - val_loss: 1.0743 - val_acc: 0.4074\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1271 - acc: 0.4135 - val_loss: 1.0644 - val_acc: 0.3704\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1367 - acc: 0.3558 - val_loss: 1.0590 - val_acc: 0.4074\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0952 - acc: 0.4327 - val_loss: 1.0565 - val_acc: 0.4074\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0891 - acc: 0.4038 - val_loss: 1.0529 - val_acc: 0.4074\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0882 - acc: 0.4038 - val_loss: 1.0491 - val_acc: 0.4074\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1082 - acc: 0.4423 - val_loss: 1.0436 - val_acc: 0.3704\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.1260 - acc: 0.4038 - val_loss: 1.0383 - val_acc: 0.4074\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0479 - acc: 0.4519 - val_loss: 1.0345 - val_acc: 0.4074\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0487 - acc: 0.4423 - val_loss: 1.0374 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 1.0426 - acc: 0.4231 - val_loss: 1.0350 - val_acc: 0.3333\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0550 - acc: 0.3750 - val_loss: 1.0292 - val_acc: 0.3333\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0605 - acc: 0.4135 - val_loss: 1.0269 - val_acc: 0.3333\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0378 - acc: 0.4231 - val_loss: 1.0254 - val_acc: 0.4074\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0493 - acc: 0.4327 - val_loss: 1.0221 - val_acc: 0.4444\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.0413 - acc: 0.4808 - val_loss: 1.0232 - val_acc: 0.4444\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0240 - acc: 0.4038 - val_loss: 1.0192 - val_acc: 0.4444\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0084 - acc: 0.4519 - val_loss: 1.0166 - val_acc: 0.4444\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0288 - acc: 0.3846 - val_loss: 1.0104 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0329 - acc: 0.4231 - val_loss: 1.0046 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0332 - acc: 0.4519 - val_loss: 1.0034 - val_acc: 0.4444\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 280us/sample - loss: 1.0289 - acc: 0.4327 - val_loss: 0.9997 - val_acc: 0.4444\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0367 - acc: 0.3942 - val_loss: 0.9954 - val_acc: 0.4444\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9908 - acc: 0.4519 - val_loss: 0.9953 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 282us/sample - loss: 0.9952 - acc: 0.4135 - val_loss: 0.9926 - val_acc: 0.4444\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 279us/sample - loss: 0.9906 - acc: 0.4519 - val_loss: 0.9885 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 970us/sample - loss: 2.2880 - acc: 0.2115 - val_loss: 1.7781 - val_acc: 0.2222\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.7846 - acc: 0.3077 - val_loss: 1.6153 - val_acc: 0.2222\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.6188 - acc: 0.2788 - val_loss: 1.5143 - val_acc: 0.1852\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.5151 - acc: 0.2788 - val_loss: 1.4395 - val_acc: 0.1852\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2906 - acc: 0.3365 - val_loss: 1.3984 - val_acc: 0.1852\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.3037 - acc: 0.3365 - val_loss: 1.3593 - val_acc: 0.2222\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.2779 - acc: 0.3846 - val_loss: 1.3286 - val_acc: 0.2222\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.2337 - acc: 0.4038 - val_loss: 1.3015 - val_acc: 0.2222\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.1701 - acc: 0.4423 - val_loss: 1.2803 - val_acc: 0.2963\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.1053 - acc: 0.4712 - val_loss: 1.2671 - val_acc: 0.2963\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1835 - acc: 0.4135 - val_loss: 1.2502 - val_acc: 0.3333\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1272 - acc: 0.4615 - val_loss: 1.2376 - val_acc: 0.3333\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1064 - acc: 0.4615 - val_loss: 1.2323 - val_acc: 0.3333\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0807 - acc: 0.4712 - val_loss: 1.2265 - val_acc: 0.3333\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0867 - acc: 0.5096 - val_loss: 1.2144 - val_acc: 0.3333\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0636 - acc: 0.5000 - val_loss: 1.2099 - val_acc: 0.3333\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0929 - acc: 0.4615 - val_loss: 1.2017 - val_acc: 0.3704\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.0484 - acc: 0.4712 - val_loss: 1.2031 - val_acc: 0.3333\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0315 - acc: 0.5481 - val_loss: 1.2016 - val_acc: 0.3333\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0492 - acc: 0.4712 - val_loss: 1.1961 - val_acc: 0.4074\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0554 - acc: 0.5096 - val_loss: 1.1939 - val_acc: 0.3704\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0294 - acc: 0.5288 - val_loss: 1.1895 - val_acc: 0.3704\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9880 - acc: 0.5481 - val_loss: 1.1918 - val_acc: 0.4074\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0209 - acc: 0.5481 - val_loss: 1.1894 - val_acc: 0.4074\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0353 - acc: 0.4904 - val_loss: 1.1869 - val_acc: 0.4074\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0543 - acc: 0.4904 - val_loss: 1.1816 - val_acc: 0.3704\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9847 - acc: 0.5385 - val_loss: 1.1794 - val_acc: 0.3704\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0499 - acc: 0.4808 - val_loss: 1.1782 - val_acc: 0.3704\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9854 - acc: 0.5288 - val_loss: 1.1783 - val_acc: 0.3704\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0136 - acc: 0.4904 - val_loss: 1.1765 - val_acc: 0.3704\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9952 - acc: 0.5385 - val_loss: 1.1762 - val_acc: 0.3704\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9980 - acc: 0.5385 - val_loss: 1.1765 - val_acc: 0.4074\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 0.9855 - acc: 0.5481 - val_loss: 1.1758 - val_acc: 0.3704\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0229 - acc: 0.4904 - val_loss: 1.1709 - val_acc: 0.4074\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9847 - acc: 0.5096 - val_loss: 1.1712 - val_acc: 0.4074\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9649 - acc: 0.5673 - val_loss: 1.1709 - val_acc: 0.4074\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 0.9602 - acc: 0.5192 - val_loss: 1.1682 - val_acc: 0.4074\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0060 - acc: 0.5000 - val_loss: 1.1646 - val_acc: 0.4074\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9733 - acc: 0.5288 - val_loss: 1.1642 - val_acc: 0.4074\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9697 - acc: 0.5385 - val_loss: 1.1640 - val_acc: 0.4074\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9497 - acc: 0.5481 - val_loss: 1.1655 - val_acc: 0.4074\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0327 - acc: 0.4808 - val_loss: 1.1609 - val_acc: 0.4074\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9522 - acc: 0.5288 - val_loss: 1.1622 - val_acc: 0.4074\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9487 - acc: 0.5481 - val_loss: 1.1635 - val_acc: 0.4444\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9284 - acc: 0.5962 - val_loss: 1.1666 - val_acc: 0.4074\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9421 - acc: 0.5577 - val_loss: 1.1675 - val_acc: 0.4074\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9698 - acc: 0.5288 - val_loss: 1.1648 - val_acc: 0.4074\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 420us/sample - loss: 0.9840 - acc: 0.4808 - val_loss: 1.1598 - val_acc: 0.4444\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9391 - acc: 0.5673 - val_loss: 1.1614 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9760 - acc: 0.5096 - val_loss: 1.1601 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.0318 - acc: 0.4231 - val_loss: 1.8632 - val_acc: 0.3704\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 677us/sample - loss: 1.8627 - acc: 0.4712 - val_loss: 1.6903 - val_acc: 0.5556\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.6649 - acc: 0.4904 - val_loss: 1.5591 - val_acc: 0.5185\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.5495 - acc: 0.4904 - val_loss: 1.4571 - val_acc: 0.5185\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 287us/sample - loss: 1.4257 - acc: 0.5288 - val_loss: 1.3902 - val_acc: 0.5185\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.3670 - acc: 0.5385 - val_loss: 1.3172 - val_acc: 0.5185\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.3263 - acc: 0.5577 - val_loss: 1.2633 - val_acc: 0.5185\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2243 - acc: 0.5577 - val_loss: 1.2100 - val_acc: 0.5185\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.2004 - acc: 0.5577 - val_loss: 1.1603 - val_acc: 0.5185\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.1915 - acc: 0.5288 - val_loss: 1.1295 - val_acc: 0.5185\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1827 - acc: 0.5000 - val_loss: 1.0949 - val_acc: 0.5185\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1011 - acc: 0.5385 - val_loss: 1.0774 - val_acc: 0.5556\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0722 - acc: 0.5673 - val_loss: 1.0676 - val_acc: 0.5556\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0671 - acc: 0.5385 - val_loss: 1.0580 - val_acc: 0.5556\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0688 - acc: 0.5000 - val_loss: 1.0447 - val_acc: 0.5556\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0431 - acc: 0.5481 - val_loss: 1.0459 - val_acc: 0.5556\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0794 - acc: 0.5000 - val_loss: 1.0422 - val_acc: 0.5556\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9967 - acc: 0.5481 - val_loss: 1.0590 - val_acc: 0.5556\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9969 - acc: 0.5385 - val_loss: 1.0486 - val_acc: 0.5556\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0412 - acc: 0.5481 - val_loss: 1.0471 - val_acc: 0.5556\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 0.9387 - acc: 0.5673 - val_loss: 1.0586 - val_acc: 0.5556\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9891 - acc: 0.5385 - val_loss: 1.0614 - val_acc: 0.5556\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0183 - acc: 0.5192 - val_loss: 1.0553 - val_acc: 0.5556\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9721 - acc: 0.5577 - val_loss: 1.0498 - val_acc: 0.5556\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9675 - acc: 0.5288 - val_loss: 1.0481 - val_acc: 0.5556\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 0.9526 - acc: 0.5288 - val_loss: 1.0567 - val_acc: 0.5926\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0169 - acc: 0.4904 - val_loss: 1.0632 - val_acc: 0.5185\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0553 - acc: 0.5192 - val_loss: 1.0587 - val_acc: 0.5185\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9799 - acc: 0.5481 - val_loss: 1.0593 - val_acc: 0.5185\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 0.9479 - acc: 0.5288 - val_loss: 1.0609 - val_acc: 0.5185\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0331 - acc: 0.5096 - val_loss: 1.0545 - val_acc: 0.5926\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9796 - acc: 0.5288 - val_loss: 1.0620 - val_acc: 0.5185\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9934 - acc: 0.5577 - val_loss: 1.0677 - val_acc: 0.5185\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9757 - acc: 0.5385 - val_loss: 1.0605 - val_acc: 0.5185\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9577 - acc: 0.5481 - val_loss: 1.0713 - val_acc: 0.5185\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9798 - acc: 0.5673 - val_loss: 1.0744 - val_acc: 0.5185\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9838 - acc: 0.5769 - val_loss: 1.0695 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9348 - acc: 0.5769 - val_loss: 1.0676 - val_acc: 0.5185\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9510 - acc: 0.5577 - val_loss: 1.0657 - val_acc: 0.5185\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0234 - acc: 0.5577 - val_loss: 1.0669 - val_acc: 0.5185\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9827 - acc: 0.5481 - val_loss: 1.0612 - val_acc: 0.5185\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9693 - acc: 0.5673 - val_loss: 1.0575 - val_acc: 0.5185\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9840 - acc: 0.5481 - val_loss: 1.0698 - val_acc: 0.5185\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9875 - acc: 0.5192 - val_loss: 1.0713 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0123 - acc: 0.5288 - val_loss: 1.0904 - val_acc: 0.5185\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9558 - acc: 0.5769 - val_loss: 1.0938 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9486 - acc: 0.5192 - val_loss: 1.0861 - val_acc: 0.5185\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0254 - acc: 0.5000 - val_loss: 1.0845 - val_acc: 0.5185\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9803 - acc: 0.5673 - val_loss: 1.0821 - val_acc: 0.5185\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9841 - acc: 0.5288 - val_loss: 1.0797 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.4389 - acc: 0.3077 - val_loss: 2.3223 - val_acc: 0.2963\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 2.8527 - acc: 0.3365 - val_loss: 2.0986 - val_acc: 0.3333\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 2.6636 - acc: 0.3558 - val_loss: 1.9077 - val_acc: 0.2963\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 2.5526 - acc: 0.3462 - val_loss: 1.7571 - val_acc: 0.2593\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 2.3517 - acc: 0.3462 - val_loss: 1.6338 - val_acc: 0.2593\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 2.1403 - acc: 0.3654 - val_loss: 1.5369 - val_acc: 0.2593\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.9251 - acc: 0.3558 - val_loss: 1.4604 - val_acc: 0.2963\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.8072 - acc: 0.3558 - val_loss: 1.3970 - val_acc: 0.2963\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.7053 - acc: 0.3462 - val_loss: 1.3433 - val_acc: 0.2963\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 284us/sample - loss: 1.4942 - acc: 0.3846 - val_loss: 1.3064 - val_acc: 0.2593\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.4897 - acc: 0.3558 - val_loss: 1.2734 - val_acc: 0.2963\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.4386 - acc: 0.3846 - val_loss: 1.2438 - val_acc: 0.2963\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 1.4088 - acc: 0.3558 - val_loss: 1.2175 - val_acc: 0.2963\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.3964 - acc: 0.3654 - val_loss: 1.1923 - val_acc: 0.2963\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.3046 - acc: 0.3558 - val_loss: 1.1736 - val_acc: 0.3333\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 421us/sample - loss: 1.2864 - acc: 0.3365 - val_loss: 1.1562 - val_acc: 0.3333\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.2323 - acc: 0.3654 - val_loss: 1.1418 - val_acc: 0.3333\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.2586 - acc: 0.3365 - val_loss: 1.1271 - val_acc: 0.3333\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2562 - acc: 0.3077 - val_loss: 1.1135 - val_acc: 0.3704\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.2035 - acc: 0.3269 - val_loss: 1.1023 - val_acc: 0.3704\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1726 - acc: 0.4135 - val_loss: 1.0942 - val_acc: 0.3704\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1433 - acc: 0.4135 - val_loss: 1.0858 - val_acc: 0.3704\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.1254 - acc: 0.4135 - val_loss: 1.0788 - val_acc: 0.3333\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0710 - acc: 0.4327 - val_loss: 1.0734 - val_acc: 0.3333\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0909 - acc: 0.4327 - val_loss: 1.0677 - val_acc: 0.3704\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0887 - acc: 0.4135 - val_loss: 1.0623 - val_acc: 0.4074\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0906 - acc: 0.4327 - val_loss: 1.0569 - val_acc: 0.4074\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0840 - acc: 0.4135 - val_loss: 1.0523 - val_acc: 0.4074\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0820 - acc: 0.4423 - val_loss: 1.0489 - val_acc: 0.4074\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.0280 - acc: 0.4808 - val_loss: 1.0459 - val_acc: 0.4444\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0610 - acc: 0.4808 - val_loss: 1.0432 - val_acc: 0.4444\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0339 - acc: 0.4808 - val_loss: 1.0402 - val_acc: 0.4444\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0312 - acc: 0.4712 - val_loss: 1.0382 - val_acc: 0.4444\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0191 - acc: 0.5096 - val_loss: 1.0363 - val_acc: 0.4444\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0371 - acc: 0.4712 - val_loss: 1.0342 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0340 - acc: 0.4904 - val_loss: 1.0320 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0326 - acc: 0.4808 - val_loss: 1.0304 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0040 - acc: 0.4904 - val_loss: 1.0296 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9993 - acc: 0.5192 - val_loss: 1.0294 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0155 - acc: 0.5288 - val_loss: 1.0281 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9933 - acc: 0.5385 - val_loss: 1.0283 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0191 - acc: 0.5192 - val_loss: 1.0271 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0164 - acc: 0.5192 - val_loss: 1.0260 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0231 - acc: 0.5000 - val_loss: 1.0249 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9819 - acc: 0.5000 - val_loss: 1.0237 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0154 - acc: 0.4808 - val_loss: 1.0232 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9735 - acc: 0.5288 - val_loss: 1.0222 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 425us/sample - loss: 0.9956 - acc: 0.5096 - val_loss: 1.0214 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0003 - acc: 0.5192 - val_loss: 1.0202 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9763 - acc: 0.5096 - val_loss: 1.0198 - val_acc: 0.4815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: bf189e15c4d6e8c5d6a3c75692376110</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.49629631638526917</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23JI0eA1OFOX",
        "colab_type": "code",
        "outputId": "beda83f9-a68e-456d-c1d1-eeb917f0df93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "tuner.search_space_summary()\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">drop_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxpvAxjHSaP6",
        "colab_type": "code",
        "outputId": "4e4660a8-5548-401d-9be3-faa2d37ab7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Results in /content/my_dir/RandomSearch</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective(name='val_acc', direction='max')</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9cedb2f1274012558626680e8cf304fe</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5777777433395386</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: fa0f3144dfb3afb61cf07370dfad5da3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5703703761100769</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.6</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: c1e8e0d1adee9f0a5080f32d0464147c</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5629629492759705</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.5</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 70a76dc755caa36ef473dad5bf68a996</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5481481552124023</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.9</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: cade6f3196f7fe91bd3e1e3ff23cde72</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5481481552124023</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: f4ca1642017cbb1382d75244b0a9b374</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5407407879829407</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.7</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: f4bec78767a26245564eb9510036295d</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5185185074806213</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 74c5af08aaf0d8acef3c011f2ad29b5a</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5111111402511597</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9009ac92b32ab7f939a324b675bfb380</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5037037134170532</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: bf189e15c4d6e8c5d6a3c75692376110</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.49629631638526917</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reyZM6rGXHIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_params=tuner.get_best_hyperparameters()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJpBGIEvVkpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_model = tuner.hypermodel.build(random_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QAOJ7PuXvwK",
        "colab_type": "code",
        "outputId": "64213df2-6c37-46c3-e749-fc3efa0595ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'drop_rate': 0.8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYGZFhmPYZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = tuner.get_best_models()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVIumnBQEUq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "9a7287f2-e95e-41f7-ec3e-71d4f0989fb2"
      },
      "source": [
        "best_model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4)                 32        \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 15        \n",
            "=================================================================\n",
            "Total params: 47\n",
            "Trainable params: 47\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wJxr25jOew_",
        "colab_type": "text"
      },
      "source": [
        "##Train the best model RandomSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8w96YVEB_IW",
        "colab_type": "text"
      },
      "source": [
        "Per la valutazione del modello ottimizzato sul validation set uso la Stratified K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1apcZ19gFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBDM-PtBx5V",
        "colab_type": "code",
        "outputId": "a236b787-b890-4628-e4bc-83b448b64dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "skf.get_n_splits(train_data_stand_pca, train_labels_dec)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "a0de1800-1c87-4dc4-9df3-46c33e80f3bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "for train_index, test_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  1   2   4   5   6   8  10  11  12  13  14  15  16  17  20  21  22  23\n",
            "  24  25  26  27  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
            "  43  46  47  48  49  50  52  55  58  59  60  61  62  63  64  65  67  68\n",
            "  69  70  71  73  74  75  76  77  78  79  81  82  83  84  85  86  87  88\n",
            "  89  91  92  93  94  96  97  98  99 100 101 102 103 104 106 107 108 110\n",
            " 113 115 116 117 118 119 121 122 123 124 126 127 129 130] TEST: [  0   3   7   9  18  19  28  44  45  51  53  54  56  57  66  72  80  90\n",
            "  95 105 109 111 112 114 120 125 128]\n",
            "TRAIN: [  0   1   2   3   5   7   8   9  10  11  12  13  14  17  18  19  20  21\n",
            "  22  23  24  25  26  27  28  29  30  31  33  34  37  38  39  40  41  42\n",
            "  44  45  46  47  48  49  51  53  54  55  56  57  58  61  62  63  64  66\n",
            "  67  69  70  71  72  73  75  77  79  80  81  82  83  84  85  87  88  89\n",
            "  90  92  94  95  96  97  98  99 100 101 103 105 106 107 109 110 111 112\n",
            " 114 115 116 117 118 119 120 121 122 124 125 126 127 128 129] TEST: [  4   6  15  16  32  35  36  43  50  52  59  60  65  68  74  76  78  86\n",
            "  91  93 102 104 108 113 123 130]\n",
            "TRAIN: [  0   1   3   4   5   6   7   8   9  10  13  14  15  16  17  18  19  20\n",
            "  22  23  24  25  28  29  30  31  32  33  35  36  37  39  40  43  44  45\n",
            "  46  47  49  50  51  52  53  54  55  56  57  58  59  60  63  64  65  66\n",
            "  67  68  71  72  73  74  75  76  78  79  80  81  82  84  85  86  88  89\n",
            "  90  91  92  93  94  95  98  99 100 101 102 104 105 106 108 109 110 111\n",
            " 112 113 114 115 117 118 120 122 123 125 126 127 128 129 130] TEST: [  2  11  12  21  26  27  34  38  41  42  48  61  62  69  70  77  83  87\n",
            "  96  97 103 107 116 119 121 124]\n",
            "TRAIN: [  0   1   2   3   4   6   7   8   9  10  11  12  15  16  17  18  19  20\n",
            "  21  23  25  26  27  28  31  32  33  34  35  36  37  38  39  40  41  42\n",
            "  43  44  45  48  50  51  52  53  54  56  57  59  60  61  62  64  65  66\n",
            "  67  68  69  70  72  73  74  76  77  78  80  81  83  84  86  87  89  90\n",
            "  91  92  93  95  96  97  98  99 101 102 103 104 105 107 108 109 111 112\n",
            " 113 114 115 116 117 118 119 120 121 122 123 124 125 128 130] TEST: [  5  13  14  22  24  29  30  46  47  49  55  58  63  71  75  79  82  85\n",
            "  88  94 100 106 110 126 127 129]\n",
            "TRAIN: [  0   2   3   4   5   6   7   9  11  12  13  14  15  16  18  19  21  22\n",
            "  24  26  27  28  29  30  32  34  35  36  38  41  42  43  44  45  46  47\n",
            "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  65  66\n",
            "  68  69  70  71  72  74  75  76  77  78  79  80  82  83  85  86  87  88\n",
            "  90  91  93  94  95  96  97 100 102 103 104 105 106 107 108 109 110 111\n",
            " 112 113 114 116 119 120 121 123 124 125 126 127 128 129 130] TEST: [  1   8  10  17  20  23  25  31  33  37  39  40  64  67  73  81  84  89\n",
            "  92  98  99 101 115 117 118 122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8a1I3yU9FS",
        "colab_type": "code",
        "outputId": "6f6423ec-703f-419f-a64d-3bb46486e57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#num_epochs = 50\n",
        "all_acc_histories_RS = []\n",
        "all_loss_histories_RS = []\n",
        "all_val_acc_histories_RS = []\n",
        "all_val_loss_histories_RS = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        " \n",
        "  history_RS = best_model.fit(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=5)\n",
        "  \n",
        "  acc_history_RS = history_RS.history['acc']\n",
        "  all_acc_histories_RS.append(acc_history_RS)\n",
        "\n",
        "  loss_history_RS = history_RS.history['loss']\n",
        "  all_loss_histories_RS.append(loss_history_RS)\n",
        "\n",
        "  acc_val_history_RS = history_RS.history['val_acc']\n",
        "  all_val_acc_histories_RS.append(acc_val_history_RS)\n",
        "\n",
        "  loss_val_history_RS = history_RS.history['val_loss']\n",
        "  all_val_loss_histories_RS.append(loss_val_history_RS)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali  una lista lunga num_epochs,\n",
        "#ogni elemento pu essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 999us/sample - loss: 1.4451 - acc: 0.4808 - val_loss: 1.1109 - val_acc: 0.4444\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.4779 - acc: 0.4904 - val_loss: 1.0923 - val_acc: 0.4815\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.2140 - acc: 0.5000 - val_loss: 1.1032 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 2.0727 - acc: 0.4519 - val_loss: 1.0769 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.1151 - acc: 0.4615 - val_loss: 1.0527 - val_acc: 0.5556\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.5848 - acc: 0.4135 - val_loss: 1.0471 - val_acc: 0.5556\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.5695 - acc: 0.4808 - val_loss: 1.0608 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 414us/sample - loss: 1.0330 - acc: 0.5288 - val_loss: 1.0728 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.3348 - acc: 0.4519 - val_loss: 1.0672 - val_acc: 0.4815\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.1233 - acc: 0.5000 - val_loss: 1.0460 - val_acc: 0.5185\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0612 - acc: 0.5000 - val_loss: 1.0324 - val_acc: 0.5926\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0761 - acc: 0.5192 - val_loss: 1.0491 - val_acc: 0.5185\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.1125 - acc: 0.5096 - val_loss: 1.0190 - val_acc: 0.5926\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.2996 - acc: 0.5000 - val_loss: 1.0204 - val_acc: 0.6296\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.4638 - acc: 0.4712 - val_loss: 1.0086 - val_acc: 0.5926\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 1.1507 - acc: 0.4712 - val_loss: 1.0212 - val_acc: 0.5926\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0360 - acc: 0.5481 - val_loss: 1.0340 - val_acc: 0.5185\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.2627 - acc: 0.5385 - val_loss: 1.0339 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.2112 - acc: 0.4808 - val_loss: 1.0437 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.2031 - acc: 0.4808 - val_loss: 1.0100 - val_acc: 0.6296\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1814 - acc: 0.4327 - val_loss: 1.0185 - val_acc: 0.5926\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1539 - acc: 0.4135 - val_loss: 1.0150 - val_acc: 0.6296\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1796 - acc: 0.4808 - val_loss: 1.0211 - val_acc: 0.4815\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0683 - acc: 0.4904 - val_loss: 1.0037 - val_acc: 0.6296\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0549 - acc: 0.4615 - val_loss: 1.0047 - val_acc: 0.6296\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2206 - acc: 0.4423 - val_loss: 1.0149 - val_acc: 0.6296\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9841 - acc: 0.4712 - val_loss: 1.0067 - val_acc: 0.6296\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.1522 - acc: 0.5000 - val_loss: 1.0177 - val_acc: 0.5556\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0533 - acc: 0.5192 - val_loss: 1.0372 - val_acc: 0.4444\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0860 - acc: 0.4615 - val_loss: 1.0233 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0398 - acc: 0.4615 - val_loss: 0.9993 - val_acc: 0.5926\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0191 - acc: 0.5000 - val_loss: 1.0105 - val_acc: 0.5556\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0790 - acc: 0.5192 - val_loss: 1.0288 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0910 - acc: 0.4808 - val_loss: 1.0275 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9900 - acc: 0.5192 - val_loss: 1.0410 - val_acc: 0.4444\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0263 - acc: 0.4808 - val_loss: 1.0484 - val_acc: 0.4444\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0470 - acc: 0.5288 - val_loss: 1.0296 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.1139 - acc: 0.4327 - val_loss: 1.0031 - val_acc: 0.6296\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0578 - acc: 0.5192 - val_loss: 1.0280 - val_acc: 0.5556\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0389 - acc: 0.5577 - val_loss: 1.0519 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0268 - acc: 0.5096 - val_loss: 1.0466 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0225 - acc: 0.5000 - val_loss: 1.0302 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0396 - acc: 0.4712 - val_loss: 1.0321 - val_acc: 0.4444\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0164 - acc: 0.4904 - val_loss: 1.0210 - val_acc: 0.5185\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0511 - acc: 0.5000 - val_loss: 1.0218 - val_acc: 0.5185\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9647 - acc: 0.5288 - val_loss: 1.0199 - val_acc: 0.5185\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.0284 - acc: 0.4615 - val_loss: 1.0095 - val_acc: 0.5926\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0288 - acc: 0.4712 - val_loss: 1.0133 - val_acc: 0.5556\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9780 - acc: 0.4519 - val_loss: 1.0121 - val_acc: 0.5556\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0068 - acc: 0.5192 - val_loss: 1.0268 - val_acc: 0.4815\n",
            "Train on 105 samples, validate on 26 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 320us/sample - loss: 1.0288 - acc: 0.4762 - val_loss: 0.9511 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 337us/sample - loss: 1.0134 - acc: 0.5048 - val_loss: 0.9548 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 387us/sample - loss: 1.1004 - acc: 0.4381 - val_loss: 0.9651 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 375us/sample - loss: 1.0495 - acc: 0.5048 - val_loss: 0.9640 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 490us/sample - loss: 1.0108 - acc: 0.5048 - val_loss: 0.9706 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 1.0380 - acc: 0.4952 - val_loss: 0.9717 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 321us/sample - loss: 0.9549 - acc: 0.5524 - val_loss: 0.9764 - val_acc: 0.5000\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 312us/sample - loss: 1.0109 - acc: 0.4952 - val_loss: 0.9883 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 307us/sample - loss: 1.0442 - acc: 0.4667 - val_loss: 0.9774 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 321us/sample - loss: 1.0670 - acc: 0.4857 - val_loss: 0.9778 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 1.0251 - acc: 0.4857 - val_loss: 0.9755 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 348us/sample - loss: 0.9908 - acc: 0.5238 - val_loss: 0.9631 - val_acc: 0.5385\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 1.0227 - acc: 0.4857 - val_loss: 0.9770 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 0.9811 - acc: 0.5333 - val_loss: 0.9829 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 325us/sample - loss: 0.9869 - acc: 0.4667 - val_loss: 0.9904 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.9901 - acc: 0.4952 - val_loss: 0.9807 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 1.0355 - acc: 0.4667 - val_loss: 0.9738 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 335us/sample - loss: 0.9976 - acc: 0.5143 - val_loss: 0.9695 - val_acc: 0.4615\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 1.0335 - acc: 0.4762 - val_loss: 0.9811 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 370us/sample - loss: 1.0116 - acc: 0.4857 - val_loss: 0.9745 - val_acc: 0.4615\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 302us/sample - loss: 0.9705 - acc: 0.4667 - val_loss: 0.9692 - val_acc: 0.4615\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 317us/sample - loss: 0.9943 - acc: 0.4857 - val_loss: 0.9688 - val_acc: 0.4231\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 369us/sample - loss: 0.9912 - acc: 0.4762 - val_loss: 0.9789 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 388us/sample - loss: 0.9721 - acc: 0.5143 - val_loss: 0.9715 - val_acc: 0.4615\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 358us/sample - loss: 1.0494 - acc: 0.4667 - val_loss: 0.9696 - val_acc: 0.5385\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9649 - acc: 0.5429 - val_loss: 0.9598 - val_acc: 0.4615\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 436us/sample - loss: 0.9965 - acc: 0.4857 - val_loss: 0.9657 - val_acc: 0.5385\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 359us/sample - loss: 1.0637 - acc: 0.4476 - val_loss: 0.9805 - val_acc: 0.4231\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 384us/sample - loss: 0.9767 - acc: 0.5143 - val_loss: 0.9881 - val_acc: 0.4231\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 345us/sample - loss: 0.9930 - acc: 0.5238 - val_loss: 0.9675 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 1.0252 - acc: 0.4857 - val_loss: 0.9702 - val_acc: 0.4615\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 357us/sample - loss: 0.9953 - acc: 0.4952 - val_loss: 0.9678 - val_acc: 0.5385\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 0.9550 - acc: 0.5238 - val_loss: 0.9647 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 1.0043 - acc: 0.4762 - val_loss: 0.9702 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 389us/sample - loss: 0.9941 - acc: 0.5333 - val_loss: 0.9679 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 324us/sample - loss: 1.0483 - acc: 0.4667 - val_loss: 0.9837 - val_acc: 0.4615\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 350us/sample - loss: 0.9871 - acc: 0.4667 - val_loss: 0.9881 - val_acc: 0.4231\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 1.0130 - acc: 0.4857 - val_loss: 0.9792 - val_acc: 0.4615\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 371us/sample - loss: 1.0131 - acc: 0.4667 - val_loss: 0.9840 - val_acc: 0.4615\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 390us/sample - loss: 0.9674 - acc: 0.4762 - val_loss: 0.9802 - val_acc: 0.4615\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 381us/sample - loss: 0.9702 - acc: 0.5143 - val_loss: 1.0097 - val_acc: 0.4615\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 1.0185 - acc: 0.4762 - val_loss: 0.9995 - val_acc: 0.4231\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 0.9999 - acc: 0.4857 - val_loss: 1.0010 - val_acc: 0.4231\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 301us/sample - loss: 0.9968 - acc: 0.4857 - val_loss: 0.9936 - val_acc: 0.4231\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 0.9583 - acc: 0.4952 - val_loss: 0.9863 - val_acc: 0.4615\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 315us/sample - loss: 0.9994 - acc: 0.4857 - val_loss: 0.9965 - val_acc: 0.4231\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 350us/sample - loss: 0.9943 - acc: 0.4952 - val_loss: 0.9894 - val_acc: 0.4231\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 0.9563 - acc: 0.5238 - val_loss: 0.9867 - val_acc: 0.4231\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 358us/sample - loss: 0.9713 - acc: 0.5048 - val_loss: 0.9961 - val_acc: 0.4231\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 358us/sample - loss: 0.9654 - acc: 0.4857 - val_loss: 0.9915 - val_acc: 0.4231\n",
            "Train on 105 samples, validate on 26 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 1.0004 - acc: 0.4952 - val_loss: 0.9244 - val_acc: 0.6538\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 321us/sample - loss: 0.9817 - acc: 0.4857 - val_loss: 0.9148 - val_acc: 0.6923\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 1.0015 - acc: 0.4857 - val_loss: 0.9233 - val_acc: 0.6154\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9943 - acc: 0.5143 - val_loss: 0.9373 - val_acc: 0.6154\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 331us/sample - loss: 1.0336 - acc: 0.4476 - val_loss: 0.9384 - val_acc: 0.6154\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 317us/sample - loss: 0.9831 - acc: 0.5048 - val_loss: 0.9487 - val_acc: 0.6154\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 1.0090 - acc: 0.4667 - val_loss: 0.9383 - val_acc: 0.6538\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 301us/sample - loss: 0.9896 - acc: 0.4476 - val_loss: 0.9370 - val_acc: 0.6154\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 304us/sample - loss: 0.9471 - acc: 0.5333 - val_loss: 0.9380 - val_acc: 0.6154\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 327us/sample - loss: 0.9682 - acc: 0.4952 - val_loss: 0.9229 - val_acc: 0.6154\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 1.0212 - acc: 0.4476 - val_loss: 0.9281 - val_acc: 0.6154\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 370us/sample - loss: 1.0015 - acc: 0.5143 - val_loss: 0.9344 - val_acc: 0.6538\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 0.9716 - acc: 0.5143 - val_loss: 0.9557 - val_acc: 0.6154\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 295us/sample - loss: 1.0068 - acc: 0.4762 - val_loss: 0.9577 - val_acc: 0.6538\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 318us/sample - loss: 1.0147 - acc: 0.4952 - val_loss: 0.9695 - val_acc: 0.6154\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 316us/sample - loss: 1.0091 - acc: 0.4667 - val_loss: 0.9702 - val_acc: 0.6154\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 390us/sample - loss: 1.0234 - acc: 0.4857 - val_loss: 0.9591 - val_acc: 0.6538\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 0.9803 - acc: 0.5238 - val_loss: 0.9468 - val_acc: 0.6538\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 344us/sample - loss: 0.9751 - acc: 0.5238 - val_loss: 0.9558 - val_acc: 0.6538\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 379us/sample - loss: 0.9807 - acc: 0.4857 - val_loss: 0.9496 - val_acc: 0.6154\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 345us/sample - loss: 0.9868 - acc: 0.4762 - val_loss: 0.9433 - val_acc: 0.6538\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 359us/sample - loss: 0.9660 - acc: 0.5333 - val_loss: 0.9388 - val_acc: 0.6923\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 357us/sample - loss: 0.9942 - acc: 0.5048 - val_loss: 0.9415 - val_acc: 0.6538\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 365us/sample - loss: 0.9945 - acc: 0.4762 - val_loss: 0.9489 - val_acc: 0.6538\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 435us/sample - loss: 0.9845 - acc: 0.4952 - val_loss: 0.9377 - val_acc: 0.6538\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 378us/sample - loss: 0.9579 - acc: 0.5048 - val_loss: 0.9301 - val_acc: 0.6538\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 0.9988 - acc: 0.4667 - val_loss: 0.9320 - val_acc: 0.6538\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 1.0287 - acc: 0.4667 - val_loss: 0.9336 - val_acc: 0.6538\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 379us/sample - loss: 1.0072 - acc: 0.4857 - val_loss: 0.9499 - val_acc: 0.6538\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 388us/sample - loss: 1.0037 - acc: 0.4571 - val_loss: 0.9392 - val_acc: 0.6923\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 368us/sample - loss: 0.9724 - acc: 0.5048 - val_loss: 0.9514 - val_acc: 0.6538\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 385us/sample - loss: 0.9784 - acc: 0.5143 - val_loss: 0.9386 - val_acc: 0.6923\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 334us/sample - loss: 1.0167 - acc: 0.5048 - val_loss: 0.9645 - val_acc: 0.6538\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 302us/sample - loss: 0.9832 - acc: 0.5143 - val_loss: 0.9430 - val_acc: 0.6923\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 1.0166 - acc: 0.4571 - val_loss: 0.9539 - val_acc: 0.6538\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 386us/sample - loss: 0.9707 - acc: 0.4952 - val_loss: 0.9558 - val_acc: 0.6538\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 403us/sample - loss: 0.9818 - acc: 0.5143 - val_loss: 0.9528 - val_acc: 0.6538\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 370us/sample - loss: 0.9837 - acc: 0.4762 - val_loss: 0.9690 - val_acc: 0.6154\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 1.0084 - acc: 0.4381 - val_loss: 0.9582 - val_acc: 0.6538\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 367us/sample - loss: 0.9886 - acc: 0.4762 - val_loss: 0.9413 - val_acc: 0.6538\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 349us/sample - loss: 0.9877 - acc: 0.4762 - val_loss: 0.9308 - val_acc: 0.6923\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 1.0231 - acc: 0.4381 - val_loss: 0.9417 - val_acc: 0.5385\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 405us/sample - loss: 1.0027 - acc: 0.4476 - val_loss: 0.9358 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 1.0003 - acc: 0.4762 - val_loss: 0.9485 - val_acc: 0.5769\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 368us/sample - loss: 0.9925 - acc: 0.4857 - val_loss: 0.9506 - val_acc: 0.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 381us/sample - loss: 1.0257 - acc: 0.4762 - val_loss: 0.9624 - val_acc: 0.6154\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 342us/sample - loss: 0.9899 - acc: 0.5238 - val_loss: 0.9766 - val_acc: 0.5385\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 342us/sample - loss: 0.9762 - acc: 0.4952 - val_loss: 0.9872 - val_acc: 0.3846\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.9825 - acc: 0.4667 - val_loss: 0.9822 - val_acc: 0.4615\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 412us/sample - loss: 0.9908 - acc: 0.4476 - val_loss: 0.9538 - val_acc: 0.5385\n",
            "Train on 105 samples, validate on 26 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 0.9851 - acc: 0.4667 - val_loss: 0.9607 - val_acc: 0.5385\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 317us/sample - loss: 0.9768 - acc: 0.4762 - val_loss: 0.9658 - val_acc: 0.5769\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 323us/sample - loss: 0.9790 - acc: 0.4857 - val_loss: 0.9627 - val_acc: 0.5385\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 348us/sample - loss: 0.9876 - acc: 0.4857 - val_loss: 0.9629 - val_acc: 0.5385\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 365us/sample - loss: 0.9622 - acc: 0.5238 - val_loss: 0.9631 - val_acc: 0.5385\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 363us/sample - loss: 0.9795 - acc: 0.5048 - val_loss: 0.9690 - val_acc: 0.6154\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 0.9780 - acc: 0.4762 - val_loss: 0.9685 - val_acc: 0.5769\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 338us/sample - loss: 0.9779 - acc: 0.4571 - val_loss: 0.9649 - val_acc: 0.5385\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 323us/sample - loss: 0.9830 - acc: 0.4857 - val_loss: 0.9661 - val_acc: 0.5769\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 324us/sample - loss: 0.9601 - acc: 0.4857 - val_loss: 0.9634 - val_acc: 0.5385\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 325us/sample - loss: 0.9792 - acc: 0.4857 - val_loss: 0.9608 - val_acc: 0.5385\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 319us/sample - loss: 0.9775 - acc: 0.4952 - val_loss: 0.9566 - val_acc: 0.5385\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 0.9902 - acc: 0.4762 - val_loss: 0.9601 - val_acc: 0.5385\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.9574 - acc: 0.5333 - val_loss: 0.9598 - val_acc: 0.5385\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 345us/sample - loss: 0.9729 - acc: 0.5143 - val_loss: 0.9573 - val_acc: 0.5769\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 426us/sample - loss: 0.9583 - acc: 0.4952 - val_loss: 0.9616 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 334us/sample - loss: 1.0120 - acc: 0.4762 - val_loss: 0.9601 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 357us/sample - loss: 0.9699 - acc: 0.5143 - val_loss: 0.9585 - val_acc: 0.5385\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 339us/sample - loss: 0.9933 - acc: 0.4952 - val_loss: 0.9561 - val_acc: 0.5385\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 356us/sample - loss: 1.0095 - acc: 0.4857 - val_loss: 0.9569 - val_acc: 0.5769\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9625 - acc: 0.4952 - val_loss: 0.9622 - val_acc: 0.6154\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 384us/sample - loss: 0.9707 - acc: 0.5524 - val_loss: 0.9658 - val_acc: 0.4615\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 362us/sample - loss: 0.9549 - acc: 0.5048 - val_loss: 0.9685 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 0.9874 - acc: 0.5048 - val_loss: 0.9619 - val_acc: 0.5385\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 313us/sample - loss: 0.9560 - acc: 0.5524 - val_loss: 0.9613 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 323us/sample - loss: 1.0227 - acc: 0.4667 - val_loss: 0.9524 - val_acc: 0.5769\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 318us/sample - loss: 1.0004 - acc: 0.4571 - val_loss: 0.9609 - val_acc: 0.5769\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 300us/sample - loss: 0.9683 - acc: 0.4857 - val_loss: 0.9633 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 316us/sample - loss: 0.9654 - acc: 0.5143 - val_loss: 0.9655 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 300us/sample - loss: 0.9618 - acc: 0.4952 - val_loss: 0.9701 - val_acc: 0.4615\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 297us/sample - loss: 0.9766 - acc: 0.5238 - val_loss: 0.9592 - val_acc: 0.5769\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 282us/sample - loss: 0.9750 - acc: 0.4952 - val_loss: 0.9592 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 301us/sample - loss: 0.9697 - acc: 0.4952 - val_loss: 0.9603 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 352us/sample - loss: 0.9918 - acc: 0.4667 - val_loss: 0.9570 - val_acc: 0.5385\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 342us/sample - loss: 0.9418 - acc: 0.5524 - val_loss: 0.9632 - val_acc: 0.4615\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 327us/sample - loss: 0.9477 - acc: 0.5619 - val_loss: 0.9671 - val_acc: 0.4615\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 336us/sample - loss: 1.0273 - acc: 0.4762 - val_loss: 0.9581 - val_acc: 0.5769\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 384us/sample - loss: 0.9605 - acc: 0.5048 - val_loss: 0.9570 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 362us/sample - loss: 0.9906 - acc: 0.4952 - val_loss: 0.9581 - val_acc: 0.5385\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 360us/sample - loss: 0.9904 - acc: 0.4762 - val_loss: 0.9631 - val_acc: 0.6154\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 0.9686 - acc: 0.4952 - val_loss: 0.9643 - val_acc: 0.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 0.9478 - acc: 0.5238 - val_loss: 0.9672 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 315us/sample - loss: 0.9671 - acc: 0.5048 - val_loss: 0.9655 - val_acc: 0.5769\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.9857 - acc: 0.4571 - val_loss: 0.9667 - val_acc: 0.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 339us/sample - loss: 0.9496 - acc: 0.5048 - val_loss: 0.9672 - val_acc: 0.5769\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 391us/sample - loss: 0.9681 - acc: 0.4952 - val_loss: 0.9666 - val_acc: 0.5769\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 0.9659 - acc: 0.4952 - val_loss: 0.9648 - val_acc: 0.5769\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 361us/sample - loss: 0.9877 - acc: 0.4762 - val_loss: 0.9686 - val_acc: 0.4615\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 338us/sample - loss: 0.9890 - acc: 0.4857 - val_loss: 0.9658 - val_acc: 0.4615\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 324us/sample - loss: 0.9873 - acc: 0.4762 - val_loss: 0.9636 - val_acc: 0.5000\n",
            "Train on 105 samples, validate on 26 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 301us/sample - loss: 0.9781 - acc: 0.5238 - val_loss: 0.9716 - val_acc: 0.5385\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 0.9766 - acc: 0.4762 - val_loss: 0.9667 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 324us/sample - loss: 0.9655 - acc: 0.4952 - val_loss: 0.9677 - val_acc: 0.5385\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 0.9902 - acc: 0.4762 - val_loss: 0.9647 - val_acc: 0.5769\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9715 - acc: 0.4857 - val_loss: 0.9650 - val_acc: 0.5769\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 0.9894 - acc: 0.4571 - val_loss: 0.9724 - val_acc: 0.5385\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.9596 - acc: 0.5238 - val_loss: 0.9707 - val_acc: 0.5385\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 349us/sample - loss: 0.9487 - acc: 0.5048 - val_loss: 0.9661 - val_acc: 0.5385\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.9912 - acc: 0.4762 - val_loss: 0.9758 - val_acc: 0.5769\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 340us/sample - loss: 0.9547 - acc: 0.5143 - val_loss: 0.9780 - val_acc: 0.5769\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 328us/sample - loss: 0.9576 - acc: 0.4857 - val_loss: 0.9750 - val_acc: 0.5769\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 336us/sample - loss: 0.9894 - acc: 0.5048 - val_loss: 0.9666 - val_acc: 0.5769\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 447us/sample - loss: 0.9692 - acc: 0.5238 - val_loss: 0.9547 - val_acc: 0.6154\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 359us/sample - loss: 1.0044 - acc: 0.4857 - val_loss: 0.9688 - val_acc: 0.5769\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 338us/sample - loss: 0.9834 - acc: 0.4857 - val_loss: 0.9674 - val_acc: 0.5769\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 333us/sample - loss: 0.9780 - acc: 0.5048 - val_loss: 0.9669 - val_acc: 0.5769\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 340us/sample - loss: 0.9567 - acc: 0.5143 - val_loss: 0.9744 - val_acc: 0.5769\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 311us/sample - loss: 0.9916 - acc: 0.4667 - val_loss: 0.9609 - val_acc: 0.6154\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 380us/sample - loss: 0.9677 - acc: 0.5048 - val_loss: 0.9631 - val_acc: 0.6154\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 324us/sample - loss: 0.9902 - acc: 0.4571 - val_loss: 0.9650 - val_acc: 0.6154\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 335us/sample - loss: 0.9952 - acc: 0.4571 - val_loss: 0.9703 - val_acc: 0.5769\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 335us/sample - loss: 0.9849 - acc: 0.4571 - val_loss: 0.9696 - val_acc: 0.5385\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 313us/sample - loss: 0.9549 - acc: 0.5143 - val_loss: 0.9764 - val_acc: 0.5769\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 303us/sample - loss: 0.9824 - acc: 0.5048 - val_loss: 0.9702 - val_acc: 0.5769\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 326us/sample - loss: 0.9534 - acc: 0.5238 - val_loss: 0.9712 - val_acc: 0.5385\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 321us/sample - loss: 0.9808 - acc: 0.4762 - val_loss: 0.9681 - val_acc: 0.5385\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 305us/sample - loss: 0.9450 - acc: 0.5238 - val_loss: 0.9653 - val_acc: 0.5769\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9795 - acc: 0.5333 - val_loss: 0.9606 - val_acc: 0.5769\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 339us/sample - loss: 0.9795 - acc: 0.4667 - val_loss: 0.9616 - val_acc: 0.5769\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 352us/sample - loss: 0.9993 - acc: 0.4667 - val_loss: 0.9632 - val_acc: 0.6154\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 328us/sample - loss: 0.9923 - acc: 0.4857 - val_loss: 0.9631 - val_acc: 0.6154\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 333us/sample - loss: 0.9921 - acc: 0.4476 - val_loss: 0.9666 - val_acc: 0.5769\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 373us/sample - loss: 0.9744 - acc: 0.4857 - val_loss: 0.9673 - val_acc: 0.5385\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 371us/sample - loss: 0.9715 - acc: 0.4857 - val_loss: 0.9657 - val_acc: 0.5769\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 319us/sample - loss: 0.9726 - acc: 0.4857 - val_loss: 0.9688 - val_acc: 0.5769\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 331us/sample - loss: 0.9604 - acc: 0.4857 - val_loss: 0.9722 - val_acc: 0.5769\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 328us/sample - loss: 0.9811 - acc: 0.4857 - val_loss: 0.9686 - val_acc: 0.5769\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 331us/sample - loss: 0.9523 - acc: 0.5048 - val_loss: 0.9596 - val_acc: 0.6154\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 345us/sample - loss: 0.9584 - acc: 0.5143 - val_loss: 0.9672 - val_acc: 0.5769\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 323us/sample - loss: 1.0041 - acc: 0.4667 - val_loss: 0.9724 - val_acc: 0.5385\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 303us/sample - loss: 0.9937 - acc: 0.4857 - val_loss: 0.9718 - val_acc: 0.5385\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 306us/sample - loss: 0.9712 - acc: 0.4762 - val_loss: 0.9685 - val_acc: 0.5385\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.9872 - acc: 0.4857 - val_loss: 0.9553 - val_acc: 0.6538\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 320us/sample - loss: 0.9862 - acc: 0.4476 - val_loss: 0.9649 - val_acc: 0.5769\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 365us/sample - loss: 0.9645 - acc: 0.5048 - val_loss: 0.9592 - val_acc: 0.6154\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 361us/sample - loss: 0.9642 - acc: 0.5048 - val_loss: 0.9629 - val_acc: 0.5769\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9615 - acc: 0.5048 - val_loss: 0.9690 - val_acc: 0.5769\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 0.9787 - acc: 0.4952 - val_loss: 0.9695 - val_acc: 0.5769\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 358us/sample - loss: 0.9869 - acc: 0.4667 - val_loss: 0.9638 - val_acc: 0.5769\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 372us/sample - loss: 0.9682 - acc: 0.5048 - val_loss: 0.9599 - val_acc: 0.6154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkjHWfuvSRXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history_RS.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5o_DnOySStG",
        "colab_type": "code",
        "outputId": "fd3b9e39-e970-4249-cdfd-07b929552708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UhSxIaHtuO",
        "colab_type": "text"
      },
      "source": [
        "##Plotting training and validation loss RandomSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zsienD5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJizyjnaIPhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, num_epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z_pSVTWwtybS",
        "colab": {}
      },
      "source": [
        "average_acc_history_RS = [np.mean([x[i] for x in all_acc_histories_RS]) for i in range(num_epochs)]\n",
        "average_loss_history_RS = [np.mean([x[i] for x in all_loss_histories_RS]) for i in range(num_epochs)]\n",
        "average_val_acc_history_RS = [np.mean([x[i] for x in all_val_acc_histories_RS]) for i in range(num_epochs)]\n",
        "average_val_loss_history_RS = [np.mean([x[i] for x in all_val_loss_histories_RS]) for i in range(num_epochs)]\n",
        "#media per epoca degli score ottenuti per tutte le k-fold\n",
        "#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\n",
        "#e si fa questo per tutte le epoche"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEHEYLgIQUQ",
        "colab_type": "code",
        "outputId": "db13be00-9f6e-4cea-8395-2e6843ab7ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs, average_loss_history_RS, 'b', label='training loss')\n",
        "plt.plot(epochs, average_val_loss_history_RS, 'r', label='validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fda80bc6320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc4wMjfI97j",
        "colab_type": "text"
      },
      "source": [
        "##Plotting train and validation accuracy RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi7VzbFIbtJ",
        "colab_type": "code",
        "outputId": "41329d68-c470-469a-c721-e58ca1a49d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs, average_acc_history_RS, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, average_val_acc_history_RS, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend() "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fda7eeeac50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydd5gUVfaw30MSEMmgOIMwqGRmYMBB\nSQoMiC7BrIABXdewYnZdAyriYtbVn+sG5TOtAVFXhVVERjGLEpYBSRKVIUkcchi43x+ni+lpOlR3\nV3UPcN/n6ae7K96urrrnnnjFGIPFYrFYLKFUSHcDLBaLxVI+sQLCYrFYLGGxAsJisVgsYbECwmKx\nWCxhsQLCYrFYLGGxAsJisVgsYbECwuIaEakoIttE5AQvt00nInKSiHge6y0i+SKyPOj7QhHp7mbb\nBM41RkTuSXR/iyUSldLdAIt/iMi2oK/Vgd3AvsD3a40xb8RzPGPMPqCG19seCRhjWnhxHBG5GrjU\nGHNG0LGv9uLYFksoVkAcxhhjDnTQgRHq1caYgkjbi0glY0xJKtpmscTC3o/px5qYjmBE5C8i8raI\nvCUiW4FLReQ0EZkqIptFZLWI/J+IVA5sX0lEjIg0DXx/PbB+oohsFZHvRSQr3m0D688SkZ9FpFhE\nnhORb0VkWIR2u2njtSKyWEQ2icj/Be1bUUT+KiIbRGQp0C/K9blXRMaGLHteRJ4OfL5aROYHfs+S\nwOg+0rGKROSMwOfqIvLvQNvmAh1Dth0hIksDx50rIgMDy9sBfwO6B8x364Ou7cig/a8L/PYNIvKB\niDRyc23iuc5Oe0SkQEQ2isgaEbkz6Dz3Ba7JFhGZLiLHhzPnicg3zv8cuJ5fBc6zERghIieLyJTA\nOdYHrlutoP2bBH7jusD6Z0WkaqDNrYK2ayQiO0SkXqTfawmDMca+joAXsBzID1n2F2APMAAdLFQD\nTgE6o9plM+BnYHhg+0qAAZoGvr8OrAc6AZWBt4HXE9i2IbAVGBRYdxuwFxgW4be4aeOHQC2gKbDR\n+e3AcGAukAnUA77SxyDseZoB24Cjg479G9Ap8H1AYBsBegE7gezAunxgedCxioAzAp+fBL4A6gBN\ngHkh214ENAr8J0MCbTg2sO5q4IuQdr4OjAx87htoY3ugKvB34HM31ybO61wLWAvcDBwF1ATyAuvu\nBgqBkwO/oT1QFzgp9FoD3zj/c+C3lQDXAxXR+7E50BuoErhPvgWeDPo9PwWu59GB7bsG1r0AjA46\nz+3A++l+Dg+1V9obYF8p+qMjC4jPY+x3B/BO4HO4Tv+fQdsOBH5KYNurgK+D1gmwmggCwmUbTw1a\n/x/gjsDnr1BTm7Pu7NBOK+TYU4Ehgc9nAQujbPtf4IbA52gC4tfg/wL4Y/C2YY77E/C7wOdYAuJV\n4OGgdTVRv1NmrGsT53W+DJgWYbslTntDlrsREEtjtOEC57xAd2ANUDHMdl2BZYAEvs8CzvP6uTrc\nX9bEZFkR/EVEWorIRwGTwRZgFFA/yv5rgj7vILpjOtK2xwe3w+gTXRTpIC7b6OpcwC9R2gvwJjA4\n8HlI4LvTjv4i8kPA/LEZHb1Hu1YOjaK1QUSGiUhhwEyyGWjp8rigv+/A8YwxW4BNQEbQNq7+sxjX\nuTEqCMIRbV0sQu/H40RknIisDLThlZA2LDcaEFEGY8y3qDbSTUTaAicAHyXYpiMWKyAsoSGe/0JH\nrCcZY2oC96Mjej9ZjY5wARARoWyHFkoybVyNdiwOscJwxwH5IpKBmsDeDLSxGvAu8Ahq/qkNfOqy\nHWsitUFEmgH/QM0s9QLHXRB03FghuatQs5VzvGNQU9ZKF+0KJdp1XgGcGGG/SOu2B9pUPWjZcSHb\nhP6+x9Dou3aBNgwLaUMTEakYoR2vAZei2s44Y8zuCNtZImAFhCWUY4BiYHvAyXdtCs75XyBXRAaI\nSCXUrt3ApzaOA24RkYyAw/LP0TY2xqxBzSCvoOalRYFVR6F28XXAPhHpj9rK3bbhHhGpLZonMjxo\nXQ20k1yHyso/oBqEw1ogM9hZHMJbwO9FJFtEjkIF2NfGmIgaWRSiXefxwAkiMlxEjhKRmiKSF1g3\nBviLiJwoSnsRqYsKxjVoMERFEbmGIGEWpQ3bgWIRaYyauRy+BzYAD4s6/quJSNeg9f9GTVJDUGFh\niRMrICyh3A5cgTqN/4U6k33FGLMWuBh4Gn3gTwT+h44cvW7jP4DPgDnANFQLiMWbqE/hgHnJGLMZ\nuBV4H3X0XoAKOjc8gGoyy4GJBHVexpjZwHPAj4FtWgA/BO07GVgErBWRYFORs/8nqCno/cD+JwBD\nXbYrlIjX2RhTDPQBzkeF1s/A6YHVTwAfoNd5C+owrhowHf4BuAcNWDgp5LeF4wEgDxVU44H3gtpQ\nAvQHWqHaxK/o/+CsX47+z7uNMd/F+dstlDpwLJZyQ8BksAq4wBjzdbrbYzl0EZHXUMf3yHS35VDE\nJspZygUi0g+NGNqJhknuRUfRFktCBPw5g4B26W7LoYo1MVnKC92Apajt/UzgXOtUtCSKiDyC5mI8\nbIz5Nd3tOVSxJiaLxWKxhMVqEBaLxWIJi68+iIBd+Vk0bX6MMebRMNtcBIxEQ/sKjTFDAsuvAEYE\nNvuLMebVaOeqX7++adq0qXeNt1gsliOAGTNmrDfGhA0r983EFIhE+RkNhStCQwoHG2PmBW1zMhoT\n3ssYs0lEGhpjfgvETE9H6/YYYAbQ0RizKdL5OnXqZKZPn+7Lb7FYLJbDFRGZYYzpFG6dnyamPGCx\nMWapMWYPMBaNKAjmD8DzTsdvjPktsPxMYLIxZmNg3WSiVN20WCwWi/f4KSAyKFtXpYiDyyc0B5qL\nlnaeGjBJud0XEbkmUEp4+rp16zxsusVisVjS7aSuhJYEPgMtiPaiiNR2u7Mx5gVjTCdjTKcGDaJV\nZrBYLBZLvPjppF5J2YJkmRxcMKwI+MEYsxdYJiI/owJjJSo0gvf9wreWWiyHGXv37qWoqIhdu3al\nuymWckLVqlXJzMykcuVIZbwOxk8BMQ04WXTWsJXAJWjRrGA+QDWHl0WkPmpyWoqWCn5YROoEtuuL\nZtdaLBYXFBUVccwxx9C0aVO0OK7lSMYYw4YNGygqKiIrKyv2DgF8MzEFCmkNByYB89Fyu3NFZJQE\nplAMrNsgIvOAKcCfjDEbjDEbgYdQITMNGBVYZrFYXLBr1y7q1atnhYMFABGhXr16cWuUvuZBGGM+\nBj4OWXZ/0GeDTi95W5h9XwJe8rN9FsvhjBUOlmASuR/S7aS2WCwAixfDJ5+kuxUWSxmsgLBYygMP\nPghDQl10hy4bNmygffv2tG/fnuOOO46MjIwD3/fs2ePqGFdeeSULFy6Mus3zzz/PG2+84UWTLWGw\n5b4tlvJAYSFs2gR790IcUSbllXr16jFr1iwARo4cSY0aNbjjjjvKbGOMwRhDhQrhx6kvv/xyzPPc\ncMMNyTc2xZSUlFCp0qHR9VoNwmJJN3v3woIF+nnj4R2LsXjxYlq3bs3QoUNp06YNq1ev5pprrqFT\np060adOGUaNGHdi2W7duzJo1i5KSEmrXrs1dd91FTk4Op512Gr/9pkUXRowYwTPPPHNg+7vuuou8\nvDxatGjBd9/pJHLbt2/n/PPPp3Xr1lxwwQV06tTpgPAK5oEHHuCUU06hbdu2XHfddThliH7++Wd6\n9epFTk4Oubm5LF++HICHH36Ydu3akZOTw7333lumzQBr1qzhpJNOAmDMmDGcc8459OzZkzPPPJMt\nW7bQq1cvcnNzyc7O5r//LZ2M8OWXXyY7O5ucnByuvPJKiouLadasGSUlJQBs2rSpzHc/OTTEmMVy\nOLNwoQoJgPXr4dhjPT38LbdAmP4wKdq3h0C/HDcLFizgtddeo1MnLf/z6KOPUrduXUpKSujZsycX\nXHABrVu3LrNPcXExp59+Oo8++ii33XYbL730EnfddddBxzbG8OOPPzJ+/HhGjRrFJ598wnPPPcdx\nxx3He++9R2FhIbm5uWHbdfPNN/Pggw9ijGHIkCF88sknnHXWWQwePJiRI0cyYMAAdu3axf79+5kw\nYQITJ07kxx9/pFq1amx0Idj/97//MWvWLOrUqcPevXv54IMPqFmzJr/99htdu3alf//+FBYW8thj\nj/Hdd99Rt25dNm7cSK1atejatSuffPIJ/fv356233uLCCy9MiRZiNQiLJd3MmVP6ecOG9LUjRZx4\n4okHhAPAW2+9RW5uLrm5ucyfP5958+YdtE+1atU466yzAOjYseOBUXwo55133kHbfPPNN1xyySUA\n5OTk0KZNm7D7fvbZZ+Tl5ZGTk8OXX37J3Llz2bRpE+vXr2fAgAGAJptVr16dgoICrrrqKqpVqwZA\n3bp1Y/7uvn37UqeOpnYZY7jrrrvIzs6mb9++rFixgvXr1/P5559z8cUXHzie83711VcfMLm9/PLL\nXHnllTHP5wVWg7BY0k2wgFi/3vPDJzrS94ujjz76wOdFixbx7LPP8uOPP1K7dm0uvfTSsLH6VapU\nOfC5YsWKEc0rRx11VMxtwrFjxw6GDx/OzJkzycjIYMSIEQlloVeqVIn9+/cDHLR/8O9+7bXXKC4u\nZubMmVSqVInMzMyo5zv99NMZPnw4U6ZMoXLlyrRs2TLutiWC1SAslnQzZw44I9AjQIMIZsuWLRxz\nzDHUrFmT1atXM2nSJM/P0bVrV8aNGwfAnDlzwmooO3fupEKFCtSvX5+tW7fy3nvvAVCnTh0aNGjA\nhAkTAO30d+zYQZ8+fXjppZfYuXMnwAETU9OmTZkxYwYA7777bsQ2FRcX07BhQypVqsTkyZNZuVKr\nEPXq1Yu33377wPGCTVeXXnopQ4cOTZn2AFZAWCzpZ/Zs6NFDP/ugQZRncnNzad26NS1btuTyyy+n\na9eunp/jxhtvZOXKlbRu3ZoHH3yQ1q1bU6tWrTLb1KtXjyuuuILWrVtz1lln0blz5wPr3njjDZ56\n6imys7Pp1q0b69ato3///vTr149OnTrRvn17/vrXvwLwpz/9iWeffZbc3Fw2bYo4fQ2XXXYZ3333\nHe3atWPs2LGcfPLJgJrA7rzzTnr06EH79u3505/+dGCfoUOHUlxczMUXX+zl5YnKYTMntZ0wyHJI\nUlwMtWvDI4/AQw/B9dfDk08mfdj58+fTqlUrDxp46FNSUkJJSQlVq1Zl0aJF9O3bl0WLFh0yoaYO\nY8eOZdKkSa7CfyMR7r6INmHQoXWFLJbDjZ9+0vd27aBevSNOg0gF27Zto3fv3pSUlGCM4V//+tch\nJxyuv/56CgoK+CTF2faH1lWyWA43HAd1u3ZQv74VED5Qu3btA36BQ5V//OMfaTmv9UFYLOlkzhyo\nVQsaN1YN4ghzUlvKN1ZAWCzpZM4caNsWRKwGYSl3WAFhsaQLYzSCqV07/V6/vtUgLOUKKyAslnRR\nVKRRTI6AqFdPC/aloMaOxeIGKyAslnThOKizs/W9fn19jxI/f6jQs2fPg5LennnmGa6//vqo+9Wo\nUQOAVatWccEFF4Td5owzziBWSPszzzzDjh07Dnw/++yz2bx5s5umW4KwAsJiSReOgGjbVt/r1dP3\nw8APMXjwYMaOHVtm2dixYxk8eLCr/Y8//viomcixCBUQH3/8MbVr1074eKnGGHOgZEc6sQLCYkkX\nc+Zo9JLTcTkaxGEgIC644AI++uijA5MDLV++nFWrVtG9e/cDeQm5ubm0a9eODz/88KD9ly9fTtuA\n4Ny5cyeXXHIJrVq14txzzz1Q3gI0P8ApFf7AAw8A8H//93+sWrWKnj170rNnT0BLYKwPXNenn36a\ntm3b0rZt2wOlwpcvX06rVq34wx/+QJs2bejbt2+Z8zhMmDCBzp0706FDB/Lz81m7di2guRZXXnkl\n7dq1Izs7+0Cpjk8++YTc3FxycnLo3bs3oPNjPBmUDNm2bVuWL1/O8uXLadGiBZdffjlt27ZlxYoV\nYX8fwLRp0+jSpQs5OTnk5eWxdetWevToUaaMebdu3SgsLIzrfwvF5kFYLOlizpxS/wOUahBeO6rT\nUO+7bt265OXlMXHiRAYNGsTYsWO56KKLEBGqVq3K+++/T82aNVm/fj2nnnoqAwcOjDhn8j/+8Q+q\nV6/O/PnzmT17dply3aNHj6Zu3brs27eP3r17M3v2bG666SaefvpppkyZQn1H6AaYMWMGL7/8Mj/8\n8APGGDp37szpp59OnTp1WLRoEW+99RYvvvgiF110Ee+99x6XXnppmf27devG1KlTERHGjBnD448/\nzlNPPcVDDz1ErVq1mBPQCjdt2sS6dev4wx/+wFdffUVWVparkuCLFi3i1Vdf5dRTT434+1q2bMnF\nF1/M22+/zSmnnMKWLVuoVq0av//973nllVd45pln+Pnnn9m1axc5OTkxzxkNq0FYLOlg716YP7+s\ngDiMNAgoa2YKNi8ZY7jnnnvIzs4mPz+flStXHhiJh+Orr7460FFnZ2eT7fhsgHHjxpGbm0uHDh2Y\nO3du2EJ8wXzzzTece+65HH300dSoUYPzzjuPr7/+GoCsrCzat28PRC4pXlRUxJlnnkm7du144okn\nmDt3LgAFBQVlZrerU6cOU6dOpUePHmRlZQHuSoI3adLkgHCI9PsWLlxIo0aNOOWUUwCoWbMmlSpV\n4sILL+S///0ve/fu5aWXXmLYsGExzxcLXzUIEekHPAtUBMYYYx4NWT8MeAJYGVj0N2PMmMC6x4Hf\noUJsMnCzOVwKR1ksziRB4QSE1xpEmup9Dxo0iFtvvZWZM2eyY8cOOnbsCGjxu3Xr1jFjxgwqV65M\n06ZNEyqtvWzZMp588kmmTZtGnTp1GDZsWELHcXBKhYOWCw9nYrrxxhu57bbbGDhwIF988QUjR46M\n+zzBJcGhbFnw4JLg8f6+6tWr06dPHz788EPGjRvnSfa4bxqEiFQEngfOAloDg0WkdZhN3zbGtA+8\nHOHQBegKZANtgVOA0/1qq8WScoJLbDhUrw5Vqx42GkSNGjXo2bMnV111VRnntFPqunLlykyZMoVf\nfvkl6nF69OjBm2++CcBPP/3E7NmzAS0VfvTRR1OrVi3Wrl3LxIkTD+xzzDHHsHXr1oOO1b17dz74\n4AN27NjB9u3bef/99+nevbvr31RcXExGRgYAr7766oHlffr04fnnnz/wfdOmTZx66ql89dVXLFu2\nDChbEnzmzJkAzJw588D6UCL9vhYtWrB69WqmTZsGwNatWw/MfXH11Vdz0003ccoppxyYnCgZ/NQg\n8oDFxpilACIyFhgERNcBFQNUBaoAAlQGIuuglvRjjGYDlyf27tXOduPG0temTfrq1w/SWe10zhyo\nVAlCJ37xM1luxw7Yvx8CoaSpYPDgwZx77rllIpqGDh3KgAEDaNeuHZ06dYo5+c3111/PlVdeSatW\nrWjVqtUBTSQnJ4cOHTrQsmVLGjduXKZU+DXXXEO/fv04/vjjmTJlyoHlubm5DBs2jLy8PEA71A4d\nOkScoS6UkSNHcuGFF1KnTh169ep1oHMfMWIEN9xwA23btqVixYo88MADnHfeebzwwgucd9557N+/\nn4YNGzJ58mTOP/98XnvtNdq0aUPnzp1p3rx52HNF+n1VqlTh7bff5sYbb2Tnzp1Uq1aNgoICatSo\nQceOHalZs6Z3c0YYY3x5ARegZiXn+2WoCSl4m2HAamA28C7QOGjdk8BmoBgYHeEc1wDTgeknnHCC\nsaSJjz4yJjPTmJ9+SndLStm2zZgGDYxR0XXw67zz0tu+/v2Nadv24OU5OcYMGJD04efNm3fwwvnz\njZk505i9e5M+vqV8snLlSnPyySebffv2hV0f7r4AppsI/Xi6ndQTgKbGmGzUz/AqgIicBLQCMoEM\noJeIHKQHGmNeMMZ0MsZ0atCgQQqbbTnAnj1w882aFfznP6e7NaUUFsK6dRrB8/bb8OmnMH06LF0K\nffvCkiXpbV9oBJODn/WYdu2CfftgzRp/jm9JK6+99hqdO3dm9OjRVKjgTdfup4BYCTQO+p5JqTMa\nAGPMBmPM7sDXMUDHwOdzganGmG3GmG3AROA0H9tqSZQXXoDFi+Gss+CjjyBInU8rTvz3rbfCRRdB\nnz7QsSNkZUGLFrBsmeoS6aC4GH75JbKA8MPEtG+flvCoUAHWroXdu2PvYzmkuPzyy1mxYgUXXnih\nZ8f0U0BMA04WkSwRqQJcAowP3kBEGgV9HQjMD3z+FThdRCqJSGXUQT0fS/miuBgefBB69oT//AdO\nOAHuuEPt3Olm1iyoU0cT0UJp1gy2bFGfRDoIniQoFA8nDTLBAtARCMcfr+8rVx68g+WwxiQwIPJN\nQBhjSoDhwCS0cx9njJkrIqNEZGBgs5tEZK6IFAI3oT4JUH/EEmAOUAgUGmMm+NVWS4I89ph2Zk88\nodE3o0fDzJnw1lvpbplqEDk54R3ngbh0li5NbZscwkUwOdSvr070ffuSOkXVqlXZsGFDaafgCIhj\njoFjj1XhuH17UuewHDoYY9iwYQNVq1aNaz9f8yCMMR8DH4csuz/o893A3WH22wdc62fbLElSVAR/\n/SsMHaqmG4AhQ+Dpp+Hee+H881VopIN9+7SM9rURbqFmzfR92TIIJBullDlzoGZN1bhCqVdPTV+b\nNpXmRSRAZmYmRUVFrFu3ThcUF8PmzeBE62zcCNOmqbCwHBFUrVqVzMzMuPaxpTYsiXHffWpK+stf\nSpdVqKDaRH4+/O1vam5KB4sXw86dWg4iHOVBg2jXLrx2E5wsl4SAqFy58oEMXgCuuw7efbfUfPX5\n53DTTeo3OvvshM9jObxJdxST5VCksBBefVU7mKZNy67r3Vsd1qNHp8/G79QdilSHpkYNaNBANYhU\nY0zkCCbwr6LrkiVw4oml36+9Fk46Ce68084/YYmIFRCW+LnzTq1Aes894dc/9pg6gUePTm27HAoL\noXJlaB0ucT9AVlZ6NIiVK9XUE0lA+FWPacmSUtMaQJUq8MgjMHeuCnuLJQxWQFji49NP9XXffRol\nFI527WDYMDUzpWOUPmuWZklXqRJ5m2bN0tO2QJmImALCy1DXvXvh11/LahCgfqLTTtP/0jqsLWGw\nAsLinn37VHvIyoI//jH6tqNGQcWKkbUMPyksjOx/cGjWTHMRUm1eCZ0kKBQ/TEy//qr/XaiAEIEn\nn4TVqzW4wGIJwTqpLe55/XXtfN96C4IqX4YlIwNuu03NTHfcURrp5Dfr1sGqVZH9Dw5ZWSociooO\n9qO4xRj48ksIUxQuIgUFkJkZWfs6+mi9tl5qEE7WeKiAAOjSBc45B556CkaMKH/1tCxpxQoIizu2\nbVNtIC9PM5Pd8Kc/qT/inXdSJyCcDGo3GgSomSlRATFtmiYJxst550VeJ+JpshwQXUAAnHEGfPCB\nBhU4GozFghUQFrc8/riOzN99V8NZ3VCrltq4Cwr8bVswsSKYHIJDXRPp5EEn/AH48EPVmNzSokX0\n9V6X21iyRHNSGjUKv96JjS8qsgLCUgYrICyx+eUXzW8YPFg7/HjIz4eRI7XDS0XnU1ioHV6sczVu\nrD6SZBzVixersOzXL7pDPF780CCysiILdke4rVwZW7Bajiisk9oSm7vuUtPHY4/Fv29+vtrqU1XE\nb9Ysd51cpUqayZxMqOuSJXoML4UDeF/RNTQHIpRgDcJiCcIKCEt0vvsOxo5Vf0K4wnexOOUUTUz7\n7DPv2xbKrl2wYEFs/4NDsqGusTreRPHSxGSMCsFo7TzuONUubAE/SwhWQFgis3+/zqeQkaHhrYlQ\nubI6QVPhh5g3TyOT3JpJmjVLXoPwQ0DUq6cOYy+q4v72m+Y4RGtnpUoqJKwGYQnBCghLZF5/XSN1\nHn1Uwy8TJT9f7fUx5h5OGrcRTA5ZWdqBbtsW/7k2b9ZR/kknxb9vLOrXV+GweXPyx4oVweSQkWE1\nCMtBWAFhCc+2bXD33RrWOmRIcsfKz9d3v81Ms2apIHM7qndCXV3OR1wGtx1vIniZLOe2nZmZVoOw\nHIQVEJbwOGGtzzzjPqw1Eq1bqwnDbzNTYSFkZ7tvbzJVXf0UEF6W21iyRAMMYuV6WA3CEgYrICwH\n44S1DhkSf1hrOES0ymtBgX+zzRnjPoLJIThZLl4cARFcAM8rvNYgMjNjZ75nZqpJy9ZksgRh8yDS\nzcSJGumTRO3/hNm/X7WExYu1I1m8WF/Tp2un/uij3p0rPx/eeEOn28zO9u64Dr/+qpPiuPU/gHbE\nNWokrkE0bKgztHmNlxVd3TrSg3MhmjdP/ryWwwKrQaST777TyVoeeST15963D9q00dDVnj3h6qu1\nHs/s2WoSev31xMJaI9G7t7775Ydwm0EdjEjioa5LlvjjoAZvTUyxQlwdylsuxM6dauZMJIDA4hlW\nQKQLY9QJDDBpUurP/7//ac7AjTfC5MnaSe7cCQsX6ixj0eoFJULjxlpiwi8/RGGhdviRymhHItFQ\nV79CXEG1msqVk9cgtm2DtWvj1yDKAx99BH/+Mzz0ULpbckRjBUS6mDQJvvpKR/Fz56b+wXSE0ogR\nav5p2lRLT/hJ795a/XTPHu+PPWsWnHxy/OG4WVkqHI1xv8+uXTrS9ktAiHiTLOcIvngERHnRIByN\n8JlnSv09lpRjBUQ62L9ftYesLHjlFV326aepbcOnn0KHDmpHTxX5+eoE/eEH7489a1Z8/geHZs1g\nxw7Nh3CLI1D8EhDgTT2meBzp1atrCfLyIiAKC1XrrFxZs/gtacEKiHTwzjvaoY0apWWwjzsutQJi\n61b1f5x5ZurOCZpRXaGC936I4mLttBMpNJdIqKufIa4OXmgQ8bYzM7P8mJhmzYIePbTE/Pvvp66W\nl6UMvgoIEeknIgtFZLGI3BVm/TARWSciswKvq4PWnSAin4rIfBGZJyJN/Wxryti7V8067dppdVQR\n6NtX/QB+hYCGMmWKlqTo2zc153OoUwc6dfLeD+FM45moBgHxOaqdjtcvJzV4p0HUqRN5cqJQMjLK\nhwaxYYO2IydHJ51q0gRuvVUDKywpxTcBISIVgeeBs4DWwGARCTeL/NvGmPaB15ig5a8BTxhjWgF5\nQBw2gHLMyy9rKOno0aU2/4TV5NEAACAASURBVL599aGYOTM1bfj0UzUpdOmSmvMFk5+vJqZ4ZmGL\nhVNiIxENwkkgi1eDOOYYf0OTvajo6jaCyaG8aBDBJVOqVtWcnMJCeOml9LbrCMRPDSIPWGyMWWqM\n2QOMBQa52TEgSCoZYyYDGGO2GWN2+NfUFLFzJzz4oHbM/fuXLu/TR99TZWb69FMNbY2VPOUHvXur\n9vLVV94dc9Ys7VCPPz7+fatV04l04tEgFi/WjtfP6Tnr10++YF+8kVYZGRr1tHdv4uf0glCBf8EF\n0L073HuvmhMtKcNPAZEBrAj6XhRYFsr5IjJbRN4VESfwvjmwWUT+IyL/E5EnAhpJGUTkGhGZLiLT\n161b5/0v8Jq//U0T0x55pGzn0rChOoxTISCWLYNFi1JvXnLo0kVHhV6amQoLtTNJtMOON9TVzxBX\nh3r11KSSaIdYUqIZ8fFqEMbA6tWJndMrZs1Soe0EUIjAX/+qGtXDD6e3bUcY6XZSTwCaGmOygcnA\nq4HllYDuwB3AKUAzYFjozsaYF4wxnYwxnRo0aJCaFifK5s0qGM46S51vofTtC99+663pJRyOEEq1\ng9qhalUdDXolIEpKYM6cxPwPDllZ7gXEvn0qZP0WEMkmy/36q16beEqBlJdQ13AlUzp2hGHDbNhr\nivFTQKwEglNxMwPLDmCM2WCM2R34OgZwZrYvAmYFzFMlwAdAro9t9Z8nn4RNm9T3EI4zz9QH+osv\n/G3Hp5/qLGjpLKeQn68lN9asSf5YP/8Mu3cnN1Vms2baKbrJzygqUhOMnw5qSL4eUyKRVk42dSw/\nhDHw3HPgh9a+Z4/O9R1O4I8ebcNeU4yfAmIacLKIZIlIFeASYHzwBiISPIv6QGB+0L61RcRRC3oB\n83xsq7+sW6cq8iWXqCkpHF26qOPYTzNTSYmGmPbt66/9PBZO2Y3PP0/+WC+/rKGzXbsmfoysLLX1\n//pr7G1TEeIKyWsQibTTrQYxdy7cdBP8+9+JtS0a8+apAA4n8Bs1smGvKcY3AREY+Q8HJqEd/zhj\nzFwRGSUiAwOb3SQic0WkELiJgBnJGLMPNS99JiJzAAFe9KutvvPFF5qMdeutkbc56ijNE/Cz7MaP\nP6pNO13mJYf27bUDfO215I5TVKQj2csuS66qajyhrosX63uqBESiGsTSpXpPZYRz+0WgTh112sfS\nIObMKT2H18Sa9Om22zTyzIa9pgRffRDGmI+NMc2NMScaY0YHlt1vjBkf+Hy3MaaNMSbHGNPTGLMg\naN/JxphsY0w7Y8ywQCTUoUlhoYa0xqpieuaZ6kBOZp7kaHz6qY62e/Xy5/huqVhRM8knTdJqtoky\napSaO0aOTK498STLLVmiZg7HHOMXXpiYsrLim8tDxF0uhJN34oeAmDVLhdTJJ4dfX7WqFvGzYa8p\nId1O6iODwkJo2VJv7mg4kUWTJ/vTjkmTtLR43br+HD8ehg/XTuD22xMLq/z5Z+0grrsu9mQ4sTj+\neKhSxZ1gdjpev+tW1aypc0UnY2JKRKtykwvhtwbRrl3062vDXlOGFRCpwAnDjEWLFupA9sPMtGmT\nmpjSbV5yqFJFy4vPnw///Gf8+993nwrce+9Nvi0VK6qQcatB+G1eAh3NJ5pNbUzi7XSjQTgCYtky\nb808zqRPsSLSgsNeIwV9WDzBCgi/2bgRVqxwJyCcshuffaYOZS/5/HN1xKYr/yEc/ftrRNMDD+h1\ncsvMmTBunNqjvSo26CbU1el4/Y5gcki0HtO6dVrqOxEBkZmpuTqREvSKi9WZ37SpRhytWhX/OSJR\nVKQDGTfPSnDYq+MXsniOFRB+49hr3YZh9u2rD+G0ad62Y9IkNVt07uztcZPBGQkWF8fnR7jnHh1d\n3367d21xM3HQ+vWap5IKDQIS1yCSibTKyNCOP9J5f/pJ3wcFiiJ4aWZySny7zWkZPVod8Xfe6V0b\nLGWwAsJv4q0T1Lu3Oha9NDMZow7q3r3Vrl2eaNsWrr0W/v53NTfF4osv9NrcfTfUquVdO7KyVIuJ\nZtNOVQSTQ6IaRDICIlYuhGNe8kNAOM+K20mfbNir71gB4TeFhWoGOe44d9vXrauOZC/zIRYt0rIL\n5cm8FMyDD+osarE0AmcWvsxM+OMfvW2Dm1DXVOVAOCRasM/ptJ3orHiIlQsxe7Zqot26qe/Gaw3i\npJPim+f71lvV3HXLLTbs1QesgPAbtw7qYPr21Yqnmzd70wZHGykvDupQGjRQP8TEidHDXsePh6lT\nddtq1bxtg5tQ1yVL1CyWSMebCPXqqQYRz2x3oO3MyIgdNRcONxpEu3Ya6tukibdlLxJ5Vpxqr7Nn\n27BXH7ACwk9KSjTrNN6b/swz1Uno1cQ6n36qI7NUdWyJcMMNGvZ6223hw1737dOIpebN1TnpNW41\niMzMxDreRKhfX++hLVvi2y+ZSKtjj1XNIJwGYUypgIDE5/MOx9atasJLpKbW+efbsFefKGcG6XLG\nbbdpaYzLLktsf6dOUKwEuVDy8lSNnzRJb343TJ+uOQHVq6uZKvg1ZQpccUX87U8lTtjrwIHqk2jc\nWH0CGzdqZMuqVSpsx43zx49Su7ZmEsfSIFJlXoKyyXLx+FuWLNGikIlQsaLa9sNpEEVF2gEHC4j3\n30/sPKE4vo1EamqJaDRTp06aRGdDXz3DCohIbNyoN90ZZyQuIBKdyKZyZc12jkeDeO01jTA57TQd\nBc+Yob9hR2AajXPPja8N6aB/f+3YXn5ZH/ratUuF3HHH6Xq3AjMRYoW6Ll4MAwb4d/5QgusxuRVM\nO3ZoEcRkSo9EyoVwOvFgAbFunY7+4/EbhCPeCKZQcnOhXz947z0rIDzECohIfP65qtSzZ+t7IsXt\nCgu1s2/ZMv59e/eGDz7QDsvNw15QoJMAhdrwd+3SV+3a8bch1Yion6G4WNvrd7ZyKCeeCF9/rRM7\nhfo4tm6F335LnwbhFsdElkw7MzO1aF4ojoBo21bfg81y8WrJoRQWqgaXTAmTPn1U61+xQjVQS9JY\nH0QknHIXGzYkPoFKYSG0bq3mk3jJz9d3N1rEypUaIursE0zVqoeGcHCoVEk7xlQLB4Drr9fRd7gR\nqKNZpFJAJFLR1WmnHxrE7Nna8TpzXDvXwgtHtZNBnUyV4XieGYsrrICIxOTJpVm6TrJbvCQSleHQ\nooU+qG4m1nHKZocTEBb39OwJl1+uduzQnAynE0xVFjUkVtHVi1DczEzVmEKd48EOaigVQsk6qvft\n02MnM6cHqGbTsKEVEB5iBUQ4lixRtXn4cP3uqNbxsG6dah6J3vQiamZySmREo6BAOxO3CUaWyDz5\npNrTr7uubHhpqnMgQB3TFSvGJyCWLtX2O+apRHByIYId1Xv3woIFZe8xN459NyxapGa9ZGYFhNJn\npqAg/tBgS1isgAiHY1666CIdTSWiQSTqoA4mP187h2jnN0YfCCcD25IcDRqoBvHVV/DKK6XLlyzR\nTtfL7O1YOAX74jUxNWuWnKkmXC7EwoUqJEIHIV6EuibroA4mP1/NhOF8KJa4sT1KOCZPVltr8+b6\nQKRLQDgzr0UzMy1YoCGg1rzkHVdeqZnCf/pT6eh98eLUag8O8dZjchvUEA1HQAT7IUIjmBy8EBBO\nMEerVskdB0qfA6/mPD/CsQIilH371KzjTMuZna326HjnLCgs1HkGHDtyIhx/vDq5o93sjr3VESaW\n5KlQQUuQFxeXzn+c6hwIh3jqMe3fr6bRZAXE8cfre6iAqFTp4Ig8p8hhMmUuZs1KPJgjlBNOUD+R\n9UN4ghUQoUyfriUu+vTR79nZKhwWLozvOMk4qIPp3VtDL3fvDr++oEAf0vKcJX0o0qaNCodXXtFr\n/OuvqXVQO8SjQaxerSHNyQqyqlVVMAWbmGbPVuEQ2omfeKI+H7EmGYqGV8+KQ36+FnVMZCIqSxms\ngAhl8uRSZxeUxnfHY2bas0e1Di9u+vx8TX6aOvXgdSUlmiVtzUv+MGKECt6hQ3V0Xt41CC9CXB1C\nQ11DI5gcko1k+u03FWxe+B8c8vM1CsvrkvlHIDEFhIjcKCJ1UtGYcsHkyVpewzENtWih9tF4BMSC\nBTp6STZ5COD00zWSJZyZafp0DUW0AsIfqlfXMuS//abf0yUg1q93F5XjpYAInnrUmSTIDwHhha8u\nlJ49dZBn/RBJ40aDOBaYJiLjRKSfSDLhEeWcbdvg++9LzUtQ6jyLJ9TVy5u+Vi0t/x3uZneW9eyZ\n/Hks4enXT6PZQIsJppp69XSwsXVr7G2XLtWOsUmT5M8brEE4kwSFExCNGydX9tuJYPJSQNStq6U3\nyoMf4osv4Kqr4KGH4K23VKvZtCndrXJNTAFhjBkBnAz8P2AYsEhEHhaRmMOpgEBZKCKLReSuMOuH\nicg6EZkVeF0dsr6miBSJyN9c/6Jk+PJLfRiDBQSoJhCPBlFYqDNdNW/uTbvy8/XGCq1U+dlnZbUd\niz+MGaMVcY89NvXndpI116yJve3Spdphe+HszczUXJ7duyNHMIE6rpMp+z1njgqjZPI2wpGfr4O9\nbdu8PW487NkDv/89vPEG3H8/DBmihTjr1tXf27t3aa20coorH4QxxgBrAq8SoA7wrog8HmkfEakI\nPA+cBbQGBotI6zCbvm2MaR94jQlZ9xDwlZs2esLkyeqg69q17PJ27Urny3VDYaFmdXpVdTQ/X6NE\nvvyydNn27fDdd9a8lAqOOebgQUOqcEI/nVF8NLyMtHKS5VatKp0k6IQTwm974omJaxCzZ3tjig0l\nP18He19/7f2x3fL//p9elw8+UEHw00/w4YdatbhLF42WXLQofe1zgRsfxM0iMgN4HPgWaGeMuR7o\nCEQrrZkHLDbGLDXG7AHGAoPcNkxEOqLmLQ+nVovB5MnQo8fB9f6dG9iNmckY76MyTj1V7eHBZqZv\nvtERihUQhzdt2mjYrWO2jIYXORAOwclyjoM6knU50VyIvXs1oc0PAdG1q2rx6fJDbN8Oo0Zpf9Kv\nnxZ/bNNGy9nfdpvOhAfl3tzkRoOoC5xnjDnTGPOOMWYvgDFmP9A/yn4ZwIqg70WBZaGcLyKzReRd\nEWkMICIVgKeAO6I1TESuEZHpIjJ93bp1Ln5KFFau1Js13EgxnkimNWtUNfdSQBx1lE6IEnyzFxSo\nKaFbN+/OYyl/VK+uvo9YAmL7dli71jsBETz1aKQIJodmzdSRHu/ERpGys72gWjUVEunyQzz3nPYF\njzwSXrA6BQ8PAwExEdjofAn4BToDGGNczDIflQlAU2NMNjAZeDWw/I/Ax8aYCBPjKsaYF4wxnYwx\nnRo0aJBcS5zON5yAaNRIbYZuBIQfURmgmsL8+aryg974XbpoB2I5vMnJiS0gnDLfXmsQU6eWnSQo\nHG5m4wuHo5H7oUGAPjOFhaVRaKli0yZ47DGdO6RLl/DbHEYC4h9AsKdnW2BZLFYCwUXZMwPLDmCM\n2WCMcTLAxqBmK4DTgOEishx4ErhcRB51cc7Ecaq3hnsQRNyX3HAeZK9v+uBSxuvXw//+Z81LRwo5\nObB8efTpNL0uR16zJhx9NHzyiX53IyDidVTPnq1Rgi1aJNbGWDjPh1PtOFU8/rj+V9EmLjqMBIQE\nnNTAAdOSG+/rNOBkEckSkSrAJcD4MgcWaRT0dSAwP3COocaYE4wxTVEz02vGmIOioDzDKXiXnx+5\n4F12tjqZYlVWLSxUZ14dj1NHsrM1WqmgoPSGt+U1jgwcbTTaAMXpnL3SIERUi3AqCDiTBIXDEUrx\n+iEiZWd7RW6uVpxNpR9i9Wp49llNrowmVI85Rvuaw0BALBWRm0SkcuB1MxDzTjDGlADDgUloxz/O\nGDNXREaJyMDAZjeJyFwRKQRuQsNoU8+cOWq/jRapkp2tdt5YarTXDmqHChV0GtKCAtV2atbUOXgt\nhz/O/RTNzLR0qd4Tdet6d17HDxE8SVA4atXS8yYiIPwyL4HmZ/Tsmdry3w89pH6VBx+Mvl2FCiq8\nDgMBcR3QBTUPFQGdgWvcHNwY87Exprkx5kRjzOjAsvuNMeMDn+82xrQxxuQYY3oaYxaEOcYrxpjh\nbn9QQjjlvWMJCIg+itu1S0dcfggIUA1n1SoYO1ZvfK/CaC3lm4wM7YCj3XtelPkOxfFDuHEixxvJ\ntGmTOsD9FBCgz8wvvyRfcdYNS5bAiy/Ctde60+Tq1Dn0BYQx5jdjzCXGmIbGmGONMUOMMSn2+vjM\n5Mkab54RLsgqQJs2+vBFe0jnztV8BT+dbqDJP9b/cOQgEttR7WWIq4PzPPghIPx2UDu4KZnvFfff\nr+ayESPcbX84CAgRqSoiN4jI30XkJeeVisalhF27dHKYWIlQ1atrNc9ouRAzZ+q7XxpEVlZp1Vbr\nfziyyMnRey9cWW2nzLfXtaLi1SCWL3df9tsZaPk9C2Lz5vo7/BYQhYXw5ptwyy1w3HHu9jkcBATw\nb+A44EzgSzQayUVhmEOETZvgzDOhf7SUjgDRSm7s2wfPPKM3pJ9loc89V6M+QuvyWw5vcnJ0Ws7F\niw9et2qVlsTwWoPIydEoo1NPjb1ts2Zqey+KGpleypw5ajZz5p7wCxEtePn99/6eZ9Qo7fCd+UPc\ncJgIiJOMMfcB240xrwK/Q/0QhweNGsH777srpdCunT6g27cfvO6NNzTR7i9/8Xfqz8ce0xDXw7hm\noiUM0RzVXlZxDaZrV+3A3Ggm8UYyOQ7qVNzHWVkaXVRS4s/xd++GiRPh0kvV8eyWw0RAOLNubBaR\ntkAtoKF/TSrHZGdrNETofLe7d6v9sWNHOD9a9REPqFRJs0QtRxatWmlUTioFBGguhBviKfu9f79q\nEH77HxwyMvSca9f6c/ypU1W7i9cv6AiIVEVYJYAbAfFCYD6IEWgewzzgMV9bVV6JFMn0wgsaKfHw\nw/5qD5Yjl6pV1awYSUBUqBC5mF4qyMzUwYsbAbFsmWrhfvsfHBxnezKz3kWjoECF9+mnx7dfnTqq\n1YSzSJQTosZJBmoibTHGbEKrqvowRDmEyMrSEVWwgNi2TWOfe/ZMX8VPy5FBTo4GVISydKkKB78S\nztwQT9nvVEUwOaRCQOTlaT5IPARnU9eo4X27PCDqcDeQNX1nitpS/qlQQTNKgwXEM89ocb6HH7Z+\nAYu/5OSoE3jjxrLLlyzxx7wUL25DXWfP1melTRv/2wRlCw96TXEx/PhjYmHnh0C5DTf2kAIRuUNE\nGotIXefle8vKK9nZOgIyRucKfuIJOOccd5EeFksyRCq54UcORCK4nRdi9mzd1q1/I1kaNNBoLD80\niC+/VP9GImHnh4mAuBi4ATUxzQi8pvvZqHJNdrYKhtWr4dFHdSrIv/wl3a2yHAmEi2Tatk2rlZYH\nAdGsmT4b0YoKgv8lNkKpUEGjFf0QEAUFmiOVyADxcBAQxpisMK9ycDemCefG/vhjrfl++eWpU5Ut\nRzbHHacVh4MFhNdlvpPBTdnvHTs0VDyVAgLUzOSXgOjRQ+dsiZdDQEDELOYjIpeHW26Mec375hwC\nOJEXt9+uquXIkWltjuUII7TkhtdlvpMhuOx3+/bht5k7V82z6RAQ8cwr74aVK3WOlquuSmx/R0CE\n+pTKEW5MTKcEvboDI9HS3EcmdepoSN+WLXD99dC0abpbZDmSyMnRTtZJ+vK6zHcyuMmFSFWJjVAc\nDcLLnANntrpE66LVrKnO+kNZgzDG3Bj8XURqo/NLH7m0b69/6r33prslliONnBxNzFy4UE2bS5dq\neKXX848kQq1aOmeJU5MsHHPmqM0+1QItM1PzDbZsiT8cNRKffaa/N1Ft6BAo+Z1IVtd2IMvrhhxS\nPP202h4bHpkJ5ZY04nRGjpnJjzLfyTB0KIwbBwsOqtyvzJ6t2kOqE0q9zoVwJhnr3Tu531LOy224\nqeY6QUTGB17/BRYC7/vftHLMySfbsFZLemjZUkM2gwVEefA/ONxzj5aCue++g9cZk/oIJgevBcSC\nBVokMdmqynXrlmsB4WbGmSeDPpcAvxhjfMg4sVgsMalSBVq31o7WKfM9aFC6W1VKw4YawDFqFEyf\nXnbWw9WrNQw21f4H8F5AOOXDk52X5VDXIIBfgR+MMV8aY74FNohIU19bZbFYIuNEMq1cCXv2lA8H\ndTC33w716qk2EUyqS2wE45QV90pAfPaZXvesJK3th4GAeAfYH/R9X2CZxWJJBzk5Ohr/4Qf9Xt4E\nRM2aKhwmT4YpU0qXpyuCCdTsVbeuN+U2Skr0d3kxq+NhICAqGWP2OF8Cn9NYFcxiOcJxMqrfD7gC\ny5uAAPjjHzVy6O67S0NLZ88unV87HXiVLDd9ukZDeTGrYzkv+e1GQKwTkQN5DyIyCFjvX5MsFktU\nHAHx0UdaZjqdZb4jUbWqJpH+8AN8+KEuS5eD2sErAeH4H3r1Sv5Y5bzktxsBcR1wj4j8KiK/An8G\nrvW3WRaLJSL166tNvbhYhUPlyuluUXiuuEKnx733Xp37ff78w0NAfPYZdOig/0OylPNyG25qMS0x\nxpwKtAZaG2O6GGPCTIx7MCLST0QWishiEbkrzPphIrJORGYFXlcHlrcXke9FZK6IzBaRi+P9YRbL\nYY2jRZRH85JDpUpayHLePA173bs3vQIiM1MLG+7dG3vbSGzfDt99543/AQ59ASEiD4tIbWPMNmPM\nNhGpIyIxy5eKSEXgeeAsVLgMFpHWYTZ92xjTPvAaE1i2A7jcGNMG6Ac8E8jgtlgscGgICNApeDt2\nhKee0u/pcFA7ZGSorX/16sSP8c03Gjnmhf8BDn0BAZxljNnsfAnMLne2i/3ygMXGmKUBx/ZYwFXA\ntjHmZ2PMosDnVcBvQAM3+1osRwTOSLy8CwgReOQR7ZgrV1aTU7pwmwthjEYpTZ9+cMddUKC5KN26\nedOmci4g3CTKVRSRo4wxuwFEpBrgprZtBrAi6HsR0DnMdueLSA/gZ+BWY0zwPohIHho1ddBchiJy\nDXANwAnl0VFnsfjFqadqh5ubm+6WxCY/H/r21bkr0jktqlsBMX16WQd03bpw0kn6+vpr6NLFu8mO\nDgMB8QbwmYi8DAgwDHjVo/NPAN4yxuwWkWsDxz3wz4hII+DfwBWB6U/LYIx5AXgBoFOnTuUzTsxi\n8YOsLFizJn0ho/EgopFMTgXadOFWQDjFBseMgc2bdf6KxYvV97BqFfz5z9616VAXEMaYx0SkEMgH\nDDAJaOLi2CuBxkHfMwPLgo+9IejrGOBx54uI1AQ+Au41xkx1cT6L5cjiUBAODlWrprsFmt191FGx\nBcRPP8Exx+g8D6FFEPfv97bQYDkv+e32l65FhcOF6Ah/vot9pgEni0iWiFQBLgHGB28Q0BAcBjrH\nDWz/PvCaMeZdl220WCyWyIhoeHAsATFnDrRtG75CrtdVaMt5ye+IGoSINAcGB17rgbcBMcb0dHNg\nY0yJiAxHNY6KwEvGmLkiMgqYbowZD9wUSMIrATai5iuAi4AeQD0RcZYNM8bMivP3WSwWSymxciGM\nUQ3ivPNS16ZyXG4jmolpAfA10N/JexCRW+M5uDHmY+DjkGX3B32+G7g7zH6vA6/Hcy6LxWKJSUaG\nOqEjsWZN6ivOlmMBEU1fOg9YDUwRkRdFpDfqpLZYLJZDk8zM6FOPOhVnrYAAoggIY8wHxphLgJbA\nFOAWoKGI/ENE+qaqgRaLxeIZGRla9iNSh/zTT/retm3q2nQoCggHY8x2Y8ybxpgBaCTS/9B6TBaL\nxXJoESvUdc4cOO44b+osueVQFhDBGGM2GWNeMMZ4lGdusVgsKcSNgEil9gDluuR3imcOt1gsljQS\nTUDs26eFBVNdL6pOHS0guGNHas/rAisgLBbLkUO0qUeXLoWdO9MjICBxM9OiRbBxo3ftCcIKCMtB\nPPGE1lcrT3z0EZx9tg7yLJaEqVIFGjQILyDS4aCG5AXEjTdCjx7etScIKyAsB/H//p9OBvbbb+lu\nSSl/+xtMnFhaJsdiSZhIyXJz5mj2dJs2qW1PMgJizx4tINjTVf5y3FgBYSnD/v2wbJnedy++mO7W\nKFu3wuef6+fPPktvWyyHAdEExIknQvXqqW1PMgJi2jT1XVgBYUkFq1apcKhUCf7+9+Qm3/KKSZO0\nTdWrl04HbCmfDBkCzz2X7lbEIJKA+Omn1JuXIDkBMWWKaj2nn+5tmwJYAWEpw9Kl+n799Sos3n8/\nve0BGD9eC3FefbVO6LVzZ7pbZAnH7t3w9tvw+OOqiZZbMjNh3TptsMOuXersTceMd8kIiM8/19kF\n69Xztk0BrICwlMEREMOH62Rl6R4NlpSog/p3v4N+/fSZ/vbb9LbJEp6ff1bBUFSkZvFyixPqumpV\n6bL58zUCIh0aRK1aiZX83rVL56jwybwEVkBYQli6VCsQZ2XBDTfoiP1//0tfe779ViP4Bg6E7t11\nEjVrZiqfzJtX+vmNN9LXjpiEy4VwIpjSoUFUqKBCIl4BMXWqjpisgLCkiqVL4YQTtCO+6iq1+6dT\nixg/XiMTzzwTatTQmTatgCifzJunfd0FF8C775a14JQrwgmIOXP0Rjv55PS0KZFyG59/rhfcpxBX\nsALCEsKSJWpaAp3H5LLL4M03Yf366Pv5USXAGJ2psndvFQ6g0xvPnKkVmS3+E08nP2+eBgFdeaX2\ndZ984l+7kiKSgGjVSqMz0kEiAmLKFOjYUbUPn7ACwlKGpUtLBQRoDs7u3To9bziM0aS6449X27OX\nzJ+vAmvgwNJl+fl6zilTvD2X5WC++EL7HscvFYt586B1a+jTR2vdvfmmr81LnNq1oVq1g01M6TAv\nOcQrILZvhx9+8NW8BFZAWILYtk2T4048sXRZmzbQq5eGvIbOOW8M/OlPcM89Os/Kl196257xgQlq\nBwwoXXbKKTpdsDUz+c9//uM+KGDvXnVSt26t5smLL9b/b8sW/9sZNyJlQ103bdLRTToc1A7xCohv\nv9WL3quXf23CCghLjZ5EvwAAIABJREFUEMuW6XuwBgGqRaxYoeYeh5ISDTt96in44x/h6KN1QOMl\n48dDp06lFgHQzueMM6yASAWTJ+u7m+z1xYv1nmjdWr8PGaJBNuUhTDoswQJi7lx9P5Q0iClT1BzW\ntat/bcIKCEsQjikhVEAMGABNmpQ6q3fv1hHiSy/BffdpGYyOHeHHH71ry9q1GqQRbF5yyM9X05Mj\n0CzeU1QECxboZzdRbE4EkyMgTjtNI+HKrZkpWECkYxa5UOIt+T1lCuTllTrnfMIKCMsBIgmIihU1\n5PXLL+H776F/fzU/PP00jBqlGntennYkXkWu/Pe/+qxEEhBgy274iXNtu3bV/zVW4tu8eXoftGyp\n30VUiygoUPNjuSMzU/MgjFEBUauWLksXdepouQA3WaBbtui82j6bl8AKCEsQS5fqc+Ikdgbz+9+r\nX++MMzS67qWX4NZbS9d37qz39+zZ3rRl/HjVWrKzD17XqhU0amTNTH5SUAANG8IVV2h/FMtRPW8e\nNG1atozRkCEqWMaN87WpiZGRoaOZDRtKS2yIpK898WRTf/21JvX57KAGnwWEiPQTkYUislhE7gqz\nfpiIrBORWYHX1UHrrhCRRYHXFX6206I4Ia7hnpO6dTV8ETTG3fns0Lmzvnvhh9ixQ+3fAweGb4uI\nahGffVbOSzocohijAqJ3bzUdQmwzkxPBFEzr1tC+fTlNmnMcW0VF6ZlFLpR4BMTnn2vOxmmn+dsm\nfBQQIlIReB44C2gNDBaR1mE2fdsY0z7wGhPYty7wANAZyAMeEJEw41qLl4SGuIbyzDPwyy9w7rkH\nr8vM1Kl8vfBDFBSoph3OvOSQn6+5GY752OIdc+eqWSg/X6PYKlWK7qguKYGFCw8WEABDh+o9sWiR\nf+1NCEdA/PgjbN6cXv8DxCcgpkyBLl1UpfcZPzWIPGCxMWapMWYPMBYY5HLfM4HJxpiNxphNwGSg\nn0/tLJesWpXaZDCnzHdwiGsolSurEAiHiGoRXmgQ48dDzZrRE0R7B2ZFL69mpl9/9bcSrjHw6af+\nnMO5pvn5cNRROriOpkEsW6bWmnAC4pJL9N546y3v25kUjoBwsvkOFQGxcSPMmpUS8xL4KyAygBVB\n34sCy0I5X0Rmi8i7ItI4nn1F5BoRmS4i09etW+dVu8sFAwZoFnOqcMp8R9MgYpGXp7HwiU6MBSqo\nJkyAs85SLToSGRnqEC1PAsIY7W/y89V/4uesfN9+q+VHXn/d+2MXFEDz5lpyBaBDB9UgIgXYhEYw\nBZOZqZWo33jDn2z7hDnuOJVcjjf+UDExffmlXsgUOKgh/U7qCUBTY0w2qiW8Gs/OxpgXjDGdjDGd\nGjRo4EsD08HeversnTwZiotTc85IEUzx4Pghpk1L/Bg//qjJeoNc6Jr5+fDVV+mv+bNnD7z6qjrU\nzzpLM8CzstRX4xdOTsrUqd4ed88ezaB2IsUAcnO1OnZw8dNgHAHRqlX49UOH6sChXM0GWLkyHHus\neuCPP16dbOnErYCYMkUjAfLy/G8T/gqIlUDjoO+ZgWUHMMZsMMY4j/cYoKPbfQ9nnKSjkhKdZjMV\neCEgOnXSQVkyZqYPP1Sbdz8XBsX8fHVoe91JuqW4WOc+yMqCYcP0t7/6qppcbrpJ/SN+5Wo4WeZe\nJyf+8INWcQgVEBC5g583Dxo31gz3cJx/vmqDfmg7SeGYmTzQHmbMgL/+FZ58Eh57DEaP1hDw+++H\nf/5T79OoOPWUNm6Mvt2UKRp7HE299hJjjC8voBKwFMgCqgCFQJuQbRoFfT4XmBr4XBdYBtQJvJYB\ndaOdr2PHjuZw4b33jAFjKlQw5pJLUnPO++7T8+3Zk9xxWrUypn//xPbdv9+Yk04ypndvd9tv3qxt\nHjEisfMlytq1xtx9tzE1a+r/lJ9vzKRJ2n6HxYt13bPPen/+BQv02I0aGVOxojHbtnl37Pvv12u6\ncWPpsq1bjRExZuTI8Pvk5hpz5pnRj3vRRcZUrmzMW29519akGThQL+Tttyd9qA4d9FCRXg0bGvPU\nU8Zs3x7lILVqGTN8eOT1a9fqwR55JOn2BgNMNxH6Vd80CGNMCTAcmATMB8YZY+aKyCgRceJTbhKR\nuSJSCNwEDAvsuxF4CJgWeI0KLDsicFT2Cy9UDWLPHv/PuWRJaZnvZMjL01FoIvbmadNUexoyxN32\ntWrp+VLlh1i+XCdSatIEHn1UfQAzZqgpsG/fsiG5J56oNnlnpO8lzjHvvVfD4b2cr6OgQDXB4FyY\nGjWgRYvw59m/X01q4fwPwbzwgkZlDhmimfflAkeDSNJBvX+/Zp3fcINarHbsULPnvn36HHz9tZof\nb79dtc2nn46gUcQqt/HFF/qeIgc14J8GkerX4aRBDB5sTNOmxnz4oQ4YJk9O/FglJcb8/e86CozG\nqaca06tX4udx+Pvftc3LlsW/7803G1OlijGbNrnfZ8QIHfFu3hz/+dzy22/GXHaZjtYrVzbm6quN\n+fnn2PvddZcxlSrF93vc0K2bMe3bG7NmjV7rJ5/05rjFxfob77334HWDBxvTuPHBy5cu1Ta8+GLs\n4+/cacw55+j2991XVuPyk6lTjXnnnTArRo/WxkyfntTxly/Xw/zzn9G3+/pr1TYdjeLpp/X5PECH\nDsacfXbkA1x3nTHHHGPM3r1JtTcU0qFBWBLHSTrKz9dQ5+AiefEycaIW03vllejbLV0aPcTVLYkm\nzO3bB2PH6tSitWu73693bx3BffVVfOeLh1tu0bmWb75ZfQovvuhuXpmBA9WP5OW8COvW6SyTAweq\nj7VJE+9qYH3xhf4Pwf4Hh9xcLdgYOi9ItAimUKpWhXfe0az8hx7Sec/37Uu62VFZtUrvqcsuCzNq\nP/tsuOiipDWIhQv1vUWL6Nt166ba5jffqEZx221w6aVBFoJYGsTnn2vsdwrnrLACopyxb5+qq61a\nabBCnz4qIBINEXTMEdHMME6Z72Qc1A7t2mlHEG+nNWWKFuhza15y6NxZzWLffBPffm6ZPVtj+G+7\nTSvXZoQL1I5AXp6Wq/DSzPTxxyoQnSRCr3JPQO+RatXCJ+h26KDvoWam+fP1PVIEUyiVKqmAvftu\n+Ne/tOijX1Fo+/apYNi4USvLHvQMtG+vkj9Jh69bAeHQtasKikcf1UHROecEhFc0AVFUpKFgqTQv\nYQVEuSM06WjQIB25FRbGf6z9+7XoHWgHHDqfQ/A5wRsBUbmyjjbj7bTefFOT4373u/j2q1ZNbeZf\nfx3ffm4ZMULbdeed8e9bsaIWNvz4Y+8S2saP16hMJ7IoL0+z29euTf7YBQU6QD3qqIPXOQIiNJJp\n3jytixWuflckRODhhzXq5733NOfHj5IpTzyhg+6//139VX74g0AFxDHHRE4ijcSf/6y+mU8+UX/W\n7qOjCAgnX6NPn+QaGydWQJQzQlX2/v31gUrEzDRjBqxeraPNLVsi5yd4EeIaTF6ediRuO8Vdu7Sj\nOO+8xKoHdO+uxS3dFMKMh++/16S9O++MrwMMZuBADYf1QoDt2gWTJpWtUeWEwydrZlq5UrWBSP1P\n3bpajC9UgwhXg8ktt9yiYaGTJ3vraAcdoIwYoYEe116r1qQJE/wRRAsXqvaQSK2/P/xBtYgffoC3\nPqmDiVTy26memOKEPisgyhmhKnvDhlp2JREBMWGCzmn+xBN680YyM3ktIDp31s76p5/cbf/xxyrA\n4jUvOXTrpsLIy/kojNGZ8ho2VN9DouTnq8nNi9HrlCmaoxBcoyo3VzWVZH97cHmNSDgZ1Q7GJCcg\nQKvFVqjg7eh+yxYYPFizuF94Qe/9gQPVjOp13giogHDKnCfCRRfp71+6sQ6yZw+/LgwZ6ZhA9cRe\nvfRipRArIMoZ8+apnTt4HvJBg3SEtWJF5P3CMX682jubN9eOxJkhLJQlSyKX+U6EeEe1b76pDtdE\nzavOpFpempkmT1an7YgROlteohx9tHa648cnX2pi/Hg9XvB1OvpoHVS6udYTJ8Kzz4bPzi8ogAYN\novtrc3O16J4zjejKlbB1a3ICon599XlMmJD4MYIxRp3fv/yi5T2cgId+/dT/4bWZaft2fS7d+h8i\n0a8fXHGLPoDn99pU9lmfN6+0emKKsQKinBFuROaMGOO5uX/5Rf0Wzr75+Woy2bbt4G2dKq5elcPP\nytIH381orbhY/SQXX5x4cEbdutpJeiUgHO2hSRO45prkjzdwoPp5nJktE23T+PFqq65atey6vDwV\nENHMJ/v2afTQLbfoyPrWWzWvwzm2U9472gDV8UM4/rB4IpiiMWCADoCKipI7DsC//60DjpEjy87G\nWbu21oTyWkA4VWqTFRAAJ3ZSAbFz9aayJdId/4MVEEc2kZKOWrTQVzxmJsc57QiIPn3USf3llwdv\n61WIq4Mzw5ybUe3776tTPlHzkkP37hr+GckRHw//+Y/6b0aODO+wjZf+/fU9mc5p5kwN2QxXAr1z\nZ61YvXhx5P2nTFF/1EMPqUb63HNw0klabfX113WAGsv/6TjGHX+BVwLC+U3OPZsoixdrslqPHirg\nw51n3rzo1yle4o1gikpAhW9/wqayg52CAv2zmjTx4CTxYQVEOWLFClVZwz1wgwapycNt8b7x49W0\n1Ly5fu/aVUeeoX4Ip8y3V/4Hh86d9WF0zBGRePNNPXeytce6d1ftKJFor2D27VOzUqtW3lXTbdRI\nf18yAmL8eB3dn332weucaxdNY3vjDY3GuuMOFQjLlqkWMXEiXH65bhNrgNqokZoCHT/EvHlqlqpf\nP/7fE0zLljpAScbMtG6dBjlUrqy/r2LFg7cZMEDfvTJngQoIEXd5MTEJFAw8reUmvv02kCOyd68+\n+E59+xRjBUQ5ItqIbNAgvVfcJF1t2aIjxuDRZtWq6swNFRBelPkOR16emi5mzIi8zZo1qj0PGZK8\neatbN31PNh/i3//WPJSHHgrfySTKwIHagSc6P/P48RqsEK5ocevW6ouIpLHt3KlRYhdcUGqeatxY\ngxdWrNDSDyNHlpb3jkZublkBkaz2APrfDxig98L27fHvv2qVmo8WLdK0hsaNw2+XlaU+Fi/NTAsX\n6nXzZO6egAaR02QTxcUBk+S0aeroSYN5CayAAPzP5nRLtLLJnTtr5+DGzORMJBNqjujTRyOLVq8u\nXeZ1BJODm1HtuHGqwSRrXgLtFJo0Sc4PsXu3dpQdO+po1EuSMaP8+qvOERNphr2KFTUXJJKAmDBB\n+5ihQw9eV7OmahIPPOCuLbm5ep/u2qXvbhPkYjFggF7/eOtqLV+u2uOKFTp4imUmGzhQ75FYRVPd\n4oS4ekJAQLQ6VnMhvv4alZoiKU+QczjiBcS2bWreu/POyPXuU8X8+RpWWa/ewesqVtSHyE3S1fjx\nqq2GZsQ6gxDH5wX+CYi6dVXtjiYg3nxTk1m96mS6d9eHKtFooTFj1Ln/8MPez1/ftq3mESQyenVM\nItGmYM3LUyESLiv5jTc0ue700+M/dygdOuiAavJkzenyQoMA/e9q1YrP/PPzz7rfxo0qWNz8voED\ntf1elNE3xmMBEQhdrCubyMgICIiCApXK4TqFFHDEC4itW+HUU7WMQtOmGumxYEF62hJLZR80SH0Q\n4RzNDiUl8NFHmpEcGhXUvr3eZ8HhrkuWqG3bjXkhXqI5qpcsUeHhhfbg0L27xronOv/xhx9qR+5H\nsqoTiz95sou5AUJw/EnROqLOndVUGOqD2bhRO8PBg70xmTmOaifKxisBUbmyhnr+97/uktnmzFFn\n9O7daqJ3aoDFolMnzXj2wsy0apUOMD0TEBUrQq1ayOZNdOsG07/cjvn++7SZl8AKCBo10lo7ixZp\nVuObb+qI9pxzNCw0VbhJOnKK90W7ub//XjuFcKPNChXU11VQUDrKXrrUmzLf4ejcWR+icOGLzhzF\nl1zi3fm6d9f3RM1Ms2eXTnrkBwMHRqgJFIVw/qRwRDLpvfOOapyXXhpfWyPRtKmGjDqmTq8EBKiG\nvHatZsVHY/p0OOMM7U+/+gpyctyfo0IFPY8XZfQ9jWByCNRj6t4dTlrzNbJ3b0wH9Zo1/s1/fsQL\nCIdmzeD559XEMGKE3nhdusSXRTt+vDpLX345/ptv9WrVDqI9cNWr67wDb74ZWcsZP147+759w6/P\nz9dO28nY9jrENRin02rXTqNfgl8PPaQjwEgOxURo2VI1pEQc1b/9pp1TdrZ37QmlRw+1Iowd636f\nsWP14XcicCKRmamDnVCN7fXX9Z6KpxONhoiamXbtUkHx/9s7+yCpqiuB/w7jAAqK4AB+ADtqMAYQ\nCU6ICiSIomh0EDEbP1ZTirimiKsVBSVGjWQxCoorYlmiGyVBRMKqi4aCAKKx3KwCijNBxCWAqAEZ\nWD92CN+c/eO8xzQz/TnTr3um+/yqprrf7fveO3f69jv3nnvuOZnGH0rGhRfaQz+ZmWnjRuvDRx1l\nA4HG7GCurDTLQZheobFErSDOYwn7S9vUeWAk4MYb059BZYoriHp06WIPr02b7B8/bZr56qdiwwZz\ni1y5Eq6/3hTOww+ndvMMSden/P777Uc0ZEj8UBbz59t61lFHxT8/NJ+Eo9hwk1wUVFTA3XfbLOGy\nyw79Gz3a0nVmExH7LTVmBlFdba9NjPyclNJS61PPP5/eYvWGDeaWOmhQymdE3L0nH39syvLqq7M7\nKwo3zPXqld3rdupk7tiJZsj795tL7oEDFoSvsf323HNTz8TTYe1aG7RlEuE3JYGC6N0bLmi1hI86\nD0zqIrV9u82GIvOCTZQooqX9RZEwaPduS6fYqZPqp58mrrd3r+pZZ1kKyvXrVRcuVD3nHEsM0qGD\npafcvDn5vR591Opv2ZJarjVrLN3kMceovvdeXXmYinL69OTnn3yy6iWXWBKhCDIY5pWHHrI2/e1v\nmZ03daqd9/nn0cgVsmuX6umnq5aVJZdx3z7VgQOtT6WbfCnMfxOmC73//sYnb0rGrFl23RtuyO51\nVVWnTLFrb9zY8LPJk+2zZ59t+n1GjLAESE1JWjR8uCVuyiqjRlne3iC96MOd709a/ckn7X/y7ruN\nvyWeMKhxtG5t5pxduyyoWKLFs/vuM9v/jBnma33BBTbCeecdG7E/8ICNdlatSnyvNWtsBNWlS2q5\nTj3VTGBHHGHxu8IoreHUPNy5m4hhw2x6/dFHdhzVDCIfNHYdorraTF/p/P+bQps2NoPYsSN5n3rg\nAXjrLTN7lpend+3QzLB8ua0xzZplI/J0z0+XM86w1969s3tdSOwOXFVlpt+RI+s29jX1Po0Nox+S\nVQ+mkDAnxLJlAMypOZeamsTVn3vOngf9+mVZjpBEmqOl/UWZcvSpp0xLT57c8LNlyyyh+3XXJT5/\n7VrLFHjNNYnrfO97NmLMhA0bVE880UaZb72lOniwjU5TMW+etWfcOHtdvjyz+zZn9uxRPeKI5Lnf\n43HGGZYOMleEI7946ULfecdSlV5xRWYj3C+/tL44caLNLMFSwEbBvHmqX38dzbVPOUX1ggvqjnft\nUu3bV7VrV0v/mg22bLH/1X33Ne78nTvt/HvvzY48Bxk3TrVNG9UbbtC97TtoK/bpSy/Fr7ppk33H\nEyc27ZYkmUHk/cGerb8oFcSBA6qXXWb5iFeurCvftk31hBOsQ6fK+XzzzZZvOZEJo6xMdcyYzGXb\ntEm1Z0/Vdu0sN/Pdd6c+Z/t269xlZdYDtm/P/L7NmaFDM5v679un2rat6s9+Fp1M9TlwQHXkyIZ9\nqrbWvs/u3etMRZnwrW+pXnyx6u23m5LZti17MueK226z30qogMaPt3766qvZvc9ZZ9nAoDFUV5tM\ns2dnV6aDdsHjjtN9I0ZqmzaJ+2Voclu3rmm3TKYg3MSUBiKWJrFLF/Mn37HDpvCjR5v3y/PPQ/v2\nya8xdqx5Nj31VMPPamos129jXAa7d7d9ET16mLkilbcLmCmrosLumc0w382FwYPNdJBu3Kp168yM\nGKUHU33i9Smw1Kbr1sFvf9u472XAgCD5zPPmFZSn/VVN4pJL7LeyeLGZCqdMMRf0TLMNpuLSS82p\nZObMzM+NxIMJ6r70zZspOf88BgxI7JU3e7aZFaPyQgR8BpEJr71mI+8xY2zqDqoPP5z++eefbzOO\nPXsOLX/9dbvWokWNl62mRvWVV9KvP2GC3bN//8bfs7myZIm1bcGC9OrPnWv1Y0fyuSI0UY4erfry\nyybH+PGNv97jj9s1QHXOnKyJmVP27lXt2NHWa8vLVU86KfUMvTHs2KE6bJim5dhRn9AhIOtyzZlT\n9wV++KFOmGAzwdraQ6utXm1VHn206bckXyYmYDiwFlgH3Jmk3ihAgYrguBSYCVQDa4AJqe6VCwWh\nqnrHHfZfKy01O+n+/emfO3++nfv73x9aHiqbTz7JrqzJWLrU7nn55bm7Z66orbUf1YQJ6dX/xS/M\nPLdzZ7RyJeLnP7fvol07M43t2tX4a61YYddq394egC2Vq66ydrRqZetrUbFzp2plpWbszXfttTbY\nyzqLFpkw3bqpHjigCxbY4ZIlh1a76y7736TyjkyHZAoiMhOTiJQAjwMXAr2AK0WkgRFFRI4EbgFi\n94D+EGijqqcBZwD/LCLlUcmaCRMnwne+Y2aamTMzywB40UXmUfLYY4eWf/CBJT3Pqj91CgYOtNls\nLs0quaJdOwsJke6GuepqMxXUT8STK375SzMV7N9vXilNyUFx2mlm7rz8cvNya6mE3kx33GEbVqOi\nbVuYN8/MfBMmwF13pRfLKxIPJqgzMZ13Hohw9tlmjozty6pmXjr33OxuVIxHI3N4pcUAYJ2qrgcQ\nkTnACOCDevV+BTwIjIspU6CdiBwGHA7sAdLcchYtrVubi+nf/34wfHvalJTYWsS4cea2Fz6cwyRB\nUYV4iEebNnbfMCVjoTFokLmI7t6d+oFbVWVKP1+Ulpq9fevWptuTW7c2l+tu3bIjW74YNcoe3KlC\njGSD0lIL896+vW1Era2FRx5JPPjTIEjflVdGIEyPHvYlXnopYGuEffse6rb99tu2iTLdCLxNIcpF\n6hOA2MyqnwZlBxGR/kB3Vf1DvXPnATuAzcAm4CFVbRCgV0RuFJEVIrKiJpmzcJZp2zZz5RBy/fW2\nMXL69LqybMXVz5SuXbOTMa05MniwKYdwj0givv7afmz5nkkdeWT2Fhv79Gn5iv+ww0xJRBEjLB4l\nJfDkk+YkMG0a3HBD4jQAW7daBr9IZhBdu5rXyogRB4sGDzalH8Zbmj3bfrcjR0Zw/3rkzYtJRFoB\nU4Hb4nw8ANgPHA+cCNwmIg22c6nqDFWtUNWKzvEyqTRDOnWy0AezZtl+mC++sDhM+VAQhcygQTYj\ne+215PXCcCX5VhBO/hGBhx6ykfkzz8ATT8SvF5kHU0i9ODmDB5vFYtUqi9b8wgvm6ZUonE42iVJB\nfAbEhmLrFpSFHAn0AV4XkY3AmcB8EakArgIWqupeVd0KvAVURChrThk71rJ8PfNMXdC8bOVEcIyy\nMrPrp8ovkIsYTE7LQcQUxJAhFpOttrZhncgVRD3COFxvvmm5XLZuzW6Y/GREqSCWAz1F5EQRaQ1c\nARwMj6WqX6lqmaqWq2o58N9ApaquwMxKQwFEpB2mPPKUpSH79OtXZyMPH1A+g8g+l1xioaGTJYKq\nqjLzTh7ywTvNFBF48EF7EE+d2vDztWvNxBNFDpV4HH+8hcN5800zL3XoYHtcckFkCkJV9wE/BRZh\nrqpzVXW1iEwUkVRLT48D7UVkNaZonlHVqqhkzQc332yRVKdNszUJf0Bln3TSfIbOArl0EHCaPwMG\n2BrIlCmmKGJZu9ayJWYzZ3kqBg8255gXXzS5cuVxF+kahKouUNVTVPVkVZ0UlN2jqg0C7arqkGD2\ngKrWquoPVbW3qvZS1SlRypkPRo60kUGY1zcTd1knPXr3tuCJicI6q9oMztcfnHhMmmSm4EmTDi2P\nzMU1CWFq1dra+LnFo8IfS3mitBRuusneu3kpGkTMzLR0aV0oi1g++cTCcfj6gxOPb37Twuk88URd\n7vY9e+x9rhVEuA5x3HHZyS2eLq4g8siYMbapK58++IVOsjSfVYHR0mcQTiLuvddcbu+5x47Xrzf3\n18ZksmsKYU7yMWNya9qKcqOck4Jjj7UUii3dZ705E6b5fOWVQ1zLgToHgT59ci+X0zI4/ni49Vb4\n9a8tu9/HH1t5rmcQImaOzvVamc8g8kxZmY1QnGgoLYXhw01B1E/OU1VlzgEdOuRHNqdlMH68RcCY\nMCH3Lq6xtGrlCsJxsk5lpXmixOZrhkPDnThOIo4+2mI0LVwIzz5rm52LZVDhCsIpeC680Oy2sZvm\ndu+20aArCCcdxo613Ctr1uRn9pAvXEE4BU/HjuYmGOvuumaNLTa6B5OTDm3bWu55cAXhOAVHZaXF\nXdqwwY7dg8nJlGuvNbfXSKK4NlNcQThFQbirOjQzVVdbuISePfMnk9OyKCmBp5+Gc87JtyS5wxWE\nUxScfLLtWA/NTFVVtkHRPcgcJzGuIJyiobIS3njDdk+7B5PjpMYVhFM0VFZaPP3f/Q62bHEF4Tip\ncAXhFA3f/a5tTJw82Y7dg8lxkuMKwikaSkrg4ostSB/4DMJxUuEKwikqQm+mLl1sR6zjOIlxBeEU\nFcOGQevWbl5ynHRwJz+nqGjfHqZPh/LyfEviOM0fVxBO0TFmTL4lcJyWgZuYHMdxnLi4gnAcx3Hi\n4grCcRzHiUukCkJEhovIWhFZJyJ3Jqk3SkRURCpiyvqKyJ9FZLWIVItI2yhldRzHcQ4lskVqESkB\nHgeGAZ8Cy0Vkvqp+UK/ekcAtwNsxZYcBs4BrVPV9ETkG2BuVrI7jOE5DopxBDADWqep6Vd0DzAFG\nxKn3K+BBYFdM2flAlaq+D6Cq21V1f4SyOo7jOPWIUkGcAHwSc/xpUHYQEekPdFfVP9Q79xRARWSR\niLwrIuPj3UD74e8XAAAGEklEQVREbhSRFSKyoqamJpuyO47jFD15W6QWkVbAVOC2OB8fBgwCrg5e\nR4rIufUrqeoMVa1Q1YrOnTtHKq/jOE6xEeVGuc+A7jHH3YKykCOBPsDrIgJwLDBfRCqx2cafVHUb\ngIgsAPoDSxPdbOXKldtE5OMUMpUB2zJsR6FQrG33dhcX3u7M+YdEH0SpIJYDPUXkREwxXAFcFX6o\nql9hjQJARF4HblfVFSLyV2C8iBwB7AG+DzyS7GaqmnIKISIrVLUiVb1CpFjb7u0uLrzd2SUyE5Oq\n7gN+CiwC1gBzVXW1iEwMZgnJzv0CMz8tB1YB78ZZp3Acx3EiJNJYTKq6AFhQr+yeBHWH1Duehbm6\nOo7jOHmg2HZSz8i3AHmkWNvu7S4uvN1ZRFQ1ius6juM4LZxim0E4juM4aeIKwnEcx4lL0SiIdAMH\ntnRE5DcislVE/hJT1klEFovI/wSvHfMpYxSISHcRWSYiHwQBHm8Jygu67SLSVkTeEZH3g3bfF5Sf\nKCJvB/39BRFpnW9Zo0BESkTkPRF5NTgulnZvDIKYrhKRFUFZ1vt6USiImMCBFwK9gCtFpFd+pYqM\nZ4Hh9cruBJaqak9ss2EhKsh9wG2q2gs4ExgbfMeF3vbdwFBVPR3oBwwXkTOx+GaPqOo3gC+A0XmU\nMUpuwdzoQ4ql3QDnqGq/mP0PWe/rRaEgSD9wYItHVf8E/G+94hHAzOD9TODSnAqVA1R1s6q+G7z/\nP+yhcQIF3nY1aoPD0uBPgaHAvKC84NoNICLdgB8ATwfHQhG0OwlZ7+vFoiBSBg4scLqq6ubg/Rag\naz6FiRoRKQe+jYWQL/i2B2aWVcBWYDHwV+DLYLMqFG5//zdgPHAgOD6G4mg32CDgjyKyUkRuDMqy\n3tcj3SjnND9UVUWkYH2bRaQ98B/Arar6dRDnCyjctgeh8PuJyNHAS8CpeRYpckTkYmCrqq4UkSH5\nlicPDFLVz0SkC7BYRD6M/TBbfb1YZhCpAgcWOp+LyHEAwevWPMsTCSJSiimH51T1xaC4KNoOoKpf\nAsuAs4Cjg8RbUJj9fSBQKSIbMZPxUOBRCr/dAKjqZ8HrVmxQMIAI+nqxKIiDgQMDr4YrgPl5limX\nzAd+HLz/MfCfeZQlEgL7878Da1R1asxHBd12EekczBwQkcOxDI5rMEVxeVCt4NqtqhNUtZuqlmO/\n59dU9WoKvN0AItIuyMSJiLTDEqz9hQj6etHspBaRizCbZQnwG1WdlGeRIkFEngeGYJFyPwfuBV4G\n5gI9gI+Bf1TV+gvZLRoRGQS8CVRTZ5P+ObYOUbBtF5G+2IJkCTbgm6uqE0XkJGxk3Ql4D/gnVd2d\nP0mjIzAx3a6qFxdDu4M2vhQcHgbMVtVJQWrmrPb1olEQjuM4TmYUi4nJcRzHyRBXEI7jOE5cXEE4\njuM4cXEF4TiO48TFFYTjOI4TF1cQjpMCEdkfRM0M/7IW8E9EymMj7zpOc8JDbThOanaqar98C+E4\nucZnEI7TSIKY/JODuPzviMg3gvJyEXlNRKpEZKmI9AjKu4rIS0HuhvdF5OzgUiUi8lSQz+GPwY5o\nRORfgvwWVSIyJ0/NdIoYVxCOk5rD65mYfhTz2VeqehowHdupD/AYMFNV+wLPAdOC8mnAG0Huhv7A\n6qC8J/C4qvYGvgRGBeV3At8OrnNTVI1znET4TmrHSYGI1Kpq+zjlG7FkPeuDQIFbVPUYEdkGHKeq\ne4PyzapaJiI1QLfY0A9BaPLFQZIXROQOoFRV/1VEFgK1WKiUl2PyPjhOTvAZhOM0DU3wPhNiYwXt\np25t8AdYJsT+wPKYKKWOkxNcQThO0/hRzOufg/f/hUUYBbgaCyIIlgbyJ3AwyU+HRBcVkVZAd1Vd\nBtwBdAAazGIcJ0p8ROI4qTk8yNgWslBVQ1fXjiJShc0CrgzKbgaeEZFxQA1wXVB+CzBDREZjM4Wf\nAJuJTwkwK1AiAkwL8j04Ts7wNQjHaSTBGkSFqm7LtyyOEwVuYnIcx3Hi4jMIx3EcJy4+g3Acx3Hi\n4grCcRzHiYsrCMdxHCcuriAcx3GcuLiCcBzHceLy/z3/0i3EMTM8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}