{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hp_optimization_without_stratified_K_Fold",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/Hp_optimization_without_stratified_K_Fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZpyLcr_wktZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U keras-tuner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11sCznT-2mmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tAAGti39qMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r my_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "b3224548-b69b-4188-ba2f-9a9e5dfcd2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-87QSVhqhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSbeCedhuxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbcwLGg3iNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQdR4izXiT0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5wIylYmsQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = df_test.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data_stand = train_data - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVOoNOvm0Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_stand = test_data - mean\n",
        "test_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00VohsAyokpq",
        "colab_type": "text"
      },
      "source": [
        "##Vettorizzare i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvS_9ISpxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={'adenocarcinoma':0, 'large cell':1, 'squamous cell carcinoma':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPW9U0XrWY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_dec = [word_index[label] for label in train_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4SBiKFQsKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels_dec = [word_index[label] for label in test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMbTYR7okJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "3cfab82f-eac0-45ba-b14b-6522fa04486c"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Frv4FDNn6Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels_dec)\n",
        "one_hot_test_labels = to_categorical(test_labels_dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn0tkOGc3LKN",
        "colab_type": "text"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS76u6iu3Seg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjC4zqJ3bui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.85, svd_solver='full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLUCf9qX4p_e",
        "colab_type": "code",
        "outputId": "8b740a45-ca8d-4451-8616-71a9eb73579b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pca.fit(train_data_stand)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.85, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyaKgNZ44o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_pca = pca.transform(train_data_stand)\n",
        "test_data_stand_pca = pca.transform(test_data_stand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9C4nl05b_g",
        "colab_type": "code",
        "outputId": "39f5fe7c-4495-4f02-b58e-c72c6e967975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_stand_pca.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSKvSu4s5ip",
        "colab_type": "text"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osgm8ZvLpZh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTbHiq0D-4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAzbu7P1VylY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqbUCK5wOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KutkQ9Noj5mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hp):\n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "#  model.add(layers.Dense(units=(hp.Int('units', min_value=3, max_value=8, step=1)), \n",
        "#                         activation='relu', input_shape=(9,)))\n",
        " \n",
        "  drop_rate = hp.Choice('drop_rate', [0.0, 0.1, 0.2, 0.3,\n",
        "                              0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "\n",
        "  model.add(layers.Dense(4, activation='relu', input_shape=(7,)))\n",
        "  model.add(layers.Dropout(rate=drop_rate))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "#  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "#  lr = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "#  decay = hp.Choice('decay', [1e-4, 1e-5, 1e-6, 1e-7, 1e-8])\n",
        "#  momentum = hp.Choice('momentum', [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
        "  model.compile(optimizer=SGD(learning_rate=1e-3, momentum=0.5, decay=1e-6, nesterov=True), \n",
        "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1ZG40_dJtke",
        "colab_type": "text"
      },
      "source": [
        "##Prova Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABYrxmZxJdlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFCCTjE6JrQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_data_stand_pca, train_labels_dec,\n",
        "                                                    stratify=train_labels_dec,\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state=30)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pus4JhTKWWB",
        "colab_type": "code",
        "outputId": "e1115036-61a7-4952-9db1-af1bd51eda0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.count(2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yP9-PE1Wjz-",
        "colab_type": "text"
      },
      "source": [
        "#Keras tuner RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "89e54b2d-6fef-4772-d19d-9a6e153e93fc",
        "id": "oHDM8LE39gTU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 100\n",
        "  \n",
        "one_hot_partial_train_targets = to_categorical(y_train)\n",
        "one_hot_val_targets = to_categorical(y_val)\n",
        "\n",
        "tuner = RandomSearch(build_model, objective='val_acc', max_trials=15, \n",
        "                       executions_per_trial=5, directory='/content/my_dir', project_name='RandomSearch')\n",
        "  \n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(X_train, one_hot_partial_train_targets, validation_data=(X_val, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=5)\n",
        "  \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">drop_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 2ms/sample - loss: 2.0618 - acc: 0.3942 - val_loss: 1.1841 - val_acc: 0.5185\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.9163 - acc: 0.4615 - val_loss: 1.1724 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.4905 - acc: 0.4904 - val_loss: 1.1654 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.8202 - acc: 0.4231 - val_loss: 1.1608 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.4916 - acc: 0.4615 - val_loss: 1.1508 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.7321 - acc: 0.4231 - val_loss: 1.1278 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.2638 - acc: 0.5000 - val_loss: 1.1134 - val_acc: 0.4074\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.2965 - acc: 0.4231 - val_loss: 1.1157 - val_acc: 0.4074\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.4087 - acc: 0.4327 - val_loss: 1.1002 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.4136 - acc: 0.4038 - val_loss: 1.1012 - val_acc: 0.4815\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.2855 - acc: 0.3846 - val_loss: 1.0763 - val_acc: 0.4815\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.2055 - acc: 0.4327 - val_loss: 1.0530 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1398 - acc: 0.4038 - val_loss: 1.0566 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1861 - acc: 0.4423 - val_loss: 1.0410 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9688 - acc: 0.5192 - val_loss: 1.0426 - val_acc: 0.4444\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 1.1844 - acc: 0.4615 - val_loss: 1.0443 - val_acc: 0.4444\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0797 - acc: 0.5000 - val_loss: 1.0492 - val_acc: 0.4074\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0819 - acc: 0.4615 - val_loss: 1.0509 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1072 - acc: 0.5481 - val_loss: 1.0303 - val_acc: 0.5185\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0429 - acc: 0.5192 - val_loss: 1.0244 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.1239 - acc: 0.4808 - val_loss: 1.0179 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 285us/sample - loss: 1.0561 - acc: 0.4904 - val_loss: 1.0121 - val_acc: 0.4444\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0542 - acc: 0.4808 - val_loss: 1.0134 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1685 - acc: 0.4231 - val_loss: 1.0090 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.1330 - acc: 0.4423 - val_loss: 1.0122 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1484 - acc: 0.4423 - val_loss: 1.0140 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0888 - acc: 0.4808 - val_loss: 1.0081 - val_acc: 0.4815\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0122 - acc: 0.4038 - val_loss: 1.0083 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1170 - acc: 0.4808 - val_loss: 1.0137 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0054 - acc: 0.4712 - val_loss: 1.0169 - val_acc: 0.4815\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0501 - acc: 0.4135 - val_loss: 1.0177 - val_acc: 0.5185\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.0606 - acc: 0.4231 - val_loss: 1.0119 - val_acc: 0.5926\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9573 - acc: 0.4904 - val_loss: 1.0111 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0795 - acc: 0.4904 - val_loss: 1.0116 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.0793 - acc: 0.3654 - val_loss: 1.0153 - val_acc: 0.5185\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 549us/sample - loss: 1.0053 - acc: 0.4904 - val_loss: 1.0177 - val_acc: 0.5926\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0151 - acc: 0.4231 - val_loss: 1.0229 - val_acc: 0.5556\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0657 - acc: 0.5192 - val_loss: 1.0291 - val_acc: 0.5556\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0275 - acc: 0.4327 - val_loss: 1.0156 - val_acc: 0.5926\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0563 - acc: 0.4712 - val_loss: 1.0216 - val_acc: 0.5926\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9564 - acc: 0.4808 - val_loss: 1.0184 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0171 - acc: 0.4519 - val_loss: 1.0225 - val_acc: 0.5556\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0255 - acc: 0.4712 - val_loss: 1.0217 - val_acc: 0.5556\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0007 - acc: 0.5481 - val_loss: 1.0215 - val_acc: 0.5556\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0316 - acc: 0.4615 - val_loss: 1.0235 - val_acc: 0.5556\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9850 - acc: 0.4615 - val_loss: 1.0332 - val_acc: 0.4815\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9864 - acc: 0.5385 - val_loss: 1.0330 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0436 - acc: 0.4615 - val_loss: 1.0289 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9966 - acc: 0.4904 - val_loss: 1.0362 - val_acc: 0.5556\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 0.9926 - acc: 0.4712 - val_loss: 1.0402 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0219 - acc: 0.5192 - val_loss: 1.0272 - val_acc: 0.5556\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0293 - acc: 0.5000 - val_loss: 1.0279 - val_acc: 0.5556\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9682 - acc: 0.5577 - val_loss: 1.0278 - val_acc: 0.5556\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0054 - acc: 0.4808 - val_loss: 1.0218 - val_acc: 0.5556\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0287 - acc: 0.5577 - val_loss: 1.0215 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0133 - acc: 0.5192 - val_loss: 1.0229 - val_acc: 0.4815\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0077 - acc: 0.5096 - val_loss: 1.0213 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9963 - acc: 0.5192 - val_loss: 1.0254 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0306 - acc: 0.4327 - val_loss: 1.0164 - val_acc: 0.5556\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 0.9829 - acc: 0.4519 - val_loss: 1.0169 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0273 - acc: 0.5192 - val_loss: 1.0298 - val_acc: 0.4815\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9937 - acc: 0.5096 - val_loss: 1.0307 - val_acc: 0.4815\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9570 - acc: 0.5192 - val_loss: 1.0334 - val_acc: 0.4815\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0211 - acc: 0.4327 - val_loss: 1.0203 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0040 - acc: 0.5192 - val_loss: 1.0175 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0276 - acc: 0.4712 - val_loss: 1.0200 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9732 - acc: 0.5481 - val_loss: 1.0277 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9822 - acc: 0.5000 - val_loss: 1.0248 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9401 - acc: 0.5577 - val_loss: 1.0353 - val_acc: 0.4444\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0183 - acc: 0.4808 - val_loss: 1.0474 - val_acc: 0.4444\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9657 - acc: 0.5385 - val_loss: 1.0351 - val_acc: 0.4444\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0361 - acc: 0.4423 - val_loss: 1.0230 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0019 - acc: 0.4615 - val_loss: 1.0226 - val_acc: 0.4444\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9856 - acc: 0.4904 - val_loss: 1.0253 - val_acc: 0.5556\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0457 - acc: 0.4712 - val_loss: 1.0226 - val_acc: 0.4444\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9697 - acc: 0.5288 - val_loss: 1.0297 - val_acc: 0.4815\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 424us/sample - loss: 1.0097 - acc: 0.4519 - val_loss: 1.0261 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9969 - acc: 0.4904 - val_loss: 1.0231 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0172 - acc: 0.4135 - val_loss: 1.0188 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9806 - acc: 0.5096 - val_loss: 1.0231 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0009 - acc: 0.5096 - val_loss: 1.0231 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0000 - acc: 0.4327 - val_loss: 1.0154 - val_acc: 0.4815\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0203 - acc: 0.4519 - val_loss: 1.0110 - val_acc: 0.4815\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0006 - acc: 0.4712 - val_loss: 1.0076 - val_acc: 0.4815\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0045 - acc: 0.4423 - val_loss: 1.0101 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9740 - acc: 0.4808 - val_loss: 1.0047 - val_acc: 0.4444\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0200 - acc: 0.4231 - val_loss: 1.0080 - val_acc: 0.4815\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9842 - acc: 0.4519 - val_loss: 1.0099 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0079 - acc: 0.4808 - val_loss: 1.0099 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9582 - acc: 0.4519 - val_loss: 1.0088 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9833 - acc: 0.4904 - val_loss: 1.0095 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9613 - acc: 0.4808 - val_loss: 1.0122 - val_acc: 0.4815\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 0.9811 - acc: 0.4327 - val_loss: 1.0138 - val_acc: 0.4444\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9880 - acc: 0.4519 - val_loss: 1.0123 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 0.9899 - acc: 0.5577 - val_loss: 1.0161 - val_acc: 0.4815\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9943 - acc: 0.5481 - val_loss: 1.0117 - val_acc: 0.5926\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 419us/sample - loss: 0.9980 - acc: 0.4904 - val_loss: 1.0165 - val_acc: 0.4815\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0038 - acc: 0.4327 - val_loss: 1.0165 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9700 - acc: 0.4712 - val_loss: 1.0171 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9940 - acc: 0.4712 - val_loss: 1.0113 - val_acc: 0.5556\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.7578 - acc: 0.2692 - val_loss: 2.4607 - val_acc: 0.2222\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 3.1052 - acc: 0.2981 - val_loss: 2.1421 - val_acc: 0.2222\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 2.4467 - acc: 0.2885 - val_loss: 1.8946 - val_acc: 0.2222\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 2.7450 - acc: 0.2404 - val_loss: 1.6716 - val_acc: 0.2593\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 2.3198 - acc: 0.3077 - val_loss: 1.5845 - val_acc: 0.2963\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 2.0725 - acc: 0.2885 - val_loss: 1.5156 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.8269 - acc: 0.3269 - val_loss: 1.4486 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 1.9454 - acc: 0.2404 - val_loss: 1.3890 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.9784 - acc: 0.3269 - val_loss: 1.3578 - val_acc: 0.3333\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.5531 - acc: 0.3462 - val_loss: 1.3087 - val_acc: 0.3333\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.3585 - acc: 0.3558 - val_loss: 1.2687 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.3862 - acc: 0.3654 - val_loss: 1.2560 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.3678 - acc: 0.3462 - val_loss: 1.2117 - val_acc: 0.4074\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.4797 - acc: 0.3846 - val_loss: 1.1903 - val_acc: 0.4815\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.5884 - acc: 0.3462 - val_loss: 1.1662 - val_acc: 0.5185\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.4025 - acc: 0.3365 - val_loss: 1.1743 - val_acc: 0.3704\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.2160 - acc: 0.3942 - val_loss: 1.1719 - val_acc: 0.4074\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2905 - acc: 0.4231 - val_loss: 1.1624 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0990 - acc: 0.4615 - val_loss: 1.1575 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.4154 - acc: 0.4327 - val_loss: 1.1297 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.2329 - acc: 0.4712 - val_loss: 1.1097 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1605 - acc: 0.4808 - val_loss: 1.1025 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.2286 - acc: 0.4327 - val_loss: 1.0778 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1738 - acc: 0.3942 - val_loss: 1.0775 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.1450 - acc: 0.4615 - val_loss: 1.0598 - val_acc: 0.4815\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1770 - acc: 0.4423 - val_loss: 1.0523 - val_acc: 0.4815\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 1.2750 - acc: 0.4135 - val_loss: 1.0394 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1191 - acc: 0.4231 - val_loss: 1.0251 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0468 - acc: 0.4808 - val_loss: 1.0262 - val_acc: 0.4074\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0850 - acc: 0.4423 - val_loss: 1.0306 - val_acc: 0.4074\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.2182 - acc: 0.4231 - val_loss: 1.0156 - val_acc: 0.4074\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 414us/sample - loss: 1.0181 - acc: 0.4327 - val_loss: 1.0086 - val_acc: 0.3704\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9411 - acc: 0.5865 - val_loss: 1.0116 - val_acc: 0.3704\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0923 - acc: 0.4327 - val_loss: 0.9966 - val_acc: 0.3704\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0695 - acc: 0.4519 - val_loss: 0.9938 - val_acc: 0.4074\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0411 - acc: 0.4423 - val_loss: 0.9941 - val_acc: 0.4444\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0195 - acc: 0.4712 - val_loss: 1.0048 - val_acc: 0.4444\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 435us/sample - loss: 1.0805 - acc: 0.4519 - val_loss: 1.0069 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 0.9862 - acc: 0.4808 - val_loss: 1.0079 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0309 - acc: 0.5000 - val_loss: 1.0003 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0831 - acc: 0.4135 - val_loss: 0.9989 - val_acc: 0.4074\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1015 - acc: 0.4519 - val_loss: 0.9968 - val_acc: 0.4444\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0027 - acc: 0.5769 - val_loss: 0.9958 - val_acc: 0.4444\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1070 - acc: 0.4231 - val_loss: 0.9910 - val_acc: 0.4074\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9992 - acc: 0.4808 - val_loss: 0.9881 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.1134 - acc: 0.5000 - val_loss: 0.9923 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1212 - acc: 0.5481 - val_loss: 0.9871 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0786 - acc: 0.5288 - val_loss: 0.9822 - val_acc: 0.4815\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 411us/sample - loss: 0.9802 - acc: 0.4904 - val_loss: 0.9850 - val_acc: 0.4815\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0683 - acc: 0.4712 - val_loss: 0.9872 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9844 - acc: 0.5192 - val_loss: 0.9856 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0213 - acc: 0.4808 - val_loss: 0.9869 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0265 - acc: 0.4519 - val_loss: 0.9875 - val_acc: 0.4444\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0615 - acc: 0.4904 - val_loss: 0.9903 - val_acc: 0.4444\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0526 - acc: 0.4135 - val_loss: 0.9818 - val_acc: 0.4815\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0705 - acc: 0.4327 - val_loss: 0.9827 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9650 - acc: 0.5288 - val_loss: 0.9910 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0343 - acc: 0.5192 - val_loss: 0.9910 - val_acc: 0.4444\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9883 - acc: 0.4519 - val_loss: 0.9845 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9685 - acc: 0.5192 - val_loss: 0.9797 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0319 - acc: 0.4712 - val_loss: 0.9781 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0403 - acc: 0.4135 - val_loss: 0.9763 - val_acc: 0.4815\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0435 - acc: 0.4712 - val_loss: 0.9762 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0629 - acc: 0.4904 - val_loss: 0.9734 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 1.0526 - acc: 0.5096 - val_loss: 0.9773 - val_acc: 0.4815\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 0.9736 - acc: 0.5000 - val_loss: 0.9803 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 0.9778 - acc: 0.5000 - val_loss: 0.9825 - val_acc: 0.4444\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.0196 - acc: 0.4712 - val_loss: 0.9842 - val_acc: 0.4815\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0338 - acc: 0.4327 - val_loss: 0.9819 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.0113 - acc: 0.4038 - val_loss: 0.9788 - val_acc: 0.4815\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0465 - acc: 0.4423 - val_loss: 0.9693 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9634 - acc: 0.5865 - val_loss: 0.9776 - val_acc: 0.4815\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9985 - acc: 0.4904 - val_loss: 0.9810 - val_acc: 0.4444\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 0.9899 - acc: 0.5096 - val_loss: 0.9742 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9784 - acc: 0.5577 - val_loss: 0.9775 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9705 - acc: 0.5192 - val_loss: 0.9757 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9903 - acc: 0.4423 - val_loss: 0.9790 - val_acc: 0.4815\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9757 - acc: 0.4904 - val_loss: 0.9798 - val_acc: 0.4074\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9673 - acc: 0.4712 - val_loss: 0.9849 - val_acc: 0.4074\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0107 - acc: 0.5000 - val_loss: 0.9863 - val_acc: 0.4444\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0464 - acc: 0.4519 - val_loss: 0.9827 - val_acc: 0.4074\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9851 - acc: 0.4808 - val_loss: 0.9827 - val_acc: 0.4444\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9657 - acc: 0.5096 - val_loss: 0.9832 - val_acc: 0.4444\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9575 - acc: 0.5481 - val_loss: 0.9850 - val_acc: 0.4444\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9762 - acc: 0.5000 - val_loss: 0.9810 - val_acc: 0.4815\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.0165 - acc: 0.4712 - val_loss: 0.9777 - val_acc: 0.4815\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0356 - acc: 0.4712 - val_loss: 0.9763 - val_acc: 0.4444\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9510 - acc: 0.5481 - val_loss: 0.9808 - val_acc: 0.4444\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9627 - acc: 0.5192 - val_loss: 0.9819 - val_acc: 0.4444\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0031 - acc: 0.4327 - val_loss: 0.9781 - val_acc: 0.4815\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0128 - acc: 0.4808 - val_loss: 0.9735 - val_acc: 0.4444\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 1.0106 - acc: 0.4519 - val_loss: 0.9777 - val_acc: 0.4444\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0106 - acc: 0.5000 - val_loss: 0.9746 - val_acc: 0.4444\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9756 - acc: 0.5096 - val_loss: 0.9704 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0320 - acc: 0.5096 - val_loss: 0.9714 - val_acc: 0.4444\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9661 - acc: 0.5673 - val_loss: 0.9799 - val_acc: 0.4444\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9509 - acc: 0.5481 - val_loss: 0.9812 - val_acc: 0.4074\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 446us/sample - loss: 1.0136 - acc: 0.4808 - val_loss: 0.9708 - val_acc: 0.4444\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0334 - acc: 0.5096 - val_loss: 0.9754 - val_acc: 0.4074\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 0.9739 - acc: 0.5481 - val_loss: 0.9829 - val_acc: 0.4074\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 961us/sample - loss: 3.6395 - acc: 0.3462 - val_loss: 2.5871 - val_acc: 0.1852\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 3.0938 - acc: 0.3558 - val_loss: 2.5025 - val_acc: 0.1852\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 3.4202 - acc: 0.2885 - val_loss: 2.3282 - val_acc: 0.1852\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 2.2265 - acc: 0.3558 - val_loss: 2.1444 - val_acc: 0.1852\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 2.3121 - acc: 0.3750 - val_loss: 2.0588 - val_acc: 0.1852\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.7918 - acc: 0.3558 - val_loss: 2.0302 - val_acc: 0.2222\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 1.9002 - acc: 0.3750 - val_loss: 1.9123 - val_acc: 0.2222\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.5993 - acc: 0.3462 - val_loss: 1.8878 - val_acc: 0.2222\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.3804 - acc: 0.4135 - val_loss: 1.8657 - val_acc: 0.2593\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.5263 - acc: 0.4519 - val_loss: 1.7650 - val_acc: 0.2222\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.3156 - acc: 0.3750 - val_loss: 1.7852 - val_acc: 0.2593\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.1249 - acc: 0.4519 - val_loss: 1.7604 - val_acc: 0.2963\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.5977 - acc: 0.4231 - val_loss: 1.7074 - val_acc: 0.2593\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.2164 - acc: 0.4904 - val_loss: 1.6701 - val_acc: 0.2593\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.4214 - acc: 0.4231 - val_loss: 1.6394 - val_acc: 0.2593\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.4908 - acc: 0.3558 - val_loss: 1.5755 - val_acc: 0.2593\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.3692 - acc: 0.4423 - val_loss: 1.5366 - val_acc: 0.2963\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.3199 - acc: 0.4615 - val_loss: 1.4707 - val_acc: 0.2593\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.2118 - acc: 0.4423 - val_loss: 1.4524 - val_acc: 0.2963\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.2857 - acc: 0.3942 - val_loss: 1.3920 - val_acc: 0.3333\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.3821 - acc: 0.4135 - val_loss: 1.3995 - val_acc: 0.3704\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.3011 - acc: 0.4423 - val_loss: 1.3481 - val_acc: 0.3704\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1995 - acc: 0.5000 - val_loss: 1.3469 - val_acc: 0.3333\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2355 - acc: 0.3942 - val_loss: 1.3202 - val_acc: 0.3333\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.3994 - acc: 0.3462 - val_loss: 1.2780 - val_acc: 0.3704\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.1903 - acc: 0.4327 - val_loss: 1.2616 - val_acc: 0.3704\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.1398 - acc: 0.3462 - val_loss: 1.2358 - val_acc: 0.3333\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1155 - acc: 0.4231 - val_loss: 1.2492 - val_acc: 0.3704\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1378 - acc: 0.3846 - val_loss: 1.2286 - val_acc: 0.3704\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0920 - acc: 0.3942 - val_loss: 1.2349 - val_acc: 0.3333\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.1509 - acc: 0.4712 - val_loss: 1.2055 - val_acc: 0.3333\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0743 - acc: 0.4231 - val_loss: 1.1954 - val_acc: 0.3704\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.0562 - acc: 0.4904 - val_loss: 1.1978 - val_acc: 0.3704\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0975 - acc: 0.3846 - val_loss: 1.1904 - val_acc: 0.2963\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.1297 - acc: 0.4615 - val_loss: 1.1798 - val_acc: 0.3333\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0297 - acc: 0.4712 - val_loss: 1.2037 - val_acc: 0.3333\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 435us/sample - loss: 1.1058 - acc: 0.4038 - val_loss: 1.1935 - val_acc: 0.3333\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0881 - acc: 0.5096 - val_loss: 1.1752 - val_acc: 0.3333\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0820 - acc: 0.4038 - val_loss: 1.1527 - val_acc: 0.3333\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0707 - acc: 0.4808 - val_loss: 1.1445 - val_acc: 0.3704\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0203 - acc: 0.4904 - val_loss: 1.1452 - val_acc: 0.3704\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0567 - acc: 0.4615 - val_loss: 1.1209 - val_acc: 0.3704\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0577 - acc: 0.4712 - val_loss: 1.1094 - val_acc: 0.4074\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1023 - acc: 0.4615 - val_loss: 1.1117 - val_acc: 0.4074\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9683 - acc: 0.4519 - val_loss: 1.1345 - val_acc: 0.3333\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0514 - acc: 0.4615 - val_loss: 1.1177 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.0353 - acc: 0.4423 - val_loss: 1.1262 - val_acc: 0.3704\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 412us/sample - loss: 1.0294 - acc: 0.4519 - val_loss: 1.1096 - val_acc: 0.3704\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0289 - acc: 0.4423 - val_loss: 1.1132 - val_acc: 0.3704\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0354 - acc: 0.4615 - val_loss: 1.1120 - val_acc: 0.3704\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0252 - acc: 0.4808 - val_loss: 1.1095 - val_acc: 0.3333\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0196 - acc: 0.4327 - val_loss: 1.1186 - val_acc: 0.3333\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9925 - acc: 0.5481 - val_loss: 1.1267 - val_acc: 0.3333\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0147 - acc: 0.4712 - val_loss: 1.1178 - val_acc: 0.3333\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0196 - acc: 0.4327 - val_loss: 1.1051 - val_acc: 0.3704\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0120 - acc: 0.5000 - val_loss: 1.1051 - val_acc: 0.3704\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9501 - acc: 0.5577 - val_loss: 1.1107 - val_acc: 0.4074\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9971 - acc: 0.4808 - val_loss: 1.1092 - val_acc: 0.3704\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0504 - acc: 0.4519 - val_loss: 1.1035 - val_acc: 0.4074\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9610 - acc: 0.5096 - val_loss: 1.0982 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0103 - acc: 0.5096 - val_loss: 1.0870 - val_acc: 0.4815\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0014 - acc: 0.4808 - val_loss: 1.0887 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 0.9373 - acc: 0.5481 - val_loss: 1.1149 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0394 - acc: 0.5000 - val_loss: 1.0961 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9819 - acc: 0.4904 - val_loss: 1.0895 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0006 - acc: 0.4712 - val_loss: 1.0947 - val_acc: 0.4815\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9485 - acc: 0.5577 - val_loss: 1.0941 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0315 - acc: 0.4904 - val_loss: 1.0767 - val_acc: 0.4444\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9963 - acc: 0.5000 - val_loss: 1.0753 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9976 - acc: 0.5192 - val_loss: 1.0687 - val_acc: 0.4815\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0178 - acc: 0.4808 - val_loss: 1.0634 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0021 - acc: 0.5000 - val_loss: 1.0584 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9732 - acc: 0.5000 - val_loss: 1.0584 - val_acc: 0.4815\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0300 - acc: 0.4615 - val_loss: 1.0542 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.0199 - acc: 0.4423 - val_loss: 1.0576 - val_acc: 0.4815\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9780 - acc: 0.5192 - val_loss: 1.0553 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0028 - acc: 0.4808 - val_loss: 1.0488 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9693 - acc: 0.5000 - val_loss: 1.0603 - val_acc: 0.4074\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9824 - acc: 0.4712 - val_loss: 1.0468 - val_acc: 0.4815\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9671 - acc: 0.4712 - val_loss: 1.0649 - val_acc: 0.4444\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9446 - acc: 0.5385 - val_loss: 1.0646 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0098 - acc: 0.5288 - val_loss: 1.0482 - val_acc: 0.5556\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9847 - acc: 0.4327 - val_loss: 1.0513 - val_acc: 0.4815\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9666 - acc: 0.4904 - val_loss: 1.0523 - val_acc: 0.4815\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9468 - acc: 0.5000 - val_loss: 1.0648 - val_acc: 0.4815\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9802 - acc: 0.5481 - val_loss: 1.0692 - val_acc: 0.4815\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9991 - acc: 0.5385 - val_loss: 1.0502 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9419 - acc: 0.5577 - val_loss: 1.0531 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9810 - acc: 0.5096 - val_loss: 1.0484 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9645 - acc: 0.4615 - val_loss: 1.0582 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9998 - acc: 0.4808 - val_loss: 1.0444 - val_acc: 0.5556\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9784 - acc: 0.5288 - val_loss: 1.0359 - val_acc: 0.4815\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9868 - acc: 0.5385 - val_loss: 1.0349 - val_acc: 0.5556\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0145 - acc: 0.4712 - val_loss: 1.0407 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9892 - acc: 0.4808 - val_loss: 1.0335 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9885 - acc: 0.5000 - val_loss: 1.0291 - val_acc: 0.4815\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9535 - acc: 0.5481 - val_loss: 1.0323 - val_acc: 0.4815\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9189 - acc: 0.5481 - val_loss: 1.0411 - val_acc: 0.4444\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0024 - acc: 0.4712 - val_loss: 1.0341 - val_acc: 0.4815\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9957 - acc: 0.4904 - val_loss: 1.0268 - val_acc: 0.5556\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.1388 - acc: 0.4423 - val_loss: 1.6567 - val_acc: 0.4444\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 2.5446 - acc: 0.5385 - val_loss: 1.5614 - val_acc: 0.4444\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.9520 - acc: 0.4904 - val_loss: 1.4394 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.6693 - acc: 0.5000 - val_loss: 1.3433 - val_acc: 0.4815\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 2.2397 - acc: 0.5288 - val_loss: 1.2830 - val_acc: 0.4444\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.4825 - acc: 0.4519 - val_loss: 1.1882 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 2.0819 - acc: 0.5096 - val_loss: 1.1245 - val_acc: 0.4444\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.5114 - acc: 0.5192 - val_loss: 1.1116 - val_acc: 0.4074\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.5420 - acc: 0.4423 - val_loss: 1.0968 - val_acc: 0.4444\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.4847 - acc: 0.4135 - val_loss: 1.0763 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.5766 - acc: 0.4712 - val_loss: 1.0657 - val_acc: 0.4074\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.2444 - acc: 0.5000 - val_loss: 1.0771 - val_acc: 0.4444\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.3963 - acc: 0.4712 - val_loss: 1.0675 - val_acc: 0.4074\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.3160 - acc: 0.4904 - val_loss: 1.0675 - val_acc: 0.4074\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.3922 - acc: 0.4327 - val_loss: 1.0670 - val_acc: 0.4074\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.2649 - acc: 0.4231 - val_loss: 1.0610 - val_acc: 0.4444\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.2018 - acc: 0.4904 - val_loss: 1.0615 - val_acc: 0.4074\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1845 - acc: 0.4519 - val_loss: 1.0588 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.2106 - acc: 0.4712 - val_loss: 1.0623 - val_acc: 0.4074\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.3556 - acc: 0.5192 - val_loss: 1.0641 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1445 - acc: 0.5096 - val_loss: 1.0652 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.2339 - acc: 0.4519 - val_loss: 1.0550 - val_acc: 0.4074\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0211 - acc: 0.5000 - val_loss: 1.0526 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.2438 - acc: 0.4808 - val_loss: 1.0504 - val_acc: 0.4074\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0714 - acc: 0.4808 - val_loss: 1.0503 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.1479 - acc: 0.4423 - val_loss: 1.0509 - val_acc: 0.4074\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1348 - acc: 0.4519 - val_loss: 1.0435 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0897 - acc: 0.4904 - val_loss: 1.0454 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9720 - acc: 0.4904 - val_loss: 1.0406 - val_acc: 0.4444\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0831 - acc: 0.5096 - val_loss: 1.0437 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0914 - acc: 0.5192 - val_loss: 1.0471 - val_acc: 0.4815\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9937 - acc: 0.4808 - val_loss: 1.0463 - val_acc: 0.4444\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.0766 - acc: 0.4519 - val_loss: 1.0448 - val_acc: 0.4074\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1663 - acc: 0.5481 - val_loss: 1.0533 - val_acc: 0.4444\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1602 - acc: 0.4327 - val_loss: 1.0509 - val_acc: 0.4444\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0663 - acc: 0.5385 - val_loss: 1.0462 - val_acc: 0.4444\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0279 - acc: 0.5000 - val_loss: 1.0495 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.1130 - acc: 0.4808 - val_loss: 1.0490 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1288 - acc: 0.4327 - val_loss: 1.0447 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 448us/sample - loss: 1.0049 - acc: 0.4615 - val_loss: 1.0455 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.2472 - acc: 0.4904 - val_loss: 1.0414 - val_acc: 0.4444\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.1197 - acc: 0.5288 - val_loss: 1.0357 - val_acc: 0.4444\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1396 - acc: 0.5288 - val_loss: 1.0371 - val_acc: 0.4444\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0253 - acc: 0.4712 - val_loss: 1.0386 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0375 - acc: 0.5096 - val_loss: 1.0376 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0395 - acc: 0.5000 - val_loss: 1.0349 - val_acc: 0.4074\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0415 - acc: 0.5385 - val_loss: 1.0352 - val_acc: 0.4074\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0339 - acc: 0.5481 - val_loss: 1.0378 - val_acc: 0.4074\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0534 - acc: 0.4519 - val_loss: 1.0401 - val_acc: 0.3704\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0099 - acc: 0.5385 - val_loss: 1.0486 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9939 - acc: 0.4615 - val_loss: 1.0452 - val_acc: 0.4074\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0378 - acc: 0.5481 - val_loss: 1.0462 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0610 - acc: 0.5865 - val_loss: 1.0444 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9758 - acc: 0.5385 - val_loss: 1.0410 - val_acc: 0.4815\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9443 - acc: 0.5481 - val_loss: 1.0391 - val_acc: 0.4815\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9972 - acc: 0.4615 - val_loss: 1.0375 - val_acc: 0.4815\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0080 - acc: 0.4808 - val_loss: 1.0348 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0517 - acc: 0.4615 - val_loss: 1.0292 - val_acc: 0.4074\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9748 - acc: 0.5288 - val_loss: 1.0346 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9986 - acc: 0.5000 - val_loss: 1.0390 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9660 - acc: 0.4712 - val_loss: 1.0321 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0228 - acc: 0.5096 - val_loss: 1.0340 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9680 - acc: 0.5385 - val_loss: 1.0353 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0415 - acc: 0.5481 - val_loss: 1.0349 - val_acc: 0.4444\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0452 - acc: 0.4808 - val_loss: 1.0335 - val_acc: 0.4444\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1021 - acc: 0.5192 - val_loss: 1.0346 - val_acc: 0.4444\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9949 - acc: 0.5769 - val_loss: 1.0363 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0666 - acc: 0.5000 - val_loss: 1.0347 - val_acc: 0.4074\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9967 - acc: 0.4423 - val_loss: 1.0256 - val_acc: 0.3704\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9937 - acc: 0.5481 - val_loss: 1.0288 - val_acc: 0.4444\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 418us/sample - loss: 0.9977 - acc: 0.5000 - val_loss: 1.0311 - val_acc: 0.3704\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0337 - acc: 0.5481 - val_loss: 1.0311 - val_acc: 0.3704\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9473 - acc: 0.6058 - val_loss: 1.0308 - val_acc: 0.4444\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0338 - acc: 0.5096 - val_loss: 1.0309 - val_acc: 0.4074\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9555 - acc: 0.6058 - val_loss: 1.0322 - val_acc: 0.4444\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.0080 - acc: 0.5481 - val_loss: 1.0319 - val_acc: 0.4074\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.0025 - acc: 0.5385 - val_loss: 1.0283 - val_acc: 0.3704\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0279 - acc: 0.4423 - val_loss: 1.0273 - val_acc: 0.4074\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.1280 - acc: 0.4423 - val_loss: 1.0252 - val_acc: 0.4074\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9790 - acc: 0.5096 - val_loss: 1.0203 - val_acc: 0.4074\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0481 - acc: 0.4904 - val_loss: 1.0238 - val_acc: 0.4074\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9424 - acc: 0.4808 - val_loss: 1.0261 - val_acc: 0.3333\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 1.0173 - acc: 0.4519 - val_loss: 1.0193 - val_acc: 0.4074\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9745 - acc: 0.4808 - val_loss: 1.0173 - val_acc: 0.4074\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9787 - acc: 0.4712 - val_loss: 1.0175 - val_acc: 0.4074\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9428 - acc: 0.5096 - val_loss: 1.0195 - val_acc: 0.4074\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0773 - acc: 0.5000 - val_loss: 1.0234 - val_acc: 0.3704\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0168 - acc: 0.4712 - val_loss: 1.0207 - val_acc: 0.3704\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0189 - acc: 0.4808 - val_loss: 1.0206 - val_acc: 0.4074\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9686 - acc: 0.5096 - val_loss: 1.0199 - val_acc: 0.3704\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9807 - acc: 0.5000 - val_loss: 1.0212 - val_acc: 0.4074\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9713 - acc: 0.5000 - val_loss: 1.0237 - val_acc: 0.3704\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9417 - acc: 0.5192 - val_loss: 1.0276 - val_acc: 0.4074\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0581 - acc: 0.4904 - val_loss: 1.0229 - val_acc: 0.3704\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9947 - acc: 0.4519 - val_loss: 1.0255 - val_acc: 0.4074\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0378 - acc: 0.5192 - val_loss: 1.0237 - val_acc: 0.3704\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9618 - acc: 0.5096 - val_loss: 1.0272 - val_acc: 0.4074\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0063 - acc: 0.5288 - val_loss: 1.0221 - val_acc: 0.3704\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9886 - acc: 0.5481 - val_loss: 1.0262 - val_acc: 0.4074\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9927 - acc: 0.5192 - val_loss: 1.0183 - val_acc: 0.3704\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.2634 - acc: 0.2885 - val_loss: 2.2069 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 2.5129 - acc: 0.3750 - val_loss: 1.9594 - val_acc: 0.2963\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.3187 - acc: 0.4423 - val_loss: 1.8883 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.3230 - acc: 0.4712 - val_loss: 1.8185 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.9821 - acc: 0.3365 - val_loss: 1.7128 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.3422 - acc: 0.4423 - val_loss: 1.6711 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.2774 - acc: 0.5000 - val_loss: 1.6292 - val_acc: 0.4444\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.5013 - acc: 0.3269 - val_loss: 1.5947 - val_acc: 0.4074\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.2757 - acc: 0.4327 - val_loss: 1.5959 - val_acc: 0.4444\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.3895 - acc: 0.4519 - val_loss: 1.5638 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1005 - acc: 0.5096 - val_loss: 1.5655 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0380 - acc: 0.5192 - val_loss: 1.5678 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0493 - acc: 0.5192 - val_loss: 1.5545 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1238 - acc: 0.5000 - val_loss: 1.5471 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.1779 - acc: 0.5000 - val_loss: 1.5386 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0787 - acc: 0.5096 - val_loss: 1.4917 - val_acc: 0.4074\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1298 - acc: 0.5192 - val_loss: 1.4854 - val_acc: 0.4074\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1005 - acc: 0.4904 - val_loss: 1.4603 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1895 - acc: 0.5288 - val_loss: 1.4751 - val_acc: 0.4074\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0798 - acc: 0.5288 - val_loss: 1.4570 - val_acc: 0.4074\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9857 - acc: 0.5481 - val_loss: 1.4597 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0524 - acc: 0.5288 - val_loss: 1.4203 - val_acc: 0.4444\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0687 - acc: 0.5192 - val_loss: 1.4005 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0655 - acc: 0.4904 - val_loss: 1.3800 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0708 - acc: 0.5385 - val_loss: 1.3875 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0715 - acc: 0.5673 - val_loss: 1.3883 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9919 - acc: 0.4808 - val_loss: 1.3611 - val_acc: 0.4815\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0246 - acc: 0.5769 - val_loss: 1.3726 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0896 - acc: 0.5481 - val_loss: 1.3404 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0960 - acc: 0.5096 - val_loss: 1.3245 - val_acc: 0.4815\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0956 - acc: 0.5385 - val_loss: 1.3177 - val_acc: 0.4815\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9559 - acc: 0.5673 - val_loss: 1.3076 - val_acc: 0.4815\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 1.0090 - acc: 0.5481 - val_loss: 1.2978 - val_acc: 0.5185\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9584 - acc: 0.5962 - val_loss: 1.2916 - val_acc: 0.5185\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0366 - acc: 0.5385 - val_loss: 1.2995 - val_acc: 0.5185\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0296 - acc: 0.5385 - val_loss: 1.2958 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0390 - acc: 0.5577 - val_loss: 1.2891 - val_acc: 0.5185\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9784 - acc: 0.5673 - val_loss: 1.2825 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0321 - acc: 0.5481 - val_loss: 1.2824 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0578 - acc: 0.5192 - val_loss: 1.2741 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9595 - acc: 0.5673 - val_loss: 1.2796 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9264 - acc: 0.5673 - val_loss: 1.2806 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0015 - acc: 0.5192 - val_loss: 1.2655 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9221 - acc: 0.5673 - val_loss: 1.2652 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9928 - acc: 0.5481 - val_loss: 1.2615 - val_acc: 0.4815\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9765 - acc: 0.5769 - val_loss: 1.2497 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 431us/sample - loss: 1.0670 - acc: 0.5192 - val_loss: 1.2423 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0482 - acc: 0.5288 - val_loss: 1.2460 - val_acc: 0.4815\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0024 - acc: 0.5962 - val_loss: 1.2535 - val_acc: 0.4815\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0188 - acc: 0.5000 - val_loss: 1.2367 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9758 - acc: 0.5385 - val_loss: 1.2409 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0241 - acc: 0.5577 - val_loss: 1.2314 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9645 - acc: 0.5385 - val_loss: 1.2210 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9940 - acc: 0.5481 - val_loss: 1.2238 - val_acc: 0.4815\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 0.9647 - acc: 0.5769 - val_loss: 1.2288 - val_acc: 0.4815\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 414us/sample - loss: 0.9893 - acc: 0.5481 - val_loss: 1.2067 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9806 - acc: 0.5288 - val_loss: 1.2030 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0376 - acc: 0.4519 - val_loss: 1.2047 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9380 - acc: 0.5865 - val_loss: 1.2082 - val_acc: 0.4815\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9977 - acc: 0.5769 - val_loss: 1.2118 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9995 - acc: 0.5096 - val_loss: 1.2104 - val_acc: 0.4815\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0041 - acc: 0.5385 - val_loss: 1.1935 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9803 - acc: 0.5096 - val_loss: 1.1805 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9680 - acc: 0.5288 - val_loss: 1.1770 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9895 - acc: 0.5577 - val_loss: 1.1911 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 439us/sample - loss: 1.0148 - acc: 0.5769 - val_loss: 1.1886 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9657 - acc: 0.5288 - val_loss: 1.1857 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9986 - acc: 0.5096 - val_loss: 1.1893 - val_acc: 0.4815\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0048 - acc: 0.5288 - val_loss: 1.1896 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0079 - acc: 0.5577 - val_loss: 1.1878 - val_acc: 0.4815\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9713 - acc: 0.5769 - val_loss: 1.1830 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0136 - acc: 0.4808 - val_loss: 1.1807 - val_acc: 0.4815\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9842 - acc: 0.5192 - val_loss: 1.1770 - val_acc: 0.4815\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9800 - acc: 0.5481 - val_loss: 1.1770 - val_acc: 0.4815\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0192 - acc: 0.5096 - val_loss: 1.1716 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0191 - acc: 0.5385 - val_loss: 1.1712 - val_acc: 0.4815\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9763 - acc: 0.5096 - val_loss: 1.1491 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9544 - acc: 0.5481 - val_loss: 1.1550 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 0.9466 - acc: 0.5577 - val_loss: 1.1468 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9050 - acc: 0.5577 - val_loss: 1.1443 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9810 - acc: 0.5481 - val_loss: 1.1621 - val_acc: 0.4815\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9807 - acc: 0.4904 - val_loss: 1.1542 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0023 - acc: 0.5577 - val_loss: 1.1655 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9583 - acc: 0.5385 - val_loss: 1.1658 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9334 - acc: 0.5577 - val_loss: 1.1594 - val_acc: 0.4815\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9662 - acc: 0.5769 - val_loss: 1.1597 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0020 - acc: 0.5385 - val_loss: 1.1408 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9734 - acc: 0.5096 - val_loss: 1.1494 - val_acc: 0.5556\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9602 - acc: 0.5577 - val_loss: 1.1517 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 0.9312 - acc: 0.5962 - val_loss: 1.1592 - val_acc: 0.5556\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9956 - acc: 0.5385 - val_loss: 1.1552 - val_acc: 0.5556\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9547 - acc: 0.5192 - val_loss: 1.1425 - val_acc: 0.5556\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9676 - acc: 0.5288 - val_loss: 1.1391 - val_acc: 0.5556\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0490 - acc: 0.4519 - val_loss: 1.1172 - val_acc: 0.5556\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9582 - acc: 0.5385 - val_loss: 1.1180 - val_acc: 0.5556\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9685 - acc: 0.5481 - val_loss: 1.1295 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9679 - acc: 0.5385 - val_loss: 1.1282 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9172 - acc: 0.6058 - val_loss: 1.1361 - val_acc: 0.5556\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9562 - acc: 0.5865 - val_loss: 1.1436 - val_acc: 0.5556\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0120 - acc: 0.5192 - val_loss: 1.1360 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 4c8dfcb185b8bedfd686be7b003f7305</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5481481552124023</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.6</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.1616 - acc: 0.4615 - val_loss: 1.6970 - val_acc: 0.4815\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 2.6706 - acc: 0.4327 - val_loss: 1.6361 - val_acc: 0.4815\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 2.1975 - acc: 0.4423 - val_loss: 1.5206 - val_acc: 0.4815\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 2.1129 - acc: 0.4423 - val_loss: 1.4964 - val_acc: 0.4815\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.7759 - acc: 0.4712 - val_loss: 1.4560 - val_acc: 0.4815\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.6943 - acc: 0.4327 - val_loss: 1.3994 - val_acc: 0.5185\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 415us/sample - loss: 1.2437 - acc: 0.4519 - val_loss: 1.3944 - val_acc: 0.5185\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.6573 - acc: 0.4519 - val_loss: 1.3823 - val_acc: 0.5185\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.8400 - acc: 0.4135 - val_loss: 1.3389 - val_acc: 0.5185\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.7098 - acc: 0.4423 - val_loss: 1.2795 - val_acc: 0.5185\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.6502 - acc: 0.3654 - val_loss: 1.2181 - val_acc: 0.5185\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.4802 - acc: 0.4135 - val_loss: 1.1984 - val_acc: 0.4444\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.2002 - acc: 0.4904 - val_loss: 1.1827 - val_acc: 0.4444\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.2266 - acc: 0.4712 - val_loss: 1.1874 - val_acc: 0.4815\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1067 - acc: 0.4808 - val_loss: 1.2084 - val_acc: 0.4815\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.4042 - acc: 0.4712 - val_loss: 1.2122 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.2357 - acc: 0.4327 - val_loss: 1.1903 - val_acc: 0.4444\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2305 - acc: 0.5096 - val_loss: 1.1670 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.5412 - acc: 0.4519 - val_loss: 1.1460 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.4661 - acc: 0.4423 - val_loss: 1.1383 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.1228 - acc: 0.4038 - val_loss: 1.1068 - val_acc: 0.4444\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.2996 - acc: 0.4231 - val_loss: 1.0997 - val_acc: 0.4444\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.2667 - acc: 0.4423 - val_loss: 1.0666 - val_acc: 0.4444\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1289 - acc: 0.5000 - val_loss: 1.0660 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.1745 - acc: 0.4423 - val_loss: 1.0381 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.2023 - acc: 0.5000 - val_loss: 1.0435 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0092 - acc: 0.4327 - val_loss: 1.0447 - val_acc: 0.4815\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2477 - acc: 0.4712 - val_loss: 1.0219 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0640 - acc: 0.4423 - val_loss: 1.0243 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0901 - acc: 0.5192 - val_loss: 1.0285 - val_acc: 0.4815\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.0581 - acc: 0.5000 - val_loss: 1.0219 - val_acc: 0.4815\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1527 - acc: 0.5000 - val_loss: 1.0110 - val_acc: 0.5185\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0749 - acc: 0.4712 - val_loss: 1.0167 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9987 - acc: 0.4615 - val_loss: 1.0189 - val_acc: 0.4815\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1358 - acc: 0.4904 - val_loss: 1.0319 - val_acc: 0.5185\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1270 - acc: 0.4615 - val_loss: 1.0120 - val_acc: 0.5185\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0187 - acc: 0.5192 - val_loss: 1.0130 - val_acc: 0.5185\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 1.1624 - acc: 0.4808 - val_loss: 0.9818 - val_acc: 0.5556\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 0.9576 - acc: 0.5192 - val_loss: 0.9841 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1728 - acc: 0.4519 - val_loss: 0.9604 - val_acc: 0.5556\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 430us/sample - loss: 1.0540 - acc: 0.4712 - val_loss: 0.9576 - val_acc: 0.5556\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0998 - acc: 0.4038 - val_loss: 0.9691 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0284 - acc: 0.5096 - val_loss: 0.9682 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9837 - acc: 0.4231 - val_loss: 0.9687 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0239 - acc: 0.5000 - val_loss: 0.9746 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9992 - acc: 0.4423 - val_loss: 0.9754 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0455 - acc: 0.4423 - val_loss: 0.9735 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0114 - acc: 0.5096 - val_loss: 0.9799 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9793 - acc: 0.5288 - val_loss: 0.9822 - val_acc: 0.4815\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0616 - acc: 0.4712 - val_loss: 0.9761 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0280 - acc: 0.5096 - val_loss: 0.9861 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9635 - acc: 0.5385 - val_loss: 0.9954 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9524 - acc: 0.5385 - val_loss: 0.9990 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0433 - acc: 0.4327 - val_loss: 0.9858 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 1.0244 - acc: 0.4615 - val_loss: 0.9844 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0546 - acc: 0.4135 - val_loss: 0.9699 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9954 - acc: 0.4904 - val_loss: 0.9730 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9447 - acc: 0.4712 - val_loss: 0.9810 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0197 - acc: 0.4904 - val_loss: 0.9771 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9875 - acc: 0.5096 - val_loss: 0.9791 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9752 - acc: 0.4808 - val_loss: 0.9815 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9797 - acc: 0.4712 - val_loss: 0.9778 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9871 - acc: 0.5192 - val_loss: 0.9813 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0727 - acc: 0.4327 - val_loss: 0.9721 - val_acc: 0.4815\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0175 - acc: 0.4808 - val_loss: 0.9699 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9876 - acc: 0.4808 - val_loss: 0.9781 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9623 - acc: 0.5000 - val_loss: 0.9842 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0405 - acc: 0.4423 - val_loss: 0.9853 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0132 - acc: 0.4615 - val_loss: 0.9798 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9891 - acc: 0.5000 - val_loss: 0.9915 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0584 - acc: 0.4327 - val_loss: 0.9730 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9989 - acc: 0.4808 - val_loss: 0.9726 - val_acc: 0.4444\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9545 - acc: 0.4712 - val_loss: 0.9848 - val_acc: 0.4815\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0168 - acc: 0.4231 - val_loss: 0.9780 - val_acc: 0.4815\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0435 - acc: 0.4519 - val_loss: 0.9738 - val_acc: 0.4444\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9958 - acc: 0.4519 - val_loss: 0.9759 - val_acc: 0.4815\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9806 - acc: 0.4231 - val_loss: 0.9772 - val_acc: 0.4815\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9771 - acc: 0.4423 - val_loss: 0.9776 - val_acc: 0.4815\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9941 - acc: 0.4712 - val_loss: 0.9867 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9581 - acc: 0.5000 - val_loss: 0.9990 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9931 - acc: 0.5096 - val_loss: 0.9969 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9652 - acc: 0.5192 - val_loss: 0.9965 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0296 - acc: 0.4327 - val_loss: 0.9806 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9835 - acc: 0.5000 - val_loss: 0.9786 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 0.9451 - acc: 0.5096 - val_loss: 0.9801 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9345 - acc: 0.5192 - val_loss: 0.9824 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0617 - acc: 0.4519 - val_loss: 0.9761 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9689 - acc: 0.4808 - val_loss: 0.9895 - val_acc: 0.4815\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9618 - acc: 0.5288 - val_loss: 0.9801 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0252 - acc: 0.5000 - val_loss: 0.9750 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0415 - acc: 0.4423 - val_loss: 0.9788 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0249 - acc: 0.4038 - val_loss: 0.9692 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 0.9800 - acc: 0.5000 - val_loss: 0.9657 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0044 - acc: 0.4231 - val_loss: 0.9613 - val_acc: 0.4815\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0178 - acc: 0.4327 - val_loss: 0.9584 - val_acc: 0.4815\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9756 - acc: 0.3846 - val_loss: 0.9642 - val_acc: 0.4815\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9565 - acc: 0.4327 - val_loss: 0.9726 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0146 - acc: 0.4712 - val_loss: 0.9788 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.0021 - acc: 0.4423 - val_loss: 0.9847 - val_acc: 0.4815\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9565 - acc: 0.4712 - val_loss: 0.9880 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.3272 - acc: 0.3654 - val_loss: 1.7940 - val_acc: 0.4815\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 3.0786 - acc: 0.4038 - val_loss: 1.7068 - val_acc: 0.4815\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.9498 - acc: 0.4615 - val_loss: 1.6517 - val_acc: 0.4815\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 2.8856 - acc: 0.4327 - val_loss: 1.5269 - val_acc: 0.4815\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 699us/sample - loss: 1.8876 - acc: 0.3750 - val_loss: 1.4957 - val_acc: 0.5926\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.8161 - acc: 0.3942 - val_loss: 1.5082 - val_acc: 0.5926\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.8861 - acc: 0.4327 - val_loss: 1.4746 - val_acc: 0.5926\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 2.3640 - acc: 0.3558 - val_loss: 1.4276 - val_acc: 0.6296\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 417us/sample - loss: 1.7146 - acc: 0.3846 - val_loss: 1.3949 - val_acc: 0.6296\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.5494 - acc: 0.4808 - val_loss: 1.3778 - val_acc: 0.6296\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.3823 - acc: 0.4423 - val_loss: 1.3875 - val_acc: 0.5185\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.6236 - acc: 0.4327 - val_loss: 1.3485 - val_acc: 0.5185\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.4239 - acc: 0.4423 - val_loss: 1.3429 - val_acc: 0.5185\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.4598 - acc: 0.3846 - val_loss: 1.3249 - val_acc: 0.5185\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2020 - acc: 0.4519 - val_loss: 1.3150 - val_acc: 0.5185\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.6564 - acc: 0.4038 - val_loss: 1.2919 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.6461 - acc: 0.4808 - val_loss: 1.2783 - val_acc: 0.4815\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.4439 - acc: 0.4231 - val_loss: 1.2637 - val_acc: 0.4815\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.6346 - acc: 0.3942 - val_loss: 1.2481 - val_acc: 0.4815\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.3613 - acc: 0.4231 - val_loss: 1.2303 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.5411 - acc: 0.4904 - val_loss: 1.2195 - val_acc: 0.5185\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.2323 - acc: 0.4904 - val_loss: 1.2267 - val_acc: 0.5185\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2788 - acc: 0.4135 - val_loss: 1.2142 - val_acc: 0.5185\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0901 - acc: 0.4231 - val_loss: 1.2015 - val_acc: 0.5185\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.3456 - acc: 0.3942 - val_loss: 1.1952 - val_acc: 0.5185\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.3864 - acc: 0.4038 - val_loss: 1.1798 - val_acc: 0.5185\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.3185 - acc: 0.4231 - val_loss: 1.1682 - val_acc: 0.5185\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9579 - acc: 0.4615 - val_loss: 1.1728 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0386 - acc: 0.4327 - val_loss: 1.1676 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1890 - acc: 0.4423 - val_loss: 1.1668 - val_acc: 0.4815\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.3462 - acc: 0.4519 - val_loss: 1.1622 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0730 - acc: 0.4712 - val_loss: 1.1657 - val_acc: 0.4815\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1980 - acc: 0.4519 - val_loss: 1.1460 - val_acc: 0.4815\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0638 - acc: 0.5000 - val_loss: 1.1505 - val_acc: 0.4815\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.2011 - acc: 0.4615 - val_loss: 1.1485 - val_acc: 0.4815\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1157 - acc: 0.5000 - val_loss: 1.1471 - val_acc: 0.5185\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1340 - acc: 0.4904 - val_loss: 1.1422 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1578 - acc: 0.5192 - val_loss: 1.1425 - val_acc: 0.4074\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1892 - acc: 0.4327 - val_loss: 1.1478 - val_acc: 0.5556\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.1541 - acc: 0.4519 - val_loss: 1.1456 - val_acc: 0.5556\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0552 - acc: 0.4519 - val_loss: 1.1486 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.2301 - acc: 0.4135 - val_loss: 1.1486 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0943 - acc: 0.3846 - val_loss: 1.1467 - val_acc: 0.4444\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0806 - acc: 0.4519 - val_loss: 1.1482 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1239 - acc: 0.4615 - val_loss: 1.1552 - val_acc: 0.4815\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9934 - acc: 0.5000 - val_loss: 1.1537 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1385 - acc: 0.4808 - val_loss: 1.1507 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0078 - acc: 0.4615 - val_loss: 1.1460 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0201 - acc: 0.4519 - val_loss: 1.1448 - val_acc: 0.4815\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0343 - acc: 0.4519 - val_loss: 1.1472 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.2390 - acc: 0.4712 - val_loss: 1.1461 - val_acc: 0.4074\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 1.0774 - acc: 0.4615 - val_loss: 1.1469 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9921 - acc: 0.4038 - val_loss: 1.1460 - val_acc: 0.4444\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0882 - acc: 0.4808 - val_loss: 1.1421 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0668 - acc: 0.4712 - val_loss: 1.1417 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0889 - acc: 0.4904 - val_loss: 1.1422 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0280 - acc: 0.4712 - val_loss: 1.1428 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 1.1145 - acc: 0.4712 - val_loss: 1.1464 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0627 - acc: 0.4615 - val_loss: 1.1465 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0819 - acc: 0.5096 - val_loss: 1.1477 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1188 - acc: 0.4423 - val_loss: 1.1458 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1239 - acc: 0.4519 - val_loss: 1.1460 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 1.0902 - acc: 0.4423 - val_loss: 1.1464 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1255 - acc: 0.5096 - val_loss: 1.1452 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 416us/sample - loss: 0.9312 - acc: 0.5192 - val_loss: 1.1460 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0444 - acc: 0.4327 - val_loss: 1.1478 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9775 - acc: 0.4712 - val_loss: 1.1496 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.1052 - acc: 0.4904 - val_loss: 1.1435 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1433 - acc: 0.4615 - val_loss: 1.1454 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0003 - acc: 0.4712 - val_loss: 1.1416 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0400 - acc: 0.4423 - val_loss: 1.1409 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.1077 - acc: 0.4519 - val_loss: 1.1433 - val_acc: 0.4444\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0458 - acc: 0.4615 - val_loss: 1.1387 - val_acc: 0.4074\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1041 - acc: 0.4423 - val_loss: 1.1287 - val_acc: 0.4815\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0856 - acc: 0.4615 - val_loss: 1.1248 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0454 - acc: 0.4712 - val_loss: 1.1244 - val_acc: 0.4444\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9442 - acc: 0.4519 - val_loss: 1.1242 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0986 - acc: 0.4327 - val_loss: 1.1199 - val_acc: 0.5926\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9516 - acc: 0.4615 - val_loss: 1.1189 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0470 - acc: 0.4615 - val_loss: 1.1200 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0415 - acc: 0.4327 - val_loss: 1.1146 - val_acc: 0.5556\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9763 - acc: 0.4712 - val_loss: 1.1170 - val_acc: 0.5556\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0596 - acc: 0.4038 - val_loss: 1.1116 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0603 - acc: 0.5000 - val_loss: 1.1092 - val_acc: 0.5556\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 426us/sample - loss: 1.0054 - acc: 0.4519 - val_loss: 1.1106 - val_acc: 0.6296\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0237 - acc: 0.4712 - val_loss: 1.1062 - val_acc: 0.6296\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 437us/sample - loss: 1.0080 - acc: 0.4904 - val_loss: 1.1094 - val_acc: 0.6667\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0386 - acc: 0.4327 - val_loss: 1.1104 - val_acc: 0.6667\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9607 - acc: 0.5096 - val_loss: 1.1106 - val_acc: 0.6296\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0060 - acc: 0.4808 - val_loss: 1.1063 - val_acc: 0.6296\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 468us/sample - loss: 1.0369 - acc: 0.4712 - val_loss: 1.1060 - val_acc: 0.7037\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0431 - acc: 0.4231 - val_loss: 1.1065 - val_acc: 0.6667\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9784 - acc: 0.4615 - val_loss: 1.1066 - val_acc: 0.6296\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0554 - acc: 0.4519 - val_loss: 1.0997 - val_acc: 0.6296\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0263 - acc: 0.5000 - val_loss: 1.1007 - val_acc: 0.6667\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9803 - acc: 0.4615 - val_loss: 1.1041 - val_acc: 0.5926\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0322 - acc: 0.5096 - val_loss: 1.1035 - val_acc: 0.6667\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0405 - acc: 0.4808 - val_loss: 1.1035 - val_acc: 0.6296\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0151 - acc: 0.4519 - val_loss: 1.0988 - val_acc: 0.6296\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9765 - acc: 0.4808 - val_loss: 1.1010 - val_acc: 0.6296\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.2946 - acc: 0.4327 - val_loss: 1.6601 - val_acc: 0.4074\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.8572 - acc: 0.4615 - val_loss: 1.5892 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.9890 - acc: 0.4519 - val_loss: 1.4972 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.7107 - acc: 0.4423 - val_loss: 1.4288 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.4559 - acc: 0.4231 - val_loss: 1.3770 - val_acc: 0.3704\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.6931 - acc: 0.4038 - val_loss: 1.3251 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.5075 - acc: 0.4327 - val_loss: 1.2839 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.4782 - acc: 0.3846 - val_loss: 1.2358 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.3783 - acc: 0.4615 - val_loss: 1.1998 - val_acc: 0.3704\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.3885 - acc: 0.4038 - val_loss: 1.1737 - val_acc: 0.3704\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.3969 - acc: 0.3942 - val_loss: 1.1646 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.1826 - acc: 0.4038 - val_loss: 1.1496 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.3397 - acc: 0.4038 - val_loss: 1.1154 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0404 - acc: 0.4808 - val_loss: 1.1199 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.2958 - acc: 0.4038 - val_loss: 1.0886 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.2044 - acc: 0.4135 - val_loss: 1.0770 - val_acc: 0.4074\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.2578 - acc: 0.4519 - val_loss: 1.0666 - val_acc: 0.3704\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0838 - acc: 0.4519 - val_loss: 1.0766 - val_acc: 0.3704\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.1071 - acc: 0.4423 - val_loss: 1.0804 - val_acc: 0.4074\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.1471 - acc: 0.5000 - val_loss: 1.0811 - val_acc: 0.3704\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1424 - acc: 0.4135 - val_loss: 1.0624 - val_acc: 0.3704\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0644 - acc: 0.4712 - val_loss: 1.0622 - val_acc: 0.4074\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.1962 - acc: 0.4231 - val_loss: 1.0652 - val_acc: 0.4074\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.1406 - acc: 0.4038 - val_loss: 1.0659 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0924 - acc: 0.4808 - val_loss: 1.0658 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1744 - acc: 0.4712 - val_loss: 1.0686 - val_acc: 0.3704\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1581 - acc: 0.4615 - val_loss: 1.0601 - val_acc: 0.4074\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1080 - acc: 0.3942 - val_loss: 1.0634 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.1216 - acc: 0.4519 - val_loss: 1.0590 - val_acc: 0.4444\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.2046 - acc: 0.4423 - val_loss: 1.0590 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0920 - acc: 0.4231 - val_loss: 1.0656 - val_acc: 0.4074\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0120 - acc: 0.4519 - val_loss: 1.0725 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1001 - acc: 0.4423 - val_loss: 1.0603 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1317 - acc: 0.4231 - val_loss: 1.0573 - val_acc: 0.4074\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.0522 - acc: 0.4231 - val_loss: 1.0645 - val_acc: 0.4444\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1244 - acc: 0.4712 - val_loss: 1.0710 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0788 - acc: 0.5000 - val_loss: 1.0786 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0647 - acc: 0.4519 - val_loss: 1.0684 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0517 - acc: 0.4904 - val_loss: 1.0667 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1199 - acc: 0.5096 - val_loss: 1.0571 - val_acc: 0.4444\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0866 - acc: 0.4808 - val_loss: 1.0574 - val_acc: 0.4074\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0935 - acc: 0.5673 - val_loss: 1.0649 - val_acc: 0.4444\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0870 - acc: 0.5096 - val_loss: 1.0673 - val_acc: 0.4444\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1202 - acc: 0.4712 - val_loss: 1.0595 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0501 - acc: 0.4423 - val_loss: 1.0508 - val_acc: 0.4815\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 1.0291 - acc: 0.5096 - val_loss: 1.0559 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0620 - acc: 0.4615 - val_loss: 1.0514 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0613 - acc: 0.4904 - val_loss: 1.0556 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9922 - acc: 0.5288 - val_loss: 1.0603 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9623 - acc: 0.4615 - val_loss: 1.0576 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0077 - acc: 0.5000 - val_loss: 1.0621 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 423us/sample - loss: 0.9974 - acc: 0.4519 - val_loss: 1.0728 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0794 - acc: 0.4904 - val_loss: 1.0707 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0848 - acc: 0.4135 - val_loss: 1.0681 - val_acc: 0.4444\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0164 - acc: 0.5192 - val_loss: 1.0566 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9720 - acc: 0.5673 - val_loss: 1.0688 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 436us/sample - loss: 1.0437 - acc: 0.4615 - val_loss: 1.0661 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9610 - acc: 0.5096 - val_loss: 1.0726 - val_acc: 0.4444\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0332 - acc: 0.4615 - val_loss: 1.0735 - val_acc: 0.4815\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9887 - acc: 0.4808 - val_loss: 1.0645 - val_acc: 0.4074\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0096 - acc: 0.4712 - val_loss: 1.0672 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0367 - acc: 0.5096 - val_loss: 1.0615 - val_acc: 0.4815\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9484 - acc: 0.5000 - val_loss: 1.0629 - val_acc: 0.4815\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0041 - acc: 0.5192 - val_loss: 1.0604 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0429 - acc: 0.5000 - val_loss: 1.0532 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0136 - acc: 0.4519 - val_loss: 1.0560 - val_acc: 0.5556\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0663 - acc: 0.4712 - val_loss: 1.0469 - val_acc: 0.5926\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 496us/sample - loss: 1.0739 - acc: 0.4423 - val_loss: 1.0414 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0377 - acc: 0.4904 - val_loss: 1.0435 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0603 - acc: 0.4808 - val_loss: 1.0427 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0468 - acc: 0.4423 - val_loss: 1.0455 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9748 - acc: 0.4712 - val_loss: 1.0498 - val_acc: 0.5926\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9865 - acc: 0.4904 - val_loss: 1.0480 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0177 - acc: 0.5385 - val_loss: 1.0503 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9970 - acc: 0.5000 - val_loss: 1.0536 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0457 - acc: 0.4327 - val_loss: 1.0463 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0453 - acc: 0.4904 - val_loss: 1.0422 - val_acc: 0.4815\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 1.0506 - acc: 0.4904 - val_loss: 1.0352 - val_acc: 0.4815\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9948 - acc: 0.4808 - val_loss: 1.0453 - val_acc: 0.4815\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0068 - acc: 0.4615 - val_loss: 1.0416 - val_acc: 0.4815\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0208 - acc: 0.4712 - val_loss: 1.0415 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 1.0044 - acc: 0.4038 - val_loss: 1.0343 - val_acc: 0.4815\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0077 - acc: 0.4808 - val_loss: 1.0312 - val_acc: 0.4444\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9928 - acc: 0.5096 - val_loss: 1.0316 - val_acc: 0.4074\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0598 - acc: 0.4904 - val_loss: 1.0363 - val_acc: 0.4815\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 0.9820 - acc: 0.4808 - val_loss: 1.0300 - val_acc: 0.4074\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0062 - acc: 0.5577 - val_loss: 1.0385 - val_acc: 0.4815\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9962 - acc: 0.4712 - val_loss: 1.0325 - val_acc: 0.4815\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9410 - acc: 0.5000 - val_loss: 1.0340 - val_acc: 0.4815\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0089 - acc: 0.3750 - val_loss: 1.0314 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 1.0107 - acc: 0.4519 - val_loss: 1.0311 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.0252 - acc: 0.4712 - val_loss: 1.0203 - val_acc: 0.4444\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0415 - acc: 0.4712 - val_loss: 1.0221 - val_acc: 0.4815\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9833 - acc: 0.4423 - val_loss: 1.0239 - val_acc: 0.4815\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0548 - acc: 0.4615 - val_loss: 1.0213 - val_acc: 0.4815\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9999 - acc: 0.4712 - val_loss: 1.0229 - val_acc: 0.4815\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0247 - acc: 0.4615 - val_loss: 1.0247 - val_acc: 0.4444\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9672 - acc: 0.5096 - val_loss: 1.0276 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0041 - acc: 0.5096 - val_loss: 1.0327 - val_acc: 0.4444\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.0177 - acc: 0.4519 - val_loss: 1.0311 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.4781 - acc: 0.3846 - val_loss: 1.6756 - val_acc: 0.4074\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 2.0946 - acc: 0.4712 - val_loss: 1.6216 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.6547 - acc: 0.4231 - val_loss: 1.5826 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.7291 - acc: 0.3750 - val_loss: 1.5350 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.3619 - acc: 0.3942 - val_loss: 1.5064 - val_acc: 0.3704\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.8654 - acc: 0.4038 - val_loss: 1.4425 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.2844 - acc: 0.4904 - val_loss: 1.4222 - val_acc: 0.4074\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.3650 - acc: 0.5288 - val_loss: 1.3969 - val_acc: 0.4074\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.3597 - acc: 0.4423 - val_loss: 1.3724 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.2592 - acc: 0.5192 - val_loss: 1.3453 - val_acc: 0.4815\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.2459 - acc: 0.4231 - val_loss: 1.3254 - val_acc: 0.4444\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 420us/sample - loss: 1.1192 - acc: 0.4904 - val_loss: 1.3112 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.2900 - acc: 0.4615 - val_loss: 1.2828 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.1165 - acc: 0.4904 - val_loss: 1.2742 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.2507 - acc: 0.3942 - val_loss: 1.2530 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1824 - acc: 0.4423 - val_loss: 1.2364 - val_acc: 0.3704\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0850 - acc: 0.4712 - val_loss: 1.2273 - val_acc: 0.3704\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1187 - acc: 0.4135 - val_loss: 1.2097 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0894 - acc: 0.4327 - val_loss: 1.1979 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0948 - acc: 0.4519 - val_loss: 1.1933 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0763 - acc: 0.4904 - val_loss: 1.1916 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0092 - acc: 0.4231 - val_loss: 1.1831 - val_acc: 0.4074\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0206 - acc: 0.5000 - val_loss: 1.1787 - val_acc: 0.4444\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0966 - acc: 0.4327 - val_loss: 1.1695 - val_acc: 0.5185\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0928 - acc: 0.5000 - val_loss: 1.1630 - val_acc: 0.5185\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0320 - acc: 0.4712 - val_loss: 1.1598 - val_acc: 0.5185\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0891 - acc: 0.5288 - val_loss: 1.1529 - val_acc: 0.5185\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 413us/sample - loss: 1.0267 - acc: 0.4808 - val_loss: 1.1482 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0797 - acc: 0.4712 - val_loss: 1.1433 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 443us/sample - loss: 1.0010 - acc: 0.5000 - val_loss: 1.1404 - val_acc: 0.5185\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0428 - acc: 0.4615 - val_loss: 1.1370 - val_acc: 0.5185\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0421 - acc: 0.5192 - val_loss: 1.1342 - val_acc: 0.5185\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0467 - acc: 0.5096 - val_loss: 1.1261 - val_acc: 0.5185\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0651 - acc: 0.5000 - val_loss: 1.1281 - val_acc: 0.5185\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0625 - acc: 0.5288 - val_loss: 1.1271 - val_acc: 0.5185\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9975 - acc: 0.5385 - val_loss: 1.1275 - val_acc: 0.5185\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9882 - acc: 0.4519 - val_loss: 1.1279 - val_acc: 0.5185\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 0.9907 - acc: 0.4712 - val_loss: 1.1254 - val_acc: 0.5185\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0308 - acc: 0.4808 - val_loss: 1.1225 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0356 - acc: 0.4231 - val_loss: 1.1153 - val_acc: 0.5185\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9923 - acc: 0.5673 - val_loss: 1.1105 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0667 - acc: 0.5192 - val_loss: 1.1157 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9782 - acc: 0.5288 - val_loss: 1.1211 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0499 - acc: 0.4519 - val_loss: 1.1153 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.0063 - acc: 0.5385 - val_loss: 1.1184 - val_acc: 0.5556\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9518 - acc: 0.4808 - val_loss: 1.1231 - val_acc: 0.5556\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0907 - acc: 0.5096 - val_loss: 1.1177 - val_acc: 0.5556\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0545 - acc: 0.4519 - val_loss: 1.1102 - val_acc: 0.5556\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 0.9532 - acc: 0.5288 - val_loss: 1.1102 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0098 - acc: 0.4808 - val_loss: 1.1027 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9829 - acc: 0.5000 - val_loss: 1.0995 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0242 - acc: 0.5673 - val_loss: 1.0989 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0339 - acc: 0.5000 - val_loss: 1.1038 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9889 - acc: 0.4712 - val_loss: 1.1062 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0196 - acc: 0.4808 - val_loss: 1.1085 - val_acc: 0.5556\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0201 - acc: 0.4904 - val_loss: 1.1052 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9989 - acc: 0.5096 - val_loss: 1.1054 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9803 - acc: 0.5288 - val_loss: 1.1090 - val_acc: 0.5556\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0166 - acc: 0.4423 - val_loss: 1.1004 - val_acc: 0.5556\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0772 - acc: 0.5192 - val_loss: 1.0970 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9952 - acc: 0.4712 - val_loss: 1.0928 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9506 - acc: 0.5000 - val_loss: 1.0955 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9930 - acc: 0.4808 - val_loss: 1.0963 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0419 - acc: 0.5096 - val_loss: 1.0967 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9965 - acc: 0.4519 - val_loss: 1.0973 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1017 - acc: 0.4327 - val_loss: 1.0961 - val_acc: 0.5556\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9832 - acc: 0.4712 - val_loss: 1.0930 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0514 - acc: 0.5385 - val_loss: 1.0897 - val_acc: 0.5556\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0562 - acc: 0.4808 - val_loss: 1.0825 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0391 - acc: 0.4904 - val_loss: 1.0861 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9761 - acc: 0.5192 - val_loss: 1.0852 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0425 - acc: 0.5000 - val_loss: 1.0814 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9475 - acc: 0.5096 - val_loss: 1.0841 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9993 - acc: 0.4712 - val_loss: 1.0836 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9875 - acc: 0.4904 - val_loss: 1.0841 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9698 - acc: 0.5288 - val_loss: 1.0880 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0270 - acc: 0.4615 - val_loss: 1.0834 - val_acc: 0.5556\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0021 - acc: 0.5096 - val_loss: 1.0789 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9456 - acc: 0.5673 - val_loss: 1.0812 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0071 - acc: 0.4423 - val_loss: 1.0787 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9866 - acc: 0.4904 - val_loss: 1.0825 - val_acc: 0.5556\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9765 - acc: 0.5769 - val_loss: 1.0800 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0340 - acc: 0.5192 - val_loss: 1.0772 - val_acc: 0.5556\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0346 - acc: 0.5096 - val_loss: 1.0747 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9534 - acc: 0.5288 - val_loss: 1.0779 - val_acc: 0.5556\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9859 - acc: 0.4808 - val_loss: 1.0715 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.0565 - acc: 0.4808 - val_loss: 1.0692 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9459 - acc: 0.5481 - val_loss: 1.0721 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9816 - acc: 0.5288 - val_loss: 1.0695 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9743 - acc: 0.5673 - val_loss: 1.0666 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0133 - acc: 0.4808 - val_loss: 1.0676 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0032 - acc: 0.4904 - val_loss: 1.0682 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9981 - acc: 0.4904 - val_loss: 1.0730 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9860 - acc: 0.4712 - val_loss: 1.0726 - val_acc: 0.5556\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9428 - acc: 0.5000 - val_loss: 1.0726 - val_acc: 0.5556\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0005 - acc: 0.5481 - val_loss: 1.0712 - val_acc: 0.5556\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0179 - acc: 0.4712 - val_loss: 1.0670 - val_acc: 0.5926\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9794 - acc: 0.5192 - val_loss: 1.0704 - val_acc: 0.6296\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9971 - acc: 0.4519 - val_loss: 1.0727 - val_acc: 0.6296\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9531 - acc: 0.4808 - val_loss: 1.0738 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.7744 - acc: 0.3173 - val_loss: 2.0733 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 3.0188 - acc: 0.2788 - val_loss: 1.7632 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.8897 - acc: 0.3173 - val_loss: 1.6100 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.7399 - acc: 0.3462 - val_loss: 1.4709 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.9605 - acc: 0.3173 - val_loss: 1.3518 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.8271 - acc: 0.3173 - val_loss: 1.2396 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.7691 - acc: 0.3462 - val_loss: 1.1859 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.6778 - acc: 0.3462 - val_loss: 1.1374 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.3474 - acc: 0.4327 - val_loss: 1.1193 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.2911 - acc: 0.3750 - val_loss: 1.0837 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.3255 - acc: 0.3462 - val_loss: 1.0546 - val_acc: 0.4444\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1700 - acc: 0.4423 - val_loss: 1.0388 - val_acc: 0.5185\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1531 - acc: 0.4135 - val_loss: 1.0266 - val_acc: 0.5185\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.1324 - acc: 0.4519 - val_loss: 1.0205 - val_acc: 0.5185\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0722 - acc: 0.4904 - val_loss: 1.0050 - val_acc: 0.5185\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1742 - acc: 0.5192 - val_loss: 1.0051 - val_acc: 0.5185\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0039 - acc: 0.5192 - val_loss: 0.9951 - val_acc: 0.4815\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0361 - acc: 0.4904 - val_loss: 0.9868 - val_acc: 0.5556\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.1762 - acc: 0.3846 - val_loss: 0.9823 - val_acc: 0.5185\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0624 - acc: 0.5192 - val_loss: 0.9839 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.1142 - acc: 0.4712 - val_loss: 1.0032 - val_acc: 0.5556\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0751 - acc: 0.4712 - val_loss: 1.0050 - val_acc: 0.5185\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0195 - acc: 0.4904 - val_loss: 1.0068 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.1530 - acc: 0.3846 - val_loss: 1.0035 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 1.1427 - acc: 0.4615 - val_loss: 0.9932 - val_acc: 0.5185\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1415 - acc: 0.4135 - val_loss: 0.9960 - val_acc: 0.5185\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0227 - acc: 0.4327 - val_loss: 0.9957 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0669 - acc: 0.4712 - val_loss: 0.9901 - val_acc: 0.5185\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 414us/sample - loss: 1.0162 - acc: 0.5192 - val_loss: 0.9884 - val_acc: 0.5926\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0321 - acc: 0.4038 - val_loss: 0.9915 - val_acc: 0.5556\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0482 - acc: 0.4904 - val_loss: 0.9877 - val_acc: 0.5926\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9658 - acc: 0.5000 - val_loss: 0.9961 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0461 - acc: 0.4423 - val_loss: 0.9975 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0534 - acc: 0.4615 - val_loss: 0.9917 - val_acc: 0.6296\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0301 - acc: 0.5000 - val_loss: 0.9861 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9842 - acc: 0.4904 - val_loss: 0.9856 - val_acc: 0.5926\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9874 - acc: 0.5192 - val_loss: 0.9877 - val_acc: 0.5926\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9887 - acc: 0.4712 - val_loss: 0.9862 - val_acc: 0.5926\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0109 - acc: 0.4615 - val_loss: 0.9811 - val_acc: 0.5556\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0389 - acc: 0.4808 - val_loss: 0.9801 - val_acc: 0.5556\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0300 - acc: 0.4615 - val_loss: 0.9793 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0302 - acc: 0.4712 - val_loss: 0.9803 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0585 - acc: 0.4519 - val_loss: 0.9789 - val_acc: 0.5556\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0939 - acc: 0.3846 - val_loss: 0.9722 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0461 - acc: 0.4038 - val_loss: 0.9738 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0321 - acc: 0.4519 - val_loss: 0.9733 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0185 - acc: 0.4327 - val_loss: 0.9732 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0420 - acc: 0.4038 - val_loss: 0.9800 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0425 - acc: 0.4327 - val_loss: 0.9831 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9774 - acc: 0.4904 - val_loss: 0.9858 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9835 - acc: 0.4615 - val_loss: 0.9823 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9794 - acc: 0.5288 - val_loss: 0.9806 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0760 - acc: 0.3942 - val_loss: 0.9798 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0190 - acc: 0.4519 - val_loss: 0.9723 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 410us/sample - loss: 1.0050 - acc: 0.4519 - val_loss: 0.9702 - val_acc: 0.5556\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9902 - acc: 0.4519 - val_loss: 0.9769 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9643 - acc: 0.4519 - val_loss: 0.9807 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0003 - acc: 0.4038 - val_loss: 0.9792 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9708 - acc: 0.5000 - val_loss: 0.9776 - val_acc: 0.4815\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9852 - acc: 0.4712 - val_loss: 0.9807 - val_acc: 0.4815\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9546 - acc: 0.5096 - val_loss: 0.9767 - val_acc: 0.5556\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0197 - acc: 0.4904 - val_loss: 0.9735 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0227 - acc: 0.5000 - val_loss: 0.9732 - val_acc: 0.4815\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9494 - acc: 0.4808 - val_loss: 0.9791 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0630 - acc: 0.3654 - val_loss: 0.9719 - val_acc: 0.4815\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9850 - acc: 0.4519 - val_loss: 0.9749 - val_acc: 0.4815\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9730 - acc: 0.5000 - val_loss: 0.9738 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0204 - acc: 0.5000 - val_loss: 0.9740 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0024 - acc: 0.4904 - val_loss: 0.9711 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9846 - acc: 0.4519 - val_loss: 0.9764 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9961 - acc: 0.4712 - val_loss: 0.9736 - val_acc: 0.5926\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9743 - acc: 0.4423 - val_loss: 0.9682 - val_acc: 0.5926\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0012 - acc: 0.4519 - val_loss: 0.9710 - val_acc: 0.4815\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0067 - acc: 0.4904 - val_loss: 0.9783 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9990 - acc: 0.4615 - val_loss: 0.9744 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9561 - acc: 0.4808 - val_loss: 0.9765 - val_acc: 0.5926\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9680 - acc: 0.4712 - val_loss: 0.9724 - val_acc: 0.5556\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0316 - acc: 0.4519 - val_loss: 0.9724 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9710 - acc: 0.4712 - val_loss: 0.9775 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9782 - acc: 0.4904 - val_loss: 0.9799 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9775 - acc: 0.4904 - val_loss: 0.9825 - val_acc: 0.4815\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9689 - acc: 0.5096 - val_loss: 0.9803 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9796 - acc: 0.4712 - val_loss: 0.9819 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 514us/sample - loss: 0.9557 - acc: 0.4904 - val_loss: 0.9788 - val_acc: 0.5556\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0087 - acc: 0.4712 - val_loss: 0.9773 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9767 - acc: 0.4327 - val_loss: 0.9758 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9787 - acc: 0.4615 - val_loss: 0.9705 - val_acc: 0.5556\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9586 - acc: 0.5192 - val_loss: 0.9685 - val_acc: 0.5556\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9808 - acc: 0.4519 - val_loss: 0.9764 - val_acc: 0.4815\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9748 - acc: 0.4327 - val_loss: 0.9800 - val_acc: 0.4444\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9945 - acc: 0.4423 - val_loss: 0.9763 - val_acc: 0.4815\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0041 - acc: 0.4231 - val_loss: 0.9768 - val_acc: 0.4815\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0008 - acc: 0.4327 - val_loss: 0.9763 - val_acc: 0.4444\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9800 - acc: 0.4519 - val_loss: 0.9755 - val_acc: 0.4815\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0177 - acc: 0.4519 - val_loss: 0.9746 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0150 - acc: 0.4327 - val_loss: 0.9749 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0083 - acc: 0.4327 - val_loss: 0.9700 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0091 - acc: 0.4327 - val_loss: 0.9715 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0104 - acc: 0.4519 - val_loss: 0.9723 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9878 - acc: 0.4808 - val_loss: 0.9740 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: a8dce0b625f954179c32303d144239a2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.6222222447395325</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.7</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.7038 - acc: 0.4327 - val_loss: 1.7737 - val_acc: 0.4815\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 2.6035 - acc: 0.3942 - val_loss: 1.6269 - val_acc: 0.4444\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 2.2241 - acc: 0.4808 - val_loss: 1.4521 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.7217 - acc: 0.4231 - val_loss: 1.4321 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.6560 - acc: 0.4808 - val_loss: 1.4063 - val_acc: 0.4444\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.8091 - acc: 0.4327 - val_loss: 1.3762 - val_acc: 0.4074\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.8526 - acc: 0.4327 - val_loss: 1.3566 - val_acc: 0.4444\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.2745 - acc: 0.4135 - val_loss: 1.3444 - val_acc: 0.4444\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.7412 - acc: 0.4327 - val_loss: 1.2751 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.6794 - acc: 0.4519 - val_loss: 1.2533 - val_acc: 0.3704\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.4626 - acc: 0.4135 - val_loss: 1.2414 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.3346 - acc: 0.4135 - val_loss: 1.2267 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.8608 - acc: 0.3942 - val_loss: 1.2258 - val_acc: 0.4444\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.2248 - acc: 0.4231 - val_loss: 1.2254 - val_acc: 0.4444\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.2308 - acc: 0.3750 - val_loss: 1.2423 - val_acc: 0.4074\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.4653 - acc: 0.3750 - val_loss: 1.2204 - val_acc: 0.4444\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.1454 - acc: 0.4135 - val_loss: 1.2483 - val_acc: 0.4815\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.4240 - acc: 0.4038 - val_loss: 1.2202 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.2725 - acc: 0.4038 - val_loss: 1.2165 - val_acc: 0.3704\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 410us/sample - loss: 1.1673 - acc: 0.4135 - val_loss: 1.1781 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.3062 - acc: 0.3942 - val_loss: 1.1769 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.3180 - acc: 0.3846 - val_loss: 1.1496 - val_acc: 0.4444\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1965 - acc: 0.3558 - val_loss: 1.1202 - val_acc: 0.4444\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.1458 - acc: 0.4231 - val_loss: 1.1207 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 425us/sample - loss: 1.1840 - acc: 0.3942 - val_loss: 1.1143 - val_acc: 0.5185\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.3270 - acc: 0.4038 - val_loss: 1.0616 - val_acc: 0.4074\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.2650 - acc: 0.4423 - val_loss: 1.0865 - val_acc: 0.3704\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 455us/sample - loss: 1.3098 - acc: 0.4038 - val_loss: 1.0901 - val_acc: 0.6296\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.2024 - acc: 0.3846 - val_loss: 1.0768 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1155 - acc: 0.4808 - val_loss: 1.1039 - val_acc: 0.5556\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0620 - acc: 0.4423 - val_loss: 1.1052 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 1.4512 - acc: 0.4231 - val_loss: 1.0563 - val_acc: 0.4815\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0507 - acc: 0.4615 - val_loss: 1.0673 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0803 - acc: 0.4808 - val_loss: 1.0609 - val_acc: 0.4074\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0263 - acc: 0.4808 - val_loss: 1.0591 - val_acc: 0.4444\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0911 - acc: 0.4519 - val_loss: 1.0615 - val_acc: 0.4444\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.1144 - acc: 0.4615 - val_loss: 1.0611 - val_acc: 0.4444\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.2811 - acc: 0.4712 - val_loss: 1.0375 - val_acc: 0.3704\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0961 - acc: 0.4615 - val_loss: 1.0307 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.1411 - acc: 0.4519 - val_loss: 1.0279 - val_acc: 0.5556\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0421 - acc: 0.4519 - val_loss: 1.0228 - val_acc: 0.5556\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0911 - acc: 0.4423 - val_loss: 1.0238 - val_acc: 0.5926\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0258 - acc: 0.4327 - val_loss: 1.0232 - val_acc: 0.5926\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0735 - acc: 0.4615 - val_loss: 1.0262 - val_acc: 0.5926\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.0529 - acc: 0.4423 - val_loss: 1.0209 - val_acc: 0.5556\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0343 - acc: 0.4423 - val_loss: 1.0476 - val_acc: 0.4815\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0424 - acc: 0.4615 - val_loss: 1.0475 - val_acc: 0.5926\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0757 - acc: 0.4808 - val_loss: 1.0387 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0209 - acc: 0.4904 - val_loss: 1.0388 - val_acc: 0.5926\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0383 - acc: 0.4519 - val_loss: 1.0396 - val_acc: 0.5556\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9990 - acc: 0.5000 - val_loss: 1.0393 - val_acc: 0.6296\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 1.0113 - acc: 0.5000 - val_loss: 1.0412 - val_acc: 0.5926\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0433 - acc: 0.4712 - val_loss: 1.0406 - val_acc: 0.6296\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0133 - acc: 0.4904 - val_loss: 1.0399 - val_acc: 0.5926\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0276 - acc: 0.4615 - val_loss: 1.0393 - val_acc: 0.6296\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9781 - acc: 0.5000 - val_loss: 1.0401 - val_acc: 0.5926\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0347 - acc: 0.5096 - val_loss: 1.0401 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0345 - acc: 0.4423 - val_loss: 1.0333 - val_acc: 0.6296\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9810 - acc: 0.4615 - val_loss: 1.0371 - val_acc: 0.6296\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0305 - acc: 0.4712 - val_loss: 1.0362 - val_acc: 0.6667\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0358 - acc: 0.4519 - val_loss: 1.0356 - val_acc: 0.5926\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9921 - acc: 0.4808 - val_loss: 1.0327 - val_acc: 0.5926\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9977 - acc: 0.4519 - val_loss: 1.0369 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0013 - acc: 0.4712 - val_loss: 1.0372 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0284 - acc: 0.4808 - val_loss: 1.0293 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0218 - acc: 0.4519 - val_loss: 1.0095 - val_acc: 0.4074\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0244 - acc: 0.4423 - val_loss: 1.0153 - val_acc: 0.4444\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0092 - acc: 0.4712 - val_loss: 1.0121 - val_acc: 0.4815\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0054 - acc: 0.4808 - val_loss: 1.0105 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0102 - acc: 0.4615 - val_loss: 1.0102 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0075 - acc: 0.4808 - val_loss: 1.0251 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 0.9950 - acc: 0.4904 - val_loss: 1.0257 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9778 - acc: 0.4808 - val_loss: 1.0389 - val_acc: 0.4074\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9910 - acc: 0.4615 - val_loss: 1.0367 - val_acc: 0.4074\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9729 - acc: 0.4808 - val_loss: 1.0357 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0005 - acc: 0.4423 - val_loss: 1.0392 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0832 - acc: 0.4808 - val_loss: 1.0300 - val_acc: 0.4815\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9984 - acc: 0.4808 - val_loss: 1.0257 - val_acc: 0.4444\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9962 - acc: 0.4904 - val_loss: 1.0272 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9796 - acc: 0.4615 - val_loss: 1.0269 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9908 - acc: 0.4808 - val_loss: 1.0219 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0787 - acc: 0.3942 - val_loss: 1.0224 - val_acc: 0.4815\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0252 - acc: 0.4423 - val_loss: 1.0238 - val_acc: 0.4815\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0729 - acc: 0.4712 - val_loss: 1.0164 - val_acc: 0.5556\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9977 - acc: 0.4615 - val_loss: 1.0159 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9834 - acc: 0.5385 - val_loss: 1.0155 - val_acc: 0.5926\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0014 - acc: 0.4231 - val_loss: 1.0142 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9765 - acc: 0.4808 - val_loss: 1.0140 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9756 - acc: 0.4904 - val_loss: 1.0124 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9894 - acc: 0.4519 - val_loss: 1.0225 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9870 - acc: 0.4519 - val_loss: 1.0207 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0106 - acc: 0.4423 - val_loss: 1.0233 - val_acc: 0.4815\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9927 - acc: 0.4615 - val_loss: 1.0421 - val_acc: 0.4815\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0619 - acc: 0.4615 - val_loss: 1.0194 - val_acc: 0.4815\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0246 - acc: 0.4712 - val_loss: 1.0212 - val_acc: 0.4815\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9893 - acc: 0.4904 - val_loss: 1.0157 - val_acc: 0.5556\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9641 - acc: 0.5288 - val_loss: 1.0152 - val_acc: 0.5926\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9911 - acc: 0.4423 - val_loss: 1.0146 - val_acc: 0.5926\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9665 - acc: 0.4712 - val_loss: 1.0134 - val_acc: 0.5926\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 0.9738 - acc: 0.4808 - val_loss: 1.0141 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 954us/sample - loss: 2.0542 - acc: 0.4231 - val_loss: 1.7024 - val_acc: 0.4444\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 2.6965 - acc: 0.4615 - val_loss: 1.7055 - val_acc: 0.4444\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 3.1520 - acc: 0.3558 - val_loss: 1.6024 - val_acc: 0.4444\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 2.3983 - acc: 0.4423 - val_loss: 1.5800 - val_acc: 0.4444\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.3970 - acc: 0.4327 - val_loss: 1.5980 - val_acc: 0.4444\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.5848 - acc: 0.5385 - val_loss: 1.5162 - val_acc: 0.4815\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.8463 - acc: 0.4712 - val_loss: 1.4850 - val_acc: 0.4815\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 2.0814 - acc: 0.4615 - val_loss: 1.4315 - val_acc: 0.4815\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.4085 - acc: 0.5096 - val_loss: 1.3858 - val_acc: 0.5185\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.2518 - acc: 0.4712 - val_loss: 1.3955 - val_acc: 0.5185\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.6302 - acc: 0.5288 - val_loss: 1.3747 - val_acc: 0.5185\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.9408 - acc: 0.4904 - val_loss: 1.3579 - val_acc: 0.5556\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.5056 - acc: 0.4135 - val_loss: 1.3436 - val_acc: 0.5185\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 2.0934 - acc: 0.4712 - val_loss: 1.3052 - val_acc: 0.5556\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.3749 - acc: 0.4519 - val_loss: 1.2728 - val_acc: 0.5185\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.7719 - acc: 0.4712 - val_loss: 1.2800 - val_acc: 0.5556\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.5147 - acc: 0.4423 - val_loss: 1.2114 - val_acc: 0.5926\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.5886 - acc: 0.4519 - val_loss: 1.1527 - val_acc: 0.5926\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.5638 - acc: 0.4423 - val_loss: 1.1039 - val_acc: 0.5926\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.3506 - acc: 0.4038 - val_loss: 1.0700 - val_acc: 0.6667\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.1436 - acc: 0.5096 - val_loss: 1.0801 - val_acc: 0.6667\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2835 - acc: 0.4615 - val_loss: 1.0592 - val_acc: 0.6667\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1024 - acc: 0.4808 - val_loss: 1.0628 - val_acc: 0.6667\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0182 - acc: 0.4615 - val_loss: 1.0578 - val_acc: 0.6667\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1837 - acc: 0.4904 - val_loss: 1.0761 - val_acc: 0.5556\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.3537 - acc: 0.4712 - val_loss: 1.0636 - val_acc: 0.5556\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1188 - acc: 0.4712 - val_loss: 1.0702 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1271 - acc: 0.4615 - val_loss: 1.0665 - val_acc: 0.6296\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0251 - acc: 0.4904 - val_loss: 1.0766 - val_acc: 0.6296\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9866 - acc: 0.4808 - val_loss: 1.0707 - val_acc: 0.6296\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0611 - acc: 0.4808 - val_loss: 1.0700 - val_acc: 0.6296\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.1971 - acc: 0.4808 - val_loss: 1.0615 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0907 - acc: 0.4712 - val_loss: 1.0591 - val_acc: 0.5185\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1527 - acc: 0.4712 - val_loss: 1.0569 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0286 - acc: 0.4808 - val_loss: 1.0583 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.1453 - acc: 0.4615 - val_loss: 1.0511 - val_acc: 0.5556\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0908 - acc: 0.4712 - val_loss: 1.0434 - val_acc: 0.5926\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.1031 - acc: 0.5000 - val_loss: 1.0455 - val_acc: 0.5185\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0492 - acc: 0.4808 - val_loss: 1.0522 - val_acc: 0.5556\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1171 - acc: 0.4615 - val_loss: 1.0441 - val_acc: 0.5926\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0510 - acc: 0.4712 - val_loss: 1.0467 - val_acc: 0.5556\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0490 - acc: 0.4904 - val_loss: 1.0432 - val_acc: 0.5556\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1556 - acc: 0.4423 - val_loss: 1.0520 - val_acc: 0.5556\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.0172 - acc: 0.5192 - val_loss: 1.0655 - val_acc: 0.5556\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9894 - acc: 0.4904 - val_loss: 1.0649 - val_acc: 0.5926\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 411us/sample - loss: 1.0017 - acc: 0.4904 - val_loss: 1.0540 - val_acc: 0.5926\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0915 - acc: 0.4712 - val_loss: 1.0495 - val_acc: 0.5926\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0571 - acc: 0.4519 - val_loss: 1.0286 - val_acc: 0.5926\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0113 - acc: 0.4808 - val_loss: 1.0307 - val_acc: 0.5556\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0128 - acc: 0.5096 - val_loss: 1.0274 - val_acc: 0.5926\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.2554 - acc: 0.4712 - val_loss: 1.0303 - val_acc: 0.5556\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0855 - acc: 0.4904 - val_loss: 1.0350 - val_acc: 0.5556\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0089 - acc: 0.5000 - val_loss: 1.0369 - val_acc: 0.5556\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0168 - acc: 0.4712 - val_loss: 1.0365 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0139 - acc: 0.4712 - val_loss: 1.0336 - val_acc: 0.5556\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0609 - acc: 0.4615 - val_loss: 1.0287 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0099 - acc: 0.5096 - val_loss: 1.0305 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0531 - acc: 0.5000 - val_loss: 1.0228 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.1015 - acc: 0.4519 - val_loss: 1.0155 - val_acc: 0.4815\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0213 - acc: 0.4904 - val_loss: 1.0165 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0251 - acc: 0.5288 - val_loss: 1.0173 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0993 - acc: 0.4327 - val_loss: 1.0048 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0097 - acc: 0.4904 - val_loss: 1.0003 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0373 - acc: 0.4519 - val_loss: 0.9968 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0043 - acc: 0.4808 - val_loss: 0.9989 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9830 - acc: 0.4904 - val_loss: 1.0073 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0433 - acc: 0.4904 - val_loss: 1.0074 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9949 - acc: 0.4904 - val_loss: 1.0081 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0408 - acc: 0.4615 - val_loss: 1.0100 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9933 - acc: 0.4712 - val_loss: 1.0074 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0316 - acc: 0.4904 - val_loss: 1.0113 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0264 - acc: 0.5288 - val_loss: 1.0219 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9791 - acc: 0.4712 - val_loss: 1.0100 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0069 - acc: 0.5192 - val_loss: 1.0054 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.1021 - acc: 0.4904 - val_loss: 1.0059 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0075 - acc: 0.4712 - val_loss: 1.0015 - val_acc: 0.5926\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9943 - acc: 0.4519 - val_loss: 0.9979 - val_acc: 0.5926\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0620 - acc: 0.4519 - val_loss: 0.9982 - val_acc: 0.5926\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9681 - acc: 0.5192 - val_loss: 0.9973 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 462us/sample - loss: 1.0260 - acc: 0.4519 - val_loss: 1.0020 - val_acc: 0.5926\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0148 - acc: 0.4712 - val_loss: 0.9997 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0272 - acc: 0.4904 - val_loss: 1.0025 - val_acc: 0.5556\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0081 - acc: 0.5096 - val_loss: 0.9974 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9986 - acc: 0.4904 - val_loss: 1.0077 - val_acc: 0.5926\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0128 - acc: 0.4615 - val_loss: 1.0066 - val_acc: 0.5556\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 0.9989 - acc: 0.4808 - val_loss: 1.0083 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0366 - acc: 0.4904 - val_loss: 0.9947 - val_acc: 0.5556\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0112 - acc: 0.4615 - val_loss: 0.9925 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9882 - acc: 0.4808 - val_loss: 0.9924 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0198 - acc: 0.4904 - val_loss: 0.9909 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0028 - acc: 0.4615 - val_loss: 0.9906 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0067 - acc: 0.4904 - val_loss: 0.9877 - val_acc: 0.5926\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9976 - acc: 0.4519 - val_loss: 0.9872 - val_acc: 0.5926\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0268 - acc: 0.4615 - val_loss: 0.9854 - val_acc: 0.5926\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9945 - acc: 0.4712 - val_loss: 0.9851 - val_acc: 0.5926\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9887 - acc: 0.4712 - val_loss: 0.9845 - val_acc: 0.5926\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0039 - acc: 0.4712 - val_loss: 0.9851 - val_acc: 0.5926\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0050 - acc: 0.4519 - val_loss: 0.9856 - val_acc: 0.5926\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9623 - acc: 0.5096 - val_loss: 0.9888 - val_acc: 0.5926\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0092 - acc: 0.4615 - val_loss: 0.9904 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.5145 - acc: 0.4423 - val_loss: 2.7235 - val_acc: 0.2222\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 3.6547 - acc: 0.4327 - val_loss: 2.2134 - val_acc: 0.2593\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 3.8803 - acc: 0.4904 - val_loss: 2.1013 - val_acc: 0.2963\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 3.7017 - acc: 0.4231 - val_loss: 1.7664 - val_acc: 0.2963\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 2.2403 - acc: 0.4808 - val_loss: 1.7117 - val_acc: 0.3333\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 2.2697 - acc: 0.4135 - val_loss: 1.6298 - val_acc: 0.3333\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 2.3232 - acc: 0.4327 - val_loss: 1.6181 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 2.3209 - acc: 0.4327 - val_loss: 1.4637 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.9153 - acc: 0.4423 - val_loss: 1.3540 - val_acc: 0.3704\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 2.9613 - acc: 0.4135 - val_loss: 1.2549 - val_acc: 0.3704\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 2.0008 - acc: 0.4519 - val_loss: 1.1802 - val_acc: 0.4074\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.4216 - acc: 0.4712 - val_loss: 1.1537 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.4305 - acc: 0.4519 - val_loss: 1.1094 - val_acc: 0.4444\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.3409 - acc: 0.4519 - val_loss: 1.1079 - val_acc: 0.4444\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.3843 - acc: 0.4327 - val_loss: 1.0675 - val_acc: 0.5185\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1719 - acc: 0.4712 - val_loss: 1.0528 - val_acc: 0.5185\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.2723 - acc: 0.4615 - val_loss: 1.0510 - val_acc: 0.5556\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.2304 - acc: 0.4615 - val_loss: 1.0285 - val_acc: 0.5926\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.2007 - acc: 0.4135 - val_loss: 1.0229 - val_acc: 0.6296\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 696us/sample - loss: 1.2220 - acc: 0.4808 - val_loss: 1.0214 - val_acc: 0.7037\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1058 - acc: 0.4904 - val_loss: 1.0284 - val_acc: 0.7037\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0787 - acc: 0.4904 - val_loss: 1.0397 - val_acc: 0.6296\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0141 - acc: 0.5000 - val_loss: 1.0351 - val_acc: 0.6667\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0663 - acc: 0.4519 - val_loss: 1.0346 - val_acc: 0.7037\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0727 - acc: 0.4615 - val_loss: 1.0442 - val_acc: 0.6296\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0374 - acc: 0.4904 - val_loss: 1.0468 - val_acc: 0.6296\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0738 - acc: 0.4519 - val_loss: 1.0511 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0282 - acc: 0.4327 - val_loss: 1.0510 - val_acc: 0.5185\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0511 - acc: 0.4904 - val_loss: 1.0541 - val_acc: 0.6667\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1416 - acc: 0.4519 - val_loss: 1.0461 - val_acc: 0.7407\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.1221 - acc: 0.4712 - val_loss: 1.0295 - val_acc: 0.7037\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0258 - acc: 0.4904 - val_loss: 1.0325 - val_acc: 0.7037\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0626 - acc: 0.4519 - val_loss: 1.0335 - val_acc: 0.6296\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 1.1190 - acc: 0.4615 - val_loss: 1.0292 - val_acc: 0.6667\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0683 - acc: 0.4808 - val_loss: 1.0321 - val_acc: 0.6667\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0203 - acc: 0.4615 - val_loss: 1.0328 - val_acc: 0.5926\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0456 - acc: 0.4423 - val_loss: 1.0371 - val_acc: 0.5185\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0796 - acc: 0.4808 - val_loss: 1.0346 - val_acc: 0.6667\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0661 - acc: 0.5192 - val_loss: 1.0278 - val_acc: 0.6667\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9881 - acc: 0.5288 - val_loss: 1.0262 - val_acc: 0.7037\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 424us/sample - loss: 1.0981 - acc: 0.5577 - val_loss: 1.0219 - val_acc: 0.5556\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9971 - acc: 0.5288 - val_loss: 1.0180 - val_acc: 0.6296\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0902 - acc: 0.4519 - val_loss: 1.0173 - val_acc: 0.6296\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0327 - acc: 0.4519 - val_loss: 1.0160 - val_acc: 0.6667\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.0423 - acc: 0.5000 - val_loss: 1.0186 - val_acc: 0.5926\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0542 - acc: 0.4712 - val_loss: 1.0192 - val_acc: 0.5926\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0581 - acc: 0.4615 - val_loss: 1.0340 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1629 - acc: 0.4423 - val_loss: 1.0150 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0453 - acc: 0.4519 - val_loss: 1.0047 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0107 - acc: 0.4712 - val_loss: 1.0049 - val_acc: 0.5556\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0159 - acc: 0.4519 - val_loss: 1.0062 - val_acc: 0.5926\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0117 - acc: 0.4808 - val_loss: 1.0032 - val_acc: 0.6667\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0566 - acc: 0.4327 - val_loss: 1.0048 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0529 - acc: 0.4615 - val_loss: 1.0008 - val_acc: 0.5556\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0367 - acc: 0.4615 - val_loss: 1.0030 - val_acc: 0.4815\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0263 - acc: 0.4615 - val_loss: 1.0048 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0077 - acc: 0.5000 - val_loss: 1.0014 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0139 - acc: 0.4423 - val_loss: 1.0073 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0475 - acc: 0.4904 - val_loss: 1.0055 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0341 - acc: 0.4615 - val_loss: 1.0048 - val_acc: 0.5926\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9389 - acc: 0.5192 - val_loss: 1.0033 - val_acc: 0.5926\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0249 - acc: 0.4808 - val_loss: 1.0038 - val_acc: 0.5926\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9881 - acc: 0.4808 - val_loss: 1.0051 - val_acc: 0.5926\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0050 - acc: 0.5000 - val_loss: 1.0110 - val_acc: 0.6296\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0347 - acc: 0.4808 - val_loss: 1.0117 - val_acc: 0.6667\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.1547 - acc: 0.4712 - val_loss: 1.0077 - val_acc: 0.5556\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0657 - acc: 0.5096 - val_loss: 1.0075 - val_acc: 0.5926\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0613 - acc: 0.5096 - val_loss: 0.9998 - val_acc: 0.6296\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0711 - acc: 0.4423 - val_loss: 1.0091 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0025 - acc: 0.4519 - val_loss: 1.0052 - val_acc: 0.4815\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0119 - acc: 0.4519 - val_loss: 0.9989 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0106 - acc: 0.4423 - val_loss: 1.0079 - val_acc: 0.4815\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9906 - acc: 0.4712 - val_loss: 0.9974 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0149 - acc: 0.4615 - val_loss: 1.0043 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0361 - acc: 0.4712 - val_loss: 1.0155 - val_acc: 0.4815\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0074 - acc: 0.4808 - val_loss: 1.0108 - val_acc: 0.4815\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0657 - acc: 0.5000 - val_loss: 0.9978 - val_acc: 0.4815\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0155 - acc: 0.4327 - val_loss: 0.9946 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 288us/sample - loss: 1.0436 - acc: 0.4615 - val_loss: 0.9925 - val_acc: 0.4815\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9709 - acc: 0.5192 - val_loss: 0.9851 - val_acc: 0.5926\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 422us/sample - loss: 1.0476 - acc: 0.4519 - val_loss: 0.9859 - val_acc: 0.4815\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0242 - acc: 0.4808 - val_loss: 0.9974 - val_acc: 0.4815\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0481 - acc: 0.4615 - val_loss: 0.9973 - val_acc: 0.4815\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0123 - acc: 0.4519 - val_loss: 0.9922 - val_acc: 0.4815\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9812 - acc: 0.5000 - val_loss: 0.9874 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9991 - acc: 0.4904 - val_loss: 0.9847 - val_acc: 0.5926\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0214 - acc: 0.4615 - val_loss: 0.9864 - val_acc: 0.4815\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0007 - acc: 0.4327 - val_loss: 0.9873 - val_acc: 0.4815\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0301 - acc: 0.4519 - val_loss: 0.9963 - val_acc: 0.4815\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0453 - acc: 0.4615 - val_loss: 0.9905 - val_acc: 0.4815\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0481 - acc: 0.4615 - val_loss: 0.9936 - val_acc: 0.4815\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0091 - acc: 0.4808 - val_loss: 0.9914 - val_acc: 0.4815\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9812 - acc: 0.5000 - val_loss: 0.9827 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9895 - acc: 0.4904 - val_loss: 0.9769 - val_acc: 0.6667\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0273 - acc: 0.4615 - val_loss: 0.9751 - val_acc: 0.6667\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0650 - acc: 0.4519 - val_loss: 0.9798 - val_acc: 0.4815\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.0072 - acc: 0.5000 - val_loss: 0.9766 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0129 - acc: 0.4519 - val_loss: 0.9710 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9794 - acc: 0.4808 - val_loss: 0.9714 - val_acc: 0.4815\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0007 - acc: 0.4712 - val_loss: 0.9711 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.6796 - acc: 0.4808 - val_loss: 3.4144 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 6.8240 - acc: 0.4423 - val_loss: 2.7373 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 3.5888 - acc: 0.4712 - val_loss: 2.4916 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 2.2411 - acc: 0.5000 - val_loss: 2.3719 - val_acc: 0.4444\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 2.1246 - acc: 0.4904 - val_loss: 2.2254 - val_acc: 0.4444\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 3.4946 - acc: 0.4615 - val_loss: 2.1122 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.8058 - acc: 0.4808 - val_loss: 2.0650 - val_acc: 0.4815\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 288us/sample - loss: 1.9841 - acc: 0.4423 - val_loss: 1.9990 - val_acc: 0.4815\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 2.2772 - acc: 0.4327 - val_loss: 1.8794 - val_acc: 0.5556\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.8885 - acc: 0.4327 - val_loss: 1.7879 - val_acc: 0.5185\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.9030 - acc: 0.4231 - val_loss: 1.7247 - val_acc: 0.5185\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 2.1765 - acc: 0.4712 - val_loss: 1.6160 - val_acc: 0.5926\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.5950 - acc: 0.4519 - val_loss: 1.5617 - val_acc: 0.5185\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.5045 - acc: 0.4808 - val_loss: 1.5281 - val_acc: 0.5185\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.9757 - acc: 0.4423 - val_loss: 1.4588 - val_acc: 0.5556\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.3334 - acc: 0.4519 - val_loss: 1.4481 - val_acc: 0.5556\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.6230 - acc: 0.4423 - val_loss: 1.3648 - val_acc: 0.5556\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.1739 - acc: 0.5192 - val_loss: 1.3452 - val_acc: 0.5556\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1265 - acc: 0.4904 - val_loss: 1.3429 - val_acc: 0.5185\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.2786 - acc: 0.4808 - val_loss: 1.3115 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.4788 - acc: 0.4423 - val_loss: 1.2629 - val_acc: 0.5185\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0703 - acc: 0.4423 - val_loss: 1.2493 - val_acc: 0.5556\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0115 - acc: 0.5096 - val_loss: 1.2472 - val_acc: 0.5556\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0948 - acc: 0.4904 - val_loss: 1.2454 - val_acc: 0.5926\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.2605 - acc: 0.4615 - val_loss: 1.2366 - val_acc: 0.5556\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.4286 - acc: 0.5096 - val_loss: 1.1970 - val_acc: 0.5185\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1940 - acc: 0.4904 - val_loss: 1.1702 - val_acc: 0.5185\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1510 - acc: 0.4615 - val_loss: 1.1493 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0800 - acc: 0.4712 - val_loss: 1.1248 - val_acc: 0.5185\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1823 - acc: 0.4615 - val_loss: 1.0938 - val_acc: 0.5556\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0835 - acc: 0.5000 - val_loss: 1.0806 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0865 - acc: 0.4808 - val_loss: 1.0795 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0888 - acc: 0.5000 - val_loss: 1.0833 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9962 - acc: 0.5096 - val_loss: 1.0768 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9912 - acc: 0.5192 - val_loss: 1.0700 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0170 - acc: 0.5192 - val_loss: 1.0756 - val_acc: 0.5556\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0644 - acc: 0.4808 - val_loss: 1.0667 - val_acc: 0.5185\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0341 - acc: 0.4615 - val_loss: 1.0580 - val_acc: 0.5185\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0505 - acc: 0.4615 - val_loss: 1.0531 - val_acc: 0.5556\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0601 - acc: 0.4808 - val_loss: 1.0606 - val_acc: 0.5185\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0752 - acc: 0.4712 - val_loss: 1.0541 - val_acc: 0.4444\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0895 - acc: 0.4327 - val_loss: 1.0414 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0033 - acc: 0.4904 - val_loss: 1.0363 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9875 - acc: 0.4712 - val_loss: 1.0353 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1394 - acc: 0.4615 - val_loss: 1.0361 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0298 - acc: 0.4712 - val_loss: 1.0421 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0471 - acc: 0.4808 - val_loss: 1.0470 - val_acc: 0.5556\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.0318 - acc: 0.4808 - val_loss: 1.0425 - val_acc: 0.6296\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0188 - acc: 0.4808 - val_loss: 1.0406 - val_acc: 0.6296\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0097 - acc: 0.4808 - val_loss: 1.0450 - val_acc: 0.5926\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0340 - acc: 0.5096 - val_loss: 1.0449 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0390 - acc: 0.4615 - val_loss: 1.0520 - val_acc: 0.5556\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 429us/sample - loss: 1.0387 - acc: 0.4712 - val_loss: 1.0531 - val_acc: 0.5926\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9825 - acc: 0.5192 - val_loss: 1.0590 - val_acc: 0.5926\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0049 - acc: 0.4712 - val_loss: 1.0445 - val_acc: 0.5926\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0560 - acc: 0.4519 - val_loss: 1.0353 - val_acc: 0.5556\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0146 - acc: 0.4712 - val_loss: 1.0342 - val_acc: 0.5556\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9932 - acc: 0.4808 - val_loss: 1.0388 - val_acc: 0.5926\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0059 - acc: 0.4808 - val_loss: 1.0349 - val_acc: 0.5926\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0581 - acc: 0.4423 - val_loss: 1.0349 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0009 - acc: 0.4808 - val_loss: 1.0394 - val_acc: 0.5926\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0451 - acc: 0.4615 - val_loss: 1.0405 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.0124 - acc: 0.4904 - val_loss: 1.0389 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9843 - acc: 0.4808 - val_loss: 1.0409 - val_acc: 0.5926\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0715 - acc: 0.4423 - val_loss: 1.0355 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0713 - acc: 0.4231 - val_loss: 1.0290 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9825 - acc: 0.5000 - val_loss: 1.0323 - val_acc: 0.5926\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0102 - acc: 0.4808 - val_loss: 1.0343 - val_acc: 0.5556\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9995 - acc: 0.4808 - val_loss: 1.0431 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0728 - acc: 0.4808 - val_loss: 1.0275 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0443 - acc: 0.4327 - val_loss: 1.0311 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0717 - acc: 0.4327 - val_loss: 1.0273 - val_acc: 0.5926\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9850 - acc: 0.5096 - val_loss: 1.0292 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9842 - acc: 0.4904 - val_loss: 1.0302 - val_acc: 0.5556\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9900 - acc: 0.4712 - val_loss: 1.0316 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9663 - acc: 0.5096 - val_loss: 1.0346 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0169 - acc: 0.4712 - val_loss: 1.0393 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0412 - acc: 0.4808 - val_loss: 1.0332 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0600 - acc: 0.4327 - val_loss: 1.0196 - val_acc: 0.4444\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9813 - acc: 0.5192 - val_loss: 1.0278 - val_acc: 0.4815\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0084 - acc: 0.4712 - val_loss: 1.0215 - val_acc: 0.4444\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0012 - acc: 0.4808 - val_loss: 1.0206 - val_acc: 0.4444\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9483 - acc: 0.5481 - val_loss: 1.0230 - val_acc: 0.4815\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0787 - acc: 0.4615 - val_loss: 1.0194 - val_acc: 0.4815\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.0238 - acc: 0.4519 - val_loss: 1.0191 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9972 - acc: 0.4712 - val_loss: 1.0254 - val_acc: 0.4444\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9993 - acc: 0.4423 - val_loss: 1.0221 - val_acc: 0.4444\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0783 - acc: 0.4327 - val_loss: 1.0213 - val_acc: 0.4444\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9989 - acc: 0.4712 - val_loss: 1.0146 - val_acc: 0.4444\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9975 - acc: 0.4519 - val_loss: 1.0116 - val_acc: 0.4815\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9908 - acc: 0.4712 - val_loss: 1.0127 - val_acc: 0.4815\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9938 - acc: 0.5096 - val_loss: 1.0217 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9887 - acc: 0.4808 - val_loss: 1.0149 - val_acc: 0.5556\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0256 - acc: 0.4327 - val_loss: 1.0129 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0119 - acc: 0.4712 - val_loss: 1.0079 - val_acc: 0.4815\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9844 - acc: 0.4808 - val_loss: 1.0091 - val_acc: 0.4815\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0089 - acc: 0.4712 - val_loss: 1.0131 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9793 - acc: 0.4904 - val_loss: 1.0136 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0096 - acc: 0.4519 - val_loss: 1.0068 - val_acc: 0.4815\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9849 - acc: 0.4904 - val_loss: 1.0107 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 987us/sample - loss: 2.6574 - acc: 0.3750 - val_loss: 1.3657 - val_acc: 0.4815\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.4646 - acc: 0.4712 - val_loss: 1.3092 - val_acc: 0.4815\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.6383 - acc: 0.4135 - val_loss: 1.2781 - val_acc: 0.4815\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.6154 - acc: 0.4615 - val_loss: 1.1925 - val_acc: 0.5185\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.6125 - acc: 0.4423 - val_loss: 1.1735 - val_acc: 0.5185\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.1881 - acc: 0.4712 - val_loss: 1.1555 - val_acc: 0.5185\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.2551 - acc: 0.4519 - val_loss: 1.1383 - val_acc: 0.5185\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.3413 - acc: 0.4231 - val_loss: 1.1183 - val_acc: 0.5185\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.3031 - acc: 0.4231 - val_loss: 1.0957 - val_acc: 0.5185\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.5181 - acc: 0.4327 - val_loss: 1.0784 - val_acc: 0.5185\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.4898 - acc: 0.4712 - val_loss: 1.0568 - val_acc: 0.5185\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.3226 - acc: 0.4423 - val_loss: 1.0560 - val_acc: 0.5556\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.1876 - acc: 0.4423 - val_loss: 1.0606 - val_acc: 0.5556\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1425 - acc: 0.4615 - val_loss: 1.0380 - val_acc: 0.5556\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.3239 - acc: 0.4135 - val_loss: 1.0245 - val_acc: 0.4815\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.2430 - acc: 0.3942 - val_loss: 1.0259 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.2956 - acc: 0.3846 - val_loss: 1.0166 - val_acc: 0.5185\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1463 - acc: 0.4423 - val_loss: 1.0133 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.2377 - acc: 0.4808 - val_loss: 1.0102 - val_acc: 0.4815\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.2674 - acc: 0.4423 - val_loss: 1.0057 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1770 - acc: 0.4135 - val_loss: 1.0107 - val_acc: 0.5185\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 1.1945 - acc: 0.4135 - val_loss: 0.9820 - val_acc: 0.4444\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0229 - acc: 0.4519 - val_loss: 0.9777 - val_acc: 0.5185\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0075 - acc: 0.4904 - val_loss: 0.9769 - val_acc: 0.5185\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0511 - acc: 0.4231 - val_loss: 0.9836 - val_acc: 0.4815\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.0858 - acc: 0.4423 - val_loss: 0.9825 - val_acc: 0.5556\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1850 - acc: 0.3846 - val_loss: 0.9687 - val_acc: 0.4815\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0153 - acc: 0.4327 - val_loss: 0.9656 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0536 - acc: 0.4423 - val_loss: 0.9729 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0429 - acc: 0.4808 - val_loss: 0.9723 - val_acc: 0.4815\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0393 - acc: 0.4135 - val_loss: 0.9702 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9998 - acc: 0.4519 - val_loss: 0.9681 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0027 - acc: 0.4904 - val_loss: 0.9652 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0170 - acc: 0.4327 - val_loss: 0.9623 - val_acc: 0.5926\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0275 - acc: 0.4423 - val_loss: 0.9624 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0307 - acc: 0.4231 - val_loss: 0.9622 - val_acc: 0.5556\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0604 - acc: 0.3846 - val_loss: 0.9603 - val_acc: 0.5185\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9975 - acc: 0.4808 - val_loss: 0.9596 - val_acc: 0.5926\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0509 - acc: 0.4615 - val_loss: 0.9591 - val_acc: 0.5926\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0397 - acc: 0.5096 - val_loss: 0.9583 - val_acc: 0.5926\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9991 - acc: 0.4712 - val_loss: 0.9569 - val_acc: 0.6296\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0741 - acc: 0.3942 - val_loss: 0.9615 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9816 - acc: 0.4808 - val_loss: 0.9617 - val_acc: 0.5556\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0434 - acc: 0.3846 - val_loss: 0.9594 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0102 - acc: 0.4519 - val_loss: 0.9583 - val_acc: 0.6296\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0347 - acc: 0.4615 - val_loss: 0.9535 - val_acc: 0.6296\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.0290 - acc: 0.4135 - val_loss: 0.9547 - val_acc: 0.5926\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0508 - acc: 0.4519 - val_loss: 0.9560 - val_acc: 0.5926\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9836 - acc: 0.5096 - val_loss: 0.9584 - val_acc: 0.6296\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0176 - acc: 0.4327 - val_loss: 0.9592 - val_acc: 0.5556\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0263 - acc: 0.4231 - val_loss: 0.9562 - val_acc: 0.5556\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0097 - acc: 0.4519 - val_loss: 0.9555 - val_acc: 0.5556\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0981 - acc: 0.4135 - val_loss: 0.9593 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9916 - acc: 0.4904 - val_loss: 0.9545 - val_acc: 0.6296\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0783 - acc: 0.4808 - val_loss: 0.9535 - val_acc: 0.5926\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9977 - acc: 0.4615 - val_loss: 0.9512 - val_acc: 0.5556\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9824 - acc: 0.4808 - val_loss: 0.9517 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0150 - acc: 0.4423 - val_loss: 0.9497 - val_acc: 0.5556\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9932 - acc: 0.4423 - val_loss: 0.9482 - val_acc: 0.5556\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0108 - acc: 0.4519 - val_loss: 0.9502 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0031 - acc: 0.4519 - val_loss: 0.9512 - val_acc: 0.5556\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0446 - acc: 0.4327 - val_loss: 0.9510 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0072 - acc: 0.4808 - val_loss: 0.9493 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0037 - acc: 0.4423 - val_loss: 0.9484 - val_acc: 0.5926\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0554 - acc: 0.4135 - val_loss: 0.9515 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9773 - acc: 0.4808 - val_loss: 0.9468 - val_acc: 0.5926\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0191 - acc: 0.4135 - val_loss: 0.9443 - val_acc: 0.5926\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 0.9962 - acc: 0.4519 - val_loss: 0.9439 - val_acc: 0.5926\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9614 - acc: 0.4615 - val_loss: 0.9426 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0121 - acc: 0.3846 - val_loss: 0.9460 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0386 - acc: 0.4135 - val_loss: 0.9462 - val_acc: 0.5926\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0105 - acc: 0.3942 - val_loss: 0.9497 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0431 - acc: 0.4327 - val_loss: 0.9476 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9894 - acc: 0.4038 - val_loss: 0.9429 - val_acc: 0.4815\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 1.0037 - acc: 0.4231 - val_loss: 0.9432 - val_acc: 0.4815\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0049 - acc: 0.4615 - val_loss: 0.9437 - val_acc: 0.4815\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9764 - acc: 0.4615 - val_loss: 0.9412 - val_acc: 0.4815\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0038 - acc: 0.4615 - val_loss: 0.9437 - val_acc: 0.4815\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9783 - acc: 0.4615 - val_loss: 0.9424 - val_acc: 0.4815\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0127 - acc: 0.4615 - val_loss: 0.9383 - val_acc: 0.4815\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0256 - acc: 0.4712 - val_loss: 0.9424 - val_acc: 0.4444\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9971 - acc: 0.4808 - val_loss: 0.9439 - val_acc: 0.4815\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.0492 - acc: 0.4519 - val_loss: 0.9445 - val_acc: 0.4444\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.0038 - acc: 0.4615 - val_loss: 0.9385 - val_acc: 0.4815\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9998 - acc: 0.4423 - val_loss: 0.9403 - val_acc: 0.4815\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9959 - acc: 0.4615 - val_loss: 0.9390 - val_acc: 0.4815\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0136 - acc: 0.4519 - val_loss: 0.9449 - val_acc: 0.4815\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9944 - acc: 0.4615 - val_loss: 0.9621 - val_acc: 0.4815\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9944 - acc: 0.4519 - val_loss: 0.9658 - val_acc: 0.4815\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9725 - acc: 0.4615 - val_loss: 0.9684 - val_acc: 0.4815\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9923 - acc: 0.4615 - val_loss: 0.9741 - val_acc: 0.4815\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9906 - acc: 0.4615 - val_loss: 0.9770 - val_acc: 0.4815\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9990 - acc: 0.4519 - val_loss: 0.9720 - val_acc: 0.4815\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0691 - acc: 0.4423 - val_loss: 0.9435 - val_acc: 0.4815\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 1.0237 - acc: 0.4615 - val_loss: 0.9432 - val_acc: 0.4815\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 389us/sample - loss: 0.9802 - acc: 0.4615 - val_loss: 0.9424 - val_acc: 0.4815\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 420us/sample - loss: 1.0070 - acc: 0.4615 - val_loss: 0.9478 - val_acc: 0.4815\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9719 - acc: 0.4615 - val_loss: 0.9440 - val_acc: 0.4815\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0020 - acc: 0.4615 - val_loss: 0.9449 - val_acc: 0.4815\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0083 - acc: 0.4615 - val_loss: 0.9444 - val_acc: 0.4815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: b0cdeed1bcb32dea3594172743fea037</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.6666666269302368</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.9</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.4147 - acc: 0.4038 - val_loss: 1.4682 - val_acc: 0.4074\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 472us/sample - loss: 1.3655 - acc: 0.3942 - val_loss: 1.4326 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.3226 - acc: 0.4038 - val_loss: 1.4025 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.2839 - acc: 0.3942 - val_loss: 1.3770 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.2496 - acc: 0.4135 - val_loss: 1.3545 - val_acc: 0.3704\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.2191 - acc: 0.4231 - val_loss: 1.3342 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1918 - acc: 0.4327 - val_loss: 1.3165 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.1685 - acc: 0.4519 - val_loss: 1.3008 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 1.1463 - acc: 0.4712 - val_loss: 1.2865 - val_acc: 0.3704\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1267 - acc: 0.4808 - val_loss: 1.2729 - val_acc: 0.2963\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1093 - acc: 0.4808 - val_loss: 1.2614 - val_acc: 0.2963\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 282us/sample - loss: 1.0939 - acc: 0.5000 - val_loss: 1.2503 - val_acc: 0.2963\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0803 - acc: 0.5000 - val_loss: 1.2397 - val_acc: 0.2963\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0675 - acc: 0.5288 - val_loss: 1.2314 - val_acc: 0.2963\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 290us/sample - loss: 1.0561 - acc: 0.5288 - val_loss: 1.2234 - val_acc: 0.3333\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0458 - acc: 0.5192 - val_loss: 1.2170 - val_acc: 0.3333\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0363 - acc: 0.5192 - val_loss: 1.2113 - val_acc: 0.3333\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 291us/sample - loss: 1.0280 - acc: 0.5000 - val_loss: 1.2056 - val_acc: 0.3333\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0196 - acc: 0.5000 - val_loss: 1.2011 - val_acc: 0.3333\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0121 - acc: 0.5096 - val_loss: 1.1963 - val_acc: 0.3333\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0054 - acc: 0.5096 - val_loss: 1.1918 - val_acc: 0.3333\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9991 - acc: 0.5000 - val_loss: 1.1885 - val_acc: 0.3704\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9938 - acc: 0.5192 - val_loss: 1.1858 - val_acc: 0.3704\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 290us/sample - loss: 0.9878 - acc: 0.5000 - val_loss: 1.1838 - val_acc: 0.3704\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 429us/sample - loss: 0.9826 - acc: 0.5000 - val_loss: 1.1819 - val_acc: 0.3704\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9776 - acc: 0.5096 - val_loss: 1.1802 - val_acc: 0.3704\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9735 - acc: 0.5096 - val_loss: 1.1782 - val_acc: 0.3704\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9693 - acc: 0.4904 - val_loss: 1.1764 - val_acc: 0.3704\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9654 - acc: 0.5096 - val_loss: 1.1747 - val_acc: 0.3704\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9621 - acc: 0.5192 - val_loss: 1.1733 - val_acc: 0.3704\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9582 - acc: 0.5192 - val_loss: 1.1723 - val_acc: 0.3704\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9549 - acc: 0.5192 - val_loss: 1.1715 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9521 - acc: 0.5192 - val_loss: 1.1711 - val_acc: 0.4074\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9486 - acc: 0.5288 - val_loss: 1.1717 - val_acc: 0.4074\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9463 - acc: 0.5288 - val_loss: 1.1715 - val_acc: 0.4074\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9442 - acc: 0.5481 - val_loss: 1.1718 - val_acc: 0.4074\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9414 - acc: 0.5577 - val_loss: 1.1725 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 664us/sample - loss: 0.9390 - acc: 0.5577 - val_loss: 1.1726 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9366 - acc: 0.5577 - val_loss: 1.1725 - val_acc: 0.4074\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 0.9349 - acc: 0.5577 - val_loss: 1.1724 - val_acc: 0.4074\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9327 - acc: 0.5577 - val_loss: 1.1726 - val_acc: 0.4074\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9307 - acc: 0.5577 - val_loss: 1.1726 - val_acc: 0.3704\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9290 - acc: 0.5577 - val_loss: 1.1727 - val_acc: 0.3704\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9274 - acc: 0.5673 - val_loss: 1.1726 - val_acc: 0.3704\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9257 - acc: 0.5673 - val_loss: 1.1728 - val_acc: 0.3704\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9246 - acc: 0.5673 - val_loss: 1.1725 - val_acc: 0.3704\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9227 - acc: 0.5577 - val_loss: 1.1728 - val_acc: 0.4074\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9218 - acc: 0.5481 - val_loss: 1.1725 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 444us/sample - loss: 0.9199 - acc: 0.5481 - val_loss: 1.1726 - val_acc: 0.4815\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9186 - acc: 0.5577 - val_loss: 1.1732 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 0.9172 - acc: 0.5577 - val_loss: 1.1737 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9157 - acc: 0.5481 - val_loss: 1.1742 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9148 - acc: 0.5481 - val_loss: 1.1749 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9138 - acc: 0.5673 - val_loss: 1.1742 - val_acc: 0.4815\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9125 - acc: 0.5769 - val_loss: 1.1745 - val_acc: 0.4815\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9118 - acc: 0.5962 - val_loss: 1.1749 - val_acc: 0.4815\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9103 - acc: 0.6058 - val_loss: 1.1753 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9094 - acc: 0.6058 - val_loss: 1.1755 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9082 - acc: 0.6058 - val_loss: 1.1755 - val_acc: 0.4815\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9074 - acc: 0.6154 - val_loss: 1.1761 - val_acc: 0.4815\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9062 - acc: 0.6058 - val_loss: 1.1768 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9053 - acc: 0.6058 - val_loss: 1.1772 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9045 - acc: 0.6058 - val_loss: 1.1783 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9032 - acc: 0.6058 - val_loss: 1.1790 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9023 - acc: 0.6058 - val_loss: 1.1796 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9015 - acc: 0.6058 - val_loss: 1.1800 - val_acc: 0.5556\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.8999 - acc: 0.6058 - val_loss: 1.1805 - val_acc: 0.5556\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.8991 - acc: 0.6058 - val_loss: 1.1818 - val_acc: 0.5556\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.8985 - acc: 0.6058 - val_loss: 1.1826 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.8977 - acc: 0.6058 - val_loss: 1.1836 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.8969 - acc: 0.6058 - val_loss: 1.1837 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.8953 - acc: 0.6058 - val_loss: 1.1843 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 0.8943 - acc: 0.6058 - val_loss: 1.1845 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8935 - acc: 0.6058 - val_loss: 1.1844 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.8924 - acc: 0.6058 - val_loss: 1.1855 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.8917 - acc: 0.6058 - val_loss: 1.1861 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.8906 - acc: 0.6058 - val_loss: 1.1868 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.8900 - acc: 0.6058 - val_loss: 1.1874 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.8892 - acc: 0.6058 - val_loss: 1.1882 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.8884 - acc: 0.6058 - val_loss: 1.1889 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.8877 - acc: 0.6058 - val_loss: 1.1896 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.8871 - acc: 0.6058 - val_loss: 1.1910 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.8865 - acc: 0.6058 - val_loss: 1.1913 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.8858 - acc: 0.6058 - val_loss: 1.1922 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.8851 - acc: 0.6058 - val_loss: 1.1931 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 0.8852 - acc: 0.6058 - val_loss: 1.1938 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.8839 - acc: 0.6058 - val_loss: 1.1941 - val_acc: 0.5556\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.8835 - acc: 0.6058 - val_loss: 1.1947 - val_acc: 0.5556\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.8827 - acc: 0.6058 - val_loss: 1.1954 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.8822 - acc: 0.6058 - val_loss: 1.1964 - val_acc: 0.5556\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.8814 - acc: 0.6058 - val_loss: 1.1965 - val_acc: 0.5556\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.8809 - acc: 0.6058 - val_loss: 1.1971 - val_acc: 0.5556\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.8803 - acc: 0.6058 - val_loss: 1.1979 - val_acc: 0.5556\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.8800 - acc: 0.5962 - val_loss: 1.1989 - val_acc: 0.5556\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.8793 - acc: 0.5962 - val_loss: 1.1994 - val_acc: 0.5556\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.8787 - acc: 0.5962 - val_loss: 1.2008 - val_acc: 0.5556\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.8784 - acc: 0.5962 - val_loss: 1.2016 - val_acc: 0.5556\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.8779 - acc: 0.6058 - val_loss: 1.2018 - val_acc: 0.5556\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.8771 - acc: 0.5962 - val_loss: 1.2026 - val_acc: 0.5556\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.8768 - acc: 0.5962 - val_loss: 1.2028 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 937us/sample - loss: 2.3378 - acc: 0.3173 - val_loss: 1.7150 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.9380 - acc: 0.3077 - val_loss: 1.5628 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.6771 - acc: 0.3462 - val_loss: 1.4536 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.5233 - acc: 0.3365 - val_loss: 1.3793 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.4271 - acc: 0.3654 - val_loss: 1.3274 - val_acc: 0.3333\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.3635 - acc: 0.3846 - val_loss: 1.2867 - val_acc: 0.3333\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.3161 - acc: 0.4231 - val_loss: 1.2536 - val_acc: 0.3333\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.2772 - acc: 0.4327 - val_loss: 1.2252 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.2461 - acc: 0.4231 - val_loss: 1.2009 - val_acc: 0.3704\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.2175 - acc: 0.4327 - val_loss: 1.1796 - val_acc: 0.3333\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.1957 - acc: 0.4327 - val_loss: 1.1607 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.1758 - acc: 0.4423 - val_loss: 1.1450 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1573 - acc: 0.4231 - val_loss: 1.1310 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1393 - acc: 0.4327 - val_loss: 1.1198 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1253 - acc: 0.4519 - val_loss: 1.1087 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.1105 - acc: 0.4615 - val_loss: 1.0981 - val_acc: 0.3704\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0974 - acc: 0.4615 - val_loss: 1.0886 - val_acc: 0.4444\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0864 - acc: 0.4808 - val_loss: 1.0809 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0743 - acc: 0.5000 - val_loss: 1.0746 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0649 - acc: 0.5000 - val_loss: 1.0679 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0549 - acc: 0.5000 - val_loss: 1.0618 - val_acc: 0.4444\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0467 - acc: 0.4904 - val_loss: 1.0565 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0379 - acc: 0.4904 - val_loss: 1.0534 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0308 - acc: 0.4712 - val_loss: 1.0495 - val_acc: 0.5185\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0238 - acc: 0.4712 - val_loss: 1.0428 - val_acc: 0.5185\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0170 - acc: 0.4712 - val_loss: 1.0367 - val_acc: 0.5185\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0107 - acc: 0.5000 - val_loss: 1.0319 - val_acc: 0.5185\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.0056 - acc: 0.4904 - val_loss: 1.0274 - val_acc: 0.5556\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9994 - acc: 0.5000 - val_loss: 1.0225 - val_acc: 0.5556\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9950 - acc: 0.5000 - val_loss: 1.0195 - val_acc: 0.5556\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9905 - acc: 0.5096 - val_loss: 1.0128 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9868 - acc: 0.5096 - val_loss: 1.0083 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9836 - acc: 0.5096 - val_loss: 1.0040 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9810 - acc: 0.4904 - val_loss: 1.0007 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9787 - acc: 0.5000 - val_loss: 0.9978 - val_acc: 0.5185\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9761 - acc: 0.5192 - val_loss: 0.9942 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 412us/sample - loss: 0.9733 - acc: 0.5192 - val_loss: 0.9912 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9716 - acc: 0.5192 - val_loss: 0.9881 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9705 - acc: 0.5096 - val_loss: 0.9863 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9682 - acc: 0.5192 - val_loss: 0.9842 - val_acc: 0.4444\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9665 - acc: 0.5192 - val_loss: 0.9812 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9645 - acc: 0.5288 - val_loss: 0.9794 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9635 - acc: 0.5192 - val_loss: 0.9772 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9620 - acc: 0.5288 - val_loss: 0.9750 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9607 - acc: 0.5192 - val_loss: 0.9733 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9596 - acc: 0.5192 - val_loss: 0.9715 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9585 - acc: 0.5192 - val_loss: 0.9705 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9577 - acc: 0.5192 - val_loss: 0.9695 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9563 - acc: 0.5192 - val_loss: 0.9686 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9556 - acc: 0.5192 - val_loss: 0.9677 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9544 - acc: 0.5192 - val_loss: 0.9667 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9542 - acc: 0.5288 - val_loss: 0.9666 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9526 - acc: 0.5288 - val_loss: 0.9667 - val_acc: 0.4444\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9519 - acc: 0.5288 - val_loss: 0.9666 - val_acc: 0.4444\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9517 - acc: 0.5385 - val_loss: 0.9634 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9501 - acc: 0.5288 - val_loss: 0.9617 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9497 - acc: 0.5288 - val_loss: 0.9625 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9487 - acc: 0.5385 - val_loss: 0.9607 - val_acc: 0.4444\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9478 - acc: 0.5288 - val_loss: 0.9608 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9470 - acc: 0.5385 - val_loss: 0.9587 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9462 - acc: 0.5288 - val_loss: 0.9566 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9455 - acc: 0.5192 - val_loss: 0.9548 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9446 - acc: 0.5096 - val_loss: 0.9554 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9441 - acc: 0.5096 - val_loss: 0.9561 - val_acc: 0.4444\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9439 - acc: 0.5288 - val_loss: 0.9544 - val_acc: 0.4444\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9433 - acc: 0.5192 - val_loss: 0.9522 - val_acc: 0.4444\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9426 - acc: 0.5096 - val_loss: 0.9510 - val_acc: 0.4444\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9424 - acc: 0.5000 - val_loss: 0.9498 - val_acc: 0.4444\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9416 - acc: 0.5288 - val_loss: 0.9483 - val_acc: 0.4074\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9413 - acc: 0.5192 - val_loss: 0.9493 - val_acc: 0.4444\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9405 - acc: 0.5192 - val_loss: 0.9483 - val_acc: 0.4444\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9398 - acc: 0.5192 - val_loss: 0.9476 - val_acc: 0.4815\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9396 - acc: 0.5288 - val_loss: 0.9469 - val_acc: 0.4815\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9394 - acc: 0.5288 - val_loss: 0.9453 - val_acc: 0.4815\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9385 - acc: 0.5288 - val_loss: 0.9446 - val_acc: 0.4815\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9380 - acc: 0.5288 - val_loss: 0.9453 - val_acc: 0.4815\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9373 - acc: 0.5385 - val_loss: 0.9442 - val_acc: 0.4815\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9372 - acc: 0.5288 - val_loss: 0.9431 - val_acc: 0.4815\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9366 - acc: 0.5481 - val_loss: 0.9423 - val_acc: 0.4815\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9360 - acc: 0.5288 - val_loss: 0.9411 - val_acc: 0.4815\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9360 - acc: 0.5288 - val_loss: 0.9404 - val_acc: 0.4815\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9353 - acc: 0.5288 - val_loss: 0.9394 - val_acc: 0.4815\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9355 - acc: 0.5385 - val_loss: 0.9401 - val_acc: 0.4815\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9345 - acc: 0.5385 - val_loss: 0.9395 - val_acc: 0.4815\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9344 - acc: 0.5481 - val_loss: 0.9384 - val_acc: 0.4815\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9332 - acc: 0.5481 - val_loss: 0.9379 - val_acc: 0.4815\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9334 - acc: 0.5481 - val_loss: 0.9375 - val_acc: 0.4815\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9325 - acc: 0.5481 - val_loss: 0.9373 - val_acc: 0.4815\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9326 - acc: 0.5481 - val_loss: 0.9364 - val_acc: 0.4815\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9318 - acc: 0.5481 - val_loss: 0.9363 - val_acc: 0.4815\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9318 - acc: 0.5481 - val_loss: 0.9357 - val_acc: 0.4444\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9312 - acc: 0.5481 - val_loss: 0.9353 - val_acc: 0.4444\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9307 - acc: 0.5577 - val_loss: 0.9349 - val_acc: 0.4444\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9303 - acc: 0.5481 - val_loss: 0.9340 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9298 - acc: 0.5481 - val_loss: 0.9337 - val_acc: 0.4444\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9296 - acc: 0.5481 - val_loss: 0.9331 - val_acc: 0.4444\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9287 - acc: 0.5481 - val_loss: 0.9328 - val_acc: 0.4444\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9287 - acc: 0.5577 - val_loss: 0.9328 - val_acc: 0.4444\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9281 - acc: 0.5577 - val_loss: 0.9321 - val_acc: 0.4444\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9277 - acc: 0.5577 - val_loss: 0.9319 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 896us/sample - loss: 2.5897 - acc: 0.2885 - val_loss: 2.4786 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 2.1742 - acc: 0.3173 - val_loss: 2.3009 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.8735 - acc: 0.3173 - val_loss: 2.1621 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.6505 - acc: 0.2981 - val_loss: 2.0533 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.4876 - acc: 0.3077 - val_loss: 1.9610 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.3638 - acc: 0.3846 - val_loss: 1.8891 - val_acc: 0.4074\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 431us/sample - loss: 1.2755 - acc: 0.3846 - val_loss: 1.8310 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.2090 - acc: 0.4231 - val_loss: 1.7855 - val_acc: 0.3333\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1571 - acc: 0.4327 - val_loss: 1.7500 - val_acc: 0.2963\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1189 - acc: 0.4519 - val_loss: 1.7210 - val_acc: 0.2963\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0886 - acc: 0.4712 - val_loss: 1.6952 - val_acc: 0.3333\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0652 - acc: 0.4712 - val_loss: 1.6744 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0462 - acc: 0.4712 - val_loss: 1.6570 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0313 - acc: 0.5000 - val_loss: 1.6426 - val_acc: 0.3333\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0193 - acc: 0.5096 - val_loss: 1.6299 - val_acc: 0.3333\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0099 - acc: 0.4904 - val_loss: 1.6186 - val_acc: 0.3333\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0014 - acc: 0.4808 - val_loss: 1.6087 - val_acc: 0.3333\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 0.9936 - acc: 0.4712 - val_loss: 1.6001 - val_acc: 0.3333\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9865 - acc: 0.4904 - val_loss: 1.5924 - val_acc: 0.3333\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9813 - acc: 0.4904 - val_loss: 1.5853 - val_acc: 0.3333\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9756 - acc: 0.5000 - val_loss: 1.5791 - val_acc: 0.3333\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9705 - acc: 0.5000 - val_loss: 1.5718 - val_acc: 0.3704\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9670 - acc: 0.5000 - val_loss: 1.5660 - val_acc: 0.3704\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 0.9633 - acc: 0.5000 - val_loss: 1.5596 - val_acc: 0.3704\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9591 - acc: 0.5000 - val_loss: 1.5565 - val_acc: 0.3704\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9571 - acc: 0.5000 - val_loss: 1.5509 - val_acc: 0.3704\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9537 - acc: 0.5000 - val_loss: 1.5471 - val_acc: 0.3704\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9502 - acc: 0.5096 - val_loss: 1.5423 - val_acc: 0.4074\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9480 - acc: 0.5192 - val_loss: 1.5389 - val_acc: 0.4074\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 422us/sample - loss: 0.9459 - acc: 0.5096 - val_loss: 1.5358 - val_acc: 0.4074\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9433 - acc: 0.5192 - val_loss: 1.5326 - val_acc: 0.4074\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9409 - acc: 0.5192 - val_loss: 1.5303 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9394 - acc: 0.5192 - val_loss: 1.5271 - val_acc: 0.4074\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9372 - acc: 0.5288 - val_loss: 1.5243 - val_acc: 0.4074\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9355 - acc: 0.5288 - val_loss: 1.5226 - val_acc: 0.4074\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9334 - acc: 0.5385 - val_loss: 1.5205 - val_acc: 0.4074\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9319 - acc: 0.5192 - val_loss: 1.5188 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9304 - acc: 0.5481 - val_loss: 1.5166 - val_acc: 0.4074\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9288 - acc: 0.5288 - val_loss: 1.5142 - val_acc: 0.4074\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9265 - acc: 0.5192 - val_loss: 1.5124 - val_acc: 0.4074\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9250 - acc: 0.5288 - val_loss: 1.5092 - val_acc: 0.4444\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9238 - acc: 0.5192 - val_loss: 1.5074 - val_acc: 0.4444\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9225 - acc: 0.5288 - val_loss: 1.5061 - val_acc: 0.4444\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9207 - acc: 0.5288 - val_loss: 1.5046 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9201 - acc: 0.5481 - val_loss: 1.5038 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9195 - acc: 0.5288 - val_loss: 1.5023 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9174 - acc: 0.5385 - val_loss: 1.5004 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9165 - acc: 0.5385 - val_loss: 1.4986 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9153 - acc: 0.5385 - val_loss: 1.4977 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9152 - acc: 0.5385 - val_loss: 1.4969 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9134 - acc: 0.5385 - val_loss: 1.4961 - val_acc: 0.4444\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9125 - acc: 0.5481 - val_loss: 1.4954 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9116 - acc: 0.5481 - val_loss: 1.4952 - val_acc: 0.4444\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9102 - acc: 0.5385 - val_loss: 1.4944 - val_acc: 0.4444\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9100 - acc: 0.5481 - val_loss: 1.4923 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9096 - acc: 0.5481 - val_loss: 1.4916 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9082 - acc: 0.5481 - val_loss: 1.4913 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9083 - acc: 0.5577 - val_loss: 1.4911 - val_acc: 0.4444\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9062 - acc: 0.5481 - val_loss: 1.4901 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9054 - acc: 0.5481 - val_loss: 1.4898 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9049 - acc: 0.5481 - val_loss: 1.4886 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9046 - acc: 0.5481 - val_loss: 1.4882 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9039 - acc: 0.5577 - val_loss: 1.4879 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9029 - acc: 0.5577 - val_loss: 1.4873 - val_acc: 0.4815\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9026 - acc: 0.5577 - val_loss: 1.4872 - val_acc: 0.4815\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9014 - acc: 0.5577 - val_loss: 1.4872 - val_acc: 0.4815\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9014 - acc: 0.5577 - val_loss: 1.4870 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9002 - acc: 0.5577 - val_loss: 1.4873 - val_acc: 0.4815\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8998 - acc: 0.5577 - val_loss: 1.4877 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.8987 - acc: 0.5577 - val_loss: 1.4858 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.8986 - acc: 0.5577 - val_loss: 1.4854 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.8985 - acc: 0.5673 - val_loss: 1.4847 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.8968 - acc: 0.5673 - val_loss: 1.4846 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.8969 - acc: 0.5673 - val_loss: 1.4848 - val_acc: 0.5556\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.8956 - acc: 0.5673 - val_loss: 1.4848 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.8948 - acc: 0.5673 - val_loss: 1.4843 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.8948 - acc: 0.5673 - val_loss: 1.4842 - val_acc: 0.5556\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.8936 - acc: 0.5769 - val_loss: 1.4837 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.8932 - acc: 0.5673 - val_loss: 1.4833 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8927 - acc: 0.5673 - val_loss: 1.4829 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.8919 - acc: 0.5673 - val_loss: 1.4823 - val_acc: 0.5556\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.8917 - acc: 0.5673 - val_loss: 1.4823 - val_acc: 0.5556\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8907 - acc: 0.5673 - val_loss: 1.4822 - val_acc: 0.5556\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.8906 - acc: 0.5673 - val_loss: 1.4825 - val_acc: 0.5556\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.8902 - acc: 0.5769 - val_loss: 1.4817 - val_acc: 0.5556\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.8890 - acc: 0.5769 - val_loss: 1.4818 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.8880 - acc: 0.5769 - val_loss: 1.4811 - val_acc: 0.5556\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.8884 - acc: 0.5769 - val_loss: 1.4809 - val_acc: 0.5556\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.8888 - acc: 0.5865 - val_loss: 1.4817 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.8878 - acc: 0.5769 - val_loss: 1.4814 - val_acc: 0.5556\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.8868 - acc: 0.5865 - val_loss: 1.4814 - val_acc: 0.5556\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.8861 - acc: 0.5865 - val_loss: 1.4815 - val_acc: 0.5556\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.8856 - acc: 0.5769 - val_loss: 1.4817 - val_acc: 0.5556\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.8852 - acc: 0.5769 - val_loss: 1.4830 - val_acc: 0.5556\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.8846 - acc: 0.5865 - val_loss: 1.4831 - val_acc: 0.5556\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.8844 - acc: 0.5769 - val_loss: 1.4833 - val_acc: 0.5556\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.8837 - acc: 0.5769 - val_loss: 1.4845 - val_acc: 0.5556\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.8829 - acc: 0.5865 - val_loss: 1.4843 - val_acc: 0.5556\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.8833 - acc: 0.5865 - val_loss: 1.4847 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.8824 - acc: 0.5865 - val_loss: 1.4848 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 973us/sample - loss: 1.7175 - acc: 0.2596 - val_loss: 1.7211 - val_acc: 0.2593\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.4887 - acc: 0.3077 - val_loss: 1.6245 - val_acc: 0.2963\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.3409 - acc: 0.3558 - val_loss: 1.5677 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.2460 - acc: 0.3750 - val_loss: 1.5246 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.1894 - acc: 0.4808 - val_loss: 1.4855 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1520 - acc: 0.4615 - val_loss: 1.4503 - val_acc: 0.4074\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1225 - acc: 0.4615 - val_loss: 1.4172 - val_acc: 0.4074\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.1039 - acc: 0.5096 - val_loss: 1.3872 - val_acc: 0.4444\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0853 - acc: 0.5000 - val_loss: 1.3615 - val_acc: 0.4815\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0723 - acc: 0.5288 - val_loss: 1.3395 - val_acc: 0.4815\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0605 - acc: 0.5192 - val_loss: 1.3211 - val_acc: 0.4815\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0526 - acc: 0.5096 - val_loss: 1.3043 - val_acc: 0.4815\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0448 - acc: 0.5096 - val_loss: 1.2867 - val_acc: 0.4815\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0385 - acc: 0.5096 - val_loss: 1.2731 - val_acc: 0.4815\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0295 - acc: 0.5096 - val_loss: 1.2575 - val_acc: 0.4815\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0201 - acc: 0.5192 - val_loss: 1.2416 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0115 - acc: 0.5288 - val_loss: 1.2276 - val_acc: 0.4815\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0044 - acc: 0.5577 - val_loss: 1.2165 - val_acc: 0.4815\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9978 - acc: 0.5577 - val_loss: 1.2050 - val_acc: 0.4815\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9924 - acc: 0.5577 - val_loss: 1.1930 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9871 - acc: 0.5673 - val_loss: 1.1828 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9820 - acc: 0.5481 - val_loss: 1.1755 - val_acc: 0.4444\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9780 - acc: 0.5481 - val_loss: 1.1681 - val_acc: 0.4444\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9753 - acc: 0.5577 - val_loss: 1.1601 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 413us/sample - loss: 0.9708 - acc: 0.5481 - val_loss: 1.1568 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9688 - acc: 0.5481 - val_loss: 1.1516 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9656 - acc: 0.5673 - val_loss: 1.1468 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9620 - acc: 0.5673 - val_loss: 1.1445 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 437us/sample - loss: 0.9601 - acc: 0.5673 - val_loss: 1.1438 - val_acc: 0.4444\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9571 - acc: 0.5288 - val_loss: 1.1414 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9543 - acc: 0.5481 - val_loss: 1.1383 - val_acc: 0.4444\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9522 - acc: 0.5673 - val_loss: 1.1381 - val_acc: 0.4444\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9506 - acc: 0.5192 - val_loss: 1.1373 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9486 - acc: 0.5865 - val_loss: 1.1365 - val_acc: 0.4444\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9462 - acc: 0.5577 - val_loss: 1.1357 - val_acc: 0.4444\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9440 - acc: 0.5481 - val_loss: 1.1339 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9435 - acc: 0.5288 - val_loss: 1.1328 - val_acc: 0.4444\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9399 - acc: 0.5481 - val_loss: 1.1327 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9384 - acc: 0.5288 - val_loss: 1.1314 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9370 - acc: 0.5481 - val_loss: 1.1328 - val_acc: 0.4444\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9336 - acc: 0.5673 - val_loss: 1.1330 - val_acc: 0.4444\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9329 - acc: 0.5673 - val_loss: 1.1339 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9311 - acc: 0.5673 - val_loss: 1.1337 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9293 - acc: 0.5769 - val_loss: 1.1342 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9275 - acc: 0.5673 - val_loss: 1.1350 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9264 - acc: 0.5673 - val_loss: 1.1337 - val_acc: 0.4815\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9245 - acc: 0.5865 - val_loss: 1.1341 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9232 - acc: 0.5962 - val_loss: 1.1353 - val_acc: 0.4815\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 642us/sample - loss: 0.9216 - acc: 0.5769 - val_loss: 1.1369 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9201 - acc: 0.5769 - val_loss: 1.1382 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9190 - acc: 0.5962 - val_loss: 1.1396 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9176 - acc: 0.5769 - val_loss: 1.1419 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9172 - acc: 0.5962 - val_loss: 1.1431 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9160 - acc: 0.6058 - val_loss: 1.1444 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9138 - acc: 0.5865 - val_loss: 1.1453 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9131 - acc: 0.5769 - val_loss: 1.1472 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9102 - acc: 0.5962 - val_loss: 1.1476 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9094 - acc: 0.6058 - val_loss: 1.1495 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9082 - acc: 0.5962 - val_loss: 1.1518 - val_acc: 0.4815\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9083 - acc: 0.6058 - val_loss: 1.1527 - val_acc: 0.4815\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9056 - acc: 0.6154 - val_loss: 1.1550 - val_acc: 0.4815\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9051 - acc: 0.6058 - val_loss: 1.1574 - val_acc: 0.4815\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9043 - acc: 0.5962 - val_loss: 1.1591 - val_acc: 0.4815\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9020 - acc: 0.5962 - val_loss: 1.1606 - val_acc: 0.4815\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9021 - acc: 0.6154 - val_loss: 1.1608 - val_acc: 0.4815\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9008 - acc: 0.5962 - val_loss: 1.1639 - val_acc: 0.4815\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9009 - acc: 0.5962 - val_loss: 1.1637 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.8991 - acc: 0.6154 - val_loss: 1.1641 - val_acc: 0.4815\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.8993 - acc: 0.5962 - val_loss: 1.1662 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.8969 - acc: 0.5962 - val_loss: 1.1671 - val_acc: 0.4815\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 0.8959 - acc: 0.5865 - val_loss: 1.1680 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.8955 - acc: 0.6058 - val_loss: 1.1686 - val_acc: 0.4815\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.8943 - acc: 0.6058 - val_loss: 1.1693 - val_acc: 0.4815\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.8947 - acc: 0.5962 - val_loss: 1.1704 - val_acc: 0.4815\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.8935 - acc: 0.5962 - val_loss: 1.1721 - val_acc: 0.4815\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.8914 - acc: 0.6250 - val_loss: 1.1749 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.8915 - acc: 0.6058 - val_loss: 1.1762 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.8912 - acc: 0.5962 - val_loss: 1.1773 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.8895 - acc: 0.5865 - val_loss: 1.1782 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8891 - acc: 0.5962 - val_loss: 1.1789 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.8882 - acc: 0.5962 - val_loss: 1.1795 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8872 - acc: 0.5962 - val_loss: 1.1808 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8869 - acc: 0.5769 - val_loss: 1.1828 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.8859 - acc: 0.5865 - val_loss: 1.1838 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.8851 - acc: 0.6058 - val_loss: 1.1848 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.8837 - acc: 0.5962 - val_loss: 1.1870 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.8824 - acc: 0.5865 - val_loss: 1.1883 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.8835 - acc: 0.5865 - val_loss: 1.1895 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.8806 - acc: 0.5865 - val_loss: 1.1912 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.8805 - acc: 0.5769 - val_loss: 1.1916 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.8809 - acc: 0.5769 - val_loss: 1.1920 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.8805 - acc: 0.5865 - val_loss: 1.1927 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 0.8789 - acc: 0.5865 - val_loss: 1.1951 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.8772 - acc: 0.5769 - val_loss: 1.1963 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.8787 - acc: 0.5673 - val_loss: 1.1972 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.8753 - acc: 0.5962 - val_loss: 1.1972 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.8761 - acc: 0.5769 - val_loss: 1.1998 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.8760 - acc: 0.5673 - val_loss: 1.2017 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.8741 - acc: 0.5673 - val_loss: 1.2033 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.8734 - acc: 0.5673 - val_loss: 1.2043 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 968us/sample - loss: 1.8495 - acc: 0.4423 - val_loss: 2.3439 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.7358 - acc: 0.4519 - val_loss: 2.1682 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.6349 - acc: 0.4519 - val_loss: 2.0199 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.5492 - acc: 0.4519 - val_loss: 1.8876 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.4707 - acc: 0.4519 - val_loss: 1.7653 - val_acc: 0.3333\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.4032 - acc: 0.4519 - val_loss: 1.6580 - val_acc: 0.3333\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.3449 - acc: 0.4423 - val_loss: 1.5627 - val_acc: 0.3333\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.2947 - acc: 0.4423 - val_loss: 1.4854 - val_acc: 0.3333\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.2520 - acc: 0.4519 - val_loss: 1.4123 - val_acc: 0.3333\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.2105 - acc: 0.4519 - val_loss: 1.3495 - val_acc: 0.3333\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.1763 - acc: 0.4519 - val_loss: 1.2965 - val_acc: 0.3333\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.1462 - acc: 0.4423 - val_loss: 1.2503 - val_acc: 0.3333\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1212 - acc: 0.4519 - val_loss: 1.2102 - val_acc: 0.3333\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0996 - acc: 0.4423 - val_loss: 1.1740 - val_acc: 0.3333\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0813 - acc: 0.4423 - val_loss: 1.1389 - val_acc: 0.3333\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0639 - acc: 0.4423 - val_loss: 1.1140 - val_acc: 0.3333\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0521 - acc: 0.4423 - val_loss: 1.0919 - val_acc: 0.3704\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0413 - acc: 0.4423 - val_loss: 1.0724 - val_acc: 0.3704\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0305 - acc: 0.4519 - val_loss: 1.0553 - val_acc: 0.4074\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0235 - acc: 0.4712 - val_loss: 1.0414 - val_acc: 0.3704\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0168 - acc: 0.4808 - val_loss: 1.0294 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0107 - acc: 0.4712 - val_loss: 1.0204 - val_acc: 0.4074\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0068 - acc: 0.4712 - val_loss: 1.0071 - val_acc: 0.4074\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0023 - acc: 0.4712 - val_loss: 0.9990 - val_acc: 0.4074\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9980 - acc: 0.4712 - val_loss: 0.9917 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9950 - acc: 0.4904 - val_loss: 0.9853 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9938 - acc: 0.5000 - val_loss: 0.9796 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9902 - acc: 0.5000 - val_loss: 0.9766 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 0.9887 - acc: 0.5000 - val_loss: 0.9729 - val_acc: 0.4444\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9876 - acc: 0.5000 - val_loss: 0.9707 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9862 - acc: 0.4904 - val_loss: 0.9656 - val_acc: 0.4444\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9829 - acc: 0.5000 - val_loss: 0.9619 - val_acc: 0.4444\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9818 - acc: 0.5192 - val_loss: 0.9607 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9799 - acc: 0.5096 - val_loss: 0.9572 - val_acc: 0.4444\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9786 - acc: 0.5096 - val_loss: 0.9549 - val_acc: 0.4444\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 0.9775 - acc: 0.5096 - val_loss: 0.9540 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9764 - acc: 0.5096 - val_loss: 0.9523 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9761 - acc: 0.5096 - val_loss: 0.9518 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9737 - acc: 0.5096 - val_loss: 0.9512 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9715 - acc: 0.5096 - val_loss: 0.9481 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 0.9711 - acc: 0.5096 - val_loss: 0.9474 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9686 - acc: 0.5192 - val_loss: 0.9454 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9679 - acc: 0.5000 - val_loss: 0.9434 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9662 - acc: 0.5096 - val_loss: 0.9409 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9653 - acc: 0.5096 - val_loss: 0.9405 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9632 - acc: 0.5096 - val_loss: 0.9405 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9630 - acc: 0.5096 - val_loss: 0.9390 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9619 - acc: 0.5096 - val_loss: 0.9382 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9610 - acc: 0.5096 - val_loss: 0.9370 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 389us/sample - loss: 0.9601 - acc: 0.5096 - val_loss: 0.9366 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9582 - acc: 0.5096 - val_loss: 0.9353 - val_acc: 0.4444\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9589 - acc: 0.5000 - val_loss: 0.9349 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9571 - acc: 0.5000 - val_loss: 0.9357 - val_acc: 0.5556\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9560 - acc: 0.5481 - val_loss: 0.9355 - val_acc: 0.5556\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 0.9551 - acc: 0.5481 - val_loss: 0.9356 - val_acc: 0.5556\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9551 - acc: 0.5481 - val_loss: 0.9346 - val_acc: 0.5556\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9535 - acc: 0.5481 - val_loss: 0.9331 - val_acc: 0.5556\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9530 - acc: 0.5385 - val_loss: 0.9310 - val_acc: 0.5556\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9514 - acc: 0.5481 - val_loss: 0.9299 - val_acc: 0.5556\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9512 - acc: 0.5577 - val_loss: 0.9289 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9503 - acc: 0.5481 - val_loss: 0.9278 - val_acc: 0.5556\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9491 - acc: 0.5481 - val_loss: 0.9270 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9484 - acc: 0.5577 - val_loss: 0.9259 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9482 - acc: 0.5481 - val_loss: 0.9254 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9478 - acc: 0.5481 - val_loss: 0.9258 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9455 - acc: 0.5577 - val_loss: 0.9260 - val_acc: 0.5556\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9459 - acc: 0.5577 - val_loss: 0.9257 - val_acc: 0.5556\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9444 - acc: 0.5577 - val_loss: 0.9270 - val_acc: 0.5556\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9437 - acc: 0.5577 - val_loss: 0.9263 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9426 - acc: 0.5481 - val_loss: 0.9244 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9430 - acc: 0.5481 - val_loss: 0.9237 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9412 - acc: 0.5385 - val_loss: 0.9224 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9410 - acc: 0.5673 - val_loss: 0.9211 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9399 - acc: 0.5673 - val_loss: 0.9197 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9390 - acc: 0.5481 - val_loss: 0.9197 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9388 - acc: 0.5577 - val_loss: 0.9191 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9370 - acc: 0.5481 - val_loss: 0.9194 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9377 - acc: 0.5481 - val_loss: 0.9200 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9362 - acc: 0.5577 - val_loss: 0.9200 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9356 - acc: 0.5481 - val_loss: 0.9203 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9351 - acc: 0.5481 - val_loss: 0.9197 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9338 - acc: 0.5481 - val_loss: 0.9192 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9342 - acc: 0.5481 - val_loss: 0.9178 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9321 - acc: 0.5577 - val_loss: 0.9182 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9337 - acc: 0.5385 - val_loss: 0.9173 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9322 - acc: 0.5481 - val_loss: 0.9165 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9300 - acc: 0.5481 - val_loss: 0.9160 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9302 - acc: 0.5577 - val_loss: 0.9149 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9290 - acc: 0.5577 - val_loss: 0.9148 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9283 - acc: 0.5481 - val_loss: 0.9148 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 279us/sample - loss: 0.9275 - acc: 0.5481 - val_loss: 0.9151 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 0.9272 - acc: 0.5673 - val_loss: 0.9149 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9268 - acc: 0.5481 - val_loss: 0.9143 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9259 - acc: 0.5673 - val_loss: 0.9144 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 0.9257 - acc: 0.5673 - val_loss: 0.9143 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9242 - acc: 0.5481 - val_loss: 0.9136 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9238 - acc: 0.5673 - val_loss: 0.9125 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9237 - acc: 0.5673 - val_loss: 0.9124 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9231 - acc: 0.5769 - val_loss: 0.9123 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9225 - acc: 0.5481 - val_loss: 0.9126 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 68a30c52665e8ad86467f695fdba9e6c</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5481481552124023</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.2092 - acc: 0.3654 - val_loss: 2.6624 - val_acc: 0.4074\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 3.7440 - acc: 0.4135 - val_loss: 2.2257 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 2.9453 - acc: 0.4038 - val_loss: 1.9057 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 2.2990 - acc: 0.3654 - val_loss: 1.6785 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.8127 - acc: 0.3942 - val_loss: 1.5174 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.5152 - acc: 0.5096 - val_loss: 1.4130 - val_acc: 0.4074\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 1.4734 - acc: 0.3558 - val_loss: 1.3247 - val_acc: 0.4074\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.2632 - acc: 0.4519 - val_loss: 1.2743 - val_acc: 0.4074\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.2983 - acc: 0.4038 - val_loss: 1.2314 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.2048 - acc: 0.3750 - val_loss: 1.2027 - val_acc: 0.3704\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 411us/sample - loss: 1.2206 - acc: 0.4231 - val_loss: 1.1774 - val_acc: 0.4444\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0919 - acc: 0.5192 - val_loss: 1.1660 - val_acc: 0.4444\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0986 - acc: 0.4519 - val_loss: 1.1561 - val_acc: 0.4444\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0697 - acc: 0.4327 - val_loss: 1.1495 - val_acc: 0.4444\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0507 - acc: 0.4808 - val_loss: 1.1425 - val_acc: 0.4444\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 422us/sample - loss: 1.0465 - acc: 0.5481 - val_loss: 1.1381 - val_acc: 0.4444\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.0051 - acc: 0.5481 - val_loss: 1.1333 - val_acc: 0.4815\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9904 - acc: 0.4808 - val_loss: 1.1315 - val_acc: 0.4815\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0255 - acc: 0.5096 - val_loss: 1.1269 - val_acc: 0.4815\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9913 - acc: 0.5577 - val_loss: 1.1274 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9766 - acc: 0.5096 - val_loss: 1.1225 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9812 - acc: 0.5288 - val_loss: 1.1180 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9915 - acc: 0.5385 - val_loss: 1.1167 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9702 - acc: 0.5096 - val_loss: 1.1174 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 0.9978 - acc: 0.4615 - val_loss: 1.1130 - val_acc: 0.5185\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 0.9729 - acc: 0.5192 - val_loss: 1.1088 - val_acc: 0.5556\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9817 - acc: 0.5096 - val_loss: 1.1054 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9570 - acc: 0.5288 - val_loss: 1.1040 - val_acc: 0.5556\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 0.9999 - acc: 0.4712 - val_loss: 1.1016 - val_acc: 0.5926\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9786 - acc: 0.5096 - val_loss: 1.0996 - val_acc: 0.5926\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9774 - acc: 0.5481 - val_loss: 1.1002 - val_acc: 0.5926\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9506 - acc: 0.5577 - val_loss: 1.0948 - val_acc: 0.5926\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9842 - acc: 0.5000 - val_loss: 1.0963 - val_acc: 0.5926\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9331 - acc: 0.5577 - val_loss: 1.0962 - val_acc: 0.5926\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9894 - acc: 0.4904 - val_loss: 1.0926 - val_acc: 0.5926\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9698 - acc: 0.4904 - val_loss: 1.0928 - val_acc: 0.5926\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9455 - acc: 0.5385 - val_loss: 1.0929 - val_acc: 0.5926\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9434 - acc: 0.5769 - val_loss: 1.0898 - val_acc: 0.5926\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9449 - acc: 0.5385 - val_loss: 1.0865 - val_acc: 0.5926\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9403 - acc: 0.5385 - val_loss: 1.0869 - val_acc: 0.5926\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9241 - acc: 0.5577 - val_loss: 1.0882 - val_acc: 0.5926\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9358 - acc: 0.5673 - val_loss: 1.0926 - val_acc: 0.5926\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9325 - acc: 0.5481 - val_loss: 1.0986 - val_acc: 0.5926\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 457us/sample - loss: 0.9615 - acc: 0.5192 - val_loss: 1.1017 - val_acc: 0.5926\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 418us/sample - loss: 0.9408 - acc: 0.5481 - val_loss: 1.1021 - val_acc: 0.6296\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9419 - acc: 0.5288 - val_loss: 1.1029 - val_acc: 0.6296\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9537 - acc: 0.5192 - val_loss: 1.1063 - val_acc: 0.5926\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9232 - acc: 0.5385 - val_loss: 1.1115 - val_acc: 0.5926\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 0.9271 - acc: 0.5673 - val_loss: 1.1149 - val_acc: 0.5926\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 412us/sample - loss: 0.9319 - acc: 0.5288 - val_loss: 1.1148 - val_acc: 0.5926\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9069 - acc: 0.5673 - val_loss: 1.1157 - val_acc: 0.5926\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9321 - acc: 0.5385 - val_loss: 1.1169 - val_acc: 0.5926\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9182 - acc: 0.5673 - val_loss: 1.1194 - val_acc: 0.5926\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9615 - acc: 0.4904 - val_loss: 1.1212 - val_acc: 0.5926\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 437us/sample - loss: 0.9523 - acc: 0.5481 - val_loss: 1.1213 - val_acc: 0.5926\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9541 - acc: 0.5385 - val_loss: 1.1235 - val_acc: 0.5926\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9219 - acc: 0.5096 - val_loss: 1.1243 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9197 - acc: 0.5577 - val_loss: 1.1274 - val_acc: 0.5556\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9338 - acc: 0.5000 - val_loss: 1.1281 - val_acc: 0.5556\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9342 - acc: 0.5481 - val_loss: 1.1348 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 0.8955 - acc: 0.5288 - val_loss: 1.1340 - val_acc: 0.5556\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9388 - acc: 0.5481 - val_loss: 1.1360 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9277 - acc: 0.5385 - val_loss: 1.1370 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9187 - acc: 0.5865 - val_loss: 1.1367 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9173 - acc: 0.5481 - val_loss: 1.1348 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9721 - acc: 0.4808 - val_loss: 1.1344 - val_acc: 0.5556\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9058 - acc: 0.5385 - val_loss: 1.1405 - val_acc: 0.5556\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9101 - acc: 0.5577 - val_loss: 1.1391 - val_acc: 0.5556\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9280 - acc: 0.5192 - val_loss: 1.1440 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9014 - acc: 0.5481 - val_loss: 1.1451 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9428 - acc: 0.4808 - val_loss: 1.1421 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9134 - acc: 0.5481 - val_loss: 1.1457 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 281us/sample - loss: 0.9163 - acc: 0.5192 - val_loss: 1.1544 - val_acc: 0.5926\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9045 - acc: 0.5769 - val_loss: 1.1583 - val_acc: 0.5926\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9310 - acc: 0.5288 - val_loss: 1.1567 - val_acc: 0.5926\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.8937 - acc: 0.5481 - val_loss: 1.1541 - val_acc: 0.5926\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9360 - acc: 0.5192 - val_loss: 1.1532 - val_acc: 0.5926\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 725us/sample - loss: 0.9389 - acc: 0.5096 - val_loss: 1.1554 - val_acc: 0.5926\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9426 - acc: 0.4904 - val_loss: 1.1556 - val_acc: 0.5926\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 0.9294 - acc: 0.4904 - val_loss: 1.1537 - val_acc: 0.5926\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9004 - acc: 0.5192 - val_loss: 1.1568 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9461 - acc: 0.5385 - val_loss: 1.1612 - val_acc: 0.5926\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.8904 - acc: 0.5481 - val_loss: 1.1620 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9049 - acc: 0.5288 - val_loss: 1.1661 - val_acc: 0.5926\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9334 - acc: 0.5192 - val_loss: 1.1657 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9173 - acc: 0.5481 - val_loss: 1.1660 - val_acc: 0.5926\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.8720 - acc: 0.5769 - val_loss: 1.1700 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9125 - acc: 0.5192 - val_loss: 1.1716 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 0.9193 - acc: 0.5481 - val_loss: 1.1736 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9273 - acc: 0.5288 - val_loss: 1.1731 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9315 - acc: 0.5288 - val_loss: 1.1747 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.8778 - acc: 0.5577 - val_loss: 1.1752 - val_acc: 0.5926\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9406 - acc: 0.5096 - val_loss: 1.1735 - val_acc: 0.5926\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9364 - acc: 0.5000 - val_loss: 1.1699 - val_acc: 0.5926\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9374 - acc: 0.4808 - val_loss: 1.1660 - val_acc: 0.5926\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9338 - acc: 0.5192 - val_loss: 1.1644 - val_acc: 0.5926\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9252 - acc: 0.5673 - val_loss: 1.1685 - val_acc: 0.5926\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9041 - acc: 0.5481 - val_loss: 1.1685 - val_acc: 0.5926\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9198 - acc: 0.5192 - val_loss: 1.1702 - val_acc: 0.5926\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9199 - acc: 0.5481 - val_loss: 1.1730 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 968us/sample - loss: 2.2211 - acc: 0.4135 - val_loss: 1.9511 - val_acc: 0.4444\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.9832 - acc: 0.4327 - val_loss: 1.7733 - val_acc: 0.4815\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.8120 - acc: 0.4135 - val_loss: 1.6364 - val_acc: 0.4815\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.6804 - acc: 0.4231 - val_loss: 1.5256 - val_acc: 0.4815\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 1.5797 - acc: 0.4231 - val_loss: 1.4345 - val_acc: 0.4815\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.3730 - acc: 0.4904 - val_loss: 1.3612 - val_acc: 0.4815\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.4128 - acc: 0.4231 - val_loss: 1.2886 - val_acc: 0.4815\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 440us/sample - loss: 1.4678 - acc: 0.3654 - val_loss: 1.2271 - val_acc: 0.4815\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.2168 - acc: 0.4615 - val_loss: 1.1836 - val_acc: 0.5185\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.3128 - acc: 0.4038 - val_loss: 1.1496 - val_acc: 0.5185\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.1769 - acc: 0.5096 - val_loss: 1.1162 - val_acc: 0.5185\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1715 - acc: 0.5192 - val_loss: 1.0899 - val_acc: 0.5185\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1302 - acc: 0.5192 - val_loss: 1.0652 - val_acc: 0.5556\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1510 - acc: 0.5192 - val_loss: 1.0533 - val_acc: 0.5556\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.0974 - acc: 0.5385 - val_loss: 1.0413 - val_acc: 0.5926\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0715 - acc: 0.5192 - val_loss: 1.0329 - val_acc: 0.5926\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0455 - acc: 0.5288 - val_loss: 1.0236 - val_acc: 0.5556\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0279 - acc: 0.5192 - val_loss: 1.0212 - val_acc: 0.5185\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.0266 - acc: 0.4904 - val_loss: 1.0120 - val_acc: 0.4815\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9991 - acc: 0.5288 - val_loss: 1.0116 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0040 - acc: 0.5481 - val_loss: 1.0113 - val_acc: 0.5185\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0966 - acc: 0.4519 - val_loss: 1.0042 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0495 - acc: 0.4904 - val_loss: 1.0011 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0159 - acc: 0.5865 - val_loss: 0.9965 - val_acc: 0.5185\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0642 - acc: 0.5000 - val_loss: 0.9994 - val_acc: 0.5185\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9637 - acc: 0.5769 - val_loss: 0.9981 - val_acc: 0.5185\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9455 - acc: 0.5865 - val_loss: 1.0041 - val_acc: 0.5185\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9871 - acc: 0.5673 - val_loss: 1.0016 - val_acc: 0.5185\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9276 - acc: 0.5769 - val_loss: 1.0016 - val_acc: 0.5185\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0189 - acc: 0.5288 - val_loss: 0.9951 - val_acc: 0.5185\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0228 - acc: 0.5673 - val_loss: 0.9925 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9553 - acc: 0.5577 - val_loss: 1.0048 - val_acc: 0.4815\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9374 - acc: 0.5769 - val_loss: 1.0045 - val_acc: 0.4815\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9862 - acc: 0.5481 - val_loss: 1.0019 - val_acc: 0.5185\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0172 - acc: 0.5385 - val_loss: 0.9996 - val_acc: 0.5185\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9823 - acc: 0.6154 - val_loss: 1.0002 - val_acc: 0.5556\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9786 - acc: 0.5865 - val_loss: 0.9974 - val_acc: 0.5556\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0093 - acc: 0.5481 - val_loss: 0.9990 - val_acc: 0.5556\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9347 - acc: 0.5865 - val_loss: 1.0033 - val_acc: 0.5185\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9625 - acc: 0.5769 - val_loss: 1.0030 - val_acc: 0.5185\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0300 - acc: 0.5481 - val_loss: 1.0004 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 0.9473 - acc: 0.6154 - val_loss: 1.0034 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9184 - acc: 0.5865 - val_loss: 0.9997 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9803 - acc: 0.5481 - val_loss: 0.9970 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9086 - acc: 0.6346 - val_loss: 1.0003 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9991 - acc: 0.5769 - val_loss: 1.0001 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9994 - acc: 0.5288 - val_loss: 0.9988 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9946 - acc: 0.5577 - val_loss: 1.0010 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9573 - acc: 0.5769 - val_loss: 0.9985 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9380 - acc: 0.6058 - val_loss: 0.9981 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9495 - acc: 0.5673 - val_loss: 0.9972 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9672 - acc: 0.5673 - val_loss: 1.0011 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9044 - acc: 0.5769 - val_loss: 1.0003 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.8665 - acc: 0.6538 - val_loss: 1.0053 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9495 - acc: 0.5962 - val_loss: 1.0051 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9755 - acc: 0.5673 - val_loss: 1.0036 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0112 - acc: 0.5192 - val_loss: 0.9995 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9916 - acc: 0.5481 - val_loss: 0.9984 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9451 - acc: 0.5962 - val_loss: 0.9990 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 0.9091 - acc: 0.5962 - val_loss: 0.9977 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 0.9797 - acc: 0.5865 - val_loss: 0.9974 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9473 - acc: 0.5769 - val_loss: 0.9989 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9321 - acc: 0.5577 - val_loss: 1.0014 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9176 - acc: 0.5865 - val_loss: 0.9991 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9480 - acc: 0.5865 - val_loss: 0.9971 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9508 - acc: 0.5385 - val_loss: 1.0000 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9267 - acc: 0.5673 - val_loss: 1.0025 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9376 - acc: 0.5769 - val_loss: 1.0024 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9306 - acc: 0.6154 - val_loss: 1.0028 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9400 - acc: 0.5192 - val_loss: 1.0018 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 0.9762 - acc: 0.5096 - val_loss: 0.9995 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9137 - acc: 0.5481 - val_loss: 0.9993 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9585 - acc: 0.5385 - val_loss: 0.9994 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9466 - acc: 0.5673 - val_loss: 0.9981 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 0.9578 - acc: 0.5577 - val_loss: 0.9997 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9419 - acc: 0.5577 - val_loss: 1.0034 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9657 - acc: 0.5865 - val_loss: 1.0028 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9479 - acc: 0.5481 - val_loss: 1.0038 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9391 - acc: 0.5577 - val_loss: 1.0001 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9487 - acc: 0.5769 - val_loss: 0.9979 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9055 - acc: 0.6154 - val_loss: 1.0005 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9755 - acc: 0.5192 - val_loss: 0.9986 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9462 - acc: 0.5385 - val_loss: 1.0005 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9769 - acc: 0.5385 - val_loss: 1.0012 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9189 - acc: 0.5962 - val_loss: 1.0007 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.8955 - acc: 0.6346 - val_loss: 1.0039 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.8931 - acc: 0.6058 - val_loss: 1.0088 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 0.9277 - acc: 0.5865 - val_loss: 1.0080 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9441 - acc: 0.5385 - val_loss: 1.0050 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.8704 - acc: 0.6442 - val_loss: 1.0054 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.8955 - acc: 0.6346 - val_loss: 1.0068 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9272 - acc: 0.5769 - val_loss: 1.0086 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9254 - acc: 0.5577 - val_loss: 1.0082 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9120 - acc: 0.5577 - val_loss: 1.0090 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.8896 - acc: 0.6154 - val_loss: 1.0094 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9571 - acc: 0.5288 - val_loss: 1.0123 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9339 - acc: 0.5673 - val_loss: 1.0117 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9156 - acc: 0.5962 - val_loss: 1.0107 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.8980 - acc: 0.5865 - val_loss: 1.0115 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9317 - acc: 0.5577 - val_loss: 1.0137 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.3340 - acc: 0.2981 - val_loss: 2.2255 - val_acc: 0.4444\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 2.0827 - acc: 0.3558 - val_loss: 1.9843 - val_acc: 0.4444\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.9544 - acc: 0.3750 - val_loss: 1.7861 - val_acc: 0.4444\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.6069 - acc: 0.3846 - val_loss: 1.6611 - val_acc: 0.4444\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.5266 - acc: 0.4038 - val_loss: 1.5559 - val_acc: 0.4444\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.4981 - acc: 0.4038 - val_loss: 1.4699 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.2338 - acc: 0.4327 - val_loss: 1.4044 - val_acc: 0.4444\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 1.3266 - acc: 0.3846 - val_loss: 1.3580 - val_acc: 0.4444\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.2911 - acc: 0.3846 - val_loss: 1.3085 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.3398 - acc: 0.4231 - val_loss: 1.2626 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1393 - acc: 0.5000 - val_loss: 1.2253 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.1247 - acc: 0.5000 - val_loss: 1.2088 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1941 - acc: 0.4327 - val_loss: 1.1901 - val_acc: 0.3333\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.1037 - acc: 0.4808 - val_loss: 1.1711 - val_acc: 0.2593\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0435 - acc: 0.4712 - val_loss: 1.1592 - val_acc: 0.2222\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0451 - acc: 0.5385 - val_loss: 1.1450 - val_acc: 0.2222\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0316 - acc: 0.4712 - val_loss: 1.1376 - val_acc: 0.2593\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0706 - acc: 0.4615 - val_loss: 1.1269 - val_acc: 0.2963\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0918 - acc: 0.4808 - val_loss: 1.1287 - val_acc: 0.2963\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.1057 - acc: 0.4712 - val_loss: 1.1228 - val_acc: 0.2963\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0736 - acc: 0.4615 - val_loss: 1.1185 - val_acc: 0.2593\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0275 - acc: 0.4712 - val_loss: 1.1173 - val_acc: 0.2963\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0277 - acc: 0.4712 - val_loss: 1.1154 - val_acc: 0.3333\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0654 - acc: 0.5192 - val_loss: 1.1144 - val_acc: 0.3333\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0454 - acc: 0.4904 - val_loss: 1.1166 - val_acc: 0.3333\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0774 - acc: 0.4808 - val_loss: 1.1117 - val_acc: 0.3704\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0371 - acc: 0.5000 - val_loss: 1.1081 - val_acc: 0.3704\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0710 - acc: 0.4808 - val_loss: 1.1064 - val_acc: 0.3333\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9535 - acc: 0.5192 - val_loss: 1.1078 - val_acc: 0.3333\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0586 - acc: 0.5192 - val_loss: 1.1090 - val_acc: 0.3704\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0281 - acc: 0.5192 - val_loss: 1.1077 - val_acc: 0.3704\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9685 - acc: 0.5096 - val_loss: 1.1063 - val_acc: 0.3704\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0108 - acc: 0.5096 - val_loss: 1.1125 - val_acc: 0.3704\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0105 - acc: 0.5385 - val_loss: 1.1178 - val_acc: 0.3704\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9992 - acc: 0.5192 - val_loss: 1.1221 - val_acc: 0.3704\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 1.0561 - acc: 0.4808 - val_loss: 1.1224 - val_acc: 0.3704\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0158 - acc: 0.5096 - val_loss: 1.1238 - val_acc: 0.3704\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0319 - acc: 0.4904 - val_loss: 1.1286 - val_acc: 0.3704\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0170 - acc: 0.4904 - val_loss: 1.1257 - val_acc: 0.3704\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0125 - acc: 0.4904 - val_loss: 1.1254 - val_acc: 0.3704\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9842 - acc: 0.5481 - val_loss: 1.1279 - val_acc: 0.3704\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9687 - acc: 0.5288 - val_loss: 1.1265 - val_acc: 0.3704\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0061 - acc: 0.4808 - val_loss: 1.1253 - val_acc: 0.3704\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9609 - acc: 0.4904 - val_loss: 1.1261 - val_acc: 0.3704\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0208 - acc: 0.4808 - val_loss: 1.1275 - val_acc: 0.3704\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9977 - acc: 0.5000 - val_loss: 1.1346 - val_acc: 0.3704\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9560 - acc: 0.4808 - val_loss: 1.1379 - val_acc: 0.3704\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9925 - acc: 0.4904 - val_loss: 1.1386 - val_acc: 0.3704\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9760 - acc: 0.5000 - val_loss: 1.1411 - val_acc: 0.3704\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9501 - acc: 0.5385 - val_loss: 1.1447 - val_acc: 0.3704\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9954 - acc: 0.4904 - val_loss: 1.1458 - val_acc: 0.3704\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9546 - acc: 0.5481 - val_loss: 1.1564 - val_acc: 0.3704\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9875 - acc: 0.4904 - val_loss: 1.1569 - val_acc: 0.3704\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9372 - acc: 0.5577 - val_loss: 1.1621 - val_acc: 0.3704\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9815 - acc: 0.4712 - val_loss: 1.1663 - val_acc: 0.3704\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9690 - acc: 0.4904 - val_loss: 1.1650 - val_acc: 0.3704\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9550 - acc: 0.5385 - val_loss: 1.1666 - val_acc: 0.3704\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9350 - acc: 0.5192 - val_loss: 1.1649 - val_acc: 0.3704\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9520 - acc: 0.5385 - val_loss: 1.1703 - val_acc: 0.3704\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9777 - acc: 0.4712 - val_loss: 1.1686 - val_acc: 0.3704\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9777 - acc: 0.5000 - val_loss: 1.1694 - val_acc: 0.3704\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9515 - acc: 0.5577 - val_loss: 1.1727 - val_acc: 0.3704\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9665 - acc: 0.4904 - val_loss: 1.1710 - val_acc: 0.3704\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9782 - acc: 0.4519 - val_loss: 1.1716 - val_acc: 0.3704\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9559 - acc: 0.5385 - val_loss: 1.1726 - val_acc: 0.3704\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9798 - acc: 0.4808 - val_loss: 1.1711 - val_acc: 0.3704\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 434us/sample - loss: 0.9702 - acc: 0.5288 - val_loss: 1.1729 - val_acc: 0.3704\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9562 - acc: 0.5481 - val_loss: 1.1746 - val_acc: 0.3704\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9468 - acc: 0.5577 - val_loss: 1.1809 - val_acc: 0.3704\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9481 - acc: 0.5385 - val_loss: 1.1856 - val_acc: 0.3704\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9817 - acc: 0.4904 - val_loss: 1.1827 - val_acc: 0.3704\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9445 - acc: 0.5481 - val_loss: 1.1842 - val_acc: 0.3704\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 444us/sample - loss: 0.9212 - acc: 0.5865 - val_loss: 1.1901 - val_acc: 0.3704\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9994 - acc: 0.4904 - val_loss: 1.1837 - val_acc: 0.3704\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9354 - acc: 0.5385 - val_loss: 1.1863 - val_acc: 0.3704\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.8976 - acc: 0.5673 - val_loss: 1.1964 - val_acc: 0.3704\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9702 - acc: 0.5192 - val_loss: 1.1930 - val_acc: 0.3704\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9734 - acc: 0.5096 - val_loss: 1.1910 - val_acc: 0.3704\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9519 - acc: 0.5481 - val_loss: 1.1924 - val_acc: 0.3704\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9277 - acc: 0.5481 - val_loss: 1.1903 - val_acc: 0.3704\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9458 - acc: 0.5192 - val_loss: 1.1931 - val_acc: 0.3704\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9431 - acc: 0.5096 - val_loss: 1.1898 - val_acc: 0.3704\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 0.9138 - acc: 0.5481 - val_loss: 1.1941 - val_acc: 0.3704\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9642 - acc: 0.5288 - val_loss: 1.1888 - val_acc: 0.3704\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9659 - acc: 0.4904 - val_loss: 1.1857 - val_acc: 0.3704\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9385 - acc: 0.5288 - val_loss: 1.1885 - val_acc: 0.3704\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9416 - acc: 0.5481 - val_loss: 1.1900 - val_acc: 0.3704\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9450 - acc: 0.4904 - val_loss: 1.1883 - val_acc: 0.3704\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9363 - acc: 0.5288 - val_loss: 1.1876 - val_acc: 0.3704\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.8880 - acc: 0.5865 - val_loss: 1.1966 - val_acc: 0.3704\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9597 - acc: 0.5192 - val_loss: 1.1900 - val_acc: 0.3704\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9306 - acc: 0.5288 - val_loss: 1.1893 - val_acc: 0.3704\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9268 - acc: 0.5385 - val_loss: 1.1900 - val_acc: 0.3704\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9178 - acc: 0.5096 - val_loss: 1.1914 - val_acc: 0.3704\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9225 - acc: 0.5577 - val_loss: 1.1966 - val_acc: 0.3704\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9592 - acc: 0.4904 - val_loss: 1.1904 - val_acc: 0.3704\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9460 - acc: 0.5577 - val_loss: 1.1917 - val_acc: 0.3704\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9548 - acc: 0.5000 - val_loss: 1.1858 - val_acc: 0.3704\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9341 - acc: 0.5481 - val_loss: 1.1876 - val_acc: 0.3704\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9520 - acc: 0.4904 - val_loss: 1.1865 - val_acc: 0.3704\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 974us/sample - loss: 2.2660 - acc: 0.3558 - val_loss: 1.9460 - val_acc: 0.2593\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 2.0678 - acc: 0.3654 - val_loss: 1.8345 - val_acc: 0.2593\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 280us/sample - loss: 1.9773 - acc: 0.3750 - val_loss: 1.7463 - val_acc: 0.2593\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.6848 - acc: 0.4327 - val_loss: 1.6788 - val_acc: 0.2593\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.7295 - acc: 0.4038 - val_loss: 1.6008 - val_acc: 0.2963\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.7252 - acc: 0.3750 - val_loss: 1.5359 - val_acc: 0.2963\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.8042 - acc: 0.3077 - val_loss: 1.4649 - val_acc: 0.2963\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.4433 - acc: 0.3365 - val_loss: 1.4187 - val_acc: 0.2963\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.4630 - acc: 0.3654 - val_loss: 1.3737 - val_acc: 0.2963\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.4894 - acc: 0.3750 - val_loss: 1.3256 - val_acc: 0.2963\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.3447 - acc: 0.4038 - val_loss: 1.2892 - val_acc: 0.2593\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.4024 - acc: 0.3846 - val_loss: 1.2638 - val_acc: 0.2963\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.1723 - acc: 0.4135 - val_loss: 1.2441 - val_acc: 0.3333\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.3124 - acc: 0.3942 - val_loss: 1.2199 - val_acc: 0.3333\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.2512 - acc: 0.3846 - val_loss: 1.1983 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.2762 - acc: 0.3173 - val_loss: 1.1731 - val_acc: 0.3704\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.2589 - acc: 0.3654 - val_loss: 1.1518 - val_acc: 0.3704\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.2603 - acc: 0.3365 - val_loss: 1.1298 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1350 - acc: 0.3942 - val_loss: 1.1103 - val_acc: 0.3704\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.2141 - acc: 0.3365 - val_loss: 1.0917 - val_acc: 0.3704\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0726 - acc: 0.4519 - val_loss: 1.0805 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1041 - acc: 0.4519 - val_loss: 1.0697 - val_acc: 0.4444\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1232 - acc: 0.4519 - val_loss: 1.0555 - val_acc: 0.4444\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.0211 - acc: 0.4712 - val_loss: 1.0440 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1091 - acc: 0.4519 - val_loss: 1.0317 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0705 - acc: 0.4808 - val_loss: 1.0253 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0123 - acc: 0.5096 - val_loss: 1.0165 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0632 - acc: 0.4327 - val_loss: 1.0066 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0092 - acc: 0.4712 - val_loss: 1.0010 - val_acc: 0.4444\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.0384 - acc: 0.4615 - val_loss: 0.9922 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0382 - acc: 0.4808 - val_loss: 0.9892 - val_acc: 0.4444\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0078 - acc: 0.4712 - val_loss: 0.9855 - val_acc: 0.4444\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0156 - acc: 0.4327 - val_loss: 0.9801 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0133 - acc: 0.4615 - val_loss: 0.9763 - val_acc: 0.4444\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0177 - acc: 0.4808 - val_loss: 0.9738 - val_acc: 0.4444\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 418us/sample - loss: 1.0453 - acc: 0.4519 - val_loss: 0.9737 - val_acc: 0.4444\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0148 - acc: 0.4615 - val_loss: 0.9720 - val_acc: 0.4444\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9871 - acc: 0.4327 - val_loss: 0.9723 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0023 - acc: 0.5000 - val_loss: 0.9706 - val_acc: 0.4074\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9645 - acc: 0.5096 - val_loss: 0.9698 - val_acc: 0.4444\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9915 - acc: 0.5673 - val_loss: 0.9669 - val_acc: 0.4444\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9945 - acc: 0.4712 - val_loss: 0.9647 - val_acc: 0.4444\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0208 - acc: 0.4808 - val_loss: 0.9623 - val_acc: 0.4444\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0263 - acc: 0.4712 - val_loss: 0.9592 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9536 - acc: 0.5481 - val_loss: 0.9576 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9951 - acc: 0.5096 - val_loss: 0.9567 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9847 - acc: 0.5096 - val_loss: 0.9549 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9739 - acc: 0.5577 - val_loss: 0.9536 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9985 - acc: 0.4615 - val_loss: 0.9552 - val_acc: 0.4815\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 0.9778 - acc: 0.5673 - val_loss: 0.9582 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9863 - acc: 0.5288 - val_loss: 0.9609 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9586 - acc: 0.5385 - val_loss: 0.9595 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9692 - acc: 0.5288 - val_loss: 0.9599 - val_acc: 0.4444\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 0.9586 - acc: 0.5192 - val_loss: 0.9604 - val_acc: 0.4444\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 0.9384 - acc: 0.5673 - val_loss: 0.9620 - val_acc: 0.4074\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9734 - acc: 0.5577 - val_loss: 0.9635 - val_acc: 0.4074\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9384 - acc: 0.5577 - val_loss: 0.9637 - val_acc: 0.4074\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9318 - acc: 0.5769 - val_loss: 0.9663 - val_acc: 0.4074\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9849 - acc: 0.5385 - val_loss: 0.9677 - val_acc: 0.4074\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9396 - acc: 0.5673 - val_loss: 0.9634 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9505 - acc: 0.5385 - val_loss: 0.9615 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9566 - acc: 0.5385 - val_loss: 0.9645 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9521 - acc: 0.5673 - val_loss: 0.9651 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9719 - acc: 0.5385 - val_loss: 0.9652 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9646 - acc: 0.5577 - val_loss: 0.9640 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9491 - acc: 0.5769 - val_loss: 0.9670 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9416 - acc: 0.6058 - val_loss: 0.9698 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 0.9696 - acc: 0.5096 - val_loss: 0.9676 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9793 - acc: 0.5385 - val_loss: 0.9693 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9525 - acc: 0.5865 - val_loss: 0.9699 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9524 - acc: 0.5577 - val_loss: 0.9711 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 0.9562 - acc: 0.5481 - val_loss: 0.9744 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 0.9433 - acc: 0.4904 - val_loss: 0.9741 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9954 - acc: 0.5000 - val_loss: 0.9714 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9741 - acc: 0.5000 - val_loss: 0.9716 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9290 - acc: 0.5673 - val_loss: 0.9716 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9262 - acc: 0.5385 - val_loss: 0.9736 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9224 - acc: 0.5673 - val_loss: 0.9746 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9367 - acc: 0.6250 - val_loss: 0.9773 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9404 - acc: 0.5769 - val_loss: 0.9775 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9384 - acc: 0.5673 - val_loss: 0.9766 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9419 - acc: 0.5769 - val_loss: 0.9755 - val_acc: 0.5926\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9981 - acc: 0.4904 - val_loss: 0.9727 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9662 - acc: 0.5481 - val_loss: 0.9732 - val_acc: 0.5926\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9660 - acc: 0.5192 - val_loss: 0.9738 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9545 - acc: 0.5577 - val_loss: 0.9749 - val_acc: 0.5926\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9335 - acc: 0.5577 - val_loss: 0.9767 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 0.9515 - acc: 0.5481 - val_loss: 0.9788 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9057 - acc: 0.5385 - val_loss: 0.9802 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9134 - acc: 0.6154 - val_loss: 0.9858 - val_acc: 0.5556\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9527 - acc: 0.5385 - val_loss: 0.9838 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9087 - acc: 0.5865 - val_loss: 0.9859 - val_acc: 0.5926\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9336 - acc: 0.5385 - val_loss: 0.9861 - val_acc: 0.5926\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9958 - acc: 0.4712 - val_loss: 0.9812 - val_acc: 0.5926\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9716 - acc: 0.5385 - val_loss: 0.9797 - val_acc: 0.5926\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9718 - acc: 0.5385 - val_loss: 0.9805 - val_acc: 0.5926\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9297 - acc: 0.5865 - val_loss: 0.9835 - val_acc: 0.5926\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9387 - acc: 0.5577 - val_loss: 0.9845 - val_acc: 0.5926\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9358 - acc: 0.5577 - val_loss: 0.9868 - val_acc: 0.5926\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9178 - acc: 0.5962 - val_loss: 0.9891 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.6581 - acc: 0.4135 - val_loss: 1.5429 - val_acc: 0.2222\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.5769 - acc: 0.3077 - val_loss: 1.4558 - val_acc: 0.2593\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.5834 - acc: 0.3654 - val_loss: 1.3824 - val_acc: 0.2593\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 509us/sample - loss: 1.3614 - acc: 0.4231 - val_loss: 1.3332 - val_acc: 0.2593\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 466us/sample - loss: 1.4855 - acc: 0.3750 - val_loss: 1.2904 - val_acc: 0.2222\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.3300 - acc: 0.4135 - val_loss: 1.2466 - val_acc: 0.2222\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.3420 - acc: 0.4423 - val_loss: 1.2148 - val_acc: 0.2222\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.2646 - acc: 0.4038 - val_loss: 1.1915 - val_acc: 0.2593\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.2214 - acc: 0.4808 - val_loss: 1.1726 - val_acc: 0.2593\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.2069 - acc: 0.4327 - val_loss: 1.1581 - val_acc: 0.2593\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1783 - acc: 0.4712 - val_loss: 1.1477 - val_acc: 0.2593\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1916 - acc: 0.4038 - val_loss: 1.1319 - val_acc: 0.2963\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0870 - acc: 0.4327 - val_loss: 1.1170 - val_acc: 0.3333\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1937 - acc: 0.4519 - val_loss: 1.1095 - val_acc: 0.3333\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0822 - acc: 0.4519 - val_loss: 1.1030 - val_acc: 0.3333\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.1123 - acc: 0.4423 - val_loss: 1.0979 - val_acc: 0.3704\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.1487 - acc: 0.4904 - val_loss: 1.0974 - val_acc: 0.4444\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.1571 - acc: 0.5000 - val_loss: 1.0923 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1581 - acc: 0.4231 - val_loss: 1.0891 - val_acc: 0.4074\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0507 - acc: 0.4615 - val_loss: 1.0851 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.0883 - acc: 0.4327 - val_loss: 1.0764 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0817 - acc: 0.4904 - val_loss: 1.0718 - val_acc: 0.4074\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0777 - acc: 0.5577 - val_loss: 1.0722 - val_acc: 0.4074\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0964 - acc: 0.5481 - val_loss: 1.0686 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0674 - acc: 0.5769 - val_loss: 1.0657 - val_acc: 0.4815\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0384 - acc: 0.5769 - val_loss: 1.0680 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0291 - acc: 0.5962 - val_loss: 1.0662 - val_acc: 0.4815\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9961 - acc: 0.5481 - val_loss: 1.0623 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0255 - acc: 0.5962 - val_loss: 1.0589 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0254 - acc: 0.6346 - val_loss: 1.0591 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0744 - acc: 0.5288 - val_loss: 1.0593 - val_acc: 0.4444\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.0511 - acc: 0.5673 - val_loss: 1.0591 - val_acc: 0.4444\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0225 - acc: 0.5865 - val_loss: 1.0598 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0281 - acc: 0.5481 - val_loss: 1.0542 - val_acc: 0.4444\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0314 - acc: 0.5865 - val_loss: 1.0512 - val_acc: 0.4815\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9876 - acc: 0.5673 - val_loss: 1.0487 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0122 - acc: 0.5673 - val_loss: 1.0472 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0057 - acc: 0.6058 - val_loss: 1.0474 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9630 - acc: 0.5962 - val_loss: 1.0460 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0128 - acc: 0.5385 - val_loss: 1.0413 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0389 - acc: 0.5769 - val_loss: 1.0404 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0344 - acc: 0.6154 - val_loss: 1.0381 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9777 - acc: 0.6058 - val_loss: 1.0367 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 0.9435 - acc: 0.6058 - val_loss: 1.0346 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0100 - acc: 0.5673 - val_loss: 1.0333 - val_acc: 0.4815\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0067 - acc: 0.5769 - val_loss: 1.0322 - val_acc: 0.4815\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9942 - acc: 0.5673 - val_loss: 1.0308 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0273 - acc: 0.6154 - val_loss: 1.0302 - val_acc: 0.4815\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9942 - acc: 0.6154 - val_loss: 1.0319 - val_acc: 0.4815\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0242 - acc: 0.5577 - val_loss: 1.0319 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0013 - acc: 0.5962 - val_loss: 1.0314 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0542 - acc: 0.5288 - val_loss: 1.0309 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9732 - acc: 0.6250 - val_loss: 1.0350 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9618 - acc: 0.5962 - val_loss: 1.0345 - val_acc: 0.4815\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.0249 - acc: 0.5673 - val_loss: 1.0355 - val_acc: 0.4815\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9657 - acc: 0.5962 - val_loss: 1.0368 - val_acc: 0.4815\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 1.0295 - acc: 0.5769 - val_loss: 1.0399 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9676 - acc: 0.6346 - val_loss: 1.0444 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0275 - acc: 0.5385 - val_loss: 1.0429 - val_acc: 0.5556\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0122 - acc: 0.5577 - val_loss: 1.0424 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9960 - acc: 0.5865 - val_loss: 1.0424 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9559 - acc: 0.6058 - val_loss: 1.0441 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9851 - acc: 0.5865 - val_loss: 1.0449 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9548 - acc: 0.6250 - val_loss: 1.0472 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9372 - acc: 0.6442 - val_loss: 1.0498 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9799 - acc: 0.5673 - val_loss: 1.0512 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9725 - acc: 0.5769 - val_loss: 1.0501 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0005 - acc: 0.5288 - val_loss: 1.0454 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9697 - acc: 0.5865 - val_loss: 1.0442 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9848 - acc: 0.5481 - val_loss: 1.0442 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9643 - acc: 0.6058 - val_loss: 1.0457 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 415us/sample - loss: 0.9950 - acc: 0.5673 - val_loss: 1.0450 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9861 - acc: 0.5577 - val_loss: 1.0440 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9540 - acc: 0.5577 - val_loss: 1.0424 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9343 - acc: 0.5962 - val_loss: 1.0453 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9836 - acc: 0.5865 - val_loss: 1.0478 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9661 - acc: 0.5865 - val_loss: 1.0489 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9468 - acc: 0.6250 - val_loss: 1.0496 - val_acc: 0.4815\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9379 - acc: 0.6250 - val_loss: 1.0544 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9542 - acc: 0.5288 - val_loss: 1.0534 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9636 - acc: 0.5865 - val_loss: 1.0532 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9703 - acc: 0.5673 - val_loss: 1.0529 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9759 - acc: 0.5865 - val_loss: 1.0529 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9174 - acc: 0.6346 - val_loss: 1.0535 - val_acc: 0.5556\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9501 - acc: 0.5673 - val_loss: 1.0556 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9611 - acc: 0.5865 - val_loss: 1.0554 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9626 - acc: 0.5192 - val_loss: 1.0562 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9809 - acc: 0.5577 - val_loss: 1.0546 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9501 - acc: 0.5865 - val_loss: 1.0540 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9543 - acc: 0.5962 - val_loss: 1.0557 - val_acc: 0.5556\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9407 - acc: 0.6154 - val_loss: 1.0603 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9321 - acc: 0.6058 - val_loss: 1.0598 - val_acc: 0.4815\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9629 - acc: 0.5481 - val_loss: 1.0609 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9709 - acc: 0.5288 - val_loss: 1.0598 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9321 - acc: 0.5962 - val_loss: 1.0600 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9232 - acc: 0.5577 - val_loss: 1.0627 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9395 - acc: 0.5577 - val_loss: 1.0639 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9477 - acc: 0.6058 - val_loss: 1.0656 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9451 - acc: 0.5865 - val_loss: 1.0662 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9611 - acc: 0.5673 - val_loss: 1.0634 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 925064ff7995dc6d91cb1715579432a9</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5703703761100769</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.6868 - acc: 0.2981 - val_loss: 1.6950 - val_acc: 0.2593\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 2.2047 - acc: 0.3942 - val_loss: 1.6108 - val_acc: 0.2963\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 2.2176 - acc: 0.3942 - val_loss: 1.5495 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 2.3513 - acc: 0.2596 - val_loss: 1.4823 - val_acc: 0.3333\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.8149 - acc: 0.3077 - val_loss: 1.4318 - val_acc: 0.3704\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.8014 - acc: 0.2981 - val_loss: 1.4141 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.5761 - acc: 0.3173 - val_loss: 1.3895 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.8156 - acc: 0.3077 - val_loss: 1.3759 - val_acc: 0.3333\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.6284 - acc: 0.2788 - val_loss: 1.3470 - val_acc: 0.3333\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.3435 - acc: 0.3173 - val_loss: 1.3399 - val_acc: 0.3333\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.4544 - acc: 0.3942 - val_loss: 1.3188 - val_acc: 0.2963\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.4284 - acc: 0.3365 - val_loss: 1.3116 - val_acc: 0.3333\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.4656 - acc: 0.3077 - val_loss: 1.2970 - val_acc: 0.3333\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.2766 - acc: 0.3942 - val_loss: 1.2953 - val_acc: 0.3333\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.3253 - acc: 0.3173 - val_loss: 1.2779 - val_acc: 0.2963\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.5369 - acc: 0.2885 - val_loss: 1.2613 - val_acc: 0.3333\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1756 - acc: 0.4231 - val_loss: 1.2505 - val_acc: 0.3333\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.2857 - acc: 0.3942 - val_loss: 1.2423 - val_acc: 0.3333\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.2545 - acc: 0.2885 - val_loss: 1.2285 - val_acc: 0.3704\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.1979 - acc: 0.3750 - val_loss: 1.2129 - val_acc: 0.3704\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.1866 - acc: 0.4231 - val_loss: 1.2073 - val_acc: 0.3704\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.2102 - acc: 0.3654 - val_loss: 1.2009 - val_acc: 0.3704\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.2047 - acc: 0.3750 - val_loss: 1.1938 - val_acc: 0.3704\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0982 - acc: 0.3558 - val_loss: 1.1891 - val_acc: 0.3704\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0998 - acc: 0.3846 - val_loss: 1.1813 - val_acc: 0.3704\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.1096 - acc: 0.4712 - val_loss: 1.1783 - val_acc: 0.4074\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0325 - acc: 0.5000 - val_loss: 1.1711 - val_acc: 0.4074\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0365 - acc: 0.4712 - val_loss: 1.1577 - val_acc: 0.4074\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.0644 - acc: 0.4231 - val_loss: 1.1517 - val_acc: 0.4444\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0262 - acc: 0.4423 - val_loss: 1.1445 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0834 - acc: 0.4135 - val_loss: 1.1346 - val_acc: 0.4444\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0521 - acc: 0.4615 - val_loss: 1.1254 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0450 - acc: 0.4038 - val_loss: 1.1137 - val_acc: 0.4074\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0787 - acc: 0.4519 - val_loss: 1.1061 - val_acc: 0.4074\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.0067 - acc: 0.4519 - val_loss: 1.1022 - val_acc: 0.4074\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0358 - acc: 0.4327 - val_loss: 1.0932 - val_acc: 0.4074\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9956 - acc: 0.4423 - val_loss: 1.0839 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9819 - acc: 0.4615 - val_loss: 1.0801 - val_acc: 0.3704\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0254 - acc: 0.4904 - val_loss: 1.0688 - val_acc: 0.3704\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9859 - acc: 0.4327 - val_loss: 1.0656 - val_acc: 0.3704\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0065 - acc: 0.5096 - val_loss: 1.0542 - val_acc: 0.3704\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9743 - acc: 0.5000 - val_loss: 1.0492 - val_acc: 0.3704\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9647 - acc: 0.4519 - val_loss: 1.0482 - val_acc: 0.3704\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9704 - acc: 0.4808 - val_loss: 1.0449 - val_acc: 0.3704\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9728 - acc: 0.5288 - val_loss: 1.0447 - val_acc: 0.3704\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9676 - acc: 0.5000 - val_loss: 1.0443 - val_acc: 0.3704\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9618 - acc: 0.5288 - val_loss: 1.0404 - val_acc: 0.3704\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9314 - acc: 0.5673 - val_loss: 1.0446 - val_acc: 0.3704\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9449 - acc: 0.5000 - val_loss: 1.0534 - val_acc: 0.3704\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9534 - acc: 0.4808 - val_loss: 1.0556 - val_acc: 0.3704\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9503 - acc: 0.4712 - val_loss: 1.0567 - val_acc: 0.3704\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9264 - acc: 0.4519 - val_loss: 1.0617 - val_acc: 0.3704\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9459 - acc: 0.5000 - val_loss: 1.0616 - val_acc: 0.3704\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9382 - acc: 0.4231 - val_loss: 1.0586 - val_acc: 0.3704\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9792 - acc: 0.4712 - val_loss: 1.0527 - val_acc: 0.3704\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9524 - acc: 0.5000 - val_loss: 1.0553 - val_acc: 0.3704\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9833 - acc: 0.4712 - val_loss: 1.0496 - val_acc: 0.3704\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9487 - acc: 0.4615 - val_loss: 1.0463 - val_acc: 0.4074\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9260 - acc: 0.5192 - val_loss: 1.0513 - val_acc: 0.4074\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9595 - acc: 0.4808 - val_loss: 1.0448 - val_acc: 0.4074\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9446 - acc: 0.5096 - val_loss: 1.0509 - val_acc: 0.4074\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9676 - acc: 0.4808 - val_loss: 1.0472 - val_acc: 0.4074\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9300 - acc: 0.4712 - val_loss: 1.0456 - val_acc: 0.4074\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9335 - acc: 0.4904 - val_loss: 1.0432 - val_acc: 0.4074\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9469 - acc: 0.5192 - val_loss: 1.0487 - val_acc: 0.4074\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9539 - acc: 0.4615 - val_loss: 1.0462 - val_acc: 0.4074\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9309 - acc: 0.4904 - val_loss: 1.0503 - val_acc: 0.4074\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9231 - acc: 0.5000 - val_loss: 1.0527 - val_acc: 0.4074\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9237 - acc: 0.4712 - val_loss: 1.0548 - val_acc: 0.4074\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 416us/sample - loss: 0.9335 - acc: 0.4712 - val_loss: 1.0564 - val_acc: 0.4074\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9232 - acc: 0.5481 - val_loss: 1.0553 - val_acc: 0.4074\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9568 - acc: 0.4904 - val_loss: 1.0528 - val_acc: 0.4074\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9662 - acc: 0.4712 - val_loss: 1.0480 - val_acc: 0.4074\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9314 - acc: 0.5385 - val_loss: 1.0526 - val_acc: 0.4074\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9374 - acc: 0.5288 - val_loss: 1.0508 - val_acc: 0.4074\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9336 - acc: 0.4615 - val_loss: 1.0528 - val_acc: 0.4074\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9132 - acc: 0.5577 - val_loss: 1.0479 - val_acc: 0.4074\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9570 - acc: 0.5096 - val_loss: 1.0427 - val_acc: 0.3704\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9216 - acc: 0.5288 - val_loss: 1.0440 - val_acc: 0.4074\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9357 - acc: 0.4904 - val_loss: 1.0471 - val_acc: 0.4074\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9547 - acc: 0.4808 - val_loss: 1.0446 - val_acc: 0.3333\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9322 - acc: 0.5385 - val_loss: 1.0456 - val_acc: 0.2963\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9489 - acc: 0.5000 - val_loss: 1.0407 - val_acc: 0.2963\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9550 - acc: 0.4808 - val_loss: 1.0397 - val_acc: 0.3333\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9368 - acc: 0.5000 - val_loss: 1.0413 - val_acc: 0.3704\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9561 - acc: 0.4808 - val_loss: 1.0385 - val_acc: 0.3704\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9425 - acc: 0.4904 - val_loss: 1.0366 - val_acc: 0.3704\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9593 - acc: 0.4808 - val_loss: 1.0338 - val_acc: 0.3704\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9402 - acc: 0.5096 - val_loss: 1.0352 - val_acc: 0.3704\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.8947 - acc: 0.5096 - val_loss: 1.0436 - val_acc: 0.3333\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 285us/sample - loss: 0.9160 - acc: 0.5288 - val_loss: 1.0497 - val_acc: 0.3704\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9383 - acc: 0.4808 - val_loss: 1.0522 - val_acc: 0.3704\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9289 - acc: 0.4712 - val_loss: 1.0485 - val_acc: 0.4074\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9288 - acc: 0.4712 - val_loss: 1.0504 - val_acc: 0.4074\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9304 - acc: 0.4808 - val_loss: 1.0518 - val_acc: 0.4074\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9427 - acc: 0.5096 - val_loss: 1.0467 - val_acc: 0.4074\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9467 - acc: 0.4904 - val_loss: 1.0446 - val_acc: 0.4074\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9373 - acc: 0.5096 - val_loss: 1.0397 - val_acc: 0.3704\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9548 - acc: 0.5096 - val_loss: 1.0351 - val_acc: 0.3704\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9377 - acc: 0.4615 - val_loss: 1.0345 - val_acc: 0.3333\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 990us/sample - loss: 2.3381 - acc: 0.2500 - val_loss: 2.4698 - val_acc: 0.2593\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 2.2987 - acc: 0.3365 - val_loss: 2.2284 - val_acc: 0.2963\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.7503 - acc: 0.3077 - val_loss: 2.0570 - val_acc: 0.2963\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.6206 - acc: 0.4135 - val_loss: 1.8988 - val_acc: 0.2222\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.5848 - acc: 0.4135 - val_loss: 1.7841 - val_acc: 0.2222\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.4469 - acc: 0.4231 - val_loss: 1.6801 - val_acc: 0.2222\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.4553 - acc: 0.4231 - val_loss: 1.5962 - val_acc: 0.2593\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.3093 - acc: 0.4423 - val_loss: 1.5414 - val_acc: 0.2963\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.3407 - acc: 0.4135 - val_loss: 1.4879 - val_acc: 0.2593\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.3161 - acc: 0.4519 - val_loss: 1.4436 - val_acc: 0.2963\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.2647 - acc: 0.4327 - val_loss: 1.4009 - val_acc: 0.2963\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1399 - acc: 0.4615 - val_loss: 1.3767 - val_acc: 0.2593\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.2148 - acc: 0.4423 - val_loss: 1.3459 - val_acc: 0.2593\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.1911 - acc: 0.4519 - val_loss: 1.3190 - val_acc: 0.2963\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1900 - acc: 0.4615 - val_loss: 1.2888 - val_acc: 0.2963\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1599 - acc: 0.4615 - val_loss: 1.2670 - val_acc: 0.2963\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.1369 - acc: 0.5577 - val_loss: 1.2544 - val_acc: 0.2963\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.1169 - acc: 0.4615 - val_loss: 1.2363 - val_acc: 0.3704\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0465 - acc: 0.5000 - val_loss: 1.2338 - val_acc: 0.3704\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.1390 - acc: 0.4615 - val_loss: 1.2189 - val_acc: 0.3704\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1099 - acc: 0.5000 - val_loss: 1.2113 - val_acc: 0.3704\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0508 - acc: 0.5192 - val_loss: 1.2088 - val_acc: 0.3704\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0654 - acc: 0.5192 - val_loss: 1.1926 - val_acc: 0.3704\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0500 - acc: 0.4808 - val_loss: 1.1821 - val_acc: 0.3704\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1276 - acc: 0.4231 - val_loss: 1.1748 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0920 - acc: 0.5096 - val_loss: 1.1608 - val_acc: 0.4074\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0532 - acc: 0.5000 - val_loss: 1.1592 - val_acc: 0.4074\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.0220 - acc: 0.4712 - val_loss: 1.1574 - val_acc: 0.3704\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0393 - acc: 0.5192 - val_loss: 1.1442 - val_acc: 0.3704\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0608 - acc: 0.5385 - val_loss: 1.1333 - val_acc: 0.3704\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0320 - acc: 0.5385 - val_loss: 1.1350 - val_acc: 0.3704\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0795 - acc: 0.4712 - val_loss: 1.1231 - val_acc: 0.3704\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0605 - acc: 0.5192 - val_loss: 1.1121 - val_acc: 0.3704\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0564 - acc: 0.5865 - val_loss: 1.1119 - val_acc: 0.3704\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0218 - acc: 0.5288 - val_loss: 1.1107 - val_acc: 0.3704\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0532 - acc: 0.5000 - val_loss: 1.0997 - val_acc: 0.3704\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0883 - acc: 0.4904 - val_loss: 1.0980 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0934 - acc: 0.4712 - val_loss: 1.0889 - val_acc: 0.4074\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9940 - acc: 0.5385 - val_loss: 1.0973 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0481 - acc: 0.5192 - val_loss: 1.0945 - val_acc: 0.4444\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0191 - acc: 0.5096 - val_loss: 1.0942 - val_acc: 0.4074\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0051 - acc: 0.5577 - val_loss: 1.0912 - val_acc: 0.4444\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9798 - acc: 0.5673 - val_loss: 1.0853 - val_acc: 0.4444\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9913 - acc: 0.5577 - val_loss: 1.0882 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9980 - acc: 0.5385 - val_loss: 1.0880 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9971 - acc: 0.5577 - val_loss: 1.0783 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0277 - acc: 0.4904 - val_loss: 1.0723 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9697 - acc: 0.5192 - val_loss: 1.0788 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0361 - acc: 0.5096 - val_loss: 1.0793 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0030 - acc: 0.5288 - val_loss: 1.0686 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9983 - acc: 0.5385 - val_loss: 1.0641 - val_acc: 0.4444\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0115 - acc: 0.4808 - val_loss: 1.0613 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0309 - acc: 0.5481 - val_loss: 1.0611 - val_acc: 0.4444\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 692us/sample - loss: 0.9942 - acc: 0.5288 - val_loss: 1.0562 - val_acc: 0.4815\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 290us/sample - loss: 1.0432 - acc: 0.5288 - val_loss: 1.0553 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9892 - acc: 0.5385 - val_loss: 1.0564 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.0171 - acc: 0.5096 - val_loss: 1.0620 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0064 - acc: 0.5865 - val_loss: 1.0597 - val_acc: 0.4444\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0120 - acc: 0.5192 - val_loss: 1.0648 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9626 - acc: 0.5481 - val_loss: 1.0719 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0448 - acc: 0.5192 - val_loss: 1.0674 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 445us/sample - loss: 0.9665 - acc: 0.5673 - val_loss: 1.0723 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9966 - acc: 0.5288 - val_loss: 1.0772 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9923 - acc: 0.4712 - val_loss: 1.0797 - val_acc: 0.4444\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9974 - acc: 0.4904 - val_loss: 1.0757 - val_acc: 0.4444\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9556 - acc: 0.5962 - val_loss: 1.0795 - val_acc: 0.4444\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0180 - acc: 0.4904 - val_loss: 1.0710 - val_acc: 0.4444\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9864 - acc: 0.5000 - val_loss: 1.0649 - val_acc: 0.4444\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9442 - acc: 0.5865 - val_loss: 1.0617 - val_acc: 0.4444\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9541 - acc: 0.5577 - val_loss: 1.0651 - val_acc: 0.4444\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9690 - acc: 0.5577 - val_loss: 1.0631 - val_acc: 0.4444\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9981 - acc: 0.5385 - val_loss: 1.0598 - val_acc: 0.4444\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9612 - acc: 0.5192 - val_loss: 1.0489 - val_acc: 0.4444\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9797 - acc: 0.5000 - val_loss: 1.0490 - val_acc: 0.4444\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9545 - acc: 0.5577 - val_loss: 1.0496 - val_acc: 0.4444\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9582 - acc: 0.5385 - val_loss: 1.0553 - val_acc: 0.4444\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9955 - acc: 0.5288 - val_loss: 1.0499 - val_acc: 0.4444\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9792 - acc: 0.5288 - val_loss: 1.0431 - val_acc: 0.4444\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9572 - acc: 0.5288 - val_loss: 1.0425 - val_acc: 0.4444\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9582 - acc: 0.5192 - val_loss: 1.0480 - val_acc: 0.4444\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9811 - acc: 0.5096 - val_loss: 1.0502 - val_acc: 0.4444\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9686 - acc: 0.5288 - val_loss: 1.0544 - val_acc: 0.4444\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9539 - acc: 0.5673 - val_loss: 1.0560 - val_acc: 0.4444\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9964 - acc: 0.5096 - val_loss: 1.0581 - val_acc: 0.4444\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9685 - acc: 0.5288 - val_loss: 1.0463 - val_acc: 0.4444\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 1.0022 - acc: 0.5096 - val_loss: 1.0435 - val_acc: 0.4444\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9682 - acc: 0.5769 - val_loss: 1.0471 - val_acc: 0.4444\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9472 - acc: 0.5577 - val_loss: 1.0411 - val_acc: 0.4444\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9796 - acc: 0.5481 - val_loss: 1.0458 - val_acc: 0.4444\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9637 - acc: 0.5481 - val_loss: 1.0483 - val_acc: 0.4444\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9422 - acc: 0.5481 - val_loss: 1.0488 - val_acc: 0.4444\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9738 - acc: 0.5481 - val_loss: 1.0488 - val_acc: 0.4444\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9756 - acc: 0.5481 - val_loss: 1.0438 - val_acc: 0.4444\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9729 - acc: 0.5481 - val_loss: 1.0454 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9372 - acc: 0.5481 - val_loss: 1.0465 - val_acc: 0.4444\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9748 - acc: 0.4904 - val_loss: 1.0452 - val_acc: 0.4444\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9598 - acc: 0.5192 - val_loss: 1.0460 - val_acc: 0.4444\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9751 - acc: 0.5288 - val_loss: 1.0424 - val_acc: 0.4444\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9705 - acc: 0.5577 - val_loss: 1.0425 - val_acc: 0.4444\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9681 - acc: 0.5000 - val_loss: 1.0463 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.5087 - acc: 0.3942 - val_loss: 2.4282 - val_acc: 0.4074\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 3.5833 - acc: 0.3750 - val_loss: 2.1020 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 2.5488 - acc: 0.4519 - val_loss: 1.9328 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 2.3338 - acc: 0.4423 - val_loss: 1.8092 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 2.3113 - acc: 0.4038 - val_loss: 1.7047 - val_acc: 0.3704\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.9171 - acc: 0.4423 - val_loss: 1.6345 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.9295 - acc: 0.3846 - val_loss: 1.5777 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.8579 - acc: 0.3654 - val_loss: 1.5101 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.5138 - acc: 0.4423 - val_loss: 1.4636 - val_acc: 0.3704\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.4490 - acc: 0.4423 - val_loss: 1.4304 - val_acc: 0.4074\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.5942 - acc: 0.3846 - val_loss: 1.3929 - val_acc: 0.4074\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.3473 - acc: 0.3750 - val_loss: 1.3672 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.4105 - acc: 0.3942 - val_loss: 1.3266 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.4084 - acc: 0.4231 - val_loss: 1.2937 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.2813 - acc: 0.4135 - val_loss: 1.2742 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.2699 - acc: 0.4615 - val_loss: 1.2516 - val_acc: 0.3333\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.1664 - acc: 0.4231 - val_loss: 1.2333 - val_acc: 0.3333\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.2382 - acc: 0.4327 - val_loss: 1.2092 - val_acc: 0.3333\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.1965 - acc: 0.4231 - val_loss: 1.1932 - val_acc: 0.3333\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.1435 - acc: 0.4423 - val_loss: 1.1809 - val_acc: 0.3704\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1647 - acc: 0.4712 - val_loss: 1.1684 - val_acc: 0.3704\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9946 - acc: 0.4808 - val_loss: 1.1656 - val_acc: 0.3704\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9696 - acc: 0.4712 - val_loss: 1.1600 - val_acc: 0.3333\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0761 - acc: 0.4712 - val_loss: 1.1498 - val_acc: 0.4074\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0777 - acc: 0.4519 - val_loss: 1.1402 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.1227 - acc: 0.4327 - val_loss: 1.1291 - val_acc: 0.4074\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0823 - acc: 0.4712 - val_loss: 1.1219 - val_acc: 0.4074\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0773 - acc: 0.4615 - val_loss: 1.1158 - val_acc: 0.4074\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0951 - acc: 0.5096 - val_loss: 1.1096 - val_acc: 0.4074\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0016 - acc: 0.5577 - val_loss: 1.1058 - val_acc: 0.4074\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0891 - acc: 0.5000 - val_loss: 1.0997 - val_acc: 0.4444\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 736us/sample - loss: 1.0296 - acc: 0.4712 - val_loss: 1.0949 - val_acc: 0.5185\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0980 - acc: 0.5192 - val_loss: 1.0894 - val_acc: 0.5185\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9987 - acc: 0.5769 - val_loss: 1.0877 - val_acc: 0.5185\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0071 - acc: 0.5577 - val_loss: 1.0834 - val_acc: 0.5185\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0978 - acc: 0.4423 - val_loss: 1.0781 - val_acc: 0.5185\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.0326 - acc: 0.5000 - val_loss: 1.0758 - val_acc: 0.5556\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0249 - acc: 0.4904 - val_loss: 1.0748 - val_acc: 0.5185\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0739 - acc: 0.4231 - val_loss: 1.0725 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0259 - acc: 0.4615 - val_loss: 1.0716 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0364 - acc: 0.4904 - val_loss: 1.0689 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0204 - acc: 0.4615 - val_loss: 1.0665 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0031 - acc: 0.4423 - val_loss: 1.0664 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0339 - acc: 0.5192 - val_loss: 1.0663 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9980 - acc: 0.5288 - val_loss: 1.0647 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9869 - acc: 0.4519 - val_loss: 1.0615 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9671 - acc: 0.5096 - val_loss: 1.0598 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9997 - acc: 0.4904 - val_loss: 1.0584 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9580 - acc: 0.5385 - val_loss: 1.0563 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9920 - acc: 0.5192 - val_loss: 1.0546 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9672 - acc: 0.5385 - val_loss: 1.0546 - val_acc: 0.4444\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9957 - acc: 0.5385 - val_loss: 1.0540 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9875 - acc: 0.5385 - val_loss: 1.0542 - val_acc: 0.4444\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9956 - acc: 0.5192 - val_loss: 1.0545 - val_acc: 0.4444\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9710 - acc: 0.4904 - val_loss: 1.0549 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9634 - acc: 0.5096 - val_loss: 1.0573 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9448 - acc: 0.5865 - val_loss: 1.0576 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0194 - acc: 0.5096 - val_loss: 1.0566 - val_acc: 0.4444\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9102 - acc: 0.5385 - val_loss: 1.0543 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9688 - acc: 0.5481 - val_loss: 1.0532 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9800 - acc: 0.5096 - val_loss: 1.0514 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9486 - acc: 0.5288 - val_loss: 1.0511 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9349 - acc: 0.5288 - val_loss: 1.0485 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9559 - acc: 0.5096 - val_loss: 1.0464 - val_acc: 0.4444\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.8941 - acc: 0.5673 - val_loss: 1.0456 - val_acc: 0.4444\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9589 - acc: 0.5000 - val_loss: 1.0454 - val_acc: 0.4444\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 0.9800 - acc: 0.4808 - val_loss: 1.0436 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9821 - acc: 0.4712 - val_loss: 1.0415 - val_acc: 0.4815\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9726 - acc: 0.5577 - val_loss: 1.0407 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9344 - acc: 0.5288 - val_loss: 1.0405 - val_acc: 0.4815\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9202 - acc: 0.5192 - val_loss: 1.0401 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9783 - acc: 0.4904 - val_loss: 1.0401 - val_acc: 0.4815\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 0.9413 - acc: 0.5096 - val_loss: 1.0394 - val_acc: 0.4815\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9381 - acc: 0.5481 - val_loss: 1.0401 - val_acc: 0.4815\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 0.9374 - acc: 0.5385 - val_loss: 1.0403 - val_acc: 0.4815\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 0.9574 - acc: 0.5192 - val_loss: 1.0381 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9495 - acc: 0.5096 - val_loss: 1.0376 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9305 - acc: 0.5000 - val_loss: 1.0367 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9456 - acc: 0.5192 - val_loss: 1.0358 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9845 - acc: 0.4519 - val_loss: 1.0349 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9086 - acc: 0.5385 - val_loss: 1.0336 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9170 - acc: 0.5385 - val_loss: 1.0349 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9102 - acc: 0.5192 - val_loss: 1.0345 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9623 - acc: 0.4519 - val_loss: 1.0346 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9466 - acc: 0.5288 - val_loss: 1.0333 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9429 - acc: 0.4904 - val_loss: 1.0331 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 0.9249 - acc: 0.5288 - val_loss: 1.0347 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9370 - acc: 0.5000 - val_loss: 1.0341 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9628 - acc: 0.5000 - val_loss: 1.0344 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 0.9448 - acc: 0.5481 - val_loss: 1.0347 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9662 - acc: 0.4904 - val_loss: 1.0314 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9261 - acc: 0.5481 - val_loss: 1.0309 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9593 - acc: 0.4423 - val_loss: 1.0317 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9253 - acc: 0.5192 - val_loss: 1.0326 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9158 - acc: 0.5865 - val_loss: 1.0332 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9800 - acc: 0.5096 - val_loss: 1.0335 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9286 - acc: 0.5096 - val_loss: 1.0323 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9597 - acc: 0.5288 - val_loss: 1.0334 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9502 - acc: 0.5000 - val_loss: 1.0309 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9192 - acc: 0.4808 - val_loss: 1.0324 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.0257 - acc: 0.3750 - val_loss: 1.7856 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.5802 - acc: 0.4135 - val_loss: 1.7170 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.6518 - acc: 0.3654 - val_loss: 1.6575 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.6822 - acc: 0.3654 - val_loss: 1.5925 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.5278 - acc: 0.3846 - val_loss: 1.5340 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.3724 - acc: 0.4423 - val_loss: 1.4763 - val_acc: 0.4074\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.5141 - acc: 0.4135 - val_loss: 1.4121 - val_acc: 0.4074\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.4138 - acc: 0.3942 - val_loss: 1.3370 - val_acc: 0.4074\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.3513 - acc: 0.4038 - val_loss: 1.2667 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1725 - acc: 0.4038 - val_loss: 1.2419 - val_acc: 0.4074\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.2398 - acc: 0.3750 - val_loss: 1.2186 - val_acc: 0.4074\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1533 - acc: 0.4327 - val_loss: 1.2212 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.1725 - acc: 0.3942 - val_loss: 1.1796 - val_acc: 0.4444\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.2232 - acc: 0.3846 - val_loss: 1.1738 - val_acc: 0.4444\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.2235 - acc: 0.4038 - val_loss: 1.1574 - val_acc: 0.4444\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1715 - acc: 0.4231 - val_loss: 1.1574 - val_acc: 0.4444\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.1307 - acc: 0.4038 - val_loss: 1.1387 - val_acc: 0.5185\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.2168 - acc: 0.4135 - val_loss: 1.1325 - val_acc: 0.5185\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9976 - acc: 0.5000 - val_loss: 1.1469 - val_acc: 0.5185\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0280 - acc: 0.4904 - val_loss: 1.1558 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0629 - acc: 0.4231 - val_loss: 1.1542 - val_acc: 0.5185\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.2448 - acc: 0.4135 - val_loss: 1.1461 - val_acc: 0.5185\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9696 - acc: 0.5096 - val_loss: 1.1601 - val_acc: 0.5185\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.0503 - acc: 0.4135 - val_loss: 1.1370 - val_acc: 0.5185\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0236 - acc: 0.4135 - val_loss: 1.1405 - val_acc: 0.5185\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 415us/sample - loss: 0.9318 - acc: 0.4904 - val_loss: 1.1426 - val_acc: 0.5185\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0973 - acc: 0.3942 - val_loss: 1.1453 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9181 - acc: 0.5385 - val_loss: 1.1584 - val_acc: 0.5556\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.1563 - acc: 0.4327 - val_loss: 1.1604 - val_acc: 0.5556\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 709us/sample - loss: 1.0794 - acc: 0.4231 - val_loss: 1.1556 - val_acc: 0.6296\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0166 - acc: 0.5192 - val_loss: 1.1565 - val_acc: 0.6296\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0509 - acc: 0.4904 - val_loss: 1.1464 - val_acc: 0.6296\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0491 - acc: 0.5000 - val_loss: 1.1371 - val_acc: 0.6296\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9827 - acc: 0.5000 - val_loss: 1.1522 - val_acc: 0.6296\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0508 - acc: 0.4519 - val_loss: 1.1505 - val_acc: 0.6296\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9296 - acc: 0.4904 - val_loss: 1.1593 - val_acc: 0.6296\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9868 - acc: 0.3942 - val_loss: 1.1566 - val_acc: 0.6296\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0252 - acc: 0.4712 - val_loss: 1.1542 - val_acc: 0.6296\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0117 - acc: 0.4615 - val_loss: 1.1518 - val_acc: 0.6296\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0836 - acc: 0.5096 - val_loss: 1.1474 - val_acc: 0.6296\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9874 - acc: 0.4712 - val_loss: 1.1433 - val_acc: 0.5926\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.8946 - acc: 0.5481 - val_loss: 1.1336 - val_acc: 0.5556\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0332 - acc: 0.5096 - val_loss: 1.1291 - val_acc: 0.5556\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9983 - acc: 0.5000 - val_loss: 1.1320 - val_acc: 0.5556\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9496 - acc: 0.4904 - val_loss: 1.1310 - val_acc: 0.5926\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9754 - acc: 0.4808 - val_loss: 1.1373 - val_acc: 0.5926\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0098 - acc: 0.4712 - val_loss: 1.1282 - val_acc: 0.5926\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9845 - acc: 0.5288 - val_loss: 1.1336 - val_acc: 0.5926\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9690 - acc: 0.4904 - val_loss: 1.1339 - val_acc: 0.5926\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 413us/sample - loss: 0.9609 - acc: 0.4519 - val_loss: 1.1385 - val_acc: 0.5926\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9557 - acc: 0.4519 - val_loss: 1.1346 - val_acc: 0.5926\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9560 - acc: 0.4423 - val_loss: 1.1365 - val_acc: 0.5926\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.8921 - acc: 0.5385 - val_loss: 1.1425 - val_acc: 0.5556\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9516 - acc: 0.4808 - val_loss: 1.1433 - val_acc: 0.5556\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.8916 - acc: 0.5385 - val_loss: 1.1510 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 0.9452 - acc: 0.5673 - val_loss: 1.1609 - val_acc: 0.5556\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9068 - acc: 0.5192 - val_loss: 1.1718 - val_acc: 0.5556\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9041 - acc: 0.5577 - val_loss: 1.1661 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9858 - acc: 0.5288 - val_loss: 1.1593 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9106 - acc: 0.5288 - val_loss: 1.1598 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0083 - acc: 0.4808 - val_loss: 1.1552 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9186 - acc: 0.5577 - val_loss: 1.1565 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.8997 - acc: 0.5577 - val_loss: 1.1604 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9391 - acc: 0.5385 - val_loss: 1.1612 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9149 - acc: 0.5865 - val_loss: 1.1556 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9893 - acc: 0.5096 - val_loss: 1.1510 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9185 - acc: 0.5385 - val_loss: 1.1508 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9781 - acc: 0.5096 - val_loss: 1.1494 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9144 - acc: 0.5481 - val_loss: 1.1524 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.8821 - acc: 0.5865 - val_loss: 1.1690 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9472 - acc: 0.5865 - val_loss: 1.1706 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9018 - acc: 0.5577 - val_loss: 1.1613 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9505 - acc: 0.5000 - val_loss: 1.1649 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9535 - acc: 0.5577 - val_loss: 1.1613 - val_acc: 0.5556\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.8828 - acc: 0.5673 - val_loss: 1.1583 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9083 - acc: 0.5385 - val_loss: 1.1465 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9094 - acc: 0.5096 - val_loss: 1.1449 - val_acc: 0.5556\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9188 - acc: 0.5288 - val_loss: 1.1397 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 0.9694 - acc: 0.5096 - val_loss: 1.1447 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.8456 - acc: 0.5962 - val_loss: 1.1570 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9322 - acc: 0.6058 - val_loss: 1.1607 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.8639 - acc: 0.5865 - val_loss: 1.1691 - val_acc: 0.5926\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9586 - acc: 0.5481 - val_loss: 1.1721 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.8514 - acc: 0.5962 - val_loss: 1.1688 - val_acc: 0.5556\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 511us/sample - loss: 0.8883 - acc: 0.5577 - val_loss: 1.1649 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9259 - acc: 0.5673 - val_loss: 1.1672 - val_acc: 0.5926\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.8992 - acc: 0.5385 - val_loss: 1.1665 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9316 - acc: 0.5577 - val_loss: 1.1685 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.8612 - acc: 0.5673 - val_loss: 1.1689 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8981 - acc: 0.5769 - val_loss: 1.1657 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.8677 - acc: 0.6058 - val_loss: 1.1618 - val_acc: 0.5556\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.8820 - acc: 0.5673 - val_loss: 1.1763 - val_acc: 0.5556\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.8653 - acc: 0.5673 - val_loss: 1.1730 - val_acc: 0.5556\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.8699 - acc: 0.5673 - val_loss: 1.1786 - val_acc: 0.5556\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9021 - acc: 0.5481 - val_loss: 1.1892 - val_acc: 0.5926\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9549 - acc: 0.5192 - val_loss: 1.1802 - val_acc: 0.5556\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9245 - acc: 0.5577 - val_loss: 1.1686 - val_acc: 0.5556\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.8711 - acc: 0.5673 - val_loss: 1.1637 - val_acc: 0.5556\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 0.9009 - acc: 0.5962 - val_loss: 1.1619 - val_acc: 0.5556\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.8618 - acc: 0.5577 - val_loss: 1.1619 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.9516 - acc: 0.2692 - val_loss: 3.0530 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 2.8658 - acc: 0.3846 - val_loss: 2.6669 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 2.5395 - acc: 0.3750 - val_loss: 2.3172 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 2.1408 - acc: 0.3846 - val_loss: 2.0780 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.8483 - acc: 0.4231 - val_loss: 1.8926 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.7816 - acc: 0.3654 - val_loss: 1.7256 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.6167 - acc: 0.4038 - val_loss: 1.5927 - val_acc: 0.4444\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.5726 - acc: 0.3750 - val_loss: 1.4822 - val_acc: 0.4444\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.4127 - acc: 0.4327 - val_loss: 1.3953 - val_acc: 0.4444\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.4474 - acc: 0.4038 - val_loss: 1.3229 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.3903 - acc: 0.4231 - val_loss: 1.2568 - val_acc: 0.4444\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.3438 - acc: 0.4038 - val_loss: 1.2258 - val_acc: 0.4444\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2443 - acc: 0.4615 - val_loss: 1.1960 - val_acc: 0.4815\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.2219 - acc: 0.4423 - val_loss: 1.1615 - val_acc: 0.4815\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.2626 - acc: 0.4231 - val_loss: 1.1265 - val_acc: 0.4815\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.1411 - acc: 0.5192 - val_loss: 1.1074 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0320 - acc: 0.5192 - val_loss: 1.1003 - val_acc: 0.4444\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1132 - acc: 0.4423 - val_loss: 1.0797 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1594 - acc: 0.4327 - val_loss: 1.0677 - val_acc: 0.4815\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0696 - acc: 0.5096 - val_loss: 1.0619 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0862 - acc: 0.5192 - val_loss: 1.0480 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0830 - acc: 0.4808 - val_loss: 1.0401 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0752 - acc: 0.5096 - val_loss: 1.0168 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0751 - acc: 0.4904 - val_loss: 1.0203 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1563 - acc: 0.4231 - val_loss: 1.0119 - val_acc: 0.4815\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0311 - acc: 0.4808 - val_loss: 1.0039 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1375 - acc: 0.4231 - val_loss: 0.9986 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0160 - acc: 0.5096 - val_loss: 0.9909 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9986 - acc: 0.5096 - val_loss: 0.9820 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0397 - acc: 0.4712 - val_loss: 0.9806 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0311 - acc: 0.4808 - val_loss: 0.9752 - val_acc: 0.4815\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9856 - acc: 0.5000 - val_loss: 0.9845 - val_acc: 0.4444\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0136 - acc: 0.4712 - val_loss: 0.9813 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0612 - acc: 0.4808 - val_loss: 0.9760 - val_acc: 0.4444\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0369 - acc: 0.4615 - val_loss: 0.9810 - val_acc: 0.4444\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0046 - acc: 0.4904 - val_loss: 0.9768 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0187 - acc: 0.4904 - val_loss: 0.9738 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9880 - acc: 0.5000 - val_loss: 0.9704 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0439 - acc: 0.4519 - val_loss: 0.9692 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0123 - acc: 0.4423 - val_loss: 0.9679 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0524 - acc: 0.4519 - val_loss: 0.9691 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9990 - acc: 0.5000 - val_loss: 0.9642 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0212 - acc: 0.4904 - val_loss: 0.9622 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9720 - acc: 0.5000 - val_loss: 0.9614 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 0.9767 - acc: 0.5385 - val_loss: 0.9614 - val_acc: 0.4815\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9773 - acc: 0.4712 - val_loss: 0.9662 - val_acc: 0.4815\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0090 - acc: 0.4808 - val_loss: 0.9600 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0081 - acc: 0.5000 - val_loss: 0.9524 - val_acc: 0.4815\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9312 - acc: 0.6058 - val_loss: 0.9526 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9908 - acc: 0.4808 - val_loss: 0.9583 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.0083 - acc: 0.4712 - val_loss: 0.9588 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9252 - acc: 0.5577 - val_loss: 0.9621 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.0056 - acc: 0.5385 - val_loss: 0.9581 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0054 - acc: 0.4712 - val_loss: 0.9556 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0067 - acc: 0.5288 - val_loss: 0.9560 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9689 - acc: 0.5192 - val_loss: 0.9519 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9684 - acc: 0.5096 - val_loss: 0.9574 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9993 - acc: 0.5192 - val_loss: 0.9589 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9724 - acc: 0.5192 - val_loss: 0.9591 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9590 - acc: 0.5288 - val_loss: 0.9589 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9611 - acc: 0.5192 - val_loss: 0.9658 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9541 - acc: 0.5288 - val_loss: 0.9740 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0328 - acc: 0.4904 - val_loss: 0.9607 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9751 - acc: 0.4808 - val_loss: 0.9573 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9681 - acc: 0.5192 - val_loss: 0.9565 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9903 - acc: 0.4904 - val_loss: 0.9574 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 288us/sample - loss: 0.9819 - acc: 0.5288 - val_loss: 0.9510 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9471 - acc: 0.5192 - val_loss: 0.9543 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9839 - acc: 0.5288 - val_loss: 0.9544 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9654 - acc: 0.5577 - val_loss: 0.9610 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9474 - acc: 0.5385 - val_loss: 0.9657 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9713 - acc: 0.5000 - val_loss: 0.9577 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9642 - acc: 0.5481 - val_loss: 0.9655 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9900 - acc: 0.4904 - val_loss: 0.9684 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9682 - acc: 0.5096 - val_loss: 0.9562 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9513 - acc: 0.5192 - val_loss: 0.9549 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9443 - acc: 0.5673 - val_loss: 0.9565 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9963 - acc: 0.4808 - val_loss: 0.9623 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9573 - acc: 0.5385 - val_loss: 0.9615 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9533 - acc: 0.5288 - val_loss: 0.9577 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 0.9737 - acc: 0.5385 - val_loss: 0.9598 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 0.9929 - acc: 0.5096 - val_loss: 0.9605 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9568 - acc: 0.5673 - val_loss: 0.9599 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9526 - acc: 0.5288 - val_loss: 0.9597 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9753 - acc: 0.5481 - val_loss: 0.9591 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9579 - acc: 0.5769 - val_loss: 0.9540 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9796 - acc: 0.4904 - val_loss: 0.9551 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9745 - acc: 0.5192 - val_loss: 0.9582 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9681 - acc: 0.5577 - val_loss: 0.9569 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9426 - acc: 0.5481 - val_loss: 0.9640 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9660 - acc: 0.5096 - val_loss: 0.9594 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9680 - acc: 0.5288 - val_loss: 0.9538 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 0.9715 - acc: 0.5385 - val_loss: 0.9578 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 416us/sample - loss: 0.9818 - acc: 0.5385 - val_loss: 0.9585 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9904 - acc: 0.5096 - val_loss: 0.9538 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9571 - acc: 0.5673 - val_loss: 0.9593 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9422 - acc: 0.5000 - val_loss: 0.9591 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9734 - acc: 0.5673 - val_loss: 0.9576 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9740 - acc: 0.5577 - val_loss: 0.9568 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9821 - acc: 0.5577 - val_loss: 0.9592 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e15c54cdc0c4c104dc0b6edf4c0a990d</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5259259343147278</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.7216 - acc: 0.2500 - val_loss: 1.9391 - val_acc: 0.1852\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.5351 - acc: 0.3654 - val_loss: 1.7900 - val_acc: 0.2222\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.5645 - acc: 0.2404 - val_loss: 1.6567 - val_acc: 0.2593\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.2804 - acc: 0.3750 - val_loss: 1.5974 - val_acc: 0.3333\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.2183 - acc: 0.3942 - val_loss: 1.5409 - val_acc: 0.3333\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 426us/sample - loss: 1.1196 - acc: 0.4327 - val_loss: 1.5010 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1533 - acc: 0.4423 - val_loss: 1.4627 - val_acc: 0.4074\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1285 - acc: 0.4904 - val_loss: 1.4332 - val_acc: 0.4074\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0804 - acc: 0.4327 - val_loss: 1.4062 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 443us/sample - loss: 1.1320 - acc: 0.4038 - val_loss: 1.3763 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1205 - acc: 0.4231 - val_loss: 1.3379 - val_acc: 0.4444\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.1141 - acc: 0.4135 - val_loss: 1.3090 - val_acc: 0.4815\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0632 - acc: 0.4615 - val_loss: 1.2806 - val_acc: 0.5556\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0728 - acc: 0.4615 - val_loss: 1.2628 - val_acc: 0.5556\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0157 - acc: 0.4904 - val_loss: 1.2506 - val_acc: 0.5556\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0315 - acc: 0.5000 - val_loss: 1.2329 - val_acc: 0.5556\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0163 - acc: 0.4808 - val_loss: 1.2290 - val_acc: 0.5556\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9806 - acc: 0.4904 - val_loss: 1.2174 - val_acc: 0.5556\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0118 - acc: 0.4423 - val_loss: 1.2101 - val_acc: 0.5556\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0121 - acc: 0.4615 - val_loss: 1.2091 - val_acc: 0.5556\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 1.0306 - acc: 0.4615 - val_loss: 1.2046 - val_acc: 0.5556\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0252 - acc: 0.5481 - val_loss: 1.1997 - val_acc: 0.5556\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9432 - acc: 0.5673 - val_loss: 1.2038 - val_acc: 0.5556\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0336 - acc: 0.4712 - val_loss: 1.1944 - val_acc: 0.5556\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9641 - acc: 0.5385 - val_loss: 1.1974 - val_acc: 0.5556\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0035 - acc: 0.5288 - val_loss: 1.1980 - val_acc: 0.5556\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9635 - acc: 0.5577 - val_loss: 1.1991 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9814 - acc: 0.5192 - val_loss: 1.1997 - val_acc: 0.5556\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9891 - acc: 0.5192 - val_loss: 1.1973 - val_acc: 0.5556\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9774 - acc: 0.5096 - val_loss: 1.1949 - val_acc: 0.5556\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9882 - acc: 0.4808 - val_loss: 1.1950 - val_acc: 0.5926\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9546 - acc: 0.5577 - val_loss: 1.1997 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9970 - acc: 0.5288 - val_loss: 1.1961 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9594 - acc: 0.5288 - val_loss: 1.1876 - val_acc: 0.5926\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9474 - acc: 0.5288 - val_loss: 1.1894 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9521 - acc: 0.5192 - val_loss: 1.1888 - val_acc: 0.5556\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9496 - acc: 0.4904 - val_loss: 1.1881 - val_acc: 0.5926\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9695 - acc: 0.5096 - val_loss: 1.1832 - val_acc: 0.5926\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9801 - acc: 0.5288 - val_loss: 1.1801 - val_acc: 0.5926\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9626 - acc: 0.5673 - val_loss: 1.1802 - val_acc: 0.5926\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9481 - acc: 0.5673 - val_loss: 1.1824 - val_acc: 0.5926\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9388 - acc: 0.5865 - val_loss: 1.1895 - val_acc: 0.5926\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 0.9863 - acc: 0.5288 - val_loss: 1.1763 - val_acc: 0.5926\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0245 - acc: 0.5288 - val_loss: 1.1736 - val_acc: 0.5926\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9690 - acc: 0.5577 - val_loss: 1.1689 - val_acc: 0.5926\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9922 - acc: 0.4808 - val_loss: 1.1620 - val_acc: 0.5926\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9487 - acc: 0.5577 - val_loss: 1.1618 - val_acc: 0.5926\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9585 - acc: 0.5385 - val_loss: 1.1634 - val_acc: 0.5926\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 0.9395 - acc: 0.5577 - val_loss: 1.1687 - val_acc: 0.5926\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9370 - acc: 0.5577 - val_loss: 1.1694 - val_acc: 0.5926\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9557 - acc: 0.5962 - val_loss: 1.1722 - val_acc: 0.5926\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9291 - acc: 0.5000 - val_loss: 1.1782 - val_acc: 0.5926\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9787 - acc: 0.4808 - val_loss: 1.1631 - val_acc: 0.5926\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9366 - acc: 0.5865 - val_loss: 1.1680 - val_acc: 0.5926\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9571 - acc: 0.5769 - val_loss: 1.1720 - val_acc: 0.5926\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9844 - acc: 0.5192 - val_loss: 1.1635 - val_acc: 0.5926\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9355 - acc: 0.5481 - val_loss: 1.1631 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9173 - acc: 0.5769 - val_loss: 1.1579 - val_acc: 0.5926\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9285 - acc: 0.5577 - val_loss: 1.1618 - val_acc: 0.5926\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9296 - acc: 0.5865 - val_loss: 1.1591 - val_acc: 0.5926\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9084 - acc: 0.5673 - val_loss: 1.1634 - val_acc: 0.5926\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9439 - acc: 0.5673 - val_loss: 1.1584 - val_acc: 0.5926\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9252 - acc: 0.5962 - val_loss: 1.1607 - val_acc: 0.5926\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9568 - acc: 0.5385 - val_loss: 1.1587 - val_acc: 0.5926\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9623 - acc: 0.5288 - val_loss: 1.1602 - val_acc: 0.5926\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9066 - acc: 0.5865 - val_loss: 1.1633 - val_acc: 0.5926\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9272 - acc: 0.5481 - val_loss: 1.1657 - val_acc: 0.5926\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9662 - acc: 0.5865 - val_loss: 1.1661 - val_acc: 0.5926\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.8983 - acc: 0.5865 - val_loss: 1.1756 - val_acc: 0.5926\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9614 - acc: 0.5385 - val_loss: 1.1756 - val_acc: 0.5926\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9556 - acc: 0.5673 - val_loss: 1.1737 - val_acc: 0.5926\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9408 - acc: 0.5288 - val_loss: 1.1717 - val_acc: 0.5926\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9557 - acc: 0.5769 - val_loss: 1.1646 - val_acc: 0.5926\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9504 - acc: 0.5481 - val_loss: 1.1619 - val_acc: 0.5926\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9407 - acc: 0.5481 - val_loss: 1.1585 - val_acc: 0.5926\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9263 - acc: 0.5385 - val_loss: 1.1616 - val_acc: 0.5926\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9099 - acc: 0.5385 - val_loss: 1.1712 - val_acc: 0.5926\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9575 - acc: 0.5673 - val_loss: 1.1715 - val_acc: 0.5926\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9296 - acc: 0.5577 - val_loss: 1.1676 - val_acc: 0.5926\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9559 - acc: 0.5769 - val_loss: 1.1562 - val_acc: 0.5926\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9365 - acc: 0.5673 - val_loss: 1.1561 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9390 - acc: 0.5962 - val_loss: 1.1554 - val_acc: 0.5926\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 0.9364 - acc: 0.6154 - val_loss: 1.1479 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 290us/sample - loss: 0.9481 - acc: 0.5673 - val_loss: 1.1434 - val_acc: 0.5926\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9374 - acc: 0.5288 - val_loss: 1.1378 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 279us/sample - loss: 0.9344 - acc: 0.5000 - val_loss: 1.1370 - val_acc: 0.5926\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9165 - acc: 0.5673 - val_loss: 1.1392 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9076 - acc: 0.6058 - val_loss: 1.1472 - val_acc: 0.6296\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9234 - acc: 0.5769 - val_loss: 1.1543 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9389 - acc: 0.5577 - val_loss: 1.1536 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9306 - acc: 0.5865 - val_loss: 1.1518 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9261 - acc: 0.5288 - val_loss: 1.1475 - val_acc: 0.5926\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9330 - acc: 0.5673 - val_loss: 1.1502 - val_acc: 0.5926\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9678 - acc: 0.5385 - val_loss: 1.1471 - val_acc: 0.5926\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9466 - acc: 0.5096 - val_loss: 1.1484 - val_acc: 0.5926\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9533 - acc: 0.5962 - val_loss: 1.1446 - val_acc: 0.5926\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9347 - acc: 0.5481 - val_loss: 1.1436 - val_acc: 0.5926\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9958 - acc: 0.4615 - val_loss: 1.1357 - val_acc: 0.5926\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9509 - acc: 0.5192 - val_loss: 1.1324 - val_acc: 0.5926\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9151 - acc: 0.5577 - val_loss: 1.1369 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.8518 - acc: 0.3750 - val_loss: 1.3949 - val_acc: 0.4074\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.5996 - acc: 0.4423 - val_loss: 1.2975 - val_acc: 0.3333\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.3864 - acc: 0.4327 - val_loss: 1.2432 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1682 - acc: 0.5000 - val_loss: 1.2088 - val_acc: 0.3333\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.2068 - acc: 0.4904 - val_loss: 1.1733 - val_acc: 0.2963\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.2329 - acc: 0.4712 - val_loss: 1.1480 - val_acc: 0.2963\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0856 - acc: 0.4615 - val_loss: 1.1288 - val_acc: 0.2963\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1630 - acc: 0.4808 - val_loss: 1.1070 - val_acc: 0.2963\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0700 - acc: 0.5000 - val_loss: 1.0940 - val_acc: 0.3333\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0863 - acc: 0.4519 - val_loss: 1.0872 - val_acc: 0.2963\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1881 - acc: 0.4423 - val_loss: 1.0734 - val_acc: 0.2963\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1078 - acc: 0.4712 - val_loss: 1.0634 - val_acc: 0.2963\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.1205 - acc: 0.5000 - val_loss: 1.0565 - val_acc: 0.2963\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0089 - acc: 0.5192 - val_loss: 1.0491 - val_acc: 0.2963\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0347 - acc: 0.5096 - val_loss: 1.0443 - val_acc: 0.2963\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0773 - acc: 0.5288 - val_loss: 1.0420 - val_acc: 0.2963\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0374 - acc: 0.5385 - val_loss: 1.0427 - val_acc: 0.2963\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0078 - acc: 0.4808 - val_loss: 1.0382 - val_acc: 0.2963\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0174 - acc: 0.4904 - val_loss: 1.0379 - val_acc: 0.2963\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0559 - acc: 0.5192 - val_loss: 1.0375 - val_acc: 0.2963\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0627 - acc: 0.4904 - val_loss: 1.0310 - val_acc: 0.2963\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0923 - acc: 0.5385 - val_loss: 1.0274 - val_acc: 0.2963\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0328 - acc: 0.5962 - val_loss: 1.0311 - val_acc: 0.2963\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0303 - acc: 0.5288 - val_loss: 1.0300 - val_acc: 0.2963\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.1382 - acc: 0.4615 - val_loss: 1.0259 - val_acc: 0.2963\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0614 - acc: 0.4808 - val_loss: 1.0255 - val_acc: 0.3333\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0906 - acc: 0.5769 - val_loss: 1.0286 - val_acc: 0.2963\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0174 - acc: 0.5000 - val_loss: 1.0308 - val_acc: 0.2963\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0324 - acc: 0.5481 - val_loss: 1.0321 - val_acc: 0.2963\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.1120 - acc: 0.5096 - val_loss: 1.0293 - val_acc: 0.2963\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9885 - acc: 0.5192 - val_loss: 1.0307 - val_acc: 0.2963\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0062 - acc: 0.5288 - val_loss: 1.0293 - val_acc: 0.3333\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9904 - acc: 0.4712 - val_loss: 1.0262 - val_acc: 0.2963\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0210 - acc: 0.4712 - val_loss: 1.0216 - val_acc: 0.2963\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0277 - acc: 0.5288 - val_loss: 1.0229 - val_acc: 0.3333\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9909 - acc: 0.5096 - val_loss: 1.0239 - val_acc: 0.2963\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0474 - acc: 0.5288 - val_loss: 1.0252 - val_acc: 0.2963\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0468 - acc: 0.4904 - val_loss: 1.0194 - val_acc: 0.2963\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0170 - acc: 0.4712 - val_loss: 1.0157 - val_acc: 0.2963\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0078 - acc: 0.5865 - val_loss: 1.0183 - val_acc: 0.2963\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9965 - acc: 0.5000 - val_loss: 1.0191 - val_acc: 0.2963\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9781 - acc: 0.5577 - val_loss: 1.0248 - val_acc: 0.2963\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0349 - acc: 0.4519 - val_loss: 1.0209 - val_acc: 0.2963\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 286us/sample - loss: 0.9563 - acc: 0.5000 - val_loss: 1.0234 - val_acc: 0.3333\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0260 - acc: 0.5096 - val_loss: 1.0231 - val_acc: 0.3704\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0420 - acc: 0.4423 - val_loss: 1.0175 - val_acc: 0.3704\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9990 - acc: 0.4231 - val_loss: 1.0174 - val_acc: 0.3333\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0326 - acc: 0.4808 - val_loss: 1.0163 - val_acc: 0.3704\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0486 - acc: 0.5000 - val_loss: 1.0150 - val_acc: 0.3704\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9533 - acc: 0.5096 - val_loss: 1.0140 - val_acc: 0.3704\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0321 - acc: 0.5000 - val_loss: 1.0093 - val_acc: 0.3333\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9538 - acc: 0.5288 - val_loss: 1.0091 - val_acc: 0.4074\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9592 - acc: 0.5288 - val_loss: 1.0092 - val_acc: 0.4074\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0712 - acc: 0.4808 - val_loss: 1.0074 - val_acc: 0.4074\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9583 - acc: 0.5000 - val_loss: 1.0074 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0453 - acc: 0.4423 - val_loss: 1.0041 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0267 - acc: 0.4327 - val_loss: 1.0024 - val_acc: 0.4074\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0283 - acc: 0.4519 - val_loss: 1.0008 - val_acc: 0.4074\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0013 - acc: 0.4519 - val_loss: 0.9996 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0017 - acc: 0.4327 - val_loss: 0.9982 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0184 - acc: 0.5096 - val_loss: 0.9979 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0043 - acc: 0.4808 - val_loss: 1.0008 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9965 - acc: 0.4615 - val_loss: 1.0042 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0059 - acc: 0.5096 - val_loss: 1.0055 - val_acc: 0.4444\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0327 - acc: 0.5192 - val_loss: 1.0076 - val_acc: 0.4074\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0275 - acc: 0.4808 - val_loss: 1.0083 - val_acc: 0.3704\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0020 - acc: 0.5000 - val_loss: 1.0077 - val_acc: 0.3704\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9913 - acc: 0.5096 - val_loss: 1.0047 - val_acc: 0.3704\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0205 - acc: 0.5192 - val_loss: 1.0028 - val_acc: 0.3704\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9809 - acc: 0.5000 - val_loss: 1.0045 - val_acc: 0.3704\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9881 - acc: 0.5288 - val_loss: 1.0077 - val_acc: 0.3333\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9907 - acc: 0.5481 - val_loss: 1.0073 - val_acc: 0.3704\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.0262 - acc: 0.5192 - val_loss: 1.0053 - val_acc: 0.3333\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9966 - acc: 0.4519 - val_loss: 1.0074 - val_acc: 0.4074\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0196 - acc: 0.4808 - val_loss: 1.0100 - val_acc: 0.3704\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9746 - acc: 0.5000 - val_loss: 1.0082 - val_acc: 0.3704\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9994 - acc: 0.5000 - val_loss: 1.0093 - val_acc: 0.4074\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9975 - acc: 0.4808 - val_loss: 1.0076 - val_acc: 0.3704\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9970 - acc: 0.5288 - val_loss: 1.0062 - val_acc: 0.4444\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9669 - acc: 0.4712 - val_loss: 1.0066 - val_acc: 0.4444\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9704 - acc: 0.5288 - val_loss: 1.0073 - val_acc: 0.4444\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9755 - acc: 0.4904 - val_loss: 1.0067 - val_acc: 0.4074\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0131 - acc: 0.4712 - val_loss: 1.0042 - val_acc: 0.4074\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9699 - acc: 0.5577 - val_loss: 1.0095 - val_acc: 0.3704\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9637 - acc: 0.5385 - val_loss: 1.0120 - val_acc: 0.3333\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9596 - acc: 0.5673 - val_loss: 1.0110 - val_acc: 0.3704\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0152 - acc: 0.4808 - val_loss: 1.0095 - val_acc: 0.3333\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9985 - acc: 0.5192 - val_loss: 1.0114 - val_acc: 0.3704\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0010 - acc: 0.5577 - val_loss: 1.0145 - val_acc: 0.3704\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9633 - acc: 0.4904 - val_loss: 1.0135 - val_acc: 0.3333\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9744 - acc: 0.4808 - val_loss: 1.0145 - val_acc: 0.3333\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9825 - acc: 0.5481 - val_loss: 1.0186 - val_acc: 0.3704\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0060 - acc: 0.4808 - val_loss: 1.0168 - val_acc: 0.3704\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9937 - acc: 0.5192 - val_loss: 1.0174 - val_acc: 0.4074\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0001 - acc: 0.4808 - val_loss: 1.0165 - val_acc: 0.3333\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0146 - acc: 0.5000 - val_loss: 1.0168 - val_acc: 0.4444\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9858 - acc: 0.4808 - val_loss: 1.0168 - val_acc: 0.4074\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9589 - acc: 0.5000 - val_loss: 1.0157 - val_acc: 0.4074\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0048 - acc: 0.5000 - val_loss: 1.0176 - val_acc: 0.4074\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9958 - acc: 0.5385 - val_loss: 1.0174 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.0141 - acc: 0.2404 - val_loss: 2.1279 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 2.8628 - acc: 0.3462 - val_loss: 1.9278 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 2.4420 - acc: 0.3269 - val_loss: 1.7627 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 2.0727 - acc: 0.3942 - val_loss: 1.6337 - val_acc: 0.4444\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 2.2428 - acc: 0.2981 - val_loss: 1.5168 - val_acc: 0.4815\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.8282 - acc: 0.3654 - val_loss: 1.4101 - val_acc: 0.4815\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.7603 - acc: 0.4135 - val_loss: 1.3679 - val_acc: 0.5185\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.6050 - acc: 0.3558 - val_loss: 1.3584 - val_acc: 0.4815\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.3883 - acc: 0.4423 - val_loss: 1.3474 - val_acc: 0.4815\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.4630 - acc: 0.4712 - val_loss: 1.3252 - val_acc: 0.4815\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.3184 - acc: 0.4712 - val_loss: 1.3249 - val_acc: 0.4815\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.3200 - acc: 0.4615 - val_loss: 1.3091 - val_acc: 0.4815\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.5669 - acc: 0.4615 - val_loss: 1.2808 - val_acc: 0.4815\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.2164 - acc: 0.4231 - val_loss: 1.2607 - val_acc: 0.4815\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.3287 - acc: 0.4519 - val_loss: 1.2647 - val_acc: 0.4815\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 1.3213 - acc: 0.4904 - val_loss: 1.2525 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 421us/sample - loss: 1.3966 - acc: 0.5192 - val_loss: 1.2467 - val_acc: 0.4815\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.2685 - acc: 0.4615 - val_loss: 1.2486 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.1573 - acc: 0.4327 - val_loss: 1.2531 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0800 - acc: 0.5096 - val_loss: 1.2592 - val_acc: 0.4074\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.2919 - acc: 0.4231 - val_loss: 1.2329 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.2342 - acc: 0.4615 - val_loss: 1.2137 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1763 - acc: 0.5385 - val_loss: 1.2196 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0637 - acc: 0.4904 - val_loss: 1.2093 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.3194 - acc: 0.4615 - val_loss: 1.1992 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1810 - acc: 0.4904 - val_loss: 1.1934 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0645 - acc: 0.5385 - val_loss: 1.1947 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0474 - acc: 0.5481 - val_loss: 1.1989 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 1.1181 - acc: 0.5192 - val_loss: 1.1871 - val_acc: 0.4444\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1564 - acc: 0.5481 - val_loss: 1.1767 - val_acc: 0.4815\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0817 - acc: 0.4615 - val_loss: 1.1766 - val_acc: 0.4815\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0109 - acc: 0.5385 - val_loss: 1.1813 - val_acc: 0.4815\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0513 - acc: 0.5769 - val_loss: 1.1709 - val_acc: 0.5185\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 413us/sample - loss: 1.1772 - acc: 0.4808 - val_loss: 1.1603 - val_acc: 0.4815\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0437 - acc: 0.5288 - val_loss: 1.1606 - val_acc: 0.4815\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0347 - acc: 0.5385 - val_loss: 1.1642 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0978 - acc: 0.5192 - val_loss: 1.1496 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0822 - acc: 0.4615 - val_loss: 1.1346 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0989 - acc: 0.5385 - val_loss: 1.1288 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0548 - acc: 0.5192 - val_loss: 1.1182 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 0.9764 - acc: 0.5481 - val_loss: 1.1083 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0473 - acc: 0.5096 - val_loss: 1.1126 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9873 - acc: 0.5000 - val_loss: 1.1158 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0579 - acc: 0.4327 - val_loss: 1.1124 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9845 - acc: 0.4904 - val_loss: 1.1188 - val_acc: 0.4815\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0395 - acc: 0.4135 - val_loss: 1.1100 - val_acc: 0.4815\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 459us/sample - loss: 1.0222 - acc: 0.4519 - val_loss: 1.1069 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0119 - acc: 0.5000 - val_loss: 1.1023 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9802 - acc: 0.5000 - val_loss: 1.0930 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0218 - acc: 0.4038 - val_loss: 1.0938 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9934 - acc: 0.4519 - val_loss: 1.0933 - val_acc: 0.4444\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9435 - acc: 0.5000 - val_loss: 1.0956 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9485 - acc: 0.4808 - val_loss: 1.0945 - val_acc: 0.4444\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9967 - acc: 0.4808 - val_loss: 1.0873 - val_acc: 0.4444\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 0.9784 - acc: 0.4519 - val_loss: 1.0869 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9239 - acc: 0.5192 - val_loss: 1.0896 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9538 - acc: 0.4904 - val_loss: 1.0874 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 0.9575 - acc: 0.5096 - val_loss: 1.0909 - val_acc: 0.4444\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9217 - acc: 0.5000 - val_loss: 1.0941 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9106 - acc: 0.5192 - val_loss: 1.0906 - val_acc: 0.4074\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9920 - acc: 0.4808 - val_loss: 1.0890 - val_acc: 0.4444\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9347 - acc: 0.4615 - val_loss: 1.0922 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.8890 - acc: 0.5481 - val_loss: 1.0967 - val_acc: 0.4815\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9702 - acc: 0.4808 - val_loss: 1.0974 - val_acc: 0.4444\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9202 - acc: 0.5481 - val_loss: 1.1046 - val_acc: 0.4444\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.8878 - acc: 0.5769 - val_loss: 1.1031 - val_acc: 0.4444\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9524 - acc: 0.5577 - val_loss: 1.0990 - val_acc: 0.4444\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9513 - acc: 0.5192 - val_loss: 1.1020 - val_acc: 0.4444\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9249 - acc: 0.5096 - val_loss: 1.0953 - val_acc: 0.4444\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9799 - acc: 0.5096 - val_loss: 1.0857 - val_acc: 0.4444\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0130 - acc: 0.5000 - val_loss: 1.0791 - val_acc: 0.4074\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9422 - acc: 0.4808 - val_loss: 1.0800 - val_acc: 0.4444\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9745 - acc: 0.5096 - val_loss: 1.0765 - val_acc: 0.4444\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9682 - acc: 0.5096 - val_loss: 1.0761 - val_acc: 0.4444\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9308 - acc: 0.5385 - val_loss: 1.0738 - val_acc: 0.3704\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9291 - acc: 0.5481 - val_loss: 1.0781 - val_acc: 0.4074\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9390 - acc: 0.4904 - val_loss: 1.0752 - val_acc: 0.4074\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9625 - acc: 0.5000 - val_loss: 1.0679 - val_acc: 0.4074\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9781 - acc: 0.4808 - val_loss: 1.0612 - val_acc: 0.3704\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9674 - acc: 0.4808 - val_loss: 1.0672 - val_acc: 0.4444\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 0.9541 - acc: 0.5096 - val_loss: 1.0630 - val_acc: 0.4444\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9762 - acc: 0.4808 - val_loss: 1.0593 - val_acc: 0.4444\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9347 - acc: 0.4904 - val_loss: 1.0690 - val_acc: 0.4444\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 0.9288 - acc: 0.4712 - val_loss: 1.0705 - val_acc: 0.4444\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9113 - acc: 0.5385 - val_loss: 1.0669 - val_acc: 0.4444\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9639 - acc: 0.4808 - val_loss: 1.0649 - val_acc: 0.4444\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9132 - acc: 0.5385 - val_loss: 1.0658 - val_acc: 0.4444\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9380 - acc: 0.4904 - val_loss: 1.0714 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9156 - acc: 0.5096 - val_loss: 1.0714 - val_acc: 0.4815\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9444 - acc: 0.5192 - val_loss: 1.0663 - val_acc: 0.4444\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9285 - acc: 0.5288 - val_loss: 1.0623 - val_acc: 0.4074\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9387 - acc: 0.4904 - val_loss: 1.0686 - val_acc: 0.4074\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9154 - acc: 0.5385 - val_loss: 1.0707 - val_acc: 0.4074\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9469 - acc: 0.5385 - val_loss: 1.0726 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9338 - acc: 0.5192 - val_loss: 1.0695 - val_acc: 0.3704\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9444 - acc: 0.5096 - val_loss: 1.0631 - val_acc: 0.3704\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9074 - acc: 0.5192 - val_loss: 1.0657 - val_acc: 0.4074\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9650 - acc: 0.5192 - val_loss: 1.0609 - val_acc: 0.4074\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 411us/sample - loss: 0.9354 - acc: 0.5000 - val_loss: 1.0632 - val_acc: 0.3704\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 0.9467 - acc: 0.5192 - val_loss: 1.0604 - val_acc: 0.3704\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.9443 - acc: 0.2788 - val_loss: 4.7500 - val_acc: 0.2222\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 477us/sample - loss: 3.6767 - acc: 0.2404 - val_loss: 4.0519 - val_acc: 0.2593\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 3.6231 - acc: 0.2692 - val_loss: 3.4373 - val_acc: 0.2593\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 3.1051 - acc: 0.2596 - val_loss: 2.9486 - val_acc: 0.2593\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 2.4606 - acc: 0.2885 - val_loss: 2.5546 - val_acc: 0.2593\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 2.3070 - acc: 0.2596 - val_loss: 2.3452 - val_acc: 0.2593\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 2.1661 - acc: 0.3462 - val_loss: 2.1325 - val_acc: 0.2593\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 2.3488 - acc: 0.2692 - val_loss: 1.9011 - val_acc: 0.2963\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.9864 - acc: 0.2692 - val_loss: 1.7246 - val_acc: 0.2963\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.8538 - acc: 0.2981 - val_loss: 1.6455 - val_acc: 0.3333\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.6742 - acc: 0.3942 - val_loss: 1.5571 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 1.7394 - acc: 0.3942 - val_loss: 1.4899 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.5486 - acc: 0.3846 - val_loss: 1.4409 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.4621 - acc: 0.4712 - val_loss: 1.3989 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.4108 - acc: 0.4423 - val_loss: 1.3405 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.4178 - acc: 0.4135 - val_loss: 1.3066 - val_acc: 0.3333\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.4614 - acc: 0.3558 - val_loss: 1.2728 - val_acc: 0.3333\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.2669 - acc: 0.3750 - val_loss: 1.2492 - val_acc: 0.3333\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.3191 - acc: 0.4038 - val_loss: 1.2333 - val_acc: 0.4074\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.3582 - acc: 0.4327 - val_loss: 1.2176 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1786 - acc: 0.3942 - val_loss: 1.1907 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.2311 - acc: 0.4327 - val_loss: 1.1514 - val_acc: 0.4074\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.1671 - acc: 0.4615 - val_loss: 1.1360 - val_acc: 0.4074\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.2143 - acc: 0.4038 - val_loss: 1.1287 - val_acc: 0.4074\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.3527 - acc: 0.3654 - val_loss: 1.1040 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 418us/sample - loss: 1.1433 - acc: 0.4231 - val_loss: 1.0939 - val_acc: 0.4074\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.1906 - acc: 0.3654 - val_loss: 1.0816 - val_acc: 0.4074\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.2654 - acc: 0.4038 - val_loss: 1.0741 - val_acc: 0.4074\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.1973 - acc: 0.4135 - val_loss: 1.0620 - val_acc: 0.4074\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.2013 - acc: 0.4038 - val_loss: 1.0474 - val_acc: 0.4074\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1488 - acc: 0.3846 - val_loss: 1.0436 - val_acc: 0.4074\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.1133 - acc: 0.4327 - val_loss: 1.0423 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.1012 - acc: 0.4615 - val_loss: 1.0345 - val_acc: 0.4074\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0863 - acc: 0.4615 - val_loss: 1.0318 - val_acc: 0.4074\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0411 - acc: 0.4423 - val_loss: 1.0319 - val_acc: 0.4074\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0927 - acc: 0.4135 - val_loss: 1.0261 - val_acc: 0.4074\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.2034 - acc: 0.3846 - val_loss: 1.0112 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0507 - acc: 0.4231 - val_loss: 1.0065 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.1307 - acc: 0.4038 - val_loss: 1.0065 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1112 - acc: 0.4135 - val_loss: 0.9991 - val_acc: 0.4074\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0994 - acc: 0.4135 - val_loss: 1.0032 - val_acc: 0.4444\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.1091 - acc: 0.4231 - val_loss: 1.0056 - val_acc: 0.4444\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0436 - acc: 0.4712 - val_loss: 1.0025 - val_acc: 0.4444\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.1065 - acc: 0.4423 - val_loss: 0.9934 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1199 - acc: 0.4231 - val_loss: 0.9982 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0412 - acc: 0.4423 - val_loss: 0.9936 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0376 - acc: 0.4615 - val_loss: 0.9952 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.0133 - acc: 0.4423 - val_loss: 0.9917 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0283 - acc: 0.4904 - val_loss: 0.9882 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0165 - acc: 0.4423 - val_loss: 0.9854 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0954 - acc: 0.4135 - val_loss: 0.9868 - val_acc: 0.4074\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0680 - acc: 0.4615 - val_loss: 0.9816 - val_acc: 0.4444\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9935 - acc: 0.4615 - val_loss: 0.9848 - val_acc: 0.4074\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0287 - acc: 0.4615 - val_loss: 0.9871 - val_acc: 0.4444\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0325 - acc: 0.5000 - val_loss: 0.9844 - val_acc: 0.4815\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0806 - acc: 0.4615 - val_loss: 0.9832 - val_acc: 0.4815\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0646 - acc: 0.4423 - val_loss: 0.9725 - val_acc: 0.4074\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0184 - acc: 0.4904 - val_loss: 0.9727 - val_acc: 0.4074\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0803 - acc: 0.4519 - val_loss: 0.9696 - val_acc: 0.4074\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0627 - acc: 0.4327 - val_loss: 0.9656 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0148 - acc: 0.4712 - val_loss: 0.9729 - val_acc: 0.4074\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0136 - acc: 0.4615 - val_loss: 0.9784 - val_acc: 0.4815\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0357 - acc: 0.5096 - val_loss: 0.9802 - val_acc: 0.4815\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0520 - acc: 0.3942 - val_loss: 0.9715 - val_acc: 0.4074\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0585 - acc: 0.4231 - val_loss: 0.9666 - val_acc: 0.4074\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0489 - acc: 0.4519 - val_loss: 0.9619 - val_acc: 0.4074\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0199 - acc: 0.5000 - val_loss: 0.9616 - val_acc: 0.4074\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0327 - acc: 0.4519 - val_loss: 0.9613 - val_acc: 0.4074\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.0221 - acc: 0.4712 - val_loss: 0.9618 - val_acc: 0.4074\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 0.9961 - acc: 0.4904 - val_loss: 0.9606 - val_acc: 0.4074\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0227 - acc: 0.4231 - val_loss: 0.9582 - val_acc: 0.4074\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9765 - acc: 0.4615 - val_loss: 0.9560 - val_acc: 0.4074\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0133 - acc: 0.4231 - val_loss: 0.9523 - val_acc: 0.4074\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0217 - acc: 0.4615 - val_loss: 0.9503 - val_acc: 0.4074\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9957 - acc: 0.4712 - val_loss: 0.9518 - val_acc: 0.4074\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0121 - acc: 0.4519 - val_loss: 0.9508 - val_acc: 0.4074\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 1.0171 - acc: 0.4615 - val_loss: 0.9521 - val_acc: 0.3704\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9980 - acc: 0.4327 - val_loss: 0.9478 - val_acc: 0.4074\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 389us/sample - loss: 0.9947 - acc: 0.4423 - val_loss: 0.9483 - val_acc: 0.4074\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 505us/sample - loss: 0.9979 - acc: 0.4808 - val_loss: 0.9498 - val_acc: 0.3704\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9851 - acc: 0.4712 - val_loss: 0.9500 - val_acc: 0.3704\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9575 - acc: 0.4808 - val_loss: 0.9507 - val_acc: 0.3704\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0004 - acc: 0.4712 - val_loss: 0.9515 - val_acc: 0.3704\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9963 - acc: 0.4519 - val_loss: 0.9493 - val_acc: 0.3333\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0026 - acc: 0.4712 - val_loss: 0.9472 - val_acc: 0.3333\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9949 - acc: 0.4519 - val_loss: 0.9496 - val_acc: 0.3704\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9901 - acc: 0.4615 - val_loss: 0.9506 - val_acc: 0.3704\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9805 - acc: 0.5096 - val_loss: 0.9530 - val_acc: 0.3704\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0217 - acc: 0.4519 - val_loss: 0.9527 - val_acc: 0.4074\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 1.0029 - acc: 0.4327 - val_loss: 0.9491 - val_acc: 0.3704\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0113 - acc: 0.4712 - val_loss: 0.9485 - val_acc: 0.3704\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0412 - acc: 0.4519 - val_loss: 0.9485 - val_acc: 0.3704\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9891 - acc: 0.4519 - val_loss: 0.9490 - val_acc: 0.4074\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9965 - acc: 0.5192 - val_loss: 0.9539 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0035 - acc: 0.5096 - val_loss: 0.9534 - val_acc: 0.4074\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0075 - acc: 0.4904 - val_loss: 0.9540 - val_acc: 0.4444\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 0.9651 - acc: 0.4904 - val_loss: 0.9509 - val_acc: 0.4074\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9967 - acc: 0.4519 - val_loss: 0.9475 - val_acc: 0.3704\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9909 - acc: 0.5000 - val_loss: 0.9474 - val_acc: 0.4074\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0271 - acc: 0.4423 - val_loss: 0.9488 - val_acc: 0.4074\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.0398 - acc: 0.2692 - val_loss: 2.6089 - val_acc: 0.2222\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 2.7402 - acc: 0.3462 - val_loss: 2.2675 - val_acc: 0.2593\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 2.4582 - acc: 0.2885 - val_loss: 1.8508 - val_acc: 0.2593\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 2.2399 - acc: 0.3269 - val_loss: 1.6346 - val_acc: 0.2963\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 2.0974 - acc: 0.3173 - val_loss: 1.5018 - val_acc: 0.2593\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.8386 - acc: 0.3654 - val_loss: 1.3823 - val_acc: 0.2593\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.8065 - acc: 0.3750 - val_loss: 1.3062 - val_acc: 0.2593\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.6237 - acc: 0.4038 - val_loss: 1.2944 - val_acc: 0.2593\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.4912 - acc: 0.3846 - val_loss: 1.2723 - val_acc: 0.2963\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.6560 - acc: 0.3365 - val_loss: 1.2780 - val_acc: 0.2963\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.3240 - acc: 0.3942 - val_loss: 1.2408 - val_acc: 0.2963\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.2821 - acc: 0.3846 - val_loss: 1.2312 - val_acc: 0.2963\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.4679 - acc: 0.3654 - val_loss: 1.2311 - val_acc: 0.2963\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.2684 - acc: 0.4231 - val_loss: 1.2403 - val_acc: 0.3333\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.2135 - acc: 0.3654 - val_loss: 1.2373 - val_acc: 0.2963\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.3318 - acc: 0.3558 - val_loss: 1.2381 - val_acc: 0.2593\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.3588 - acc: 0.3269 - val_loss: 1.2292 - val_acc: 0.2963\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.2205 - acc: 0.3846 - val_loss: 1.2354 - val_acc: 0.2593\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.2960 - acc: 0.3846 - val_loss: 1.2051 - val_acc: 0.2963\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1098 - acc: 0.3942 - val_loss: 1.2073 - val_acc: 0.3333\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.1924 - acc: 0.4423 - val_loss: 1.2116 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1934 - acc: 0.3654 - val_loss: 1.2249 - val_acc: 0.3333\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.2692 - acc: 0.4423 - val_loss: 1.2084 - val_acc: 0.3333\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.1903 - acc: 0.3846 - val_loss: 1.1886 - val_acc: 0.3704\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1358 - acc: 0.4712 - val_loss: 1.1901 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1961 - acc: 0.4423 - val_loss: 1.1918 - val_acc: 0.3333\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.1275 - acc: 0.3942 - val_loss: 1.1868 - val_acc: 0.3333\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.2069 - acc: 0.3654 - val_loss: 1.1646 - val_acc: 0.4074\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0897 - acc: 0.4423 - val_loss: 1.1676 - val_acc: 0.3704\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1057 - acc: 0.4327 - val_loss: 1.1817 - val_acc: 0.3704\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0851 - acc: 0.3750 - val_loss: 1.1710 - val_acc: 0.4074\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1775 - acc: 0.4423 - val_loss: 1.1580 - val_acc: 0.3333\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.1506 - acc: 0.4135 - val_loss: 1.1555 - val_acc: 0.4074\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1543 - acc: 0.4038 - val_loss: 1.1502 - val_acc: 0.4815\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0449 - acc: 0.4327 - val_loss: 1.1439 - val_acc: 0.4444\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0560 - acc: 0.3846 - val_loss: 1.1538 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0801 - acc: 0.4135 - val_loss: 1.1435 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1335 - acc: 0.4519 - val_loss: 1.1383 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0201 - acc: 0.5000 - val_loss: 1.1332 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1346 - acc: 0.4135 - val_loss: 1.1259 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0849 - acc: 0.4231 - val_loss: 1.1230 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1239 - acc: 0.4231 - val_loss: 1.1203 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0498 - acc: 0.4423 - val_loss: 1.1159 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 1.0950 - acc: 0.4231 - val_loss: 1.1079 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0226 - acc: 0.4519 - val_loss: 1.1089 - val_acc: 0.5926\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0936 - acc: 0.4038 - val_loss: 1.1081 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0654 - acc: 0.4231 - val_loss: 1.1022 - val_acc: 0.5556\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0922 - acc: 0.4423 - val_loss: 1.0949 - val_acc: 0.5556\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1032 - acc: 0.5000 - val_loss: 1.0954 - val_acc: 0.5556\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0531 - acc: 0.4808 - val_loss: 1.0952 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.0318 - acc: 0.4135 - val_loss: 1.0890 - val_acc: 0.5556\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9787 - acc: 0.4615 - val_loss: 1.0895 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0521 - acc: 0.4423 - val_loss: 1.0923 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0061 - acc: 0.4904 - val_loss: 1.0896 - val_acc: 0.5556\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0599 - acc: 0.4808 - val_loss: 1.0813 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0085 - acc: 0.4808 - val_loss: 1.0784 - val_acc: 0.5926\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0223 - acc: 0.4327 - val_loss: 1.0798 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0654 - acc: 0.4519 - val_loss: 1.0758 - val_acc: 0.5926\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0407 - acc: 0.4519 - val_loss: 1.0733 - val_acc: 0.5926\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0063 - acc: 0.4231 - val_loss: 1.0680 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0468 - acc: 0.4038 - val_loss: 1.0623 - val_acc: 0.5556\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9996 - acc: 0.4327 - val_loss: 1.0604 - val_acc: 0.4815\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0649 - acc: 0.4231 - val_loss: 1.0557 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0049 - acc: 0.4615 - val_loss: 1.0542 - val_acc: 0.4815\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0384 - acc: 0.4615 - val_loss: 1.0526 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0032 - acc: 0.4808 - val_loss: 1.0506 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0057 - acc: 0.4904 - val_loss: 1.0536 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0280 - acc: 0.4615 - val_loss: 1.0445 - val_acc: 0.5556\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0238 - acc: 0.4712 - val_loss: 1.0418 - val_acc: 0.5926\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9994 - acc: 0.4904 - val_loss: 1.0459 - val_acc: 0.5926\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0789 - acc: 0.4231 - val_loss: 1.0471 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0106 - acc: 0.4904 - val_loss: 1.0474 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0241 - acc: 0.4808 - val_loss: 1.0419 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9955 - acc: 0.5000 - val_loss: 1.0394 - val_acc: 0.5926\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0186 - acc: 0.4904 - val_loss: 1.0367 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0087 - acc: 0.4712 - val_loss: 1.0324 - val_acc: 0.5926\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0089 - acc: 0.4808 - val_loss: 1.0336 - val_acc: 0.5926\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0039 - acc: 0.4808 - val_loss: 1.0327 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0004 - acc: 0.4904 - val_loss: 1.0327 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.0195 - acc: 0.5192 - val_loss: 1.0303 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9973 - acc: 0.5000 - val_loss: 1.0289 - val_acc: 0.5556\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0078 - acc: 0.5192 - val_loss: 1.0317 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0338 - acc: 0.4904 - val_loss: 1.0322 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9941 - acc: 0.5192 - val_loss: 1.0351 - val_acc: 0.5556\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9956 - acc: 0.4808 - val_loss: 1.0307 - val_acc: 0.5556\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9969 - acc: 0.5673 - val_loss: 1.0296 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 410us/sample - loss: 0.9934 - acc: 0.5192 - val_loss: 1.0301 - val_acc: 0.5556\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0075 - acc: 0.4615 - val_loss: 1.0306 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9930 - acc: 0.4231 - val_loss: 1.0327 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9686 - acc: 0.4808 - val_loss: 1.0316 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9969 - acc: 0.5096 - val_loss: 1.0296 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0155 - acc: 0.4712 - val_loss: 1.0246 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9912 - acc: 0.5096 - val_loss: 1.0254 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0185 - acc: 0.4808 - val_loss: 1.0251 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9721 - acc: 0.5385 - val_loss: 1.0227 - val_acc: 0.5556\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 0.9790 - acc: 0.5865 - val_loss: 1.0242 - val_acc: 0.5556\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9993 - acc: 0.5288 - val_loss: 1.0237 - val_acc: 0.5556\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0013 - acc: 0.5577 - val_loss: 1.0226 - val_acc: 0.5556\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9827 - acc: 0.5385 - val_loss: 1.0243 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9622 - acc: 0.5096 - val_loss: 1.0217 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9b5bede12522180c604bcc88b7edbd8b</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5333333015441895</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.8351 - acc: 0.4038 - val_loss: 2.3048 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 2.9482 - acc: 0.4519 - val_loss: 2.0921 - val_acc: 0.3333\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 2.4157 - acc: 0.4038 - val_loss: 1.9446 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 2.7687 - acc: 0.4231 - val_loss: 1.7620 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 2.6591 - acc: 0.3846 - val_loss: 1.5990 - val_acc: 0.3333\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.4932 - acc: 0.4231 - val_loss: 1.5675 - val_acc: 0.2593\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 438us/sample - loss: 2.0223 - acc: 0.3846 - val_loss: 1.5126 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.6270 - acc: 0.4135 - val_loss: 1.4766 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.9748 - acc: 0.4327 - val_loss: 1.4278 - val_acc: 0.3704\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.8914 - acc: 0.4808 - val_loss: 1.3865 - val_acc: 0.3704\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.6396 - acc: 0.4712 - val_loss: 1.3470 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.2156 - acc: 0.4808 - val_loss: 1.3397 - val_acc: 0.3704\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.5027 - acc: 0.4327 - val_loss: 1.3082 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.2862 - acc: 0.4615 - val_loss: 1.2826 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.3882 - acc: 0.4519 - val_loss: 1.2714 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.4999 - acc: 0.5000 - val_loss: 1.2366 - val_acc: 0.3704\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 1.5347 - acc: 0.4712 - val_loss: 1.2069 - val_acc: 0.3704\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 424us/sample - loss: 1.3497 - acc: 0.4808 - val_loss: 1.1858 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.2349 - acc: 0.3942 - val_loss: 1.1668 - val_acc: 0.4074\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.1432 - acc: 0.5096 - val_loss: 1.1561 - val_acc: 0.4074\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.3250 - acc: 0.5096 - val_loss: 1.1369 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.2030 - acc: 0.4615 - val_loss: 1.1235 - val_acc: 0.4444\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.1459 - acc: 0.5000 - val_loss: 1.1162 - val_acc: 0.4444\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.2573 - acc: 0.4135 - val_loss: 1.1036 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.2948 - acc: 0.4519 - val_loss: 1.0949 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0923 - acc: 0.5096 - val_loss: 1.0916 - val_acc: 0.4074\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0797 - acc: 0.4808 - val_loss: 1.0794 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 440us/sample - loss: 1.1820 - acc: 0.4808 - val_loss: 1.0660 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 1.1042 - acc: 0.4615 - val_loss: 1.0545 - val_acc: 0.5185\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.1305 - acc: 0.5288 - val_loss: 1.0516 - val_acc: 0.5185\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0700 - acc: 0.4712 - val_loss: 1.0477 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1564 - acc: 0.4519 - val_loss: 1.0360 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.1400 - acc: 0.4904 - val_loss: 1.0332 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0509 - acc: 0.5000 - val_loss: 1.0319 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.1051 - acc: 0.4327 - val_loss: 1.0252 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 414us/sample - loss: 1.0211 - acc: 0.5385 - val_loss: 1.0273 - val_acc: 0.5556\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0707 - acc: 0.4808 - val_loss: 1.0258 - val_acc: 0.5556\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0635 - acc: 0.4615 - val_loss: 1.0240 - val_acc: 0.5556\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 422us/sample - loss: 1.0914 - acc: 0.4712 - val_loss: 1.0201 - val_acc: 0.5926\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0200 - acc: 0.5288 - val_loss: 1.0199 - val_acc: 0.5926\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0637 - acc: 0.4904 - val_loss: 1.0187 - val_acc: 0.5926\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9762 - acc: 0.5288 - val_loss: 1.0181 - val_acc: 0.5926\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0356 - acc: 0.4615 - val_loss: 1.0139 - val_acc: 0.5556\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9838 - acc: 0.4808 - val_loss: 1.0101 - val_acc: 0.5556\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0337 - acc: 0.4712 - val_loss: 1.0085 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0083 - acc: 0.5096 - val_loss: 1.0084 - val_acc: 0.5556\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0363 - acc: 0.4904 - val_loss: 1.0099 - val_acc: 0.5556\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9755 - acc: 0.5000 - val_loss: 1.0089 - val_acc: 0.5926\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9881 - acc: 0.5385 - val_loss: 1.0093 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 285us/sample - loss: 1.0194 - acc: 0.4904 - val_loss: 1.0059 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0494 - acc: 0.4327 - val_loss: 0.9976 - val_acc: 0.5556\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9706 - acc: 0.5000 - val_loss: 0.9970 - val_acc: 0.5926\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0075 - acc: 0.5192 - val_loss: 0.9981 - val_acc: 0.5926\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9692 - acc: 0.5288 - val_loss: 0.9994 - val_acc: 0.5556\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1067 - acc: 0.4423 - val_loss: 0.9981 - val_acc: 0.5556\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0797 - acc: 0.4038 - val_loss: 0.9933 - val_acc: 0.5556\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0439 - acc: 0.4615 - val_loss: 0.9936 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9957 - acc: 0.5192 - val_loss: 0.9972 - val_acc: 0.5556\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9876 - acc: 0.5288 - val_loss: 0.9998 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0311 - acc: 0.4808 - val_loss: 0.9970 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.0126 - acc: 0.5000 - val_loss: 0.9943 - val_acc: 0.5926\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0069 - acc: 0.4327 - val_loss: 0.9890 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.0257 - acc: 0.4808 - val_loss: 0.9887 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0209 - acc: 0.4808 - val_loss: 0.9901 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0052 - acc: 0.4904 - val_loss: 0.9885 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0260 - acc: 0.4519 - val_loss: 0.9844 - val_acc: 0.5556\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0386 - acc: 0.4712 - val_loss: 0.9844 - val_acc: 0.5926\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9786 - acc: 0.5000 - val_loss: 0.9842 - val_acc: 0.5926\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0034 - acc: 0.4904 - val_loss: 0.9800 - val_acc: 0.5926\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9937 - acc: 0.4712 - val_loss: 0.9813 - val_acc: 0.5926\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9774 - acc: 0.4615 - val_loss: 0.9808 - val_acc: 0.5926\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 415us/sample - loss: 0.9801 - acc: 0.4712 - val_loss: 0.9773 - val_acc: 0.6296\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9791 - acc: 0.4904 - val_loss: 0.9760 - val_acc: 0.6296\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9980 - acc: 0.4615 - val_loss: 0.9743 - val_acc: 0.6296\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0040 - acc: 0.4808 - val_loss: 0.9743 - val_acc: 0.5926\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9770 - acc: 0.4904 - val_loss: 0.9765 - val_acc: 0.5926\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0379 - acc: 0.4423 - val_loss: 0.9782 - val_acc: 0.5926\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0066 - acc: 0.4808 - val_loss: 0.9781 - val_acc: 0.6296\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0343 - acc: 0.4712 - val_loss: 0.9821 - val_acc: 0.5926\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9761 - acc: 0.5192 - val_loss: 0.9824 - val_acc: 0.5926\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9973 - acc: 0.4808 - val_loss: 0.9827 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9978 - acc: 0.4519 - val_loss: 0.9789 - val_acc: 0.6296\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0256 - acc: 0.4519 - val_loss: 0.9813 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9987 - acc: 0.4519 - val_loss: 0.9800 - val_acc: 0.6296\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0278 - acc: 0.4615 - val_loss: 0.9790 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0035 - acc: 0.4712 - val_loss: 0.9772 - val_acc: 0.6296\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9680 - acc: 0.5096 - val_loss: 0.9774 - val_acc: 0.6296\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0010 - acc: 0.4712 - val_loss: 0.9763 - val_acc: 0.6296\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9769 - acc: 0.4904 - val_loss: 0.9774 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 431us/sample - loss: 1.0250 - acc: 0.4519 - val_loss: 0.9772 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 442us/sample - loss: 0.9930 - acc: 0.4423 - val_loss: 0.9759 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9630 - acc: 0.4904 - val_loss: 0.9766 - val_acc: 0.5926\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9947 - acc: 0.4519 - val_loss: 0.9751 - val_acc: 0.6296\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9910 - acc: 0.4519 - val_loss: 0.9745 - val_acc: 0.6296\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0011 - acc: 0.4423 - val_loss: 0.9749 - val_acc: 0.6296\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9437 - acc: 0.5192 - val_loss: 0.9744 - val_acc: 0.6296\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9954 - acc: 0.4808 - val_loss: 0.9729 - val_acc: 0.6296\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9896 - acc: 0.4808 - val_loss: 0.9735 - val_acc: 0.6296\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9720 - acc: 0.4808 - val_loss: 0.9742 - val_acc: 0.6296\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9852 - acc: 0.4615 - val_loss: 0.9733 - val_acc: 0.6296\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.6967 - acc: 0.3846 - val_loss: 2.2242 - val_acc: 0.2963\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 2.0225 - acc: 0.4038 - val_loss: 2.0574 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 2.3093 - acc: 0.4615 - val_loss: 1.8864 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.6699 - acc: 0.4519 - val_loss: 1.8184 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 2.0003 - acc: 0.4615 - val_loss: 1.6613 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.8226 - acc: 0.3846 - val_loss: 1.6029 - val_acc: 0.4074\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.2473 - acc: 0.5096 - val_loss: 1.5376 - val_acc: 0.4074\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.1780 - acc: 0.5000 - val_loss: 1.5172 - val_acc: 0.4444\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.5415 - acc: 0.4423 - val_loss: 1.4440 - val_acc: 0.4444\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.4523 - acc: 0.4231 - val_loss: 1.3676 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.4608 - acc: 0.3750 - val_loss: 1.2739 - val_acc: 0.4815\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.3510 - acc: 0.4327 - val_loss: 1.1830 - val_acc: 0.4444\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1760 - acc: 0.4327 - val_loss: 1.1652 - val_acc: 0.4815\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.1820 - acc: 0.4135 - val_loss: 1.1331 - val_acc: 0.3333\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.2221 - acc: 0.4327 - val_loss: 1.1104 - val_acc: 0.3704\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0999 - acc: 0.4615 - val_loss: 1.0995 - val_acc: 0.3333\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0847 - acc: 0.4615 - val_loss: 1.0920 - val_acc: 0.4074\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0836 - acc: 0.4712 - val_loss: 1.1015 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.1848 - acc: 0.5000 - val_loss: 1.1115 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 389us/sample - loss: 1.0694 - acc: 0.4904 - val_loss: 1.1098 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1673 - acc: 0.4135 - val_loss: 1.1009 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0137 - acc: 0.5000 - val_loss: 1.0895 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0872 - acc: 0.4615 - val_loss: 1.0918 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0723 - acc: 0.5096 - val_loss: 1.0669 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 1.1025 - acc: 0.4519 - val_loss: 1.0641 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0449 - acc: 0.4519 - val_loss: 1.0545 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.1282 - acc: 0.4327 - val_loss: 1.0629 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0465 - acc: 0.4615 - val_loss: 1.0566 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.1255 - acc: 0.4231 - val_loss: 1.0635 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.0410 - acc: 0.4808 - val_loss: 1.0517 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0296 - acc: 0.4712 - val_loss: 1.0479 - val_acc: 0.4815\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0683 - acc: 0.3942 - val_loss: 1.0495 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0167 - acc: 0.4327 - val_loss: 1.0411 - val_acc: 0.4815\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0878 - acc: 0.4423 - val_loss: 1.0273 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0137 - acc: 0.4904 - val_loss: 1.0257 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0905 - acc: 0.4808 - val_loss: 1.0291 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0787 - acc: 0.4327 - val_loss: 1.0339 - val_acc: 0.4444\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0426 - acc: 0.4038 - val_loss: 1.0329 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0461 - acc: 0.4423 - val_loss: 1.0243 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0404 - acc: 0.4808 - val_loss: 1.0405 - val_acc: 0.4444\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1008 - acc: 0.3558 - val_loss: 1.0201 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0807 - acc: 0.4712 - val_loss: 1.0346 - val_acc: 0.4074\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0364 - acc: 0.4808 - val_loss: 1.0361 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0503 - acc: 0.4327 - val_loss: 1.0238 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0534 - acc: 0.4135 - val_loss: 1.0170 - val_acc: 0.5556\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0652 - acc: 0.4327 - val_loss: 1.0172 - val_acc: 0.5556\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 416us/sample - loss: 1.0313 - acc: 0.4231 - val_loss: 1.0263 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0138 - acc: 0.4808 - val_loss: 1.0248 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0353 - acc: 0.4423 - val_loss: 1.0141 - val_acc: 0.4074\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0870 - acc: 0.4615 - val_loss: 0.9948 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0369 - acc: 0.4423 - val_loss: 1.0024 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0312 - acc: 0.4327 - val_loss: 0.9973 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0389 - acc: 0.4038 - val_loss: 0.9998 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0419 - acc: 0.4038 - val_loss: 1.0063 - val_acc: 0.4815\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0499 - acc: 0.4231 - val_loss: 1.0024 - val_acc: 0.4444\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 1.0245 - acc: 0.4423 - val_loss: 1.0090 - val_acc: 0.4444\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.0387 - acc: 0.3942 - val_loss: 1.0101 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0509 - acc: 0.4327 - val_loss: 1.0123 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 288us/sample - loss: 0.9913 - acc: 0.5096 - val_loss: 1.0148 - val_acc: 0.3333\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 288us/sample - loss: 1.0270 - acc: 0.4327 - val_loss: 1.0049 - val_acc: 0.4074\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0306 - acc: 0.4135 - val_loss: 1.0033 - val_acc: 0.4815\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0139 - acc: 0.4519 - val_loss: 1.0114 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0450 - acc: 0.4519 - val_loss: 1.0126 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0457 - acc: 0.4327 - val_loss: 0.9905 - val_acc: 0.4815\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0468 - acc: 0.4423 - val_loss: 0.9966 - val_acc: 0.4815\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0028 - acc: 0.4519 - val_loss: 1.0044 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0278 - acc: 0.4615 - val_loss: 1.0186 - val_acc: 0.4074\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.0176 - acc: 0.4712 - val_loss: 1.0184 - val_acc: 0.3704\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9885 - acc: 0.4615 - val_loss: 1.0236 - val_acc: 0.4444\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0501 - acc: 0.4135 - val_loss: 1.0095 - val_acc: 0.4444\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0125 - acc: 0.4327 - val_loss: 1.0083 - val_acc: 0.4444\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0223 - acc: 0.5000 - val_loss: 1.0110 - val_acc: 0.4815\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0481 - acc: 0.4327 - val_loss: 0.9943 - val_acc: 0.4444\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0135 - acc: 0.4615 - val_loss: 1.0059 - val_acc: 0.4815\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9952 - acc: 0.4519 - val_loss: 1.0086 - val_acc: 0.4815\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9952 - acc: 0.4327 - val_loss: 1.0037 - val_acc: 0.4815\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0288 - acc: 0.4519 - val_loss: 0.9996 - val_acc: 0.4815\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 0.9988 - acc: 0.4808 - val_loss: 1.0035 - val_acc: 0.3704\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 0.9999 - acc: 0.4519 - val_loss: 1.0055 - val_acc: 0.4444\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9700 - acc: 0.4712 - val_loss: 1.0048 - val_acc: 0.4815\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0563 - acc: 0.4904 - val_loss: 0.9913 - val_acc: 0.4815\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0533 - acc: 0.4712 - val_loss: 0.9847 - val_acc: 0.3704\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0251 - acc: 0.4038 - val_loss: 0.9883 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0076 - acc: 0.5000 - val_loss: 0.9930 - val_acc: 0.4074\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0306 - acc: 0.4135 - val_loss: 0.9846 - val_acc: 0.4444\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0492 - acc: 0.4423 - val_loss: 0.9859 - val_acc: 0.4815\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0084 - acc: 0.4327 - val_loss: 0.9915 - val_acc: 0.4815\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9940 - acc: 0.4712 - val_loss: 1.0009 - val_acc: 0.3333\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9993 - acc: 0.4904 - val_loss: 1.0084 - val_acc: 0.4444\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0474 - acc: 0.4615 - val_loss: 0.9835 - val_acc: 0.4444\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0035 - acc: 0.5288 - val_loss: 0.9875 - val_acc: 0.4815\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0001 - acc: 0.4423 - val_loss: 0.9921 - val_acc: 0.4815\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9686 - acc: 0.4423 - val_loss: 0.9963 - val_acc: 0.4444\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0218 - acc: 0.4423 - val_loss: 0.9848 - val_acc: 0.4815\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0085 - acc: 0.4423 - val_loss: 0.9961 - val_acc: 0.4444\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0055 - acc: 0.4327 - val_loss: 0.9927 - val_acc: 0.4815\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0307 - acc: 0.4519 - val_loss: 1.0019 - val_acc: 0.4815\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0233 - acc: 0.4519 - val_loss: 0.9850 - val_acc: 0.4815\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0263 - acc: 0.4615 - val_loss: 0.9890 - val_acc: 0.4815\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.0387 - acc: 0.4519 - val_loss: 0.9879 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.2989 - acc: 0.3942 - val_loss: 2.6587 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 4.4286 - acc: 0.3846 - val_loss: 2.3459 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 2.8453 - acc: 0.4231 - val_loss: 2.2175 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 2.9717 - acc: 0.4615 - val_loss: 2.0458 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 2.4982 - acc: 0.4423 - val_loss: 1.9343 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 2.7821 - acc: 0.3942 - val_loss: 1.8031 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 2.2849 - acc: 0.4231 - val_loss: 1.6915 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.9914 - acc: 0.4231 - val_loss: 1.6312 - val_acc: 0.4074\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 2.3185 - acc: 0.4231 - val_loss: 1.5814 - val_acc: 0.3704\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 2.3898 - acc: 0.4135 - val_loss: 1.5123 - val_acc: 0.4074\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.7077 - acc: 0.4808 - val_loss: 1.4795 - val_acc: 0.4444\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 1.8319 - acc: 0.4519 - val_loss: 1.4469 - val_acc: 0.4815\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.4677 - acc: 0.4808 - val_loss: 1.4269 - val_acc: 0.4815\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.6412 - acc: 0.5000 - val_loss: 1.3977 - val_acc: 0.4815\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.7066 - acc: 0.4327 - val_loss: 1.3584 - val_acc: 0.4815\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.8065 - acc: 0.4327 - val_loss: 1.3388 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.5858 - acc: 0.4231 - val_loss: 1.3090 - val_acc: 0.5185\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.4880 - acc: 0.5000 - val_loss: 1.2967 - val_acc: 0.5185\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.2186 - acc: 0.5673 - val_loss: 1.2863 - val_acc: 0.5185\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.2555 - acc: 0.4231 - val_loss: 1.2817 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.6200 - acc: 0.4904 - val_loss: 1.2656 - val_acc: 0.5556\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.3926 - acc: 0.5000 - val_loss: 1.2438 - val_acc: 0.5556\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 1.2101 - acc: 0.5000 - val_loss: 1.2327 - val_acc: 0.5556\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.3108 - acc: 0.4615 - val_loss: 1.2223 - val_acc: 0.5556\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1582 - acc: 0.5000 - val_loss: 1.2208 - val_acc: 0.5556\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.2979 - acc: 0.4615 - val_loss: 1.2044 - val_acc: 0.5556\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.3470 - acc: 0.5096 - val_loss: 1.1855 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.2251 - acc: 0.4712 - val_loss: 1.1757 - val_acc: 0.5556\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.3605 - acc: 0.4423 - val_loss: 1.1718 - val_acc: 0.5556\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.2033 - acc: 0.4904 - val_loss: 1.1634 - val_acc: 0.5556\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.0812 - acc: 0.5769 - val_loss: 1.1548 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2691 - acc: 0.5192 - val_loss: 1.1440 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1352 - acc: 0.5385 - val_loss: 1.1415 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0009 - acc: 0.5096 - val_loss: 1.1406 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 1.1341 - acc: 0.5096 - val_loss: 1.1367 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1582 - acc: 0.4615 - val_loss: 1.1326 - val_acc: 0.5556\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.0756 - acc: 0.4519 - val_loss: 1.1268 - val_acc: 0.5556\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.2542 - acc: 0.3846 - val_loss: 1.1170 - val_acc: 0.5556\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2147 - acc: 0.4135 - val_loss: 1.1098 - val_acc: 0.5185\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9780 - acc: 0.5385 - val_loss: 1.1076 - val_acc: 0.5185\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0906 - acc: 0.5000 - val_loss: 1.1053 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1665 - acc: 0.5096 - val_loss: 1.0976 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0513 - acc: 0.4904 - val_loss: 1.0924 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 1.0307 - acc: 0.5096 - val_loss: 1.0868 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0596 - acc: 0.5192 - val_loss: 1.0832 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.1331 - acc: 0.4327 - val_loss: 1.0793 - val_acc: 0.4815\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0403 - acc: 0.4904 - val_loss: 1.0760 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0008 - acc: 0.5192 - val_loss: 1.0752 - val_acc: 0.4815\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0747 - acc: 0.4808 - val_loss: 1.0745 - val_acc: 0.4815\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0296 - acc: 0.5192 - val_loss: 1.0716 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 1.0021 - acc: 0.4904 - val_loss: 1.0699 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0580 - acc: 0.4712 - val_loss: 1.0675 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0899 - acc: 0.4904 - val_loss: 1.0663 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0481 - acc: 0.4615 - val_loss: 1.0627 - val_acc: 0.4815\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0920 - acc: 0.4712 - val_loss: 1.0557 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0398 - acc: 0.5096 - val_loss: 1.0531 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0495 - acc: 0.4808 - val_loss: 1.0544 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0919 - acc: 0.4615 - val_loss: 1.0528 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9938 - acc: 0.5192 - val_loss: 1.0493 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 798us/sample - loss: 0.9848 - acc: 0.5096 - val_loss: 1.0482 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 437us/sample - loss: 1.1010 - acc: 0.4712 - val_loss: 1.0436 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0022 - acc: 0.4712 - val_loss: 1.0411 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0281 - acc: 0.5000 - val_loss: 1.0425 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0664 - acc: 0.4423 - val_loss: 1.0391 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0486 - acc: 0.4615 - val_loss: 1.0369 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9847 - acc: 0.5192 - val_loss: 1.0357 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0653 - acc: 0.4327 - val_loss: 1.0301 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9498 - acc: 0.5096 - val_loss: 1.0290 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0589 - acc: 0.5288 - val_loss: 1.0329 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.0018 - acc: 0.5192 - val_loss: 1.0313 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.0766 - acc: 0.4712 - val_loss: 1.0298 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9822 - acc: 0.5096 - val_loss: 1.0295 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0102 - acc: 0.4519 - val_loss: 1.0285 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9747 - acc: 0.4808 - val_loss: 1.0255 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 1.0241 - acc: 0.4615 - val_loss: 1.0228 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0261 - acc: 0.4327 - val_loss: 1.0197 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 295us/sample - loss: 0.9700 - acc: 0.4712 - val_loss: 1.0203 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9807 - acc: 0.4808 - val_loss: 1.0196 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 0.9982 - acc: 0.5000 - val_loss: 1.0220 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0435 - acc: 0.4327 - val_loss: 1.0215 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9510 - acc: 0.5000 - val_loss: 1.0214 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9770 - acc: 0.5000 - val_loss: 1.0183 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0164 - acc: 0.5096 - val_loss: 1.0177 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0218 - acc: 0.5385 - val_loss: 1.0162 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9820 - acc: 0.5769 - val_loss: 1.0146 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9861 - acc: 0.4808 - val_loss: 1.0147 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0363 - acc: 0.5385 - val_loss: 1.0159 - val_acc: 0.5556\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9734 - acc: 0.5288 - val_loss: 1.0179 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 448us/sample - loss: 1.0047 - acc: 0.5288 - val_loss: 1.0159 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0538 - acc: 0.4615 - val_loss: 1.0152 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9593 - acc: 0.5000 - val_loss: 1.0152 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9461 - acc: 0.5288 - val_loss: 1.0152 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9780 - acc: 0.5865 - val_loss: 1.0119 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 1.0044 - acc: 0.4519 - val_loss: 1.0129 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0217 - acc: 0.4327 - val_loss: 1.0143 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9641 - acc: 0.5192 - val_loss: 1.0156 - val_acc: 0.4815\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9665 - acc: 0.5192 - val_loss: 1.0147 - val_acc: 0.4815\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9974 - acc: 0.4808 - val_loss: 1.0135 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9476 - acc: 0.5288 - val_loss: 1.0156 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9768 - acc: 0.5192 - val_loss: 1.0154 - val_acc: 0.4815\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 3.5545 - acc: 0.3846 - val_loss: 1.6963 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 3.1104 - acc: 0.5000 - val_loss: 1.6090 - val_acc: 0.2963\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 2.1345 - acc: 0.4327 - val_loss: 1.5042 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.7439 - acc: 0.4423 - val_loss: 1.4605 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 2.5094 - acc: 0.4135 - val_loss: 1.3941 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 2.6467 - acc: 0.4423 - val_loss: 1.3791 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.4758 - acc: 0.4615 - val_loss: 1.3897 - val_acc: 0.4815\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.8045 - acc: 0.4231 - val_loss: 1.3658 - val_acc: 0.4815\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.9095 - acc: 0.4423 - val_loss: 1.3564 - val_acc: 0.5185\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.5999 - acc: 0.4423 - val_loss: 1.3343 - val_acc: 0.5185\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.4712 - acc: 0.4808 - val_loss: 1.3495 - val_acc: 0.5556\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.3798 - acc: 0.4712 - val_loss: 1.3114 - val_acc: 0.5556\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.5357 - acc: 0.4231 - val_loss: 1.2741 - val_acc: 0.5185\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.3460 - acc: 0.4231 - val_loss: 1.2682 - val_acc: 0.5185\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.2052 - acc: 0.4808 - val_loss: 1.2884 - val_acc: 0.5185\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.4957 - acc: 0.4615 - val_loss: 1.2549 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.3309 - acc: 0.4808 - val_loss: 1.2480 - val_acc: 0.5185\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.2639 - acc: 0.4808 - val_loss: 1.2462 - val_acc: 0.5185\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.3779 - acc: 0.4327 - val_loss: 1.2425 - val_acc: 0.5185\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1401 - acc: 0.5096 - val_loss: 1.2176 - val_acc: 0.5556\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1576 - acc: 0.4808 - val_loss: 1.1928 - val_acc: 0.5556\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 290us/sample - loss: 1.1349 - acc: 0.4808 - val_loss: 1.1732 - val_acc: 0.5185\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.1687 - acc: 0.4423 - val_loss: 1.1638 - val_acc: 0.5556\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9979 - acc: 0.5192 - val_loss: 1.1728 - val_acc: 0.5185\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.1479 - acc: 0.4519 - val_loss: 1.1630 - val_acc: 0.5556\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0094 - acc: 0.5288 - val_loss: 1.1556 - val_acc: 0.5556\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9501 - acc: 0.5288 - val_loss: 1.1479 - val_acc: 0.5185\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.2794 - acc: 0.4038 - val_loss: 1.1164 - val_acc: 0.5185\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1591 - acc: 0.5385 - val_loss: 1.1036 - val_acc: 0.5556\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0044 - acc: 0.5096 - val_loss: 1.0981 - val_acc: 0.5556\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0805 - acc: 0.5096 - val_loss: 1.0839 - val_acc: 0.4815\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0095 - acc: 0.5000 - val_loss: 1.0792 - val_acc: 0.4815\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9959 - acc: 0.5000 - val_loss: 1.0735 - val_acc: 0.5185\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0351 - acc: 0.5096 - val_loss: 1.0649 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0441 - acc: 0.5000 - val_loss: 1.0710 - val_acc: 0.4815\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0621 - acc: 0.5000 - val_loss: 1.0774 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0233 - acc: 0.4904 - val_loss: 1.0657 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9312 - acc: 0.5481 - val_loss: 1.0721 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0399 - acc: 0.4808 - val_loss: 1.0690 - val_acc: 0.5185\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9419 - acc: 0.5481 - val_loss: 1.0758 - val_acc: 0.5185\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0136 - acc: 0.5000 - val_loss: 1.0752 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0664 - acc: 0.5385 - val_loss: 1.0670 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0593 - acc: 0.4808 - val_loss: 1.0593 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9993 - acc: 0.5673 - val_loss: 1.0662 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0001 - acc: 0.5000 - val_loss: 1.0584 - val_acc: 0.4815\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0409 - acc: 0.4712 - val_loss: 1.0473 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9927 - acc: 0.5288 - val_loss: 1.0474 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0059 - acc: 0.5673 - val_loss: 1.0419 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 412us/sample - loss: 1.0111 - acc: 0.5000 - val_loss: 1.0386 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0365 - acc: 0.5000 - val_loss: 1.0287 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0546 - acc: 0.4904 - val_loss: 1.0250 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 0.9922 - acc: 0.5577 - val_loss: 1.0336 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0394 - acc: 0.4615 - val_loss: 1.0250 - val_acc: 0.5556\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9863 - acc: 0.5096 - val_loss: 1.0248 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9911 - acc: 0.5577 - val_loss: 1.0274 - val_acc: 0.5556\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9805 - acc: 0.5288 - val_loss: 1.0285 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9303 - acc: 0.5769 - val_loss: 1.0357 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0093 - acc: 0.4904 - val_loss: 1.0296 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9918 - acc: 0.4712 - val_loss: 1.0258 - val_acc: 0.4815\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0246 - acc: 0.4712 - val_loss: 1.0205 - val_acc: 0.4815\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9887 - acc: 0.5288 - val_loss: 1.0227 - val_acc: 0.5556\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0015 - acc: 0.5096 - val_loss: 1.0187 - val_acc: 0.4815\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9680 - acc: 0.5481 - val_loss: 1.0172 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 420us/sample - loss: 1.0472 - acc: 0.4519 - val_loss: 1.0079 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9916 - acc: 0.5000 - val_loss: 1.0120 - val_acc: 0.4815\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9917 - acc: 0.5000 - val_loss: 1.0111 - val_acc: 0.4815\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9695 - acc: 0.5481 - val_loss: 1.0126 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9692 - acc: 0.5288 - val_loss: 1.0136 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9708 - acc: 0.5192 - val_loss: 1.0144 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9682 - acc: 0.5096 - val_loss: 1.0121 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9784 - acc: 0.5288 - val_loss: 1.0134 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9819 - acc: 0.5192 - val_loss: 1.0161 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 0.9815 - acc: 0.4808 - val_loss: 1.0176 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9995 - acc: 0.5000 - val_loss: 1.0195 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9876 - acc: 0.4904 - val_loss: 1.0155 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9783 - acc: 0.5000 - val_loss: 1.0152 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9435 - acc: 0.5385 - val_loss: 1.0164 - val_acc: 0.5556\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9853 - acc: 0.4904 - val_loss: 1.0203 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9694 - acc: 0.5865 - val_loss: 1.0258 - val_acc: 0.4815\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 0.9933 - acc: 0.5288 - val_loss: 1.0221 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9848 - acc: 0.4904 - val_loss: 1.0134 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0008 - acc: 0.5192 - val_loss: 1.0123 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9927 - acc: 0.5000 - val_loss: 1.0093 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9363 - acc: 0.5385 - val_loss: 1.0102 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9747 - acc: 0.5192 - val_loss: 1.0125 - val_acc: 0.5556\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0163 - acc: 0.4712 - val_loss: 1.0119 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9748 - acc: 0.5000 - val_loss: 1.0125 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9699 - acc: 0.4904 - val_loss: 1.0110 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9740 - acc: 0.5577 - val_loss: 1.0181 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9574 - acc: 0.5673 - val_loss: 1.0221 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0135 - acc: 0.4135 - val_loss: 1.0153 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0091 - acc: 0.4808 - val_loss: 1.0135 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.0009 - acc: 0.5000 - val_loss: 1.0109 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9772 - acc: 0.5385 - val_loss: 1.0125 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9742 - acc: 0.5096 - val_loss: 1.0124 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9933 - acc: 0.4808 - val_loss: 1.0136 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 0.9673 - acc: 0.5192 - val_loss: 1.0101 - val_acc: 0.5556\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 408us/sample - loss: 0.9599 - acc: 0.5288 - val_loss: 1.0142 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9790 - acc: 0.4808 - val_loss: 1.0097 - val_acc: 0.5556\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9854 - acc: 0.5096 - val_loss: 1.0059 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 995us/sample - loss: 4.9744 - acc: 0.4038 - val_loss: 3.2203 - val_acc: 0.1111\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 3.0729 - acc: 0.3750 - val_loss: 2.6341 - val_acc: 0.1111\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 3.2672 - acc: 0.3750 - val_loss: 2.2784 - val_acc: 0.1111\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 2.9694 - acc: 0.3654 - val_loss: 1.9117 - val_acc: 0.1111\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 2.1628 - acc: 0.3654 - val_loss: 1.6996 - val_acc: 0.2222\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 2.0530 - acc: 0.3846 - val_loss: 1.5902 - val_acc: 0.2593\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.5216 - acc: 0.4712 - val_loss: 1.5374 - val_acc: 0.2593\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.6200 - acc: 0.3942 - val_loss: 1.4767 - val_acc: 0.2963\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.6360 - acc: 0.4038 - val_loss: 1.4225 - val_acc: 0.3333\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.4795 - acc: 0.4327 - val_loss: 1.3642 - val_acc: 0.3333\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.5132 - acc: 0.4038 - val_loss: 1.3208 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.4692 - acc: 0.4231 - val_loss: 1.2798 - val_acc: 0.3333\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.5359 - acc: 0.3173 - val_loss: 1.2562 - val_acc: 0.4444\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.6675 - acc: 0.3942 - val_loss: 1.2117 - val_acc: 0.4444\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.4726 - acc: 0.4038 - val_loss: 1.1955 - val_acc: 0.4074\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.3883 - acc: 0.4712 - val_loss: 1.1697 - val_acc: 0.4074\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.3425 - acc: 0.4231 - val_loss: 1.1545 - val_acc: 0.4074\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.3092 - acc: 0.4038 - val_loss: 1.1266 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 1.3094 - acc: 0.3942 - val_loss: 1.1070 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.1659 - acc: 0.4904 - val_loss: 1.0999 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.2067 - acc: 0.4231 - val_loss: 1.0783 - val_acc: 0.5185\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1113 - acc: 0.4038 - val_loss: 1.0663 - val_acc: 0.5185\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0887 - acc: 0.4712 - val_loss: 1.0620 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.2709 - acc: 0.3462 - val_loss: 1.0649 - val_acc: 0.4074\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.1881 - acc: 0.3942 - val_loss: 1.0549 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1241 - acc: 0.4808 - val_loss: 1.0448 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.1863 - acc: 0.4423 - val_loss: 1.0340 - val_acc: 0.4815\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.1352 - acc: 0.4423 - val_loss: 1.0247 - val_acc: 0.5556\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1576 - acc: 0.4519 - val_loss: 1.0129 - val_acc: 0.5926\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1062 - acc: 0.4615 - val_loss: 1.0038 - val_acc: 0.5926\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.1737 - acc: 0.3846 - val_loss: 1.0040 - val_acc: 0.5926\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.2226 - acc: 0.4327 - val_loss: 0.9974 - val_acc: 0.5926\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.1416 - acc: 0.4038 - val_loss: 0.9986 - val_acc: 0.6296\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.2029 - acc: 0.4135 - val_loss: 1.0021 - val_acc: 0.6296\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.1186 - acc: 0.4231 - val_loss: 1.0049 - val_acc: 0.6296\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.1125 - acc: 0.4327 - val_loss: 1.0045 - val_acc: 0.6296\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.0569 - acc: 0.4615 - val_loss: 1.0049 - val_acc: 0.6296\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0541 - acc: 0.4519 - val_loss: 1.0068 - val_acc: 0.6296\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0483 - acc: 0.4712 - val_loss: 1.0044 - val_acc: 0.6296\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0291 - acc: 0.4904 - val_loss: 0.9965 - val_acc: 0.6296\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0623 - acc: 0.4135 - val_loss: 0.9985 - val_acc: 0.6296\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0800 - acc: 0.4038 - val_loss: 1.0007 - val_acc: 0.5926\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0368 - acc: 0.4615 - val_loss: 0.9941 - val_acc: 0.6296\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0336 - acc: 0.4423 - val_loss: 0.9927 - val_acc: 0.6296\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0340 - acc: 0.4423 - val_loss: 0.9925 - val_acc: 0.6296\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 421us/sample - loss: 1.0286 - acc: 0.4519 - val_loss: 0.9933 - val_acc: 0.5926\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 1.0262 - acc: 0.4327 - val_loss: 0.9884 - val_acc: 0.5926\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9783 - acc: 0.4904 - val_loss: 0.9830 - val_acc: 0.5926\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0386 - acc: 0.4712 - val_loss: 0.9828 - val_acc: 0.5556\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.0327 - acc: 0.4423 - val_loss: 0.9868 - val_acc: 0.5926\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0522 - acc: 0.4423 - val_loss: 0.9896 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0297 - acc: 0.4519 - val_loss: 0.9903 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0388 - acc: 0.4423 - val_loss: 0.9897 - val_acc: 0.5556\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.0172 - acc: 0.4615 - val_loss: 0.9912 - val_acc: 0.4815\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9765 - acc: 0.4712 - val_loss: 0.9872 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0191 - acc: 0.4904 - val_loss: 0.9872 - val_acc: 0.4815\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9919 - acc: 0.4904 - val_loss: 0.9832 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0188 - acc: 0.4231 - val_loss: 0.9846 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0087 - acc: 0.4712 - val_loss: 0.9831 - val_acc: 0.4815\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0237 - acc: 0.4712 - val_loss: 0.9811 - val_acc: 0.4815\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9845 - acc: 0.4423 - val_loss: 0.9802 - val_acc: 0.4815\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0186 - acc: 0.4615 - val_loss: 0.9799 - val_acc: 0.4815\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0071 - acc: 0.5000 - val_loss: 0.9791 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0056 - acc: 0.4423 - val_loss: 0.9778 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0051 - acc: 0.5096 - val_loss: 0.9758 - val_acc: 0.6296\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0100 - acc: 0.4519 - val_loss: 0.9788 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0021 - acc: 0.5096 - val_loss: 0.9762 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9365 - acc: 0.5000 - val_loss: 0.9735 - val_acc: 0.5926\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 749us/sample - loss: 1.0266 - acc: 0.5192 - val_loss: 0.9717 - val_acc: 0.7037\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0208 - acc: 0.4808 - val_loss: 0.9718 - val_acc: 0.6296\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 442us/sample - loss: 0.9669 - acc: 0.4808 - val_loss: 0.9707 - val_acc: 0.6296\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0216 - acc: 0.5000 - val_loss: 0.9703 - val_acc: 0.6296\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0071 - acc: 0.4423 - val_loss: 0.9725 - val_acc: 0.6296\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.0122 - acc: 0.4808 - val_loss: 0.9739 - val_acc: 0.6296\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0022 - acc: 0.4904 - val_loss: 0.9707 - val_acc: 0.5926\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0023 - acc: 0.4615 - val_loss: 0.9707 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9996 - acc: 0.4904 - val_loss: 0.9715 - val_acc: 0.6667\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9860 - acc: 0.4808 - val_loss: 0.9725 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9953 - acc: 0.4808 - val_loss: 0.9728 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9794 - acc: 0.5000 - val_loss: 0.9715 - val_acc: 0.6296\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0197 - acc: 0.4808 - val_loss: 0.9696 - val_acc: 0.6296\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0122 - acc: 0.4615 - val_loss: 0.9709 - val_acc: 0.6296\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9993 - acc: 0.4519 - val_loss: 0.9699 - val_acc: 0.5556\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9914 - acc: 0.5000 - val_loss: 0.9692 - val_acc: 0.6296\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0046 - acc: 0.4615 - val_loss: 0.9716 - val_acc: 0.5556\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9898 - acc: 0.4519 - val_loss: 0.9698 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9860 - acc: 0.4712 - val_loss: 0.9683 - val_acc: 0.5556\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0094 - acc: 0.4615 - val_loss: 0.9691 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0056 - acc: 0.4423 - val_loss: 0.9677 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9967 - acc: 0.4904 - val_loss: 0.9673 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0053 - acc: 0.4519 - val_loss: 0.9686 - val_acc: 0.5556\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9652 - acc: 0.4808 - val_loss: 0.9689 - val_acc: 0.5556\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0081 - acc: 0.4808 - val_loss: 0.9679 - val_acc: 0.6667\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9997 - acc: 0.4615 - val_loss: 0.9672 - val_acc: 0.5926\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9962 - acc: 0.4327 - val_loss: 0.9708 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0000 - acc: 0.4808 - val_loss: 0.9703 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0075 - acc: 0.4327 - val_loss: 0.9709 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0084 - acc: 0.4423 - val_loss: 0.9718 - val_acc: 0.4815\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 0.9812 - acc: 0.5000 - val_loss: 0.9708 - val_acc: 0.4815\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0131 - acc: 0.4615 - val_loss: 0.9710 - val_acc: 0.4815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: dc215e4b529e22ca959cc7b30f2022be</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.6074074506759644</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 2ms/sample - loss: 2.3728 - acc: 0.4712 - val_loss: 2.4368 - val_acc: 0.4074\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 456us/sample - loss: 2.0673 - acc: 0.4615 - val_loss: 2.2120 - val_acc: 0.4444\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 2.0072 - acc: 0.4519 - val_loss: 2.0285 - val_acc: 0.4074\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.6954 - acc: 0.4904 - val_loss: 1.8928 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.7590 - acc: 0.4423 - val_loss: 1.7792 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.5715 - acc: 0.4615 - val_loss: 1.6951 - val_acc: 0.4074\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.4962 - acc: 0.4519 - val_loss: 1.6241 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 396us/sample - loss: 1.5005 - acc: 0.4327 - val_loss: 1.5508 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 413us/sample - loss: 1.4377 - acc: 0.3942 - val_loss: 1.5062 - val_acc: 0.3704\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 438us/sample - loss: 1.4308 - acc: 0.3846 - val_loss: 1.4608 - val_acc: 0.4074\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 1.3307 - acc: 0.4327 - val_loss: 1.4117 - val_acc: 0.4074\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.3403 - acc: 0.4135 - val_loss: 1.3753 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.2718 - acc: 0.4135 - val_loss: 1.3444 - val_acc: 0.4444\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.2157 - acc: 0.4519 - val_loss: 1.3309 - val_acc: 0.4444\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.2894 - acc: 0.4038 - val_loss: 1.3053 - val_acc: 0.4444\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.2582 - acc: 0.4423 - val_loss: 1.2858 - val_acc: 0.4444\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.2197 - acc: 0.4231 - val_loss: 1.2651 - val_acc: 0.4444\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.1349 - acc: 0.4327 - val_loss: 1.2569 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 1.1522 - acc: 0.4615 - val_loss: 1.2510 - val_acc: 0.4815\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.1378 - acc: 0.4231 - val_loss: 1.2375 - val_acc: 0.4815\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.1726 - acc: 0.4231 - val_loss: 1.2201 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.1048 - acc: 0.4038 - val_loss: 1.2054 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.1035 - acc: 0.4231 - val_loss: 1.1952 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.1628 - acc: 0.4327 - val_loss: 1.1841 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0822 - acc: 0.5000 - val_loss: 1.1699 - val_acc: 0.4815\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0698 - acc: 0.5000 - val_loss: 1.1655 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0845 - acc: 0.5096 - val_loss: 1.1510 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0489 - acc: 0.5481 - val_loss: 1.1405 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0850 - acc: 0.5000 - val_loss: 1.1324 - val_acc: 0.4815\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0790 - acc: 0.5192 - val_loss: 1.1227 - val_acc: 0.4815\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9963 - acc: 0.5192 - val_loss: 1.1186 - val_acc: 0.4815\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0389 - acc: 0.5288 - val_loss: 1.1141 - val_acc: 0.4815\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0194 - acc: 0.5577 - val_loss: 1.1067 - val_acc: 0.4815\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 506us/sample - loss: 1.0390 - acc: 0.5288 - val_loss: 1.1020 - val_acc: 0.5185\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0049 - acc: 0.5673 - val_loss: 1.0986 - val_acc: 0.5185\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9965 - acc: 0.5481 - val_loss: 1.0979 - val_acc: 0.5185\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0027 - acc: 0.5288 - val_loss: 1.0959 - val_acc: 0.5185\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0183 - acc: 0.5288 - val_loss: 1.0910 - val_acc: 0.5185\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9791 - acc: 0.5481 - val_loss: 1.0892 - val_acc: 0.5185\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.0068 - acc: 0.5673 - val_loss: 1.0848 - val_acc: 0.5185\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 412us/sample - loss: 0.9978 - acc: 0.5577 - val_loss: 1.0812 - val_acc: 0.5185\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9762 - acc: 0.5481 - val_loss: 1.0805 - val_acc: 0.5185\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0175 - acc: 0.5385 - val_loss: 1.0791 - val_acc: 0.5185\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9711 - acc: 0.5769 - val_loss: 1.0775 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9853 - acc: 0.5865 - val_loss: 1.0734 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9759 - acc: 0.5673 - val_loss: 1.0707 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9929 - acc: 0.5577 - val_loss: 1.0663 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9813 - acc: 0.5481 - val_loss: 1.0628 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0136 - acc: 0.5385 - val_loss: 1.0586 - val_acc: 0.5556\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9606 - acc: 0.5673 - val_loss: 1.0560 - val_acc: 0.5556\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0023 - acc: 0.5096 - val_loss: 1.0533 - val_acc: 0.5556\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9707 - acc: 0.5385 - val_loss: 1.0546 - val_acc: 0.5556\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9926 - acc: 0.5000 - val_loss: 1.0527 - val_acc: 0.5556\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9742 - acc: 0.5385 - val_loss: 1.0506 - val_acc: 0.5556\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9997 - acc: 0.4712 - val_loss: 1.0476 - val_acc: 0.5556\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9651 - acc: 0.5192 - val_loss: 1.0448 - val_acc: 0.5556\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9631 - acc: 0.5096 - val_loss: 1.0427 - val_acc: 0.5556\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9590 - acc: 0.5577 - val_loss: 1.0432 - val_acc: 0.5556\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9396 - acc: 0.5577 - val_loss: 1.0430 - val_acc: 0.5556\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9569 - acc: 0.5288 - val_loss: 1.0415 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9736 - acc: 0.5096 - val_loss: 1.0379 - val_acc: 0.5556\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9685 - acc: 0.5192 - val_loss: 1.0362 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9598 - acc: 0.5481 - val_loss: 1.0351 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9645 - acc: 0.5096 - val_loss: 1.0335 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9450 - acc: 0.5288 - val_loss: 1.0316 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9076 - acc: 0.5385 - val_loss: 1.0326 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9737 - acc: 0.5288 - val_loss: 1.0305 - val_acc: 0.5556\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9527 - acc: 0.5288 - val_loss: 1.0286 - val_acc: 0.5556\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9173 - acc: 0.5769 - val_loss: 1.0297 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9414 - acc: 0.5673 - val_loss: 1.0281 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9498 - acc: 0.5673 - val_loss: 1.0263 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9335 - acc: 0.5481 - val_loss: 1.0244 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9746 - acc: 0.5192 - val_loss: 1.0219 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 394us/sample - loss: 0.9251 - acc: 0.5577 - val_loss: 1.0222 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 0.9577 - acc: 0.5385 - val_loss: 1.0205 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9477 - acc: 0.5481 - val_loss: 1.0196 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9648 - acc: 0.5288 - val_loss: 1.0182 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9635 - acc: 0.5192 - val_loss: 1.0155 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 0.9286 - acc: 0.5192 - val_loss: 1.0157 - val_acc: 0.5926\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9382 - acc: 0.5385 - val_loss: 1.0139 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9278 - acc: 0.5481 - val_loss: 1.0135 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9412 - acc: 0.5385 - val_loss: 1.0119 - val_acc: 0.5926\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9452 - acc: 0.5192 - val_loss: 1.0103 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9392 - acc: 0.5288 - val_loss: 1.0098 - val_acc: 0.5926\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9321 - acc: 0.5288 - val_loss: 1.0093 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9572 - acc: 0.5000 - val_loss: 1.0077 - val_acc: 0.5926\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9639 - acc: 0.5096 - val_loss: 1.0056 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9542 - acc: 0.4904 - val_loss: 1.0054 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9381 - acc: 0.5192 - val_loss: 1.0042 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 0.9329 - acc: 0.5192 - val_loss: 1.0038 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9257 - acc: 0.5769 - val_loss: 1.0038 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9392 - acc: 0.4904 - val_loss: 1.0029 - val_acc: 0.5926\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 0.9422 - acc: 0.5481 - val_loss: 1.0017 - val_acc: 0.5926\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9338 - acc: 0.5577 - val_loss: 1.0019 - val_acc: 0.5926\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9148 - acc: 0.5481 - val_loss: 1.0019 - val_acc: 0.5926\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9289 - acc: 0.5288 - val_loss: 1.0013 - val_acc: 0.5926\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9435 - acc: 0.5192 - val_loss: 1.0002 - val_acc: 0.5926\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9395 - acc: 0.5481 - val_loss: 1.0000 - val_acc: 0.5926\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9344 - acc: 0.5192 - val_loss: 1.0008 - val_acc: 0.5926\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9017 - acc: 0.5673 - val_loss: 1.0014 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 999us/sample - loss: 1.7347 - acc: 0.4327 - val_loss: 1.8243 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 1.4486 - acc: 0.4615 - val_loss: 1.6824 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.4688 - acc: 0.4038 - val_loss: 1.5454 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.3589 - acc: 0.3942 - val_loss: 1.4248 - val_acc: 0.3333\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.3536 - acc: 0.4038 - val_loss: 1.3158 - val_acc: 0.2963\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1490 - acc: 0.4135 - val_loss: 1.2492 - val_acc: 0.3333\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.1837 - acc: 0.4712 - val_loss: 1.1886 - val_acc: 0.3704\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0756 - acc: 0.4808 - val_loss: 1.1362 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1176 - acc: 0.5000 - val_loss: 1.0913 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0880 - acc: 0.5000 - val_loss: 1.0667 - val_acc: 0.4074\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0086 - acc: 0.5000 - val_loss: 1.0511 - val_acc: 0.4074\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 1.0364 - acc: 0.4904 - val_loss: 1.0438 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0338 - acc: 0.4904 - val_loss: 1.0357 - val_acc: 0.4074\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0618 - acc: 0.4712 - val_loss: 1.0352 - val_acc: 0.5185\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0323 - acc: 0.4615 - val_loss: 1.0337 - val_acc: 0.5185\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 0.9956 - acc: 0.4808 - val_loss: 1.0335 - val_acc: 0.5185\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0536 - acc: 0.4231 - val_loss: 1.0311 - val_acc: 0.5185\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0145 - acc: 0.5000 - val_loss: 1.0346 - val_acc: 0.5185\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.0229 - acc: 0.4808 - val_loss: 1.0355 - val_acc: 0.5556\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0341 - acc: 0.5096 - val_loss: 1.0395 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0203 - acc: 0.5096 - val_loss: 1.0406 - val_acc: 0.5556\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0065 - acc: 0.5192 - val_loss: 1.0423 - val_acc: 0.5185\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0006 - acc: 0.5481 - val_loss: 1.0452 - val_acc: 0.5556\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9802 - acc: 0.5385 - val_loss: 1.0451 - val_acc: 0.5556\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9787 - acc: 0.5288 - val_loss: 1.0469 - val_acc: 0.5556\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9503 - acc: 0.5769 - val_loss: 1.0489 - val_acc: 0.5556\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9986 - acc: 0.5577 - val_loss: 1.0542 - val_acc: 0.5556\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9450 - acc: 0.5769 - val_loss: 1.0575 - val_acc: 0.5556\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9814 - acc: 0.5577 - val_loss: 1.0601 - val_acc: 0.5556\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9783 - acc: 0.5192 - val_loss: 1.0601 - val_acc: 0.5556\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9713 - acc: 0.5865 - val_loss: 1.0619 - val_acc: 0.5556\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0023 - acc: 0.5673 - val_loss: 1.0617 - val_acc: 0.5556\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9668 - acc: 0.5769 - val_loss: 1.0665 - val_acc: 0.5556\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9679 - acc: 0.5481 - val_loss: 1.0681 - val_acc: 0.5556\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9811 - acc: 0.5288 - val_loss: 1.0692 - val_acc: 0.5556\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9626 - acc: 0.5673 - val_loss: 1.0734 - val_acc: 0.5556\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0003 - acc: 0.5673 - val_loss: 1.0687 - val_acc: 0.5556\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9390 - acc: 0.5962 - val_loss: 1.0711 - val_acc: 0.5556\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9521 - acc: 0.5962 - val_loss: 1.0716 - val_acc: 0.5556\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9423 - acc: 0.5673 - val_loss: 1.0722 - val_acc: 0.5556\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9489 - acc: 0.6058 - val_loss: 1.0737 - val_acc: 0.5556\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9531 - acc: 0.5769 - val_loss: 1.0752 - val_acc: 0.5556\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9428 - acc: 0.5769 - val_loss: 1.0783 - val_acc: 0.5556\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9482 - acc: 0.6058 - val_loss: 1.0805 - val_acc: 0.5556\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9505 - acc: 0.5865 - val_loss: 1.0812 - val_acc: 0.5556\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9595 - acc: 0.5769 - val_loss: 1.0817 - val_acc: 0.5556\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9253 - acc: 0.5962 - val_loss: 1.0827 - val_acc: 0.5556\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9306 - acc: 0.5769 - val_loss: 1.0845 - val_acc: 0.5556\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9243 - acc: 0.6250 - val_loss: 1.0885 - val_acc: 0.5556\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9657 - acc: 0.5673 - val_loss: 1.0896 - val_acc: 0.5556\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9266 - acc: 0.5962 - val_loss: 1.0865 - val_acc: 0.5556\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 0.9434 - acc: 0.5769 - val_loss: 1.0852 - val_acc: 0.5556\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9248 - acc: 0.6154 - val_loss: 1.0871 - val_acc: 0.5556\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9616 - acc: 0.5769 - val_loss: 1.0854 - val_acc: 0.5556\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9193 - acc: 0.5865 - val_loss: 1.0897 - val_acc: 0.5556\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9431 - acc: 0.6154 - val_loss: 1.0908 - val_acc: 0.5556\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9218 - acc: 0.6154 - val_loss: 1.0925 - val_acc: 0.5556\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9301 - acc: 0.5673 - val_loss: 1.0938 - val_acc: 0.5556\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9146 - acc: 0.6154 - val_loss: 1.0995 - val_acc: 0.5556\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9393 - acc: 0.5865 - val_loss: 1.0964 - val_acc: 0.5556\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9343 - acc: 0.5673 - val_loss: 1.0947 - val_acc: 0.5556\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9258 - acc: 0.5673 - val_loss: 1.0963 - val_acc: 0.5556\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9454 - acc: 0.5577 - val_loss: 1.0958 - val_acc: 0.5556\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9249 - acc: 0.5577 - val_loss: 1.0938 - val_acc: 0.5556\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.8975 - acc: 0.5769 - val_loss: 1.0934 - val_acc: 0.5556\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9067 - acc: 0.5769 - val_loss: 1.0903 - val_acc: 0.5556\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.8937 - acc: 0.6154 - val_loss: 1.0921 - val_acc: 0.5556\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9307 - acc: 0.5769 - val_loss: 1.0915 - val_acc: 0.5556\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9271 - acc: 0.5865 - val_loss: 1.0923 - val_acc: 0.5556\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9137 - acc: 0.5769 - val_loss: 1.0937 - val_acc: 0.5556\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.8900 - acc: 0.6154 - val_loss: 1.0981 - val_acc: 0.5556\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9163 - acc: 0.5962 - val_loss: 1.0995 - val_acc: 0.5556\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.8987 - acc: 0.5865 - val_loss: 1.1009 - val_acc: 0.5556\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9262 - acc: 0.5673 - val_loss: 1.0990 - val_acc: 0.5556\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9316 - acc: 0.5577 - val_loss: 1.0964 - val_acc: 0.5556\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9280 - acc: 0.5962 - val_loss: 1.0969 - val_acc: 0.5556\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9084 - acc: 0.6058 - val_loss: 1.1005 - val_acc: 0.5556\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9290 - acc: 0.5769 - val_loss: 1.1024 - val_acc: 0.5556\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9165 - acc: 0.5962 - val_loss: 1.1020 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9395 - acc: 0.5673 - val_loss: 1.1022 - val_acc: 0.5556\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.8983 - acc: 0.5865 - val_loss: 1.1024 - val_acc: 0.5556\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9176 - acc: 0.5865 - val_loss: 1.1060 - val_acc: 0.5556\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9142 - acc: 0.5865 - val_loss: 1.1061 - val_acc: 0.5556\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9077 - acc: 0.6058 - val_loss: 1.1049 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9144 - acc: 0.6058 - val_loss: 1.1056 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.8956 - acc: 0.5962 - val_loss: 1.1056 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.8973 - acc: 0.6058 - val_loss: 1.1051 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9023 - acc: 0.6058 - val_loss: 1.1058 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.8988 - acc: 0.5865 - val_loss: 1.1092 - val_acc: 0.5556\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9057 - acc: 0.5865 - val_loss: 1.1108 - val_acc: 0.5556\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9203 - acc: 0.5769 - val_loss: 1.1088 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9014 - acc: 0.5962 - val_loss: 1.1095 - val_acc: 0.5556\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9089 - acc: 0.6058 - val_loss: 1.1114 - val_acc: 0.5556\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9165 - acc: 0.5769 - val_loss: 1.1110 - val_acc: 0.5556\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.8983 - acc: 0.5962 - val_loss: 1.1115 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.8995 - acc: 0.6250 - val_loss: 1.1124 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9128 - acc: 0.5577 - val_loss: 1.1100 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9254 - acc: 0.5769 - val_loss: 1.1092 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.8931 - acc: 0.6154 - val_loss: 1.1114 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 0.8943 - acc: 0.5962 - val_loss: 1.1139 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.6563 - acc: 0.3173 - val_loss: 1.5269 - val_acc: 0.4444\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.5881 - acc: 0.2885 - val_loss: 1.4527 - val_acc: 0.4444\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.4494 - acc: 0.3558 - val_loss: 1.4031 - val_acc: 0.4444\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.3865 - acc: 0.3846 - val_loss: 1.3560 - val_acc: 0.4444\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.2945 - acc: 0.3942 - val_loss: 1.3255 - val_acc: 0.4444\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.2493 - acc: 0.4135 - val_loss: 1.2909 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.2245 - acc: 0.4327 - val_loss: 1.2648 - val_acc: 0.4444\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.2440 - acc: 0.4423 - val_loss: 1.2338 - val_acc: 0.4444\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.2079 - acc: 0.4423 - val_loss: 1.2100 - val_acc: 0.4444\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 294us/sample - loss: 1.2125 - acc: 0.4519 - val_loss: 1.1876 - val_acc: 0.4444\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.1590 - acc: 0.4327 - val_loss: 1.1735 - val_acc: 0.4074\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.1505 - acc: 0.4519 - val_loss: 1.1577 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.1466 - acc: 0.4423 - val_loss: 1.1481 - val_acc: 0.3333\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0729 - acc: 0.4904 - val_loss: 1.1434 - val_acc: 0.3333\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 1.0932 - acc: 0.4231 - val_loss: 1.1325 - val_acc: 0.3333\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0713 - acc: 0.4615 - val_loss: 1.1235 - val_acc: 0.3333\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0842 - acc: 0.4712 - val_loss: 1.1105 - val_acc: 0.3333\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0398 - acc: 0.5192 - val_loss: 1.1031 - val_acc: 0.3333\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0401 - acc: 0.5096 - val_loss: 1.0981 - val_acc: 0.3333\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.0058 - acc: 0.5192 - val_loss: 1.0913 - val_acc: 0.3333\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 1.0655 - acc: 0.4904 - val_loss: 1.0792 - val_acc: 0.3333\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0258 - acc: 0.5192 - val_loss: 1.0678 - val_acc: 0.3333\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0513 - acc: 0.4519 - val_loss: 1.0612 - val_acc: 0.3333\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 451us/sample - loss: 1.0001 - acc: 0.5096 - val_loss: 1.0604 - val_acc: 0.3333\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0013 - acc: 0.5000 - val_loss: 1.0538 - val_acc: 0.3333\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0324 - acc: 0.4808 - val_loss: 1.0487 - val_acc: 0.3704\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9855 - acc: 0.5481 - val_loss: 1.0486 - val_acc: 0.3704\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 1.0245 - acc: 0.5385 - val_loss: 1.0478 - val_acc: 0.3704\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0108 - acc: 0.5096 - val_loss: 1.0410 - val_acc: 0.3704\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9932 - acc: 0.5192 - val_loss: 1.0373 - val_acc: 0.4074\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9970 - acc: 0.5096 - val_loss: 1.0325 - val_acc: 0.4074\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9930 - acc: 0.5385 - val_loss: 1.0297 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 0.9594 - acc: 0.5865 - val_loss: 1.0304 - val_acc: 0.3704\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9643 - acc: 0.5481 - val_loss: 1.0237 - val_acc: 0.3704\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9947 - acc: 0.5000 - val_loss: 1.0184 - val_acc: 0.3333\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0057 - acc: 0.4615 - val_loss: 1.0186 - val_acc: 0.3333\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9784 - acc: 0.5385 - val_loss: 1.0154 - val_acc: 0.3333\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9696 - acc: 0.5385 - val_loss: 1.0108 - val_acc: 0.3333\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0052 - acc: 0.5096 - val_loss: 1.0093 - val_acc: 0.3333\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9490 - acc: 0.5673 - val_loss: 1.0014 - val_acc: 0.3704\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9618 - acc: 0.5385 - val_loss: 1.0029 - val_acc: 0.3704\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9527 - acc: 0.5288 - val_loss: 1.0014 - val_acc: 0.3704\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9607 - acc: 0.5673 - val_loss: 1.0026 - val_acc: 0.3704\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9469 - acc: 0.5385 - val_loss: 0.9994 - val_acc: 0.3704\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9349 - acc: 0.5481 - val_loss: 1.0010 - val_acc: 0.3704\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9429 - acc: 0.5481 - val_loss: 0.9933 - val_acc: 0.3704\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9866 - acc: 0.4904 - val_loss: 0.9909 - val_acc: 0.3704\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9618 - acc: 0.5000 - val_loss: 0.9868 - val_acc: 0.3704\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9550 - acc: 0.5577 - val_loss: 0.9874 - val_acc: 0.3704\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9373 - acc: 0.5192 - val_loss: 0.9905 - val_acc: 0.3704\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9444 - acc: 0.5288 - val_loss: 0.9855 - val_acc: 0.3704\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9976 - acc: 0.5288 - val_loss: 0.9823 - val_acc: 0.3704\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9648 - acc: 0.5000 - val_loss: 0.9770 - val_acc: 0.4074\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9435 - acc: 0.4904 - val_loss: 0.9740 - val_acc: 0.4074\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9547 - acc: 0.5096 - val_loss: 0.9753 - val_acc: 0.4074\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9583 - acc: 0.5096 - val_loss: 0.9706 - val_acc: 0.4074\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9430 - acc: 0.5192 - val_loss: 0.9692 - val_acc: 0.4074\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9588 - acc: 0.5000 - val_loss: 0.9693 - val_acc: 0.3704\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9396 - acc: 0.5385 - val_loss: 0.9678 - val_acc: 0.3704\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9420 - acc: 0.5192 - val_loss: 0.9660 - val_acc: 0.4074\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 0.9355 - acc: 0.5288 - val_loss: 0.9629 - val_acc: 0.4074\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9308 - acc: 0.5769 - val_loss: 0.9692 - val_acc: 0.4074\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.8991 - acc: 0.5673 - val_loss: 0.9747 - val_acc: 0.4074\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 0.9310 - acc: 0.5288 - val_loss: 0.9703 - val_acc: 0.3704\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9435 - acc: 0.5385 - val_loss: 0.9670 - val_acc: 0.4074\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0066 - acc: 0.4712 - val_loss: 0.9625 - val_acc: 0.4074\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9354 - acc: 0.5192 - val_loss: 0.9615 - val_acc: 0.4074\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.8965 - acc: 0.5673 - val_loss: 0.9627 - val_acc: 0.3704\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9238 - acc: 0.5385 - val_loss: 0.9641 - val_acc: 0.3704\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9330 - acc: 0.5192 - val_loss: 0.9630 - val_acc: 0.3704\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9348 - acc: 0.5481 - val_loss: 0.9609 - val_acc: 0.3704\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9444 - acc: 0.5096 - val_loss: 0.9571 - val_acc: 0.3704\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9305 - acc: 0.5288 - val_loss: 0.9567 - val_acc: 0.3704\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9534 - acc: 0.5385 - val_loss: 0.9566 - val_acc: 0.4074\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9065 - acc: 0.5577 - val_loss: 0.9554 - val_acc: 0.4074\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9261 - acc: 0.5481 - val_loss: 0.9553 - val_acc: 0.4074\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9191 - acc: 0.5577 - val_loss: 0.9578 - val_acc: 0.4074\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.8976 - acc: 0.5673 - val_loss: 0.9552 - val_acc: 0.4074\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9534 - acc: 0.5288 - val_loss: 0.9506 - val_acc: 0.4074\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9249 - acc: 0.5481 - val_loss: 0.9548 - val_acc: 0.4074\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9244 - acc: 0.5481 - val_loss: 0.9558 - val_acc: 0.4074\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9049 - acc: 0.5673 - val_loss: 0.9533 - val_acc: 0.4074\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9206 - acc: 0.5577 - val_loss: 0.9513 - val_acc: 0.4074\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9071 - acc: 0.5577 - val_loss: 0.9525 - val_acc: 0.4074\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.8967 - acc: 0.5577 - val_loss: 0.9500 - val_acc: 0.4074\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9043 - acc: 0.5577 - val_loss: 0.9460 - val_acc: 0.4074\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9042 - acc: 0.5673 - val_loss: 0.9472 - val_acc: 0.4074\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.8885 - acc: 0.5769 - val_loss: 0.9483 - val_acc: 0.4074\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9490 - acc: 0.5192 - val_loss: 0.9489 - val_acc: 0.4074\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.8848 - acc: 0.5481 - val_loss: 0.9499 - val_acc: 0.4074\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.8876 - acc: 0.5288 - val_loss: 0.9510 - val_acc: 0.4074\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9216 - acc: 0.5288 - val_loss: 0.9474 - val_acc: 0.4074\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.8887 - acc: 0.5288 - val_loss: 0.9451 - val_acc: 0.4074\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9230 - acc: 0.5288 - val_loss: 0.9437 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 468us/sample - loss: 0.8872 - acc: 0.5673 - val_loss: 0.9487 - val_acc: 0.4074\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9037 - acc: 0.5385 - val_loss: 0.9429 - val_acc: 0.4444\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9156 - acc: 0.5481 - val_loss: 0.9429 - val_acc: 0.4444\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 0.8764 - acc: 0.5962 - val_loss: 0.9435 - val_acc: 0.4444\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9074 - acc: 0.5769 - val_loss: 0.9428 - val_acc: 0.4444\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9145 - acc: 0.5385 - val_loss: 0.9393 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.4986 - acc: 0.4423 - val_loss: 1.3978 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.6299 - acc: 0.4808 - val_loss: 1.3742 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.5522 - acc: 0.4904 - val_loss: 1.3552 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.4741 - acc: 0.4808 - val_loss: 1.3325 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.3513 - acc: 0.4712 - val_loss: 1.3168 - val_acc: 0.3704\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.3305 - acc: 0.4712 - val_loss: 1.2976 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.3688 - acc: 0.4712 - val_loss: 1.2748 - val_acc: 0.3333\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 1.4512 - acc: 0.4327 - val_loss: 1.2504 - val_acc: 0.3333\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.2886 - acc: 0.5096 - val_loss: 1.2398 - val_acc: 0.3333\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2224 - acc: 0.5096 - val_loss: 1.2250 - val_acc: 0.3333\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.2287 - acc: 0.4712 - val_loss: 1.2109 - val_acc: 0.3333\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1736 - acc: 0.4904 - val_loss: 1.1999 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0919 - acc: 0.4712 - val_loss: 1.1978 - val_acc: 0.4074\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1711 - acc: 0.5096 - val_loss: 1.1873 - val_acc: 0.4074\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1951 - acc: 0.4615 - val_loss: 1.1769 - val_acc: 0.4074\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.1433 - acc: 0.4615 - val_loss: 1.1645 - val_acc: 0.4074\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.1629 - acc: 0.5288 - val_loss: 1.1538 - val_acc: 0.4074\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 298us/sample - loss: 1.1471 - acc: 0.5192 - val_loss: 1.1453 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0950 - acc: 0.5192 - val_loss: 1.1417 - val_acc: 0.4074\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.1125 - acc: 0.5288 - val_loss: 1.1364 - val_acc: 0.4074\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0710 - acc: 0.5385 - val_loss: 1.1296 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0743 - acc: 0.5096 - val_loss: 1.1200 - val_acc: 0.4074\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0597 - acc: 0.5096 - val_loss: 1.1162 - val_acc: 0.4074\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9962 - acc: 0.5577 - val_loss: 1.1170 - val_acc: 0.4074\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0179 - acc: 0.5577 - val_loss: 1.1140 - val_acc: 0.4074\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0469 - acc: 0.5288 - val_loss: 1.1096 - val_acc: 0.4074\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0336 - acc: 0.5096 - val_loss: 1.1052 - val_acc: 0.4074\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0285 - acc: 0.5385 - val_loss: 1.1037 - val_acc: 0.4074\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0811 - acc: 0.5192 - val_loss: 1.0997 - val_acc: 0.4074\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9835 - acc: 0.5481 - val_loss: 1.0994 - val_acc: 0.4074\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0126 - acc: 0.5385 - val_loss: 1.0987 - val_acc: 0.4074\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9890 - acc: 0.5385 - val_loss: 1.0958 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9888 - acc: 0.5673 - val_loss: 1.0965 - val_acc: 0.4074\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 1.0191 - acc: 0.5192 - val_loss: 1.0939 - val_acc: 0.4074\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9896 - acc: 0.5192 - val_loss: 1.0921 - val_acc: 0.4074\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.9829 - acc: 0.5096 - val_loss: 1.0933 - val_acc: 0.4074\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9890 - acc: 0.5288 - val_loss: 1.0935 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0115 - acc: 0.5096 - val_loss: 1.0929 - val_acc: 0.4074\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9645 - acc: 0.5481 - val_loss: 1.0916 - val_acc: 0.4074\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9621 - acc: 0.5385 - val_loss: 1.0879 - val_acc: 0.4074\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 397us/sample - loss: 1.0464 - acc: 0.4904 - val_loss: 1.0855 - val_acc: 0.4074\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9834 - acc: 0.4904 - val_loss: 1.0824 - val_acc: 0.4074\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9879 - acc: 0.5288 - val_loss: 1.0791 - val_acc: 0.4074\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9834 - acc: 0.5096 - val_loss: 1.0779 - val_acc: 0.4074\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9789 - acc: 0.5385 - val_loss: 1.0770 - val_acc: 0.4074\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.9634 - acc: 0.5385 - val_loss: 1.0758 - val_acc: 0.4074\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9788 - acc: 0.5288 - val_loss: 1.0764 - val_acc: 0.4074\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9659 - acc: 0.5481 - val_loss: 1.0751 - val_acc: 0.4074\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9657 - acc: 0.5288 - val_loss: 1.0726 - val_acc: 0.4074\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9616 - acc: 0.5288 - val_loss: 1.0729 - val_acc: 0.4074\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9603 - acc: 0.5385 - val_loss: 1.0706 - val_acc: 0.4074\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9483 - acc: 0.5288 - val_loss: 1.0722 - val_acc: 0.4074\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9744 - acc: 0.5192 - val_loss: 1.0726 - val_acc: 0.4074\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9381 - acc: 0.5481 - val_loss: 1.0716 - val_acc: 0.4074\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9661 - acc: 0.5192 - val_loss: 1.0711 - val_acc: 0.4074\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9700 - acc: 0.5385 - val_loss: 1.0695 - val_acc: 0.4074\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9526 - acc: 0.5385 - val_loss: 1.0680 - val_acc: 0.4074\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9491 - acc: 0.5577 - val_loss: 1.0676 - val_acc: 0.4074\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9336 - acc: 0.5481 - val_loss: 1.0686 - val_acc: 0.4074\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 0.9544 - acc: 0.5288 - val_loss: 1.0685 - val_acc: 0.4074\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9581 - acc: 0.5769 - val_loss: 1.0691 - val_acc: 0.4074\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9395 - acc: 0.5577 - val_loss: 1.0689 - val_acc: 0.4074\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9409 - acc: 0.5577 - val_loss: 1.0702 - val_acc: 0.4074\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9256 - acc: 0.5673 - val_loss: 1.0697 - val_acc: 0.3704\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 437us/sample - loss: 0.9329 - acc: 0.5673 - val_loss: 1.0701 - val_acc: 0.3704\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9757 - acc: 0.5192 - val_loss: 1.0689 - val_acc: 0.3704\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9556 - acc: 0.5673 - val_loss: 1.0674 - val_acc: 0.3704\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9467 - acc: 0.5481 - val_loss: 1.0653 - val_acc: 0.3704\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9273 - acc: 0.5481 - val_loss: 1.0648 - val_acc: 0.3704\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9673 - acc: 0.5096 - val_loss: 1.0656 - val_acc: 0.3704\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9440 - acc: 0.5481 - val_loss: 1.0662 - val_acc: 0.3704\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 0.9369 - acc: 0.5577 - val_loss: 1.0672 - val_acc: 0.3704\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9593 - acc: 0.5096 - val_loss: 1.0667 - val_acc: 0.3704\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9272 - acc: 0.5385 - val_loss: 1.0665 - val_acc: 0.3704\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9406 - acc: 0.5288 - val_loss: 1.0678 - val_acc: 0.3704\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9222 - acc: 0.5577 - val_loss: 1.0691 - val_acc: 0.3704\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9199 - acc: 0.5673 - val_loss: 1.0716 - val_acc: 0.3704\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9771 - acc: 0.5096 - val_loss: 1.0692 - val_acc: 0.3704\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9745 - acc: 0.5385 - val_loss: 1.0698 - val_acc: 0.3704\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9175 - acc: 0.5385 - val_loss: 1.0709 - val_acc: 0.3704\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9195 - acc: 0.5673 - val_loss: 1.0719 - val_acc: 0.3704\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 0.9449 - acc: 0.5577 - val_loss: 1.0721 - val_acc: 0.3704\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9338 - acc: 0.5673 - val_loss: 1.0737 - val_acc: 0.4074\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9211 - acc: 0.5385 - val_loss: 1.0758 - val_acc: 0.4074\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9180 - acc: 0.5385 - val_loss: 1.0773 - val_acc: 0.4074\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9196 - acc: 0.5673 - val_loss: 1.0782 - val_acc: 0.4074\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.8959 - acc: 0.5865 - val_loss: 1.0794 - val_acc: 0.4074\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9199 - acc: 0.5481 - val_loss: 1.0787 - val_acc: 0.3704\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9241 - acc: 0.5288 - val_loss: 1.0789 - val_acc: 0.3704\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9212 - acc: 0.5385 - val_loss: 1.0794 - val_acc: 0.3704\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9175 - acc: 0.5769 - val_loss: 1.0806 - val_acc: 0.4074\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9336 - acc: 0.5192 - val_loss: 1.0813 - val_acc: 0.4074\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9343 - acc: 0.5481 - val_loss: 1.0819 - val_acc: 0.4074\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9452 - acc: 0.5192 - val_loss: 1.0812 - val_acc: 0.4074\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 0.9311 - acc: 0.5865 - val_loss: 1.0830 - val_acc: 0.4074\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9258 - acc: 0.5481 - val_loss: 1.0842 - val_acc: 0.4074\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.9354 - acc: 0.5481 - val_loss: 1.0833 - val_acc: 0.3704\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9638 - acc: 0.5192 - val_loss: 1.0834 - val_acc: 0.3704\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.9147 - acc: 0.5769 - val_loss: 1.0844 - val_acc: 0.3704\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9165 - acc: 0.5481 - val_loss: 1.0855 - val_acc: 0.4074\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.7020 - acc: 0.4038 - val_loss: 1.3082 - val_acc: 0.5185\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.6047 - acc: 0.4423 - val_loss: 1.2661 - val_acc: 0.5185\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.4322 - acc: 0.4712 - val_loss: 1.2447 - val_acc: 0.4815\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.3126 - acc: 0.4904 - val_loss: 1.2338 - val_acc: 0.5185\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.2244 - acc: 0.5000 - val_loss: 1.2230 - val_acc: 0.5185\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.2840 - acc: 0.4808 - val_loss: 1.2139 - val_acc: 0.5185\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 1.2348 - acc: 0.4519 - val_loss: 1.2030 - val_acc: 0.5185\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.1940 - acc: 0.4808 - val_loss: 1.1856 - val_acc: 0.4815\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.1697 - acc: 0.4712 - val_loss: 1.1777 - val_acc: 0.4815\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.2023 - acc: 0.4808 - val_loss: 1.1668 - val_acc: 0.5185\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.1096 - acc: 0.4808 - val_loss: 1.1576 - val_acc: 0.5185\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0746 - acc: 0.5288 - val_loss: 1.1502 - val_acc: 0.5185\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.1017 - acc: 0.5192 - val_loss: 1.1411 - val_acc: 0.5185\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0574 - acc: 0.4519 - val_loss: 1.1334 - val_acc: 0.5185\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1084 - acc: 0.4904 - val_loss: 1.1251 - val_acc: 0.4815\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0685 - acc: 0.5096 - val_loss: 1.1191 - val_acc: 0.5185\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0264 - acc: 0.5000 - val_loss: 1.1139 - val_acc: 0.5185\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0646 - acc: 0.5192 - val_loss: 1.1077 - val_acc: 0.5185\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0212 - acc: 0.5192 - val_loss: 1.1028 - val_acc: 0.5556\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0773 - acc: 0.4712 - val_loss: 1.0982 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9764 - acc: 0.5192 - val_loss: 1.0976 - val_acc: 0.5185\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9855 - acc: 0.5192 - val_loss: 1.0946 - val_acc: 0.5556\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0243 - acc: 0.4712 - val_loss: 1.0958 - val_acc: 0.5556\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.0158 - acc: 0.4712 - val_loss: 1.0949 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9580 - acc: 0.5096 - val_loss: 1.0995 - val_acc: 0.4815\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0108 - acc: 0.4808 - val_loss: 1.0993 - val_acc: 0.5185\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0002 - acc: 0.5000 - val_loss: 1.0986 - val_acc: 0.5185\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9734 - acc: 0.5288 - val_loss: 1.0991 - val_acc: 0.5185\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 1.0322 - acc: 0.4904 - val_loss: 1.0981 - val_acc: 0.5185\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9828 - acc: 0.4904 - val_loss: 1.0987 - val_acc: 0.5185\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0130 - acc: 0.5000 - val_loss: 1.0958 - val_acc: 0.5185\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 416us/sample - loss: 0.9714 - acc: 0.5192 - val_loss: 1.0983 - val_acc: 0.5185\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0295 - acc: 0.4904 - val_loss: 1.0971 - val_acc: 0.5185\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0284 - acc: 0.5000 - val_loss: 1.0968 - val_acc: 0.4815\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9897 - acc: 0.5096 - val_loss: 1.0984 - val_acc: 0.4815\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9398 - acc: 0.5577 - val_loss: 1.1012 - val_acc: 0.4815\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9943 - acc: 0.5000 - val_loss: 1.1019 - val_acc: 0.4815\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9614 - acc: 0.5481 - val_loss: 1.1018 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9956 - acc: 0.4904 - val_loss: 1.1059 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9941 - acc: 0.5000 - val_loss: 1.1057 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 446us/sample - loss: 0.9502 - acc: 0.5481 - val_loss: 1.1073 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9570 - acc: 0.5385 - val_loss: 1.1092 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9614 - acc: 0.5481 - val_loss: 1.1115 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 0.9744 - acc: 0.5288 - val_loss: 1.1092 - val_acc: 0.4815\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9903 - acc: 0.5288 - val_loss: 1.1080 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9530 - acc: 0.5385 - val_loss: 1.1077 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9912 - acc: 0.5000 - val_loss: 1.1056 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9738 - acc: 0.5000 - val_loss: 1.1064 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 393us/sample - loss: 0.9292 - acc: 0.5577 - val_loss: 1.1056 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9398 - acc: 0.5192 - val_loss: 1.1100 - val_acc: 0.5185\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9593 - acc: 0.5000 - val_loss: 1.1112 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9490 - acc: 0.5385 - val_loss: 1.1113 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9459 - acc: 0.5481 - val_loss: 1.1118 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9588 - acc: 0.5000 - val_loss: 1.1124 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9883 - acc: 0.4615 - val_loss: 1.1125 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9326 - acc: 0.5481 - val_loss: 1.1143 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9546 - acc: 0.5288 - val_loss: 1.1155 - val_acc: 0.5185\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9846 - acc: 0.5000 - val_loss: 1.1133 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9692 - acc: 0.5096 - val_loss: 1.1119 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 0.9538 - acc: 0.5288 - val_loss: 1.1128 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9321 - acc: 0.5385 - val_loss: 1.1159 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9518 - acc: 0.5192 - val_loss: 1.1170 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9518 - acc: 0.5192 - val_loss: 1.1176 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9767 - acc: 0.5096 - val_loss: 1.1145 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9653 - acc: 0.5096 - val_loss: 1.1148 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9327 - acc: 0.5385 - val_loss: 1.1169 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 417us/sample - loss: 0.9549 - acc: 0.5385 - val_loss: 1.1166 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9574 - acc: 0.5288 - val_loss: 1.1181 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9718 - acc: 0.4904 - val_loss: 1.1215 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9770 - acc: 0.5000 - val_loss: 1.1211 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9350 - acc: 0.5385 - val_loss: 1.1193 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9415 - acc: 0.5288 - val_loss: 1.1199 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9158 - acc: 0.5385 - val_loss: 1.1224 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9338 - acc: 0.5288 - val_loss: 1.1243 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 0.9447 - acc: 0.5096 - val_loss: 1.1254 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9447 - acc: 0.5000 - val_loss: 1.1292 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9512 - acc: 0.5192 - val_loss: 1.1285 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9526 - acc: 0.4808 - val_loss: 1.1269 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9474 - acc: 0.5192 - val_loss: 1.1290 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9327 - acc: 0.5385 - val_loss: 1.1317 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9600 - acc: 0.4904 - val_loss: 1.1321 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 427us/sample - loss: 0.9379 - acc: 0.5096 - val_loss: 1.1313 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9250 - acc: 0.5288 - val_loss: 1.1327 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9477 - acc: 0.5096 - val_loss: 1.1308 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9327 - acc: 0.5096 - val_loss: 1.1332 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 0.9614 - acc: 0.5096 - val_loss: 1.1323 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9385 - acc: 0.5288 - val_loss: 1.1361 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9521 - acc: 0.5096 - val_loss: 1.1351 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 0.9367 - acc: 0.5192 - val_loss: 1.1362 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9120 - acc: 0.5288 - val_loss: 1.1408 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9508 - acc: 0.4904 - val_loss: 1.1416 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9288 - acc: 0.5288 - val_loss: 1.1435 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9294 - acc: 0.5288 - val_loss: 1.1429 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.9593 - acc: 0.5000 - val_loss: 1.1425 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9534 - acc: 0.5192 - val_loss: 1.1439 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9419 - acc: 0.4808 - val_loss: 1.1440 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9465 - acc: 0.5192 - val_loss: 1.1434 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9288 - acc: 0.5385 - val_loss: 1.1439 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 421us/sample - loss: 0.9439 - acc: 0.5096 - val_loss: 1.1454 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9147 - acc: 0.5673 - val_loss: 1.1454 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: ba87a2f055c4beaad386f5cc220dbfe3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5111111402511597</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.0474 - acc: 0.4231 - val_loss: 1.6504 - val_acc: 0.4074\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.6707 - acc: 0.5000 - val_loss: 1.6181 - val_acc: 0.4074\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 406us/sample - loss: 1.8943 - acc: 0.4135 - val_loss: 1.5803 - val_acc: 0.4444\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.9069 - acc: 0.4135 - val_loss: 1.5353 - val_acc: 0.4444\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.6597 - acc: 0.5000 - val_loss: 1.4653 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.6461 - acc: 0.4712 - val_loss: 1.4537 - val_acc: 0.4815\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.4226 - acc: 0.5865 - val_loss: 1.4209 - val_acc: 0.5185\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.4683 - acc: 0.4904 - val_loss: 1.3962 - val_acc: 0.5556\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 630us/sample - loss: 1.4128 - acc: 0.5481 - val_loss: 1.3395 - val_acc: 0.5556\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.2598 - acc: 0.4808 - val_loss: 1.3029 - val_acc: 0.5185\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.4021 - acc: 0.4904 - val_loss: 1.2911 - val_acc: 0.4815\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.4339 - acc: 0.5096 - val_loss: 1.2607 - val_acc: 0.4815\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.2306 - acc: 0.5288 - val_loss: 1.2556 - val_acc: 0.5185\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.2148 - acc: 0.4712 - val_loss: 1.2466 - val_acc: 0.5185\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0777 - acc: 0.5000 - val_loss: 1.2302 - val_acc: 0.5556\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.2462 - acc: 0.5096 - val_loss: 1.2056 - val_acc: 0.5185\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1758 - acc: 0.5192 - val_loss: 1.1978 - val_acc: 0.5185\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1840 - acc: 0.5096 - val_loss: 1.1780 - val_acc: 0.5556\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.1734 - acc: 0.4904 - val_loss: 1.1744 - val_acc: 0.5556\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 419us/sample - loss: 1.1930 - acc: 0.4135 - val_loss: 1.1713 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.1839 - acc: 0.4808 - val_loss: 1.1719 - val_acc: 0.4815\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.1262 - acc: 0.5096 - val_loss: 1.1626 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1308 - acc: 0.4712 - val_loss: 1.1514 - val_acc: 0.4815\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9503 - acc: 0.5288 - val_loss: 1.1513 - val_acc: 0.4815\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 0.9971 - acc: 0.5673 - val_loss: 1.1522 - val_acc: 0.4815\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.1328 - acc: 0.5288 - val_loss: 1.1517 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1236 - acc: 0.4615 - val_loss: 1.1410 - val_acc: 0.4074\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.1348 - acc: 0.5096 - val_loss: 1.1345 - val_acc: 0.4074\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 1.1687 - acc: 0.5769 - val_loss: 1.1319 - val_acc: 0.4074\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 404us/sample - loss: 1.0921 - acc: 0.4904 - val_loss: 1.1228 - val_acc: 0.4074\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.0756 - acc: 0.5096 - val_loss: 1.1178 - val_acc: 0.4074\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 1.0863 - acc: 0.5288 - val_loss: 1.1166 - val_acc: 0.4074\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9501 - acc: 0.5673 - val_loss: 1.1164 - val_acc: 0.4074\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.1277 - acc: 0.5000 - val_loss: 1.1110 - val_acc: 0.4074\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.0990 - acc: 0.4712 - val_loss: 1.1113 - val_acc: 0.4074\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0209 - acc: 0.4808 - val_loss: 1.1094 - val_acc: 0.4074\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9342 - acc: 0.5096 - val_loss: 1.1097 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0784 - acc: 0.4808 - val_loss: 1.1143 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 290us/sample - loss: 1.0617 - acc: 0.5385 - val_loss: 1.1051 - val_acc: 0.4074\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9973 - acc: 0.5288 - val_loss: 1.1054 - val_acc: 0.4074\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 1.0391 - acc: 0.5192 - val_loss: 1.1014 - val_acc: 0.4074\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0645 - acc: 0.5000 - val_loss: 1.1030 - val_acc: 0.4074\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.1144 - acc: 0.4038 - val_loss: 1.1004 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 1.0792 - acc: 0.4712 - val_loss: 1.0950 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0929 - acc: 0.4519 - val_loss: 1.0999 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0712 - acc: 0.5000 - val_loss: 1.0967 - val_acc: 0.4074\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.0977 - acc: 0.4808 - val_loss: 1.0918 - val_acc: 0.4815\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0123 - acc: 0.4808 - val_loss: 1.0882 - val_acc: 0.4815\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0165 - acc: 0.5577 - val_loss: 1.0883 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 0.9802 - acc: 0.5481 - val_loss: 1.0859 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9969 - acc: 0.4615 - val_loss: 1.0866 - val_acc: 0.4815\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 383us/sample - loss: 1.0583 - acc: 0.5192 - val_loss: 1.0839 - val_acc: 0.4815\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9621 - acc: 0.5096 - val_loss: 1.0894 - val_acc: 0.4815\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0062 - acc: 0.5288 - val_loss: 1.1021 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0373 - acc: 0.4423 - val_loss: 1.1051 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9607 - acc: 0.5288 - val_loss: 1.1036 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9191 - acc: 0.5288 - val_loss: 1.1161 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9711 - acc: 0.5096 - val_loss: 1.1296 - val_acc: 0.4815\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9592 - acc: 0.5000 - val_loss: 1.1516 - val_acc: 0.4444\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0195 - acc: 0.4808 - val_loss: 1.1381 - val_acc: 0.4444\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.0143 - acc: 0.5481 - val_loss: 1.1366 - val_acc: 0.3704\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.0179 - acc: 0.4423 - val_loss: 1.1387 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0788 - acc: 0.5096 - val_loss: 1.1382 - val_acc: 0.3704\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9405 - acc: 0.5385 - val_loss: 1.1344 - val_acc: 0.4444\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9473 - acc: 0.5481 - val_loss: 1.1320 - val_acc: 0.4074\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9444 - acc: 0.4712 - val_loss: 1.1218 - val_acc: 0.4444\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0418 - acc: 0.4423 - val_loss: 1.1142 - val_acc: 0.4815\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9867 - acc: 0.4423 - val_loss: 1.1053 - val_acc: 0.4815\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0373 - acc: 0.4327 - val_loss: 1.1004 - val_acc: 0.4815\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9523 - acc: 0.5192 - val_loss: 1.1107 - val_acc: 0.4815\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0231 - acc: 0.4038 - val_loss: 1.0992 - val_acc: 0.4815\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 0.9597 - acc: 0.5192 - val_loss: 1.1128 - val_acc: 0.4815\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 410us/sample - loss: 0.9818 - acc: 0.4904 - val_loss: 1.1121 - val_acc: 0.4444\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9650 - acc: 0.5577 - val_loss: 1.1087 - val_acc: 0.4444\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0242 - acc: 0.4712 - val_loss: 1.1120 - val_acc: 0.4815\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 296us/sample - loss: 0.9254 - acc: 0.5673 - val_loss: 1.1134 - val_acc: 0.4815\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9991 - acc: 0.4615 - val_loss: 1.1140 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9459 - acc: 0.4808 - val_loss: 1.1291 - val_acc: 0.4444\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0125 - acc: 0.4904 - val_loss: 1.1152 - val_acc: 0.4815\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9931 - acc: 0.5096 - val_loss: 1.1156 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9881 - acc: 0.5000 - val_loss: 1.1104 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9619 - acc: 0.5385 - val_loss: 1.1190 - val_acc: 0.4815\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9662 - acc: 0.4808 - val_loss: 1.1150 - val_acc: 0.4815\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 0.9722 - acc: 0.4904 - val_loss: 1.0938 - val_acc: 0.5556\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9989 - acc: 0.5288 - val_loss: 1.0845 - val_acc: 0.5556\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.0176 - acc: 0.4231 - val_loss: 1.0691 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9825 - acc: 0.5192 - val_loss: 1.0837 - val_acc: 0.5556\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9701 - acc: 0.4327 - val_loss: 1.0996 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9702 - acc: 0.5288 - val_loss: 1.1112 - val_acc: 0.4815\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0054 - acc: 0.4808 - val_loss: 1.0871 - val_acc: 0.5556\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9355 - acc: 0.5192 - val_loss: 1.0859 - val_acc: 0.5556\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 292us/sample - loss: 0.9605 - acc: 0.5481 - val_loss: 1.1076 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.9618 - acc: 0.4808 - val_loss: 1.1073 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9628 - acc: 0.5865 - val_loss: 1.1027 - val_acc: 0.4444\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9534 - acc: 0.4327 - val_loss: 1.1163 - val_acc: 0.4815\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 402us/sample - loss: 1.0139 - acc: 0.4423 - val_loss: 1.0947 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9903 - acc: 0.5192 - val_loss: 1.0995 - val_acc: 0.4815\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9398 - acc: 0.5000 - val_loss: 1.0954 - val_acc: 0.5556\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9741 - acc: 0.4712 - val_loss: 1.0769 - val_acc: 0.5556\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9382 - acc: 0.5192 - val_loss: 1.0720 - val_acc: 0.5185\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 4.0767 - acc: 0.3558 - val_loss: 2.9942 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 3.1406 - acc: 0.3750 - val_loss: 2.5193 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 2.6178 - acc: 0.4135 - val_loss: 2.1810 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 2.3856 - acc: 0.4135 - val_loss: 1.9651 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 2.4918 - acc: 0.3462 - val_loss: 1.7114 - val_acc: 0.3704\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 2.0034 - acc: 0.4231 - val_loss: 1.5778 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.8323 - acc: 0.4231 - val_loss: 1.4623 - val_acc: 0.3333\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.7745 - acc: 0.3750 - val_loss: 1.3656 - val_acc: 0.3333\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.5189 - acc: 0.4327 - val_loss: 1.3078 - val_acc: 0.3333\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.5468 - acc: 0.4231 - val_loss: 1.2385 - val_acc: 0.3704\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.3487 - acc: 0.4712 - val_loss: 1.2024 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 377us/sample - loss: 1.3612 - acc: 0.4519 - val_loss: 1.1667 - val_acc: 0.3333\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 401us/sample - loss: 1.3397 - acc: 0.5192 - val_loss: 1.1342 - val_acc: 0.4815\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.2002 - acc: 0.5000 - val_loss: 1.1146 - val_acc: 0.4815\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.2381 - acc: 0.4519 - val_loss: 1.0841 - val_acc: 0.5185\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.2067 - acc: 0.4519 - val_loss: 1.0721 - val_acc: 0.5185\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.2214 - acc: 0.4423 - val_loss: 1.0558 - val_acc: 0.5185\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.1595 - acc: 0.4231 - val_loss: 1.0408 - val_acc: 0.5185\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0577 - acc: 0.5288 - val_loss: 1.0353 - val_acc: 0.5185\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0314 - acc: 0.5385 - val_loss: 1.0294 - val_acc: 0.5185\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0572 - acc: 0.5096 - val_loss: 1.0275 - val_acc: 0.5185\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 719us/sample - loss: 1.0620 - acc: 0.4712 - val_loss: 1.0215 - val_acc: 0.5926\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9939 - acc: 0.5481 - val_loss: 1.0189 - val_acc: 0.5926\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 1.0612 - acc: 0.5000 - val_loss: 1.0147 - val_acc: 0.5926\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0119 - acc: 0.5481 - val_loss: 1.0125 - val_acc: 0.5926\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0072 - acc: 0.5288 - val_loss: 1.0079 - val_acc: 0.5926\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0133 - acc: 0.5288 - val_loss: 1.0105 - val_acc: 0.5926\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0429 - acc: 0.4808 - val_loss: 1.0103 - val_acc: 0.5926\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0304 - acc: 0.5096 - val_loss: 1.0107 - val_acc: 0.5926\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0013 - acc: 0.5000 - val_loss: 1.0102 - val_acc: 0.5926\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0296 - acc: 0.4904 - val_loss: 1.0093 - val_acc: 0.5926\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 1.0192 - acc: 0.4808 - val_loss: 1.0099 - val_acc: 0.5926\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9906 - acc: 0.5192 - val_loss: 1.0087 - val_acc: 0.5926\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 307us/sample - loss: 0.9829 - acc: 0.5000 - val_loss: 1.0060 - val_acc: 0.5926\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 1.0038 - acc: 0.4808 - val_loss: 1.0049 - val_acc: 0.5926\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9918 - acc: 0.5288 - val_loss: 1.0016 - val_acc: 0.5926\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9952 - acc: 0.4712 - val_loss: 1.0017 - val_acc: 0.5926\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0004 - acc: 0.5288 - val_loss: 0.9995 - val_acc: 0.5926\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0091 - acc: 0.4904 - val_loss: 1.0009 - val_acc: 0.5926\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0043 - acc: 0.5192 - val_loss: 0.9970 - val_acc: 0.5926\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9626 - acc: 0.5385 - val_loss: 0.9959 - val_acc: 0.5926\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9987 - acc: 0.5481 - val_loss: 0.9972 - val_acc: 0.5926\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 412us/sample - loss: 0.9522 - acc: 0.5385 - val_loss: 0.9980 - val_acc: 0.5926\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 449us/sample - loss: 0.9816 - acc: 0.4904 - val_loss: 1.0005 - val_acc: 0.5926\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9947 - acc: 0.5192 - val_loss: 1.0011 - val_acc: 0.5926\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 0.9970 - acc: 0.5673 - val_loss: 1.0001 - val_acc: 0.5556\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9595 - acc: 0.5577 - val_loss: 1.0012 - val_acc: 0.5926\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0156 - acc: 0.5192 - val_loss: 1.0000 - val_acc: 0.5926\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.0015 - acc: 0.5096 - val_loss: 1.0000 - val_acc: 0.5926\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9724 - acc: 0.5288 - val_loss: 0.9966 - val_acc: 0.5926\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9853 - acc: 0.5481 - val_loss: 0.9931 - val_acc: 0.5926\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9760 - acc: 0.5385 - val_loss: 0.9941 - val_acc: 0.5926\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9604 - acc: 0.5385 - val_loss: 0.9964 - val_acc: 0.5926\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9853 - acc: 0.5096 - val_loss: 0.9964 - val_acc: 0.5926\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9944 - acc: 0.4904 - val_loss: 0.9921 - val_acc: 0.5926\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9869 - acc: 0.5481 - val_loss: 0.9966 - val_acc: 0.5556\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 0.9923 - acc: 0.5000 - val_loss: 0.9924 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 379us/sample - loss: 0.9925 - acc: 0.5288 - val_loss: 0.9933 - val_acc: 0.5926\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.0117 - acc: 0.4904 - val_loss: 0.9946 - val_acc: 0.5926\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.0161 - acc: 0.4904 - val_loss: 0.9964 - val_acc: 0.5926\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0063 - acc: 0.4904 - val_loss: 0.9975 - val_acc: 0.5926\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9893 - acc: 0.5192 - val_loss: 0.9964 - val_acc: 0.5926\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9836 - acc: 0.5000 - val_loss: 0.9953 - val_acc: 0.5926\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9903 - acc: 0.4712 - val_loss: 0.9935 - val_acc: 0.5926\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9686 - acc: 0.5192 - val_loss: 0.9952 - val_acc: 0.5926\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9753 - acc: 0.5192 - val_loss: 0.9959 - val_acc: 0.5926\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9915 - acc: 0.4904 - val_loss: 0.9965 - val_acc: 0.5926\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0209 - acc: 0.4615 - val_loss: 0.9956 - val_acc: 0.5926\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9776 - acc: 0.5192 - val_loss: 0.9970 - val_acc: 0.5926\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 0.9655 - acc: 0.5288 - val_loss: 1.0010 - val_acc: 0.5926\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9862 - acc: 0.5096 - val_loss: 0.9949 - val_acc: 0.5926\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9749 - acc: 0.4712 - val_loss: 0.9908 - val_acc: 0.5926\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.9570 - acc: 0.5481 - val_loss: 0.9936 - val_acc: 0.5926\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9974 - acc: 0.4712 - val_loss: 0.9924 - val_acc: 0.5926\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9867 - acc: 0.5096 - val_loss: 0.9885 - val_acc: 0.5926\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9793 - acc: 0.4904 - val_loss: 0.9872 - val_acc: 0.5926\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9648 - acc: 0.5385 - val_loss: 0.9899 - val_acc: 0.5926\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 306us/sample - loss: 0.9799 - acc: 0.5096 - val_loss: 0.9909 - val_acc: 0.5926\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9886 - acc: 0.4904 - val_loss: 0.9924 - val_acc: 0.5556\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9505 - acc: 0.5481 - val_loss: 0.9921 - val_acc: 0.5926\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0029 - acc: 0.5000 - val_loss: 0.9931 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 0.9780 - acc: 0.4904 - val_loss: 0.9922 - val_acc: 0.5926\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 384us/sample - loss: 0.9585 - acc: 0.5577 - val_loss: 0.9950 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9859 - acc: 0.4808 - val_loss: 0.9947 - val_acc: 0.5926\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9826 - acc: 0.4904 - val_loss: 0.9930 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0050 - acc: 0.5288 - val_loss: 0.9918 - val_acc: 0.5556\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0067 - acc: 0.4904 - val_loss: 0.9887 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9890 - acc: 0.4712 - val_loss: 0.9903 - val_acc: 0.5556\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9798 - acc: 0.4712 - val_loss: 0.9903 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0043 - acc: 0.4423 - val_loss: 0.9900 - val_acc: 0.5556\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 0.9814 - acc: 0.5096 - val_loss: 0.9865 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9902 - acc: 0.5288 - val_loss: 0.9901 - val_acc: 0.5556\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9724 - acc: 0.5096 - val_loss: 0.9890 - val_acc: 0.5556\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9957 - acc: 0.4808 - val_loss: 0.9908 - val_acc: 0.5556\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 303us/sample - loss: 0.9727 - acc: 0.5192 - val_loss: 0.9898 - val_acc: 0.5556\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9608 - acc: 0.4904 - val_loss: 0.9902 - val_acc: 0.5556\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9923 - acc: 0.4808 - val_loss: 0.9870 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9908 - acc: 0.4615 - val_loss: 0.9867 - val_acc: 0.5556\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9631 - acc: 0.5192 - val_loss: 0.9879 - val_acc: 0.5556\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 366us/sample - loss: 0.9854 - acc: 0.5096 - val_loss: 0.9887 - val_acc: 0.5556\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 995us/sample - loss: 3.1286 - acc: 0.4231 - val_loss: 2.2395 - val_acc: 0.4444\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 2.3147 - acc: 0.3750 - val_loss: 2.0651 - val_acc: 0.4444\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 2.9178 - acc: 0.3942 - val_loss: 1.8535 - val_acc: 0.4444\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 2.1826 - acc: 0.4135 - val_loss: 1.7123 - val_acc: 0.4444\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.9321 - acc: 0.4327 - val_loss: 1.6044 - val_acc: 0.4815\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.8452 - acc: 0.3462 - val_loss: 1.5301 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.6505 - acc: 0.4615 - val_loss: 1.4604 - val_acc: 0.4815\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.8573 - acc: 0.3750 - val_loss: 1.3975 - val_acc: 0.4815\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.5855 - acc: 0.4135 - val_loss: 1.3714 - val_acc: 0.4444\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.4805 - acc: 0.4327 - val_loss: 1.3425 - val_acc: 0.4074\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 1.6333 - acc: 0.4327 - val_loss: 1.3011 - val_acc: 0.5185\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.4809 - acc: 0.4327 - val_loss: 1.2748 - val_acc: 0.4815\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.2979 - acc: 0.4712 - val_loss: 1.2550 - val_acc: 0.4815\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.3742 - acc: 0.4423 - val_loss: 1.2397 - val_acc: 0.4444\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.2253 - acc: 0.4135 - val_loss: 1.2240 - val_acc: 0.4074\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.3558 - acc: 0.4135 - val_loss: 1.2065 - val_acc: 0.4074\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.2662 - acc: 0.4231 - val_loss: 1.1947 - val_acc: 0.4444\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.2407 - acc: 0.4231 - val_loss: 1.1867 - val_acc: 0.4444\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.2502 - acc: 0.4712 - val_loss: 1.1827 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.1979 - acc: 0.4038 - val_loss: 1.1719 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.2736 - acc: 0.3462 - val_loss: 1.1657 - val_acc: 0.4444\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.1899 - acc: 0.4135 - val_loss: 1.1582 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1609 - acc: 0.3942 - val_loss: 1.1582 - val_acc: 0.4444\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 289us/sample - loss: 1.1679 - acc: 0.4327 - val_loss: 1.1566 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.1805 - acc: 0.4712 - val_loss: 1.1464 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 382us/sample - loss: 1.1510 - acc: 0.4327 - val_loss: 1.1398 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.1098 - acc: 0.4615 - val_loss: 1.1344 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 1.0382 - acc: 0.5288 - val_loss: 1.1321 - val_acc: 0.4444\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0485 - acc: 0.4808 - val_loss: 1.1320 - val_acc: 0.4444\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0447 - acc: 0.4519 - val_loss: 1.1292 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 1.1184 - acc: 0.4904 - val_loss: 1.1227 - val_acc: 0.4444\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0770 - acc: 0.4904 - val_loss: 1.1176 - val_acc: 0.4444\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 301us/sample - loss: 1.0915 - acc: 0.4423 - val_loss: 1.1152 - val_acc: 0.4444\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 1.0835 - acc: 0.4712 - val_loss: 1.1115 - val_acc: 0.4444\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.0541 - acc: 0.4519 - val_loss: 1.1085 - val_acc: 0.4074\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0812 - acc: 0.5000 - val_loss: 1.1038 - val_acc: 0.4444\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 329us/sample - loss: 1.0469 - acc: 0.5192 - val_loss: 1.0992 - val_acc: 0.4444\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 1.0487 - acc: 0.4423 - val_loss: 1.0985 - val_acc: 0.4444\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0300 - acc: 0.5192 - val_loss: 1.0960 - val_acc: 0.4444\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 1.0249 - acc: 0.5288 - val_loss: 1.0925 - val_acc: 0.4444\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0557 - acc: 0.4615 - val_loss: 1.0898 - val_acc: 0.4074\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0407 - acc: 0.4808 - val_loss: 1.0863 - val_acc: 0.4444\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 403us/sample - loss: 1.0660 - acc: 0.4423 - val_loss: 1.0825 - val_acc: 0.4074\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.0270 - acc: 0.4038 - val_loss: 1.0825 - val_acc: 0.4444\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0283 - acc: 0.4615 - val_loss: 1.0818 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 1.0727 - acc: 0.4615 - val_loss: 1.0778 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 1.0229 - acc: 0.5000 - val_loss: 1.0735 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9988 - acc: 0.4808 - val_loss: 1.0728 - val_acc: 0.4074\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 434us/sample - loss: 1.0126 - acc: 0.5096 - val_loss: 1.0686 - val_acc: 0.4074\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0582 - acc: 0.4038 - val_loss: 1.0682 - val_acc: 0.4074\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.0034 - acc: 0.5000 - val_loss: 1.0653 - val_acc: 0.4074\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0204 - acc: 0.4712 - val_loss: 1.0629 - val_acc: 0.4074\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9726 - acc: 0.4423 - val_loss: 1.0649 - val_acc: 0.3704\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0242 - acc: 0.4327 - val_loss: 1.0637 - val_acc: 0.3704\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.0509 - acc: 0.4615 - val_loss: 1.0598 - val_acc: 0.3704\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.0138 - acc: 0.4327 - val_loss: 1.0573 - val_acc: 0.3704\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 1.0532 - acc: 0.4231 - val_loss: 1.0560 - val_acc: 0.4444\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 1.0131 - acc: 0.4519 - val_loss: 1.0551 - val_acc: 0.4074\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.9760 - acc: 0.4423 - val_loss: 1.0565 - val_acc: 0.4074\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9786 - acc: 0.4423 - val_loss: 1.0571 - val_acc: 0.4074\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9317 - acc: 0.5385 - val_loss: 1.0566 - val_acc: 0.3704\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0033 - acc: 0.4038 - val_loss: 1.0579 - val_acc: 0.4444\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 1.0371 - acc: 0.3846 - val_loss: 1.0574 - val_acc: 0.4444\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 1.0098 - acc: 0.4808 - val_loss: 1.0561 - val_acc: 0.4444\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9794 - acc: 0.4712 - val_loss: 1.0558 - val_acc: 0.4074\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9697 - acc: 0.4904 - val_loss: 1.0570 - val_acc: 0.4074\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.9835 - acc: 0.4135 - val_loss: 1.0568 - val_acc: 0.4074\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9608 - acc: 0.5000 - val_loss: 1.0582 - val_acc: 0.4074\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 1.0079 - acc: 0.4712 - val_loss: 1.0583 - val_acc: 0.4074\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0044 - acc: 0.4712 - val_loss: 1.0550 - val_acc: 0.4444\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 0.9441 - acc: 0.5000 - val_loss: 1.0546 - val_acc: 0.4074\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 400us/sample - loss: 1.0319 - acc: 0.4327 - val_loss: 1.0533 - val_acc: 0.4074\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0475 - acc: 0.3558 - val_loss: 1.0514 - val_acc: 0.4074\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9984 - acc: 0.4904 - val_loss: 1.0480 - val_acc: 0.4074\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0051 - acc: 0.4231 - val_loss: 1.0457 - val_acc: 0.4074\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 0.9345 - acc: 0.5000 - val_loss: 1.0461 - val_acc: 0.4074\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 389us/sample - loss: 0.9610 - acc: 0.5000 - val_loss: 1.0472 - val_acc: 0.4074\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0011 - acc: 0.4231 - val_loss: 1.0465 - val_acc: 0.4074\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 1.0224 - acc: 0.3846 - val_loss: 1.0437 - val_acc: 0.4074\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9811 - acc: 0.4423 - val_loss: 1.0425 - val_acc: 0.4074\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.0123 - acc: 0.4327 - val_loss: 1.0388 - val_acc: 0.4074\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 0.9885 - acc: 0.4615 - val_loss: 1.0371 - val_acc: 0.4074\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0075 - acc: 0.4615 - val_loss: 1.0364 - val_acc: 0.4074\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9830 - acc: 0.4423 - val_loss: 1.0362 - val_acc: 0.4444\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 1.0130 - acc: 0.4519 - val_loss: 1.0346 - val_acc: 0.4815\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 398us/sample - loss: 0.9951 - acc: 0.4615 - val_loss: 1.0336 - val_acc: 0.4444\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9904 - acc: 0.4231 - val_loss: 1.0318 - val_acc: 0.4444\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9809 - acc: 0.4615 - val_loss: 1.0319 - val_acc: 0.4444\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9857 - acc: 0.3750 - val_loss: 1.0297 - val_acc: 0.4444\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9651 - acc: 0.4904 - val_loss: 1.0316 - val_acc: 0.4444\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 0.9418 - acc: 0.5096 - val_loss: 1.0317 - val_acc: 0.4074\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 0.9807 - acc: 0.4904 - val_loss: 1.0283 - val_acc: 0.3704\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9612 - acc: 0.5192 - val_loss: 1.0278 - val_acc: 0.4074\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 316us/sample - loss: 0.9630 - acc: 0.5192 - val_loss: 1.0279 - val_acc: 0.4074\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9883 - acc: 0.5000 - val_loss: 1.0280 - val_acc: 0.4444\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 407us/sample - loss: 0.9708 - acc: 0.5288 - val_loss: 1.0262 - val_acc: 0.4074\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9647 - acc: 0.5385 - val_loss: 1.0258 - val_acc: 0.4074\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 0.9432 - acc: 0.5481 - val_loss: 1.0258 - val_acc: 0.4444\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9659 - acc: 0.4519 - val_loss: 1.0268 - val_acc: 0.4444\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9475 - acc: 0.5096 - val_loss: 1.0276 - val_acc: 0.4444\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 1.8501 - acc: 0.4808 - val_loss: 1.1135 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 2.0789 - acc: 0.4423 - val_loss: 1.0924 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 448us/sample - loss: 1.6142 - acc: 0.4712 - val_loss: 1.0788 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 2.0577 - acc: 0.4423 - val_loss: 1.0566 - val_acc: 0.4074\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 1.6240 - acc: 0.4135 - val_loss: 1.0418 - val_acc: 0.4074\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.5063 - acc: 0.4615 - val_loss: 1.0358 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.4159 - acc: 0.4712 - val_loss: 1.0280 - val_acc: 0.4444\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 1.3966 - acc: 0.4135 - val_loss: 1.0216 - val_acc: 0.4444\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.4376 - acc: 0.4135 - val_loss: 1.0190 - val_acc: 0.4444\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 1.1949 - acc: 0.5000 - val_loss: 1.0164 - val_acc: 0.4815\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.3760 - acc: 0.4231 - val_loss: 1.0053 - val_acc: 0.4815\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.2682 - acc: 0.4712 - val_loss: 0.9928 - val_acc: 0.4444\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 317us/sample - loss: 1.2071 - acc: 0.4808 - val_loss: 0.9929 - val_acc: 0.5185\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 424us/sample - loss: 1.1745 - acc: 0.4904 - val_loss: 0.9829 - val_acc: 0.4815\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1735 - acc: 0.4808 - val_loss: 0.9808 - val_acc: 0.4815\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.1316 - acc: 0.4712 - val_loss: 0.9800 - val_acc: 0.4815\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 349us/sample - loss: 1.0947 - acc: 0.5096 - val_loss: 0.9694 - val_acc: 0.5926\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.1014 - acc: 0.4615 - val_loss: 0.9726 - val_acc: 0.5926\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1141 - acc: 0.4615 - val_loss: 0.9742 - val_acc: 0.5926\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 1.1509 - acc: 0.4712 - val_loss: 0.9794 - val_acc: 0.5926\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 356us/sample - loss: 1.1560 - acc: 0.4615 - val_loss: 0.9775 - val_acc: 0.5556\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.1338 - acc: 0.4231 - val_loss: 0.9714 - val_acc: 0.5926\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 1.0128 - acc: 0.5192 - val_loss: 0.9717 - val_acc: 0.5926\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.1290 - acc: 0.5096 - val_loss: 0.9724 - val_acc: 0.5926\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 369us/sample - loss: 1.0221 - acc: 0.4904 - val_loss: 0.9740 - val_acc: 0.5926\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0412 - acc: 0.5000 - val_loss: 0.9774 - val_acc: 0.5926\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0179 - acc: 0.5096 - val_loss: 0.9777 - val_acc: 0.5926\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 297us/sample - loss: 1.0327 - acc: 0.4712 - val_loss: 0.9777 - val_acc: 0.5926\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.0710 - acc: 0.4808 - val_loss: 0.9690 - val_acc: 0.5926\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0559 - acc: 0.5000 - val_loss: 0.9678 - val_acc: 0.5926\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0820 - acc: 0.5385 - val_loss: 0.9677 - val_acc: 0.5926\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1399 - acc: 0.4038 - val_loss: 0.9657 - val_acc: 0.5926\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 1.0861 - acc: 0.5000 - val_loss: 0.9696 - val_acc: 0.5926\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9775 - acc: 0.5192 - val_loss: 0.9720 - val_acc: 0.5926\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.1071 - acc: 0.5192 - val_loss: 0.9747 - val_acc: 0.5926\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0174 - acc: 0.5000 - val_loss: 0.9762 - val_acc: 0.5926\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.0058 - acc: 0.5000 - val_loss: 0.9787 - val_acc: 0.5926\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0132 - acc: 0.4712 - val_loss: 0.9761 - val_acc: 0.5926\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 385us/sample - loss: 1.0176 - acc: 0.4904 - val_loss: 0.9752 - val_acc: 0.5926\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9641 - acc: 0.5385 - val_loss: 0.9797 - val_acc: 0.5926\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 1.0607 - acc: 0.4712 - val_loss: 0.9816 - val_acc: 0.5926\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.0575 - acc: 0.5000 - val_loss: 0.9856 - val_acc: 0.5926\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9928 - acc: 0.4615 - val_loss: 0.9885 - val_acc: 0.5926\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9860 - acc: 0.5288 - val_loss: 0.9893 - val_acc: 0.5926\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 419us/sample - loss: 0.9848 - acc: 0.5577 - val_loss: 0.9923 - val_acc: 0.5926\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 1.0446 - acc: 0.5385 - val_loss: 0.9927 - val_acc: 0.5926\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 1.0628 - acc: 0.4135 - val_loss: 0.9915 - val_acc: 0.5556\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 1.0243 - acc: 0.5096 - val_loss: 0.9979 - val_acc: 0.5556\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 1.0060 - acc: 0.5577 - val_loss: 0.9987 - val_acc: 0.5556\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9866 - acc: 0.5288 - val_loss: 0.9994 - val_acc: 0.5556\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 1.0206 - acc: 0.5385 - val_loss: 1.0004 - val_acc: 0.5926\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 354us/sample - loss: 0.9927 - acc: 0.4808 - val_loss: 0.9991 - val_acc: 0.5926\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 428us/sample - loss: 1.0133 - acc: 0.4808 - val_loss: 0.9965 - val_acc: 0.5926\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9591 - acc: 0.6154 - val_loss: 0.9985 - val_acc: 0.5926\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0365 - acc: 0.5769 - val_loss: 0.9972 - val_acc: 0.5926\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 0.9453 - acc: 0.6058 - val_loss: 0.9976 - val_acc: 0.5926\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 386us/sample - loss: 0.9130 - acc: 0.5385 - val_loss: 0.9975 - val_acc: 0.5926\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.0092 - acc: 0.5481 - val_loss: 1.0011 - val_acc: 0.5926\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9634 - acc: 0.4712 - val_loss: 1.0024 - val_acc: 0.5926\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9410 - acc: 0.5288 - val_loss: 1.0054 - val_acc: 0.5926\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9439 - acc: 0.5192 - val_loss: 1.0076 - val_acc: 0.5926\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9778 - acc: 0.5288 - val_loss: 1.0059 - val_acc: 0.5926\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9978 - acc: 0.5192 - val_loss: 1.0091 - val_acc: 0.5926\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 1.0459 - acc: 0.5385 - val_loss: 1.0054 - val_acc: 0.5926\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 1.0011 - acc: 0.5096 - val_loss: 1.0058 - val_acc: 0.5926\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9487 - acc: 0.5000 - val_loss: 1.0099 - val_acc: 0.5926\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.0614 - acc: 0.4904 - val_loss: 1.0085 - val_acc: 0.5926\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 337us/sample - loss: 0.9344 - acc: 0.4904 - val_loss: 1.0104 - val_acc: 0.5926\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 1.0354 - acc: 0.4712 - val_loss: 1.0097 - val_acc: 0.5926\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.9711 - acc: 0.4615 - val_loss: 1.0093 - val_acc: 0.5926\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 0.9486 - acc: 0.5481 - val_loss: 1.0086 - val_acc: 0.5926\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 1.0451 - acc: 0.4615 - val_loss: 1.0054 - val_acc: 0.5926\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9380 - acc: 0.5481 - val_loss: 1.0062 - val_acc: 0.5926\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 392us/sample - loss: 0.9354 - acc: 0.5577 - val_loss: 1.0088 - val_acc: 0.5926\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9250 - acc: 0.5577 - val_loss: 1.0111 - val_acc: 0.5926\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9787 - acc: 0.4808 - val_loss: 1.0112 - val_acc: 0.5926\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9639 - acc: 0.5673 - val_loss: 1.0101 - val_acc: 0.5926\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.0151 - acc: 0.5096 - val_loss: 1.0122 - val_acc: 0.5926\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 0.9693 - acc: 0.5769 - val_loss: 1.0120 - val_acc: 0.5926\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9693 - acc: 0.5288 - val_loss: 1.0117 - val_acc: 0.5926\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 390us/sample - loss: 0.9308 - acc: 0.5288 - val_loss: 1.0131 - val_acc: 0.5926\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 0.9945 - acc: 0.4712 - val_loss: 1.0111 - val_acc: 0.5926\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 372us/sample - loss: 0.9457 - acc: 0.5096 - val_loss: 1.0111 - val_acc: 0.5926\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.9365 - acc: 0.5288 - val_loss: 1.0136 - val_acc: 0.5926\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 368us/sample - loss: 0.9405 - acc: 0.5288 - val_loss: 1.0163 - val_acc: 0.5926\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9807 - acc: 0.5385 - val_loss: 1.0145 - val_acc: 0.5926\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 414us/sample - loss: 0.9437 - acc: 0.5288 - val_loss: 1.0171 - val_acc: 0.5926\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9550 - acc: 0.4904 - val_loss: 1.0187 - val_acc: 0.5926\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9549 - acc: 0.5673 - val_loss: 1.0215 - val_acc: 0.5926\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9549 - acc: 0.5000 - val_loss: 1.0202 - val_acc: 0.5926\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 0.9226 - acc: 0.5385 - val_loss: 1.0222 - val_acc: 0.5926\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.9398 - acc: 0.5673 - val_loss: 1.0215 - val_acc: 0.5926\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 0.9739 - acc: 0.5385 - val_loss: 1.0205 - val_acc: 0.5926\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.9757 - acc: 0.5000 - val_loss: 1.0201 - val_acc: 0.5926\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 0.9732 - acc: 0.5192 - val_loss: 1.0211 - val_acc: 0.5926\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 0.9708 - acc: 0.5000 - val_loss: 1.0198 - val_acc: 0.5926\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 388us/sample - loss: 0.9563 - acc: 0.4904 - val_loss: 1.0202 - val_acc: 0.5926\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9596 - acc: 0.5673 - val_loss: 1.0174 - val_acc: 0.5926\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 0.9237 - acc: 0.5385 - val_loss: 1.0200 - val_acc: 0.5926\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9231 - acc: 0.5000 - val_loss: 1.0204 - val_acc: 0.5926\n",
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/100\n",
            "104/104 [==============================] - 0s 1ms/sample - loss: 2.2432 - acc: 0.4519 - val_loss: 3.2863 - val_acc: 0.3704\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 2.5687 - acc: 0.4808 - val_loss: 2.8953 - val_acc: 0.3704\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 2.0338 - acc: 0.3942 - val_loss: 2.6188 - val_acc: 0.3704\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 1.8501 - acc: 0.3462 - val_loss: 2.4143 - val_acc: 0.3704\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.5497 - acc: 0.4519 - val_loss: 2.2989 - val_acc: 0.3704\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 1.6379 - acc: 0.5577 - val_loss: 2.1881 - val_acc: 0.3704\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.5109 - acc: 0.5385 - val_loss: 2.0451 - val_acc: 0.4074\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 0s 359us/sample - loss: 1.5910 - acc: 0.5096 - val_loss: 1.9364 - val_acc: 0.3704\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 1.4555 - acc: 0.4327 - val_loss: 1.8578 - val_acc: 0.4074\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 0s 357us/sample - loss: 1.3695 - acc: 0.4327 - val_loss: 1.8028 - val_acc: 0.4074\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.5950 - acc: 0.4423 - val_loss: 1.6867 - val_acc: 0.3704\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 1.1612 - acc: 0.4808 - val_loss: 1.6738 - val_acc: 0.4074\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.3270 - acc: 0.5000 - val_loss: 1.6368 - val_acc: 0.3704\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 1.2108 - acc: 0.5000 - val_loss: 1.6124 - val_acc: 0.3704\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.1176 - acc: 0.5288 - val_loss: 1.5855 - val_acc: 0.4444\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 0s 319us/sample - loss: 1.1912 - acc: 0.4712 - val_loss: 1.5524 - val_acc: 0.4074\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 1.0985 - acc: 0.5288 - val_loss: 1.5347 - val_acc: 0.4444\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 1.2219 - acc: 0.4808 - val_loss: 1.5111 - val_acc: 0.4074\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1167 - acc: 0.5673 - val_loss: 1.4838 - val_acc: 0.4444\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 1.1347 - acc: 0.4519 - val_loss: 1.4695 - val_acc: 0.4444\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.1018 - acc: 0.5096 - val_loss: 1.4577 - val_acc: 0.4074\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 0s 341us/sample - loss: 1.2018 - acc: 0.5192 - val_loss: 1.4325 - val_acc: 0.4815\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 0s 363us/sample - loss: 1.1039 - acc: 0.4519 - val_loss: 1.4245 - val_acc: 0.4444\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0954 - acc: 0.4808 - val_loss: 1.4138 - val_acc: 0.4444\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.1998 - acc: 0.4423 - val_loss: 1.3984 - val_acc: 0.4444\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 0s 375us/sample - loss: 1.1515 - acc: 0.5000 - val_loss: 1.3886 - val_acc: 0.4444\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0464 - acc: 0.5000 - val_loss: 1.3753 - val_acc: 0.4444\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 1.1940 - acc: 0.4808 - val_loss: 1.3570 - val_acc: 0.4815\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.1116 - acc: 0.5000 - val_loss: 1.3443 - val_acc: 0.5185\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 0s 418us/sample - loss: 1.0683 - acc: 0.4904 - val_loss: 1.3396 - val_acc: 0.4444\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 1.1524 - acc: 0.4808 - val_loss: 1.3318 - val_acc: 0.4444\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 0s 399us/sample - loss: 1.0439 - acc: 0.5481 - val_loss: 1.3277 - val_acc: 0.4815\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9857 - acc: 0.5192 - val_loss: 1.3288 - val_acc: 0.4815\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 0s 327us/sample - loss: 1.1293 - acc: 0.4423 - val_loss: 1.3197 - val_acc: 0.4444\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 1.0442 - acc: 0.4808 - val_loss: 1.3107 - val_acc: 0.4815\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 0s 360us/sample - loss: 1.0557 - acc: 0.5096 - val_loss: 1.3088 - val_acc: 0.4444\n",
            "Epoch 37/100\n",
            "104/104 [==============================] - 0s 381us/sample - loss: 1.0197 - acc: 0.4712 - val_loss: 1.2972 - val_acc: 0.4074\n",
            "Epoch 38/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 1.0768 - acc: 0.5096 - val_loss: 1.2918 - val_acc: 0.4815\n",
            "Epoch 39/100\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 1.0853 - acc: 0.5192 - val_loss: 1.2844 - val_acc: 0.4815\n",
            "Epoch 40/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.0864 - acc: 0.5096 - val_loss: 1.2803 - val_acc: 0.4815\n",
            "Epoch 41/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9958 - acc: 0.5288 - val_loss: 1.2807 - val_acc: 0.4815\n",
            "Epoch 42/100\n",
            "104/104 [==============================] - 0s 387us/sample - loss: 1.0215 - acc: 0.5673 - val_loss: 1.2751 - val_acc: 0.4815\n",
            "Epoch 43/100\n",
            "104/104 [==============================] - 0s 444us/sample - loss: 1.0049 - acc: 0.5000 - val_loss: 1.2688 - val_acc: 0.4815\n",
            "Epoch 44/100\n",
            "104/104 [==============================] - 0s 409us/sample - loss: 1.0293 - acc: 0.5096 - val_loss: 1.2607 - val_acc: 0.5185\n",
            "Epoch 45/100\n",
            "104/104 [==============================] - 0s 367us/sample - loss: 0.9811 - acc: 0.5577 - val_loss: 1.2602 - val_acc: 0.5185\n",
            "Epoch 46/100\n",
            "104/104 [==============================] - 0s 335us/sample - loss: 1.1191 - acc: 0.4904 - val_loss: 1.2513 - val_acc: 0.5185\n",
            "Epoch 47/100\n",
            "104/104 [==============================] - 0s 344us/sample - loss: 1.0164 - acc: 0.4808 - val_loss: 1.2483 - val_acc: 0.5185\n",
            "Epoch 48/100\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 1.0175 - acc: 0.5288 - val_loss: 1.2480 - val_acc: 0.5185\n",
            "Epoch 49/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0148 - acc: 0.5577 - val_loss: 1.2401 - val_acc: 0.5185\n",
            "Epoch 50/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 1.0824 - acc: 0.5000 - val_loss: 1.2319 - val_acc: 0.4815\n",
            "Epoch 51/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9712 - acc: 0.5000 - val_loss: 1.2305 - val_acc: 0.5185\n",
            "Epoch 52/100\n",
            "104/104 [==============================] - 0s 380us/sample - loss: 0.9957 - acc: 0.5577 - val_loss: 1.2279 - val_acc: 0.5185\n",
            "Epoch 53/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9963 - acc: 0.5481 - val_loss: 1.2243 - val_acc: 0.5185\n",
            "Epoch 54/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0540 - acc: 0.5096 - val_loss: 1.2188 - val_acc: 0.5185\n",
            "Epoch 55/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0016 - acc: 0.5192 - val_loss: 1.2186 - val_acc: 0.5185\n",
            "Epoch 56/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9890 - acc: 0.5577 - val_loss: 1.2161 - val_acc: 0.5185\n",
            "Epoch 57/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0162 - acc: 0.5096 - val_loss: 1.2151 - val_acc: 0.4815\n",
            "Epoch 58/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9768 - acc: 0.5385 - val_loss: 1.2175 - val_acc: 0.5185\n",
            "Epoch 59/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9915 - acc: 0.5385 - val_loss: 1.2120 - val_acc: 0.5185\n",
            "Epoch 60/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 1.0570 - acc: 0.4904 - val_loss: 1.2039 - val_acc: 0.5185\n",
            "Epoch 61/100\n",
            "104/104 [==============================] - 0s 348us/sample - loss: 1.0297 - acc: 0.5385 - val_loss: 1.1986 - val_acc: 0.5185\n",
            "Epoch 62/100\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.9860 - acc: 0.5288 - val_loss: 1.1955 - val_acc: 0.5185\n",
            "Epoch 63/100\n",
            "104/104 [==============================] - 0s 353us/sample - loss: 1.0123 - acc: 0.5385 - val_loss: 1.1934 - val_acc: 0.5185\n",
            "Epoch 64/100\n",
            "104/104 [==============================] - 0s 325us/sample - loss: 0.9327 - acc: 0.5673 - val_loss: 1.1930 - val_acc: 0.5185\n",
            "Epoch 65/100\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.9684 - acc: 0.5673 - val_loss: 1.1918 - val_acc: 0.5185\n",
            "Epoch 66/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 1.0049 - acc: 0.5000 - val_loss: 1.1911 - val_acc: 0.5185\n",
            "Epoch 67/100\n",
            "104/104 [==============================] - 0s 321us/sample - loss: 1.0278 - acc: 0.5192 - val_loss: 1.1861 - val_acc: 0.5185\n",
            "Epoch 68/100\n",
            "104/104 [==============================] - 0s 334us/sample - loss: 0.9646 - acc: 0.4808 - val_loss: 1.1842 - val_acc: 0.5185\n",
            "Epoch 69/100\n",
            "104/104 [==============================] - 0s 308us/sample - loss: 0.9684 - acc: 0.5577 - val_loss: 1.1889 - val_acc: 0.5185\n",
            "Epoch 70/100\n",
            "104/104 [==============================] - 0s 338us/sample - loss: 0.9491 - acc: 0.5481 - val_loss: 1.1909 - val_acc: 0.5185\n",
            "Epoch 71/100\n",
            "104/104 [==============================] - 0s 395us/sample - loss: 0.9422 - acc: 0.5288 - val_loss: 1.1932 - val_acc: 0.5185\n",
            "Epoch 72/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9528 - acc: 0.5096 - val_loss: 1.1902 - val_acc: 0.5185\n",
            "Epoch 73/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9374 - acc: 0.5385 - val_loss: 1.1891 - val_acc: 0.5185\n",
            "Epoch 74/100\n",
            "104/104 [==============================] - 0s 351us/sample - loss: 0.9806 - acc: 0.4904 - val_loss: 1.1877 - val_acc: 0.5185\n",
            "Epoch 75/100\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.8981 - acc: 0.5865 - val_loss: 1.1855 - val_acc: 0.5185\n",
            "Epoch 76/100\n",
            "104/104 [==============================] - 0s 331us/sample - loss: 0.9882 - acc: 0.5962 - val_loss: 1.1816 - val_acc: 0.5185\n",
            "Epoch 77/100\n",
            "104/104 [==============================] - 0s 378us/sample - loss: 0.9642 - acc: 0.5481 - val_loss: 1.1812 - val_acc: 0.5185\n",
            "Epoch 78/100\n",
            "104/104 [==============================] - 0s 373us/sample - loss: 0.9307 - acc: 0.5288 - val_loss: 1.1818 - val_acc: 0.5185\n",
            "Epoch 79/100\n",
            "104/104 [==============================] - 0s 314us/sample - loss: 1.0212 - acc: 0.4808 - val_loss: 1.1750 - val_acc: 0.5185\n",
            "Epoch 80/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9655 - acc: 0.5288 - val_loss: 1.1772 - val_acc: 0.5185\n",
            "Epoch 81/100\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.9070 - acc: 0.5385 - val_loss: 1.1769 - val_acc: 0.5185\n",
            "Epoch 82/100\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9794 - acc: 0.5385 - val_loss: 1.1789 - val_acc: 0.5185\n",
            "Epoch 83/100\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.9192 - acc: 0.5385 - val_loss: 1.1808 - val_acc: 0.5185\n",
            "Epoch 84/100\n",
            "104/104 [==============================] - 0s 340us/sample - loss: 0.9704 - acc: 0.5385 - val_loss: 1.1817 - val_acc: 0.5185\n",
            "Epoch 85/100\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9789 - acc: 0.4904 - val_loss: 1.1805 - val_acc: 0.5185\n",
            "Epoch 86/100\n",
            "104/104 [==============================] - 0s 352us/sample - loss: 0.9617 - acc: 0.5481 - val_loss: 1.1811 - val_acc: 0.5185\n",
            "Epoch 87/100\n",
            "104/104 [==============================] - 0s 343us/sample - loss: 0.9786 - acc: 0.5000 - val_loss: 1.1773 - val_acc: 0.5185\n",
            "Epoch 88/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0068 - acc: 0.4519 - val_loss: 1.1768 - val_acc: 0.5185\n",
            "Epoch 89/100\n",
            "104/104 [==============================] - 0s 391us/sample - loss: 0.9662 - acc: 0.5577 - val_loss: 1.1762 - val_acc: 0.5185\n",
            "Epoch 90/100\n",
            "104/104 [==============================] - 0s 342us/sample - loss: 0.8846 - acc: 0.5962 - val_loss: 1.1792 - val_acc: 0.5185\n",
            "Epoch 91/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.9968 - acc: 0.5385 - val_loss: 1.1798 - val_acc: 0.5185\n",
            "Epoch 92/100\n",
            "104/104 [==============================] - 0s 324us/sample - loss: 0.9326 - acc: 0.5096 - val_loss: 1.1810 - val_acc: 0.5185\n",
            "Epoch 93/100\n",
            "104/104 [==============================] - 0s 300us/sample - loss: 0.9329 - acc: 0.5481 - val_loss: 1.1831 - val_acc: 0.5185\n",
            "Epoch 94/100\n",
            "104/104 [==============================] - 0s 318us/sample - loss: 0.9232 - acc: 0.5577 - val_loss: 1.1839 - val_acc: 0.5185\n",
            "Epoch 95/100\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 1.0140 - acc: 0.5288 - val_loss: 1.1799 - val_acc: 0.5185\n",
            "Epoch 96/100\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9701 - acc: 0.5096 - val_loss: 1.1772 - val_acc: 0.5185\n",
            "Epoch 97/100\n",
            "104/104 [==============================] - 0s 286us/sample - loss: 0.9744 - acc: 0.5481 - val_loss: 1.1732 - val_acc: 0.5185\n",
            "Epoch 98/100\n",
            "104/104 [==============================] - 0s 299us/sample - loss: 0.9393 - acc: 0.5865 - val_loss: 1.1735 - val_acc: 0.5185\n",
            "Epoch 99/100\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.9517 - acc: 0.5481 - val_loss: 1.1702 - val_acc: 0.5185\n",
            "Epoch 100/100\n",
            "104/104 [==============================] - 0s 293us/sample - loss: 0.9493 - acc: 0.5192 - val_loss: 1.1726 - val_acc: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e95da52e9c3536f6ecc4533b2e5a58e9</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.555555522441864</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.5</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23JI0eA1OFOX",
        "colab_type": "code",
        "outputId": "aca18426-6988-418c-ce09-6b511da2778e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "tuner.search_space_summary()\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">drop_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxpvAxjHSaP6",
        "colab_type": "code",
        "outputId": "56b3a9f3-fb27-4681-afd4-3f6a596d1fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Results in /content/my_dir/RandomSearch</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective(name='val_acc', direction='max')</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: b0cdeed1bcb32dea3594172743fea037</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.6666666269302368</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.9</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: a8dce0b625f954179c32303d144239a2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.6222222447395325</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.7</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: dc215e4b529e22ca959cc7b30f2022be</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.6074074506759644</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 925064ff7995dc6d91cb1715579432a9</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5703703761100769</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e95da52e9c3536f6ecc4533b2e5a58e9</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.555555522441864</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.5</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 4c8dfcb185b8bedfd686be7b003f7305</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5481481552124023</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.6</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 68a30c52665e8ad86467f695fdba9e6c</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5481481552124023</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9b5bede12522180c604bcc88b7edbd8b</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5333333015441895</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e15c54cdc0c4c104dc0b6edf4c0a990d</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5259259343147278</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: ba87a2f055c4beaad386f5cc220dbfe3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5111111402511597</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-drop_rate: 0.1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reyZM6rGXHIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_params=tuner.get_best_hyperparameters()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJpBGIEvVkpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_model = tuner.hypermodel.build(random_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QAOJ7PuXvwK",
        "colab_type": "code",
        "outputId": "82dd8541-6167-45ec-8e1e-189998da5b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'drop_rate': 0.9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYGZFhmPYZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = tuner.get_best_models()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVIumnBQEUq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "15f1ecf6-6dd5-4903-9c0c-f8d957e324d4"
      },
      "source": [
        "best_model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4)                 32        \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 15        \n",
            "=================================================================\n",
            "Total params: 47\n",
            "Trainable params: 47\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wJxr25jOew_",
        "colab_type": "text"
      },
      "source": [
        "##Train the best model RandomSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8w96YVEB_IW",
        "colab_type": "text"
      },
      "source": [
        "Per la valutazione del modello ottimizzato sul validation set uso la Stratified K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1apcZ19gFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBDM-PtBx5V",
        "colab_type": "code",
        "outputId": "0fab87e3-a6fc-4a32-daea-5c779628fa1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "skf.get_n_splits(train_data_stand_pca, train_labels_dec)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "9a030844-6814-466a-e408-57365f5fd699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "for train_index, test_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  1   2   4   5   6   8  10  11  12  13  14  15  16  17  20  21  22  23\n",
            "  24  25  26  27  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
            "  43  46  47  48  49  50  52  55  58  59  60  61  62  63  64  65  67  68\n",
            "  69  70  71  73  74  75  76  77  78  79  81  82  83  84  85  86  87  88\n",
            "  89  91  92  93  94  96  97  98  99 100 101 102 103 104 106 107 108 110\n",
            " 113 115 116 117 118 119 121 122 123 124 126 127 129 130] TEST: [  0   3   7   9  18  19  28  44  45  51  53  54  56  57  66  72  80  90\n",
            "  95 105 109 111 112 114 120 125 128]\n",
            "TRAIN: [  0   1   2   3   5   7   8   9  10  11  12  13  14  17  18  19  20  21\n",
            "  22  23  24  25  26  27  28  29  30  31  33  34  37  38  39  40  41  42\n",
            "  44  45  46  47  48  49  51  53  54  55  56  57  58  61  62  63  64  66\n",
            "  67  69  70  71  72  73  75  77  79  80  81  82  83  84  85  87  88  89\n",
            "  90  92  94  95  96  97  98  99 100 101 103 105 106 107 109 110 111 112\n",
            " 114 115 116 117 118 119 120 121 122 124 125 126 127 128 129] TEST: [  4   6  15  16  32  35  36  43  50  52  59  60  65  68  74  76  78  86\n",
            "  91  93 102 104 108 113 123 130]\n",
            "TRAIN: [  0   1   3   4   5   6   7   8   9  10  13  14  15  16  17  18  19  20\n",
            "  22  23  24  25  28  29  30  31  32  33  35  36  37  39  40  43  44  45\n",
            "  46  47  49  50  51  52  53  54  55  56  57  58  59  60  63  64  65  66\n",
            "  67  68  71  72  73  74  75  76  78  79  80  81  82  84  85  86  88  89\n",
            "  90  91  92  93  94  95  98  99 100 101 102 104 105 106 108 109 110 111\n",
            " 112 113 114 115 117 118 120 122 123 125 126 127 128 129 130] TEST: [  2  11  12  21  26  27  34  38  41  42  48  61  62  69  70  77  83  87\n",
            "  96  97 103 107 116 119 121 124]\n",
            "TRAIN: [  0   1   2   3   4   6   7   8   9  10  11  12  15  16  17  18  19  20\n",
            "  21  23  25  26  27  28  31  32  33  34  35  36  37  38  39  40  41  42\n",
            "  43  44  45  48  50  51  52  53  54  56  57  59  60  61  62  64  65  66\n",
            "  67  68  69  70  72  73  74  76  77  78  80  81  83  84  86  87  89  90\n",
            "  91  92  93  95  96  97  98  99 101 102 103 104 105 107 108 109 111 112\n",
            " 113 114 115 116 117 118 119 120 121 122 123 124 125 128 130] TEST: [  5  13  14  22  24  29  30  46  47  49  55  58  63  71  75  79  82  85\n",
            "  88  94 100 106 110 126 127 129]\n",
            "TRAIN: [  0   2   3   4   5   6   7   9  11  12  13  14  15  16  18  19  21  22\n",
            "  24  26  27  28  29  30  32  34  35  36  38  41  42  43  44  45  46  47\n",
            "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  65  66\n",
            "  68  69  70  71  72  74  75  76  77  78  79  80  82  83  85  86  87  88\n",
            "  90  91  93  94  95  96  97 100 102 103 104 105 106 107 108 109 110 111\n",
            " 112 113 114 116 119 120 121 123 124 125 126 127 128 129 130] TEST: [  1   8  10  17  20  23  25  31  33  37  39  40  64  67  73  81  84  89\n",
            "  92  98  99 101 115 117 118 122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8a1I3yU9FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#num_epochs = 50\n",
        "all_acc_histories_RS = []\n",
        "all_loss_histories_RS = []\n",
        "all_val_acc_histories_RS = []\n",
        "all_val_loss_histories_RS = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        " \n",
        "  history_RS = best_model.fit(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=5)\n",
        "  \n",
        "  acc_history_RS = history_RS.history['acc']\n",
        "  all_acc_histories_RS.append(acc_history_RS)\n",
        "\n",
        "  loss_history_RS = history_RS.history['loss']\n",
        "  all_loss_histories_RS.append(loss_history_RS)\n",
        "\n",
        "  acc_val_history_RS = history_RS.history['val_acc']\n",
        "  all_val_acc_histories_RS.append(acc_val_history_RS)\n",
        "\n",
        "  loss_val_history_RS = history_RS.history['val_loss']\n",
        "  all_val_loss_histories_RS.append(loss_val_history_RS)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali  una lista lunga num_epochs,\n",
        "#ogni elemento pu essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkjHWfuvSRXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history_RS.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5o_DnOySStG",
        "colab_type": "code",
        "outputId": "5c833a07-eaae-4952-c48c-0b7850c4a959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UhSxIaHtuO",
        "colab_type": "text"
      },
      "source": [
        "##Plotting training and validation loss RandomSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zsienD5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJizyjnaIPhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, num_epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z_pSVTWwtybS",
        "colab": {}
      },
      "source": [
        "average_acc_history_RS = [np.mean([x[i] for x in all_acc_histories_RS]) for i in range(num_epochs)]\n",
        "average_loss_history_RS = [np.mean([x[i] for x in all_loss_histories_RS]) for i in range(num_epochs)]\n",
        "average_val_acc_history_RS = [np.mean([x[i] for x in all_val_acc_histories_RS]) for i in range(num_epochs)]\n",
        "average_val_loss_history_RS = [np.mean([x[i] for x in all_val_loss_histories_RS]) for i in range(num_epochs)]\n",
        "#media per epoca degli score ottenuti per tutte le k-fold\n",
        "#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\n",
        "#e si fa questo per tutte le epoche"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEHEYLgIQUQ",
        "colab_type": "code",
        "outputId": "c79e3994-e41a-4112-c508-3d32922d871b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs, average_loss_history_RS, 'b', label='training loss')\n",
        "plt.plot(epochs, average_val_loss_history_RS, 'r', label='validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f00fbede358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc4wMjfI97j",
        "colab_type": "text"
      },
      "source": [
        "##Plotting train and validation accuracy RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi7VzbFIbtJ",
        "colab_type": "code",
        "outputId": "6099f203-b2cb-4db2-b92d-1101c50325c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs, average_acc_history_RS, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, average_val_acc_history_RS, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend() "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f00fc0afb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}