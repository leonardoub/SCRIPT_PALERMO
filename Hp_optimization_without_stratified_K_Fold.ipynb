{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hp_optimization_without_stratified_K_Fold",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/Hp_optimization_without_stratified_K_Fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZpyLcr_wktZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "1b96bcfe-d1f7-486a-e015-f306ad65395d"
      },
      "source": [
        "!pip install -U keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\r\u001b[K     |██████                          | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.6)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.14.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73199 sha256=aaee0ccc5971ca50d237bc1abd073bf8b531846d2bccfe4b3f44c5b75b3ab20c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15354 sha256=7a2b7fbf63604a71afe16ef1f01c62fc4a3ae4782209b9d0fcdae12875bc02ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.3 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11sCznT-2mmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tAAGti39qMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a046ffd7-4e9e-44c2-8b1f-7937e60f3a38"
      },
      "source": [
        "!rm -r my_dir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'my_dir': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "251fa955-ed5c-43c9-a53d-f8ed6a72deff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-87QSVhqhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSbeCedhuxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbcwLGg3iNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQdR4izXiT0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5wIylYmsQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = df_test.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data_stand = train_data - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVOoNOvm0Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_stand = test_data - mean\n",
        "test_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00VohsAyokpq",
        "colab_type": "text"
      },
      "source": [
        "##Vettorizzare i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvS_9ISpxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={'adenocarcinoma':0, 'large cell':1, 'squamous cell carcinoma':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPW9U0XrWY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_dec = [word_index[label] for label in train_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4SBiKFQsKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels_dec = [word_index[label] for label in test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMbTYR7okJq",
        "colab_type": "code",
        "outputId": "fcd1b76b-b02e-4770-d211-e39fbad2a779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Frv4FDNn6Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels_dec)\n",
        "one_hot_test_labels = to_categorical(test_labels_dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn0tkOGc3LKN",
        "colab_type": "text"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS76u6iu3Seg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjC4zqJ3bui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.85, svd_solver='full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLUCf9qX4p_e",
        "colab_type": "code",
        "outputId": "032b2fae-3ad7-4de7-c205-ce1d9cddd07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pca.fit(train_data_stand)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.85, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyaKgNZ44o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_pca = pca.transform(train_data_stand)\n",
        "test_data_stand_pca = pca.transform(test_data_stand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9C4nl05b_g",
        "colab_type": "code",
        "outputId": "28a10c51-0bfb-48ed-99bd-ee60776a0ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_stand_pca.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSKvSu4s5ip",
        "colab_type": "text"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osgm8ZvLpZh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTbHiq0D-4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAzbu7P1VylY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqbUCK5wOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KutkQ9Noj5mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hp):\n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "#  model.add(layers.Dense(units=(hp.Int('units', min_value=3, max_value=8, step=1)), \n",
        "#                         activation='relu', input_shape=(9,)))\n",
        " \n",
        "#  drop_rate = hp.Choice('drop_rate', [0.0, 0.1, 0.2, 0.3,\n",
        "#                              0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "\n",
        "  model.add(layers.Dense(4, activation='relu', input_shape=(7,)))\n",
        "#  model.add(layers.Dropout(rate=drop_rate))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "#  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "#  lr = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "  decay = hp.Choice('decay', [1e-4, 1e-5, 1e-6, 1e-7, 1e-8])\n",
        "#  momentum = hp.Choice('momentum', [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
        "  model.compile(optimizer=SGD(learning_rate=1e-3, momentum=0.5, decay=decay, nesterov=True), \n",
        "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1ZG40_dJtke",
        "colab_type": "text"
      },
      "source": [
        "##Prova Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABYrxmZxJdlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFCCTjE6JrQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_data_stand_pca, train_labels_dec,\n",
        "                                                    stratify=train_labels_dec,\n",
        "                                                    test_size=0.30,\n",
        "                                                    random_state=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pus4JhTKWWB",
        "colab_type": "code",
        "outputId": "84d4f6cd-f57b-411c-b9cf-046ede440f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.count(2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yP9-PE1Wjz-",
        "colab_type": "text"
      },
      "source": [
        "#Keras tuner RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0eed5ab7-58c5-4105-c273-d1dc18782ad0",
        "id": "oHDM8LE39gTU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 50\n",
        "  \n",
        "one_hot_partial_train_targets = to_categorical(y_train)\n",
        "one_hot_val_targets = to_categorical(y_val)\n",
        "\n",
        "tuner = RandomSearch(build_model, objective='val_acc', max_trials=8, \n",
        "                       executions_per_trial=5, directory='/content/my_dir', project_name='RandomSearch')\n",
        "  \n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(X_train, one_hot_partial_train_targets, validation_data=(X_val, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=5)\n",
        "  \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">decay (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0001, 1e-05, 1e-06, 1e-07, 1e-08]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 3ms/sample - loss: 1.5808 - acc: 0.2747 - val_loss: 1.1216 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 1.4522 - acc: 0.3187 - val_loss: 1.0941 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 466us/sample - loss: 1.3524 - acc: 0.3846 - val_loss: 1.0797 - val_acc: 0.5250\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 1.2812 - acc: 0.4176 - val_loss: 1.0744 - val_acc: 0.5250\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.2187 - acc: 0.4505 - val_loss: 1.0735 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 1.1696 - acc: 0.5055 - val_loss: 1.0742 - val_acc: 0.4750\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.1324 - acc: 0.5165 - val_loss: 1.0740 - val_acc: 0.4750\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 1.1066 - acc: 0.5275 - val_loss: 1.0688 - val_acc: 0.4500\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 462us/sample - loss: 1.0881 - acc: 0.5275 - val_loss: 1.0652 - val_acc: 0.4500\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 462us/sample - loss: 1.0740 - acc: 0.5385 - val_loss: 1.0628 - val_acc: 0.4500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.0638 - acc: 0.5275 - val_loss: 1.0593 - val_acc: 0.4500\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 1.0583 - acc: 0.5165 - val_loss: 1.0580 - val_acc: 0.4500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 1.0493 - acc: 0.5495 - val_loss: 1.0530 - val_acc: 0.4500\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 1.0406 - acc: 0.5495 - val_loss: 1.0509 - val_acc: 0.4500\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 434us/sample - loss: 1.0343 - acc: 0.5604 - val_loss: 1.0497 - val_acc: 0.4500\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 417us/sample - loss: 1.0297 - acc: 0.5604 - val_loss: 1.0383 - val_acc: 0.4250\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.0269 - acc: 0.5495 - val_loss: 1.0327 - val_acc: 0.4250\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 1.0195 - acc: 0.5604 - val_loss: 1.0308 - val_acc: 0.4250\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 439us/sample - loss: 1.0130 - acc: 0.5495 - val_loss: 1.0305 - val_acc: 0.4250\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 444us/sample - loss: 1.0091 - acc: 0.5495 - val_loss: 1.0350 - val_acc: 0.4750\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 347us/sample - loss: 1.0033 - acc: 0.5934 - val_loss: 1.0348 - val_acc: 0.4750\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 0.9968 - acc: 0.5824 - val_loss: 1.0334 - val_acc: 0.4750\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 0.9937 - acc: 0.5824 - val_loss: 1.0325 - val_acc: 0.4750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 0.9906 - acc: 0.5824 - val_loss: 1.0319 - val_acc: 0.4750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 410us/sample - loss: 0.9868 - acc: 0.5714 - val_loss: 1.0309 - val_acc: 0.4750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 573us/sample - loss: 0.9842 - acc: 0.5604 - val_loss: 1.0310 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 0.9813 - acc: 0.5604 - val_loss: 1.0296 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 469us/sample - loss: 0.9780 - acc: 0.5824 - val_loss: 1.0299 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 465us/sample - loss: 0.9756 - acc: 0.5385 - val_loss: 1.0319 - val_acc: 0.4750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 0.9736 - acc: 0.5714 - val_loss: 1.0352 - val_acc: 0.4750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 518us/sample - loss: 0.9712 - acc: 0.5604 - val_loss: 1.0355 - val_acc: 0.4750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 492us/sample - loss: 0.9682 - acc: 0.5714 - val_loss: 1.0364 - val_acc: 0.4750\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 429us/sample - loss: 0.9657 - acc: 0.5824 - val_loss: 1.0311 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 417us/sample - loss: 0.9637 - acc: 0.5385 - val_loss: 1.0298 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 446us/sample - loss: 0.9616 - acc: 0.5495 - val_loss: 1.0269 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 471us/sample - loss: 0.9590 - acc: 0.5495 - val_loss: 1.0245 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 0.9576 - acc: 0.5495 - val_loss: 1.0275 - val_acc: 0.4750\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 488us/sample - loss: 0.9571 - acc: 0.5385 - val_loss: 1.0284 - val_acc: 0.4750\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 453us/sample - loss: 0.9531 - acc: 0.5385 - val_loss: 1.0282 - val_acc: 0.4750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 473us/sample - loss: 0.9525 - acc: 0.5495 - val_loss: 1.0308 - val_acc: 0.4750\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 531us/sample - loss: 0.9514 - acc: 0.5495 - val_loss: 1.0299 - val_acc: 0.4750\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9494 - acc: 0.5165 - val_loss: 1.0311 - val_acc: 0.4750\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 443us/sample - loss: 0.9475 - acc: 0.5495 - val_loss: 1.0297 - val_acc: 0.4750\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9468 - acc: 0.5275 - val_loss: 1.0290 - val_acc: 0.4750\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 485us/sample - loss: 0.9453 - acc: 0.5275 - val_loss: 1.0293 - val_acc: 0.4750\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 499us/sample - loss: 0.9439 - acc: 0.5275 - val_loss: 1.0210 - val_acc: 0.4750\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 453us/sample - loss: 0.9473 - acc: 0.5055 - val_loss: 1.0194 - val_acc: 0.4750\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 0.9432 - acc: 0.5055 - val_loss: 1.0206 - val_acc: 0.4750\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 530us/sample - loss: 0.9409 - acc: 0.5165 - val_loss: 1.0224 - val_acc: 0.5000\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 429us/sample - loss: 0.9398 - acc: 0.5165 - val_loss: 1.0232 - val_acc: 0.5000\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.7005 - acc: 0.3626 - val_loss: 1.9441 - val_acc: 0.4750\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 450us/sample - loss: 1.4434 - acc: 0.4066 - val_loss: 1.7821 - val_acc: 0.4750\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 1.2915 - acc: 0.4176 - val_loss: 1.6958 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 877us/sample - loss: 1.2279 - acc: 0.4066 - val_loss: 1.6379 - val_acc: 0.5500\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 498us/sample - loss: 1.1828 - acc: 0.5275 - val_loss: 1.5972 - val_acc: 0.5500\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 1.1574 - acc: 0.5495 - val_loss: 1.5588 - val_acc: 0.5500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 1.1352 - acc: 0.5495 - val_loss: 1.5276 - val_acc: 0.5500\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.1163 - acc: 0.5495 - val_loss: 1.4998 - val_acc: 0.5500\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 335us/sample - loss: 1.0995 - acc: 0.5275 - val_loss: 1.4722 - val_acc: 0.5250\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 1.0846 - acc: 0.5495 - val_loss: 1.4495 - val_acc: 0.5250\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 1.0710 - acc: 0.5604 - val_loss: 1.4255 - val_acc: 0.5250\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 432us/sample - loss: 1.0581 - acc: 0.5604 - val_loss: 1.4037 - val_acc: 0.5250\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 1.0466 - acc: 0.5604 - val_loss: 1.3829 - val_acc: 0.5250\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 1.0351 - acc: 0.5714 - val_loss: 1.3643 - val_acc: 0.5500\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 429us/sample - loss: 1.0262 - acc: 0.5824 - val_loss: 1.3469 - val_acc: 0.5500\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 1.0158 - acc: 0.5824 - val_loss: 1.3311 - val_acc: 0.5500\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 1.0068 - acc: 0.5934 - val_loss: 1.3162 - val_acc: 0.5500\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 474us/sample - loss: 0.9988 - acc: 0.5934 - val_loss: 1.3011 - val_acc: 0.5500\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9904 - acc: 0.5934 - val_loss: 1.2884 - val_acc: 0.5500\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9827 - acc: 0.5824 - val_loss: 1.2784 - val_acc: 0.5250\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 558us/sample - loss: 0.9773 - acc: 0.5824 - val_loss: 1.2671 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 475us/sample - loss: 0.9698 - acc: 0.5824 - val_loss: 1.2573 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9638 - acc: 0.5824 - val_loss: 1.2498 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 0.9595 - acc: 0.5824 - val_loss: 1.2276 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 366us/sample - loss: 0.9501 - acc: 0.5824 - val_loss: 1.2144 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9456 - acc: 0.5824 - val_loss: 1.2088 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 530us/sample - loss: 0.9413 - acc: 0.5824 - val_loss: 1.2051 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 466us/sample - loss: 0.9377 - acc: 0.5824 - val_loss: 1.2019 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 0.9335 - acc: 0.5934 - val_loss: 1.1991 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 0.9293 - acc: 0.5934 - val_loss: 1.1951 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9269 - acc: 0.5934 - val_loss: 1.1908 - val_acc: 0.4750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 0.9239 - acc: 0.5934 - val_loss: 1.1862 - val_acc: 0.4500\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 418us/sample - loss: 0.9210 - acc: 0.5934 - val_loss: 1.1836 - val_acc: 0.4500\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 536us/sample - loss: 0.9189 - acc: 0.5934 - val_loss: 1.1813 - val_acc: 0.4500\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 439us/sample - loss: 0.9161 - acc: 0.5824 - val_loss: 1.1804 - val_acc: 0.4500\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 468us/sample - loss: 0.9141 - acc: 0.5934 - val_loss: 1.1796 - val_acc: 0.4500\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 0.9122 - acc: 0.5824 - val_loss: 1.1780 - val_acc: 0.4500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 0.9099 - acc: 0.5824 - val_loss: 1.1762 - val_acc: 0.4500\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 0.9078 - acc: 0.5934 - val_loss: 1.1731 - val_acc: 0.4500\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 0.9063 - acc: 0.5934 - val_loss: 1.1709 - val_acc: 0.4500\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 435us/sample - loss: 0.9047 - acc: 0.5824 - val_loss: 1.1695 - val_acc: 0.4500\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 476us/sample - loss: 0.9024 - acc: 0.5824 - val_loss: 1.1687 - val_acc: 0.4500\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 477us/sample - loss: 0.9008 - acc: 0.5824 - val_loss: 1.1687 - val_acc: 0.4750\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 0.9002 - acc: 0.5824 - val_loss: 1.1673 - val_acc: 0.4500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.8987 - acc: 0.5824 - val_loss: 1.1676 - val_acc: 0.4500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.8983 - acc: 0.5824 - val_loss: 1.1673 - val_acc: 0.4500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 455us/sample - loss: 0.8964 - acc: 0.5824 - val_loss: 1.1668 - val_acc: 0.4500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 467us/sample - loss: 0.8953 - acc: 0.5824 - val_loss: 1.1672 - val_acc: 0.4500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 462us/sample - loss: 0.8935 - acc: 0.5824 - val_loss: 1.1668 - val_acc: 0.4500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 410us/sample - loss: 0.8920 - acc: 0.5934 - val_loss: 1.1664 - val_acc: 0.4500\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.4743 - acc: 0.5165 - val_loss: 1.8826 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 1.4008 - acc: 0.5055 - val_loss: 1.7823 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 1.3308 - acc: 0.4945 - val_loss: 1.6680 - val_acc: 0.4750\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 439us/sample - loss: 1.2467 - acc: 0.4945 - val_loss: 1.5868 - val_acc: 0.4750\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 1.2003 - acc: 0.5055 - val_loss: 1.5096 - val_acc: 0.4750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 371us/sample - loss: 1.1482 - acc: 0.5055 - val_loss: 1.4620 - val_acc: 0.4500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.1226 - acc: 0.5055 - val_loss: 1.4266 - val_acc: 0.4000\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 419us/sample - loss: 1.0942 - acc: 0.5055 - val_loss: 1.3967 - val_acc: 0.4250\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 1.0748 - acc: 0.5055 - val_loss: 1.3661 - val_acc: 0.4000\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 1.0514 - acc: 0.5055 - val_loss: 1.3429 - val_acc: 0.4000\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 1.0374 - acc: 0.5055 - val_loss: 1.3264 - val_acc: 0.4000\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 576us/sample - loss: 1.0254 - acc: 0.5165 - val_loss: 1.3119 - val_acc: 0.3750\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 514us/sample - loss: 1.0155 - acc: 0.5165 - val_loss: 1.2839 - val_acc: 0.3250\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 462us/sample - loss: 1.0032 - acc: 0.5165 - val_loss: 1.2700 - val_acc: 0.3500\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 504us/sample - loss: 0.9963 - acc: 0.4725 - val_loss: 1.2631 - val_acc: 0.3750\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9889 - acc: 0.4725 - val_loss: 1.2583 - val_acc: 0.3750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9832 - acc: 0.4725 - val_loss: 1.2543 - val_acc: 0.3750\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9775 - acc: 0.4725 - val_loss: 1.2491 - val_acc: 0.3750\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 536us/sample - loss: 0.9712 - acc: 0.4835 - val_loss: 1.2437 - val_acc: 0.3750\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 446us/sample - loss: 0.9660 - acc: 0.4835 - val_loss: 1.2386 - val_acc: 0.3750\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 486us/sample - loss: 0.9616 - acc: 0.4945 - val_loss: 1.2339 - val_acc: 0.3750\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 0.9576 - acc: 0.4945 - val_loss: 1.2278 - val_acc: 0.3750\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 0.9528 - acc: 0.4725 - val_loss: 1.2226 - val_acc: 0.3750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 513us/sample - loss: 0.9490 - acc: 0.4835 - val_loss: 1.2180 - val_acc: 0.3750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 429us/sample - loss: 0.9467 - acc: 0.4835 - val_loss: 1.2143 - val_acc: 0.3750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9422 - acc: 0.4835 - val_loss: 1.2112 - val_acc: 0.3750\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 458us/sample - loss: 0.9398 - acc: 0.4725 - val_loss: 1.2094 - val_acc: 0.3750\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 0.9346 - acc: 0.4945 - val_loss: 1.2088 - val_acc: 0.4000\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 487us/sample - loss: 0.9312 - acc: 0.5055 - val_loss: 1.2075 - val_acc: 0.4000\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 428us/sample - loss: 0.9288 - acc: 0.5055 - val_loss: 1.2064 - val_acc: 0.4000\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9263 - acc: 0.5055 - val_loss: 1.2059 - val_acc: 0.4000\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 0.9232 - acc: 0.4945 - val_loss: 1.2049 - val_acc: 0.4000\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 0.9214 - acc: 0.5055 - val_loss: 1.2018 - val_acc: 0.4000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9196 - acc: 0.5055 - val_loss: 1.2012 - val_acc: 0.4000\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 0.9177 - acc: 0.5055 - val_loss: 1.1987 - val_acc: 0.3750\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 410us/sample - loss: 0.9151 - acc: 0.5055 - val_loss: 1.1968 - val_acc: 0.3750\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 0.9143 - acc: 0.5055 - val_loss: 1.1959 - val_acc: 0.3750\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 464us/sample - loss: 0.9116 - acc: 0.5055 - val_loss: 1.1941 - val_acc: 0.3750\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9096 - acc: 0.5275 - val_loss: 1.1936 - val_acc: 0.3750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 429us/sample - loss: 0.9077 - acc: 0.5165 - val_loss: 1.1927 - val_acc: 0.3750\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9061 - acc: 0.5275 - val_loss: 1.1909 - val_acc: 0.3750\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9051 - acc: 0.5275 - val_loss: 1.1912 - val_acc: 0.3750\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 420us/sample - loss: 0.9033 - acc: 0.5165 - val_loss: 1.1913 - val_acc: 0.3750\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 459us/sample - loss: 0.9031 - acc: 0.5055 - val_loss: 1.1875 - val_acc: 0.4000\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 428us/sample - loss: 0.9022 - acc: 0.5275 - val_loss: 1.1845 - val_acc: 0.4000\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 447us/sample - loss: 0.9005 - acc: 0.5165 - val_loss: 1.1822 - val_acc: 0.3750\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 486us/sample - loss: 0.9000 - acc: 0.4945 - val_loss: 1.1816 - val_acc: 0.3750\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.8993 - acc: 0.5165 - val_loss: 1.1798 - val_acc: 0.3750\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 0.8981 - acc: 0.5165 - val_loss: 1.1789 - val_acc: 0.4000\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 0.8977 - acc: 0.4945 - val_loss: 1.1786 - val_acc: 0.4000\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 3.5977 - acc: 0.2088 - val_loss: 3.2425 - val_acc: 0.2250\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 3.2084 - acc: 0.2198 - val_loss: 2.9138 - val_acc: 0.2250\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 463us/sample - loss: 2.8819 - acc: 0.2308 - val_loss: 2.6162 - val_acc: 0.2250\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 440us/sample - loss: 2.5840 - acc: 0.2088 - val_loss: 2.3782 - val_acc: 0.2000\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 351us/sample - loss: 2.3643 - acc: 0.2198 - val_loss: 2.1910 - val_acc: 0.2000\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 2.1712 - acc: 0.2308 - val_loss: 2.0314 - val_acc: 0.2000\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 351us/sample - loss: 2.0043 - acc: 0.2418 - val_loss: 1.8939 - val_acc: 0.2000\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.8617 - acc: 0.2527 - val_loss: 1.7696 - val_acc: 0.1750\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 1.7460 - acc: 0.2527 - val_loss: 1.6698 - val_acc: 0.2000\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 1.6326 - acc: 0.2967 - val_loss: 1.5955 - val_acc: 0.2250\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 1.5513 - acc: 0.2967 - val_loss: 1.5390 - val_acc: 0.2250\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 1.4723 - acc: 0.3626 - val_loss: 1.4967 - val_acc: 0.2500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 1.4082 - acc: 0.3516 - val_loss: 1.4637 - val_acc: 0.2750\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 1.3522 - acc: 0.3626 - val_loss: 1.4358 - val_acc: 0.2750\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 455us/sample - loss: 1.3007 - acc: 0.3736 - val_loss: 1.4160 - val_acc: 0.3000\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 457us/sample - loss: 1.2568 - acc: 0.3736 - val_loss: 1.3946 - val_acc: 0.2750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 350us/sample - loss: 1.2192 - acc: 0.4176 - val_loss: 1.3806 - val_acc: 0.3000\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 1.1879 - acc: 0.4945 - val_loss: 1.3685 - val_acc: 0.3000\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 1.1611 - acc: 0.4725 - val_loss: 1.3549 - val_acc: 0.3250\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 1.1387 - acc: 0.4725 - val_loss: 1.3400 - val_acc: 0.3500\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 453us/sample - loss: 1.1124 - acc: 0.4945 - val_loss: 1.3224 - val_acc: 0.3750\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 447us/sample - loss: 1.0977 - acc: 0.4945 - val_loss: 1.3087 - val_acc: 0.3500\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 369us/sample - loss: 1.0837 - acc: 0.5165 - val_loss: 1.2969 - val_acc: 0.3500\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 357us/sample - loss: 1.0722 - acc: 0.5385 - val_loss: 1.2877 - val_acc: 0.3750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 349us/sample - loss: 1.0613 - acc: 0.5385 - val_loss: 1.2793 - val_acc: 0.3750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.0506 - acc: 0.5495 - val_loss: 1.2706 - val_acc: 0.3750\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.0431 - acc: 0.5714 - val_loss: 1.2611 - val_acc: 0.3500\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 1.0353 - acc: 0.5604 - val_loss: 1.2556 - val_acc: 0.3750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.0268 - acc: 0.5824 - val_loss: 1.2450 - val_acc: 0.3750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 1.0194 - acc: 0.5824 - val_loss: 1.2388 - val_acc: 0.3750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 482us/sample - loss: 1.0154 - acc: 0.5824 - val_loss: 1.2301 - val_acc: 0.3750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 1.0101 - acc: 0.5824 - val_loss: 1.2190 - val_acc: 0.3750\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 1.0047 - acc: 0.5824 - val_loss: 1.2122 - val_acc: 0.3750\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 1.0005 - acc: 0.5934 - val_loss: 1.2086 - val_acc: 0.3750\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9969 - acc: 0.5824 - val_loss: 1.2045 - val_acc: 0.3750\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9932 - acc: 0.5714 - val_loss: 1.2073 - val_acc: 0.3750\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 419us/sample - loss: 0.9897 - acc: 0.5604 - val_loss: 1.2172 - val_acc: 0.3750\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9868 - acc: 0.5824 - val_loss: 1.2167 - val_acc: 0.3750\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9839 - acc: 0.5934 - val_loss: 1.2166 - val_acc: 0.3750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 0.9796 - acc: 0.5824 - val_loss: 1.2127 - val_acc: 0.3750\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9765 - acc: 0.5824 - val_loss: 1.2079 - val_acc: 0.3750\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 0.9723 - acc: 0.5824 - val_loss: 1.2069 - val_acc: 0.3750\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 0.9705 - acc: 0.5824 - val_loss: 1.2046 - val_acc: 0.3750\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 0.9682 - acc: 0.5604 - val_loss: 1.2014 - val_acc: 0.3750\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 0.9659 - acc: 0.5714 - val_loss: 1.2026 - val_acc: 0.3750\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 476us/sample - loss: 0.9625 - acc: 0.5824 - val_loss: 1.1946 - val_acc: 0.3750\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 0.9607 - acc: 0.5824 - val_loss: 1.1954 - val_acc: 0.3750\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 0.9593 - acc: 0.5714 - val_loss: 1.1964 - val_acc: 0.3750\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9570 - acc: 0.5714 - val_loss: 1.1924 - val_acc: 0.3750\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 418us/sample - loss: 0.9557 - acc: 0.5824 - val_loss: 1.1899 - val_acc: 0.3750\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 975us/sample - loss: 1.5070 - acc: 0.2967 - val_loss: 1.4962 - val_acc: 0.2500\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 1.3128 - acc: 0.3626 - val_loss: 1.3680 - val_acc: 0.2500\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 1.1817 - acc: 0.3736 - val_loss: 1.2810 - val_acc: 0.3250\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 1.0972 - acc: 0.4066 - val_loss: 1.2289 - val_acc: 0.2750\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 1.0496 - acc: 0.4615 - val_loss: 1.1965 - val_acc: 0.4000\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 1.0230 - acc: 0.4505 - val_loss: 1.1682 - val_acc: 0.4000\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 452us/sample - loss: 1.0036 - acc: 0.4945 - val_loss: 1.1506 - val_acc: 0.4000\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 449us/sample - loss: 0.9915 - acc: 0.4945 - val_loss: 1.1393 - val_acc: 0.4000\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9843 - acc: 0.5275 - val_loss: 1.1286 - val_acc: 0.4000\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 0.9775 - acc: 0.5385 - val_loss: 1.1174 - val_acc: 0.3750\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 0.9717 - acc: 0.5385 - val_loss: 1.1068 - val_acc: 0.3750\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 483us/sample - loss: 0.9678 - acc: 0.5385 - val_loss: 1.1013 - val_acc: 0.4000\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 0.9660 - acc: 0.5385 - val_loss: 1.0973 - val_acc: 0.4000\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9631 - acc: 0.5385 - val_loss: 1.0948 - val_acc: 0.4000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9611 - acc: 0.5495 - val_loss: 1.0925 - val_acc: 0.4000\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9592 - acc: 0.5385 - val_loss: 1.0903 - val_acc: 0.4000\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 0.9571 - acc: 0.5385 - val_loss: 1.0872 - val_acc: 0.4000\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9554 - acc: 0.5385 - val_loss: 1.0872 - val_acc: 0.4000\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9534 - acc: 0.5385 - val_loss: 1.0865 - val_acc: 0.4000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 451us/sample - loss: 0.9520 - acc: 0.5385 - val_loss: 1.0849 - val_acc: 0.4000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 0.9513 - acc: 0.5385 - val_loss: 1.0849 - val_acc: 0.4250\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 0.9492 - acc: 0.5275 - val_loss: 1.0850 - val_acc: 0.4250\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 456us/sample - loss: 0.9483 - acc: 0.5275 - val_loss: 1.0843 - val_acc: 0.4250\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 0.9472 - acc: 0.5385 - val_loss: 1.0834 - val_acc: 0.4250\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 0.9463 - acc: 0.5385 - val_loss: 1.0830 - val_acc: 0.4250\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 0.9444 - acc: 0.5385 - val_loss: 1.0834 - val_acc: 0.4250\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 359us/sample - loss: 0.9443 - acc: 0.5385 - val_loss: 1.0798 - val_acc: 0.4250\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 432us/sample - loss: 0.9436 - acc: 0.5385 - val_loss: 1.0786 - val_acc: 0.4250\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 438us/sample - loss: 0.9430 - acc: 0.5385 - val_loss: 1.0796 - val_acc: 0.4250\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9416 - acc: 0.5495 - val_loss: 1.0798 - val_acc: 0.4250\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 0.9397 - acc: 0.5495 - val_loss: 1.0745 - val_acc: 0.4250\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 0.9395 - acc: 0.5604 - val_loss: 1.0732 - val_acc: 0.4250\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 0.9384 - acc: 0.5604 - val_loss: 1.0695 - val_acc: 0.4000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 0.9374 - acc: 0.5604 - val_loss: 1.0689 - val_acc: 0.4000\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 0.9367 - acc: 0.5604 - val_loss: 1.0717 - val_acc: 0.4000\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9353 - acc: 0.5604 - val_loss: 1.0743 - val_acc: 0.4250\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9345 - acc: 0.5604 - val_loss: 1.0731 - val_acc: 0.4250\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 420us/sample - loss: 0.9339 - acc: 0.5604 - val_loss: 1.0742 - val_acc: 0.4250\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 378us/sample - loss: 0.9337 - acc: 0.5604 - val_loss: 1.0705 - val_acc: 0.4000\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 0.9337 - acc: 0.5604 - val_loss: 1.0701 - val_acc: 0.4250\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 0.9313 - acc: 0.5495 - val_loss: 1.0700 - val_acc: 0.4250\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 0.9318 - acc: 0.5604 - val_loss: 1.0708 - val_acc: 0.4250\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9307 - acc: 0.5495 - val_loss: 1.0738 - val_acc: 0.4250\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9294 - acc: 0.5495 - val_loss: 1.0781 - val_acc: 0.4500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.9290 - acc: 0.5495 - val_loss: 1.0796 - val_acc: 0.4500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 351us/sample - loss: 0.9277 - acc: 0.5495 - val_loss: 1.0809 - val_acc: 0.4500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 336us/sample - loss: 0.9276 - acc: 0.5495 - val_loss: 1.0832 - val_acc: 0.4500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 354us/sample - loss: 0.9277 - acc: 0.5495 - val_loss: 1.0854 - val_acc: 0.4500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9258 - acc: 0.5495 - val_loss: 1.0860 - val_acc: 0.4500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 371us/sample - loss: 0.9252 - acc: 0.5495 - val_loss: 1.0854 - val_acc: 0.4500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9d2f08afe8b3fed19c6e38f7e3d5be14</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.48000001907348633</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 2.1208 - acc: 0.2967 - val_loss: 2.2338 - val_acc: 0.2750\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 486us/sample - loss: 1.8759 - acc: 0.2857 - val_loss: 1.9796 - val_acc: 0.3000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 1.6736 - acc: 0.2967 - val_loss: 1.8214 - val_acc: 0.2750\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 1.5599 - acc: 0.2967 - val_loss: 1.7277 - val_acc: 0.2750\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 354us/sample - loss: 1.4652 - acc: 0.2857 - val_loss: 1.6226 - val_acc: 0.2750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 1.3830 - acc: 0.3077 - val_loss: 1.5436 - val_acc: 0.2250\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 518us/sample - loss: 1.3323 - acc: 0.2967 - val_loss: 1.4899 - val_acc: 0.2250\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 1.2880 - acc: 0.3077 - val_loss: 1.4445 - val_acc: 0.2500\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 457us/sample - loss: 1.2527 - acc: 0.3077 - val_loss: 1.4113 - val_acc: 0.2750\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 1.2234 - acc: 0.3297 - val_loss: 1.3726 - val_acc: 0.2500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 369us/sample - loss: 1.1950 - acc: 0.3736 - val_loss: 1.3408 - val_acc: 0.2750\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 1.1751 - acc: 0.3516 - val_loss: 1.3126 - val_acc: 0.3000\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 448us/sample - loss: 1.1574 - acc: 0.3956 - val_loss: 1.2904 - val_acc: 0.3500\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 1.1403 - acc: 0.4286 - val_loss: 1.2747 - val_acc: 0.3250\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.1267 - acc: 0.4066 - val_loss: 1.2648 - val_acc: 0.3500\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 1.1140 - acc: 0.4176 - val_loss: 1.2498 - val_acc: 0.3500\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 1.1022 - acc: 0.3736 - val_loss: 1.2352 - val_acc: 0.3500\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 482us/sample - loss: 1.0909 - acc: 0.3846 - val_loss: 1.2251 - val_acc: 0.3500\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 1.0825 - acc: 0.3736 - val_loss: 1.2150 - val_acc: 0.3250\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 338us/sample - loss: 1.0732 - acc: 0.4066 - val_loss: 1.2030 - val_acc: 0.3000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.0619 - acc: 0.4176 - val_loss: 1.1890 - val_acc: 0.3000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 1.0541 - acc: 0.4066 - val_loss: 1.1818 - val_acc: 0.3000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.0491 - acc: 0.3846 - val_loss: 1.1829 - val_acc: 0.2750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 1.0401 - acc: 0.4176 - val_loss: 1.1794 - val_acc: 0.2750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 1.0352 - acc: 0.4286 - val_loss: 1.1742 - val_acc: 0.3000\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 1.0285 - acc: 0.4396 - val_loss: 1.1700 - val_acc: 0.3000\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 482us/sample - loss: 1.0231 - acc: 0.4396 - val_loss: 1.1685 - val_acc: 0.3250\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 1.0186 - acc: 0.4615 - val_loss: 1.1643 - val_acc: 0.3250\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 1.0125 - acc: 0.4725 - val_loss: 1.1587 - val_acc: 0.3250\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 1.0075 - acc: 0.4835 - val_loss: 1.1524 - val_acc: 0.3250\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 1.0044 - acc: 0.4505 - val_loss: 1.1469 - val_acc: 0.2750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9987 - acc: 0.5055 - val_loss: 1.1441 - val_acc: 0.3000\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9952 - acc: 0.4835 - val_loss: 1.1436 - val_acc: 0.3000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 0.9898 - acc: 0.4835 - val_loss: 1.1425 - val_acc: 0.3500\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 0.9866 - acc: 0.4945 - val_loss: 1.1407 - val_acc: 0.3500\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9826 - acc: 0.5165 - val_loss: 1.1386 - val_acc: 0.3500\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9802 - acc: 0.5165 - val_loss: 1.1374 - val_acc: 0.3500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 468us/sample - loss: 0.9761 - acc: 0.5055 - val_loss: 1.1373 - val_acc: 0.3500\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 0.9739 - acc: 0.5055 - val_loss: 1.1312 - val_acc: 0.3500\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 0.9721 - acc: 0.5055 - val_loss: 1.1289 - val_acc: 0.3500\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 453us/sample - loss: 0.9686 - acc: 0.5055 - val_loss: 1.1287 - val_acc: 0.3750\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 460us/sample - loss: 0.9653 - acc: 0.5165 - val_loss: 1.1257 - val_acc: 0.4000\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 0.9629 - acc: 0.5165 - val_loss: 1.1248 - val_acc: 0.4000\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 0.9621 - acc: 0.5165 - val_loss: 1.1215 - val_acc: 0.4000\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 410us/sample - loss: 0.9588 - acc: 0.5275 - val_loss: 1.1201 - val_acc: 0.4000\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 426us/sample - loss: 0.9569 - acc: 0.5275 - val_loss: 1.1168 - val_acc: 0.4000\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 432us/sample - loss: 0.9548 - acc: 0.5275 - val_loss: 1.1184 - val_acc: 0.4000\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 548us/sample - loss: 0.9527 - acc: 0.5275 - val_loss: 1.1186 - val_acc: 0.4000\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 471us/sample - loss: 0.9513 - acc: 0.5385 - val_loss: 1.1180 - val_acc: 0.4000\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 463us/sample - loss: 0.9488 - acc: 0.5385 - val_loss: 1.1162 - val_acc: 0.4000\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 2ms/sample - loss: 1.7849 - acc: 0.4396 - val_loss: 1.6948 - val_acc: 0.4500\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 605us/sample - loss: 1.6509 - acc: 0.4505 - val_loss: 1.6155 - val_acc: 0.4750\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 1.5294 - acc: 0.4505 - val_loss: 1.5511 - val_acc: 0.4750\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.4293 - acc: 0.4835 - val_loss: 1.4966 - val_acc: 0.4750\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.3378 - acc: 0.4945 - val_loss: 1.4351 - val_acc: 0.4750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 1.2340 - acc: 0.5055 - val_loss: 1.3948 - val_acc: 0.4500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.1774 - acc: 0.5275 - val_loss: 1.3622 - val_acc: 0.4250\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 1.1265 - acc: 0.5275 - val_loss: 1.3399 - val_acc: 0.4250\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 1.0935 - acc: 0.5495 - val_loss: 1.3219 - val_acc: 0.4500\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 428us/sample - loss: 1.0685 - acc: 0.5495 - val_loss: 1.3035 - val_acc: 0.4500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 1.0495 - acc: 0.5495 - val_loss: 1.2883 - val_acc: 0.4500\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 1.0326 - acc: 0.5824 - val_loss: 1.2830 - val_acc: 0.4750\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.0149 - acc: 0.5714 - val_loss: 1.2669 - val_acc: 0.4750\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 460us/sample - loss: 1.0047 - acc: 0.5824 - val_loss: 1.2531 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 423us/sample - loss: 0.9967 - acc: 0.5824 - val_loss: 1.2433 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 0.9885 - acc: 0.5714 - val_loss: 1.2237 - val_acc: 0.4750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 0.9786 - acc: 0.5934 - val_loss: 1.2193 - val_acc: 0.4750\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9713 - acc: 0.6154 - val_loss: 1.2244 - val_acc: 0.4750\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 482us/sample - loss: 0.9677 - acc: 0.6264 - val_loss: 1.2149 - val_acc: 0.5500\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 496us/sample - loss: 0.9625 - acc: 0.6264 - val_loss: 1.2066 - val_acc: 0.5750\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 0.9587 - acc: 0.6154 - val_loss: 1.2007 - val_acc: 0.5750\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 419us/sample - loss: 0.9556 - acc: 0.6264 - val_loss: 1.1952 - val_acc: 0.5750\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 0.9509 - acc: 0.6264 - val_loss: 1.1898 - val_acc: 0.5750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 349us/sample - loss: 0.9484 - acc: 0.6264 - val_loss: 1.1795 - val_acc: 0.5500\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9438 - acc: 0.6264 - val_loss: 1.1675 - val_acc: 0.5500\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 0.9408 - acc: 0.6593 - val_loss: 1.1628 - val_acc: 0.5250\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 458us/sample - loss: 0.9383 - acc: 0.6484 - val_loss: 1.1504 - val_acc: 0.5500\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 0.9361 - acc: 0.6374 - val_loss: 1.0970 - val_acc: 0.5750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9491 - acc: 0.6154 - val_loss: 1.1025 - val_acc: 0.5750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.9367 - acc: 0.6374 - val_loss: 1.1203 - val_acc: 0.5500\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 0.9320 - acc: 0.6374 - val_loss: 1.1328 - val_acc: 0.5250\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9279 - acc: 0.6154 - val_loss: 1.1365 - val_acc: 0.5250\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 426us/sample - loss: 0.9227 - acc: 0.6044 - val_loss: 1.1386 - val_acc: 0.5250\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9213 - acc: 0.6264 - val_loss: 1.1460 - val_acc: 0.5250\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9195 - acc: 0.5934 - val_loss: 1.1488 - val_acc: 0.5250\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 0.9166 - acc: 0.6264 - val_loss: 1.1440 - val_acc: 0.5250\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 349us/sample - loss: 0.9151 - acc: 0.6264 - val_loss: 1.1432 - val_acc: 0.5250\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 0.9138 - acc: 0.6264 - val_loss: 1.1442 - val_acc: 0.5250\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 0.9127 - acc: 0.6044 - val_loss: 1.1411 - val_acc: 0.5250\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 0.9121 - acc: 0.6374 - val_loss: 1.1160 - val_acc: 0.5500\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 447us/sample - loss: 0.9119 - acc: 0.6593 - val_loss: 1.1167 - val_acc: 0.5500\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 0.9128 - acc: 0.6374 - val_loss: 1.1201 - val_acc: 0.5250\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 0.9077 - acc: 0.6593 - val_loss: 1.1244 - val_acc: 0.5250\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 446us/sample - loss: 0.9074 - acc: 0.6484 - val_loss: 1.1261 - val_acc: 0.5250\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 436us/sample - loss: 0.9042 - acc: 0.6264 - val_loss: 1.1340 - val_acc: 0.5250\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9025 - acc: 0.6703 - val_loss: 1.1326 - val_acc: 0.5250\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 0.9010 - acc: 0.6374 - val_loss: 1.1305 - val_acc: 0.5250\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 0.8990 - acc: 0.6374 - val_loss: 1.1280 - val_acc: 0.5250\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 0.9000 - acc: 0.6813 - val_loss: 1.1264 - val_acc: 0.5500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 420us/sample - loss: 0.8979 - acc: 0.6703 - val_loss: 1.1315 - val_acc: 0.5500\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 996us/sample - loss: 3.5678 - acc: 0.1868 - val_loss: 3.1343 - val_acc: 0.2500\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 2.9012 - acc: 0.1978 - val_loss: 2.6679 - val_acc: 0.2500\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 2.4623 - acc: 0.2088 - val_loss: 2.3223 - val_acc: 0.2750\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 2.1175 - acc: 0.2418 - val_loss: 2.0698 - val_acc: 0.3500\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 1.8722 - acc: 0.2418 - val_loss: 1.8796 - val_acc: 0.3750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 1.6926 - acc: 0.2747 - val_loss: 1.7317 - val_acc: 0.4000\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 1.5599 - acc: 0.2857 - val_loss: 1.6131 - val_acc: 0.4500\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 462us/sample - loss: 1.4507 - acc: 0.2967 - val_loss: 1.5198 - val_acc: 0.4500\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 439us/sample - loss: 1.3659 - acc: 0.2967 - val_loss: 1.4520 - val_acc: 0.4500\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 1.3039 - acc: 0.3626 - val_loss: 1.4015 - val_acc: 0.4500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 1.2570 - acc: 0.3736 - val_loss: 1.3581 - val_acc: 0.4750\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 1.2177 - acc: 0.3956 - val_loss: 1.3203 - val_acc: 0.4500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 1.1786 - acc: 0.3956 - val_loss: 1.2881 - val_acc: 0.4500\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.1455 - acc: 0.3956 - val_loss: 1.2626 - val_acc: 0.4500\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 1.1209 - acc: 0.4176 - val_loss: 1.2392 - val_acc: 0.4500\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 1.0975 - acc: 0.4176 - val_loss: 1.2215 - val_acc: 0.4250\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.0792 - acc: 0.4286 - val_loss: 1.2036 - val_acc: 0.4250\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 423us/sample - loss: 1.0626 - acc: 0.4505 - val_loss: 1.1876 - val_acc: 0.4250\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 1.0454 - acc: 0.4176 - val_loss: 1.1741 - val_acc: 0.4250\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 1.0339 - acc: 0.4066 - val_loss: 1.1634 - val_acc: 0.3500\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 1.0230 - acc: 0.4396 - val_loss: 1.1508 - val_acc: 0.3500\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 1.0141 - acc: 0.4396 - val_loss: 1.1347 - val_acc: 0.3750\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 455us/sample - loss: 1.0059 - acc: 0.4505 - val_loss: 1.1263 - val_acc: 0.4000\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9986 - acc: 0.4505 - val_loss: 1.1195 - val_acc: 0.4250\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 0.9913 - acc: 0.4505 - val_loss: 1.1145 - val_acc: 0.4000\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.9876 - acc: 0.4505 - val_loss: 1.1101 - val_acc: 0.4000\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 0.9827 - acc: 0.4505 - val_loss: 1.1031 - val_acc: 0.4000\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9784 - acc: 0.4505 - val_loss: 1.0985 - val_acc: 0.3750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9762 - acc: 0.4396 - val_loss: 1.0973 - val_acc: 0.3250\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 0.9716 - acc: 0.4505 - val_loss: 1.0973 - val_acc: 0.3500\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9691 - acc: 0.4286 - val_loss: 1.0969 - val_acc: 0.3500\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 0.9662 - acc: 0.4286 - val_loss: 1.0983 - val_acc: 0.3500\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 0.9644 - acc: 0.4286 - val_loss: 1.0988 - val_acc: 0.3500\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 0.9627 - acc: 0.4286 - val_loss: 1.0961 - val_acc: 0.3750\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9596 - acc: 0.4615 - val_loss: 1.0955 - val_acc: 0.3500\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9572 - acc: 0.4505 - val_loss: 1.0990 - val_acc: 0.3500\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9563 - acc: 0.4615 - val_loss: 1.1036 - val_acc: 0.3500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 0.9552 - acc: 0.4505 - val_loss: 1.1048 - val_acc: 0.3750\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 0.9535 - acc: 0.4505 - val_loss: 1.1045 - val_acc: 0.3750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 0.9516 - acc: 0.4615 - val_loss: 1.1069 - val_acc: 0.3500\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 481us/sample - loss: 0.9507 - acc: 0.4725 - val_loss: 1.1049 - val_acc: 0.3500\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9495 - acc: 0.4725 - val_loss: 1.1003 - val_acc: 0.3250\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 0.9479 - acc: 0.5275 - val_loss: 1.0998 - val_acc: 0.3000\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 439us/sample - loss: 0.9469 - acc: 0.4835 - val_loss: 1.1019 - val_acc: 0.3000\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9453 - acc: 0.5055 - val_loss: 1.1009 - val_acc: 0.3000\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 450us/sample - loss: 0.9445 - acc: 0.5055 - val_loss: 1.1002 - val_acc: 0.2750\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9444 - acc: 0.4835 - val_loss: 1.1027 - val_acc: 0.2750\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 432us/sample - loss: 0.9431 - acc: 0.4945 - val_loss: 1.1061 - val_acc: 0.3250\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 446us/sample - loss: 0.9409 - acc: 0.4945 - val_loss: 1.1119 - val_acc: 0.3000\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 544us/sample - loss: 0.9416 - acc: 0.4725 - val_loss: 1.1103 - val_acc: 0.2750\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 2.6523 - acc: 0.1978 - val_loss: 2.5364 - val_acc: 0.2500\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 429us/sample - loss: 2.4016 - acc: 0.1978 - val_loss: 2.3938 - val_acc: 0.3000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 2.2305 - acc: 0.2637 - val_loss: 2.2887 - val_acc: 0.3000\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 2.0692 - acc: 0.2857 - val_loss: 2.1973 - val_acc: 0.3250\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 484us/sample - loss: 1.9541 - acc: 0.3187 - val_loss: 2.1045 - val_acc: 0.3500\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 438us/sample - loss: 1.8447 - acc: 0.3187 - val_loss: 2.0361 - val_acc: 0.3500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 1.7561 - acc: 0.3187 - val_loss: 1.9715 - val_acc: 0.3750\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 463us/sample - loss: 1.6797 - acc: 0.3407 - val_loss: 1.8928 - val_acc: 0.3750\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 1.6184 - acc: 0.3516 - val_loss: 1.8237 - val_acc: 0.3750\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 1.5573 - acc: 0.3736 - val_loss: 1.7671 - val_acc: 0.4000\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 1.5048 - acc: 0.3846 - val_loss: 1.7187 - val_acc: 0.3750\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.4508 - acc: 0.4066 - val_loss: 1.6675 - val_acc: 0.3500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 1.4073 - acc: 0.4286 - val_loss: 1.6148 - val_acc: 0.3500\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 438us/sample - loss: 1.3693 - acc: 0.4066 - val_loss: 1.5459 - val_acc: 0.3500\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 1.3208 - acc: 0.4176 - val_loss: 1.4849 - val_acc: 0.3500\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 420us/sample - loss: 1.2840 - acc: 0.4505 - val_loss: 1.4359 - val_acc: 0.3750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 479us/sample - loss: 1.2521 - acc: 0.4505 - val_loss: 1.3692 - val_acc: 0.3750\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 1.2217 - acc: 0.4286 - val_loss: 1.3325 - val_acc: 0.4250\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 417us/sample - loss: 1.1964 - acc: 0.4615 - val_loss: 1.3030 - val_acc: 0.4250\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 1.1728 - acc: 0.4505 - val_loss: 1.2719 - val_acc: 0.4000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 432us/sample - loss: 1.1517 - acc: 0.4615 - val_loss: 1.2450 - val_acc: 0.4000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 1.1322 - acc: 0.4615 - val_loss: 1.2137 - val_acc: 0.3750\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 484us/sample - loss: 1.1122 - acc: 0.4835 - val_loss: 1.2013 - val_acc: 0.3750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 419us/sample - loss: 1.0928 - acc: 0.5055 - val_loss: 1.1757 - val_acc: 0.3750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 426us/sample - loss: 1.0764 - acc: 0.5275 - val_loss: 1.1476 - val_acc: 0.4500\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 490us/sample - loss: 1.0636 - acc: 0.5165 - val_loss: 1.1369 - val_acc: 0.4500\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 1.0467 - acc: 0.5275 - val_loss: 1.1219 - val_acc: 0.4750\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 1.0369 - acc: 0.5275 - val_loss: 1.1139 - val_acc: 0.4750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 478us/sample - loss: 1.0262 - acc: 0.5385 - val_loss: 1.0939 - val_acc: 0.4750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 445us/sample - loss: 1.0139 - acc: 0.5385 - val_loss: 1.0745 - val_acc: 0.4750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 1.0060 - acc: 0.5495 - val_loss: 1.0704 - val_acc: 0.4750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 485us/sample - loss: 0.9982 - acc: 0.5385 - val_loss: 1.0477 - val_acc: 0.4750\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 0.9918 - acc: 0.5385 - val_loss: 1.0409 - val_acc: 0.4750\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 428us/sample - loss: 0.9849 - acc: 0.5495 - val_loss: 1.0251 - val_acc: 0.5500\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 447us/sample - loss: 0.9789 - acc: 0.5495 - val_loss: 1.0060 - val_acc: 0.5250\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 350us/sample - loss: 0.9745 - acc: 0.5495 - val_loss: 1.0025 - val_acc: 0.5250\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 502us/sample - loss: 0.9705 - acc: 0.5604 - val_loss: 1.0097 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9674 - acc: 0.5714 - val_loss: 1.0201 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 418us/sample - loss: 0.9626 - acc: 0.5604 - val_loss: 1.0100 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 0.9596 - acc: 0.5714 - val_loss: 0.9744 - val_acc: 0.5250\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 0.9553 - acc: 0.5495 - val_loss: 0.9710 - val_acc: 0.5250\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 447us/sample - loss: 0.9507 - acc: 0.5714 - val_loss: 0.9758 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9484 - acc: 0.5934 - val_loss: 0.9761 - val_acc: 0.5250\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9445 - acc: 0.5824 - val_loss: 0.9616 - val_acc: 0.5500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 0.9436 - acc: 0.5604 - val_loss: 0.9568 - val_acc: 0.5500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 0.9394 - acc: 0.5604 - val_loss: 0.9578 - val_acc: 0.5250\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 0.9377 - acc: 0.5714 - val_loss: 0.9524 - val_acc: 0.5250\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 447us/sample - loss: 0.9360 - acc: 0.5495 - val_loss: 0.9526 - val_acc: 0.5250\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 0.9322 - acc: 0.5604 - val_loss: 0.9524 - val_acc: 0.5250\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 0.9312 - acc: 0.5495 - val_loss: 0.9511 - val_acc: 0.5000\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 2.2913 - acc: 0.3187 - val_loss: 2.0256 - val_acc: 0.4750\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 486us/sample - loss: 2.0384 - acc: 0.3187 - val_loss: 1.8893 - val_acc: 0.4750\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 439us/sample - loss: 1.8604 - acc: 0.3516 - val_loss: 1.7892 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 480us/sample - loss: 1.7332 - acc: 0.3846 - val_loss: 1.7083 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 480us/sample - loss: 1.6381 - acc: 0.4176 - val_loss: 1.6425 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 447us/sample - loss: 1.5566 - acc: 0.4286 - val_loss: 1.5866 - val_acc: 0.5000\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 1.4919 - acc: 0.4286 - val_loss: 1.5241 - val_acc: 0.5250\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 1.4310 - acc: 0.4286 - val_loss: 1.4866 - val_acc: 0.5000\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 1.3912 - acc: 0.4286 - val_loss: 1.4560 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 444us/sample - loss: 1.3528 - acc: 0.4396 - val_loss: 1.4247 - val_acc: 0.5500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 355us/sample - loss: 1.3184 - acc: 0.4725 - val_loss: 1.3715 - val_acc: 0.5500\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 417us/sample - loss: 1.2842 - acc: 0.4945 - val_loss: 1.3392 - val_acc: 0.5250\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 1.2621 - acc: 0.4945 - val_loss: 1.3199 - val_acc: 0.5250\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.2404 - acc: 0.5055 - val_loss: 1.3020 - val_acc: 0.5250\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.2204 - acc: 0.5275 - val_loss: 1.2893 - val_acc: 0.5250\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 435us/sample - loss: 1.2039 - acc: 0.5165 - val_loss: 1.2741 - val_acc: 0.5500\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 1.1861 - acc: 0.5165 - val_loss: 1.2607 - val_acc: 0.5250\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 1.1682 - acc: 0.5385 - val_loss: 1.2482 - val_acc: 0.5250\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 1.1533 - acc: 0.5385 - val_loss: 1.2322 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 1.1376 - acc: 0.5495 - val_loss: 1.2170 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.1252 - acc: 0.5495 - val_loss: 1.2068 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 1.1141 - acc: 0.5495 - val_loss: 1.2007 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 1.1035 - acc: 0.5495 - val_loss: 1.1921 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 1.0961 - acc: 0.5495 - val_loss: 1.1844 - val_acc: 0.5250\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 444us/sample - loss: 1.0867 - acc: 0.5714 - val_loss: 1.1785 - val_acc: 0.5250\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.0801 - acc: 0.5714 - val_loss: 1.1744 - val_acc: 0.5250\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.0724 - acc: 0.5714 - val_loss: 1.1688 - val_acc: 0.5250\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.0649 - acc: 0.5714 - val_loss: 1.1627 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.0571 - acc: 0.5604 - val_loss: 1.1566 - val_acc: 0.5250\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.0508 - acc: 0.5714 - val_loss: 1.1532 - val_acc: 0.5250\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 1.0432 - acc: 0.5714 - val_loss: 1.1490 - val_acc: 0.5500\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 470us/sample - loss: 1.0375 - acc: 0.5604 - val_loss: 1.1456 - val_acc: 0.5500\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 1.0313 - acc: 0.5714 - val_loss: 1.1416 - val_acc: 0.5250\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 1.0252 - acc: 0.5714 - val_loss: 1.1378 - val_acc: 0.5500\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 529us/sample - loss: 1.0206 - acc: 0.5714 - val_loss: 1.1332 - val_acc: 0.5500\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 1.0159 - acc: 0.5714 - val_loss: 1.1290 - val_acc: 0.5500\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 1.0109 - acc: 0.5714 - val_loss: 1.1242 - val_acc: 0.5500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 1.0058 - acc: 0.5714 - val_loss: 1.1173 - val_acc: 0.5500\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 378us/sample - loss: 1.0002 - acc: 0.5824 - val_loss: 1.1133 - val_acc: 0.5500\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9966 - acc: 0.5824 - val_loss: 1.1100 - val_acc: 0.5500\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 0.9927 - acc: 0.5824 - val_loss: 1.1073 - val_acc: 0.5500\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9888 - acc: 0.5934 - val_loss: 1.1031 - val_acc: 0.5500\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 444us/sample - loss: 0.9855 - acc: 0.5934 - val_loss: 1.1003 - val_acc: 0.5500\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9820 - acc: 0.5934 - val_loss: 1.0980 - val_acc: 0.5500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 0.9788 - acc: 0.6044 - val_loss: 1.0965 - val_acc: 0.5500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 0.9758 - acc: 0.6154 - val_loss: 1.0950 - val_acc: 0.5500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 0.9734 - acc: 0.6154 - val_loss: 1.0920 - val_acc: 0.5500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 0.9699 - acc: 0.6154 - val_loss: 1.0908 - val_acc: 0.5250\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9679 - acc: 0.6044 - val_loss: 1.0888 - val_acc: 0.5250\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9655 - acc: 0.6044 - val_loss: 1.0858 - val_acc: 0.5250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 33ff0bffe206a2f57d8e40877e91a17b</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5099999904632568</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 1e-06</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 3.7167 - acc: 0.2637 - val_loss: 3.3503 - val_acc: 0.3000\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 3.3417 - acc: 0.2637 - val_loss: 3.0803 - val_acc: 0.3000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 2.9961 - acc: 0.2527 - val_loss: 2.8734 - val_acc: 0.2750\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 2.7302 - acc: 0.2527 - val_loss: 2.6982 - val_acc: 0.2750\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 2.4934 - acc: 0.2527 - val_loss: 2.5083 - val_acc: 0.2750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 2.2784 - acc: 0.2857 - val_loss: 2.3577 - val_acc: 0.3000\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 2.1084 - acc: 0.2747 - val_loss: 2.2401 - val_acc: 0.3000\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 481us/sample - loss: 1.9695 - acc: 0.2967 - val_loss: 2.1383 - val_acc: 0.3250\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 436us/sample - loss: 1.8554 - acc: 0.3077 - val_loss: 2.0577 - val_acc: 0.3250\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 1.7626 - acc: 0.3297 - val_loss: 1.9997 - val_acc: 0.3000\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.6660 - acc: 0.3077 - val_loss: 1.9603 - val_acc: 0.3250\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 1.6002 - acc: 0.3516 - val_loss: 1.9164 - val_acc: 0.3000\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 479us/sample - loss: 1.5542 - acc: 0.3516 - val_loss: 1.8691 - val_acc: 0.3750\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 505us/sample - loss: 1.5045 - acc: 0.3956 - val_loss: 1.8218 - val_acc: 0.4000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 533us/sample - loss: 1.4644 - acc: 0.3846 - val_loss: 1.7825 - val_acc: 0.4250\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 1.4283 - acc: 0.3956 - val_loss: 1.7459 - val_acc: 0.4000\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 436us/sample - loss: 1.3979 - acc: 0.4066 - val_loss: 1.7077 - val_acc: 0.4250\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.3644 - acc: 0.4396 - val_loss: 1.6753 - val_acc: 0.4000\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 357us/sample - loss: 1.3347 - acc: 0.4505 - val_loss: 1.6458 - val_acc: 0.4000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 369us/sample - loss: 1.3097 - acc: 0.4286 - val_loss: 1.6176 - val_acc: 0.4000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 1.2851 - acc: 0.4176 - val_loss: 1.5886 - val_acc: 0.3750\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.2612 - acc: 0.4286 - val_loss: 1.5629 - val_acc: 0.4000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 1.2400 - acc: 0.4396 - val_loss: 1.5419 - val_acc: 0.3750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 1.2224 - acc: 0.4286 - val_loss: 1.5182 - val_acc: 0.3750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 1.2034 - acc: 0.4396 - val_loss: 1.4961 - val_acc: 0.3250\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 353us/sample - loss: 1.1833 - acc: 0.4396 - val_loss: 1.4711 - val_acc: 0.3250\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 1.1696 - acc: 0.4396 - val_loss: 1.4500 - val_acc: 0.3000\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 1.1490 - acc: 0.4396 - val_loss: 1.4315 - val_acc: 0.2750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 1.1393 - acc: 0.4286 - val_loss: 1.4119 - val_acc: 0.2750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 1.1238 - acc: 0.4505 - val_loss: 1.3960 - val_acc: 0.2500\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.1113 - acc: 0.4396 - val_loss: 1.3803 - val_acc: 0.3000\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 1.1001 - acc: 0.4505 - val_loss: 1.3646 - val_acc: 0.3000\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 1.0901 - acc: 0.4505 - val_loss: 1.3503 - val_acc: 0.3000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 1.0814 - acc: 0.4396 - val_loss: 1.3381 - val_acc: 0.3000\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 1.0728 - acc: 0.4396 - val_loss: 1.3239 - val_acc: 0.3000\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 1.0660 - acc: 0.4396 - val_loss: 1.3142 - val_acc: 0.3000\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.0574 - acc: 0.4505 - val_loss: 1.3048 - val_acc: 0.2750\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 1.0511 - acc: 0.4396 - val_loss: 1.2936 - val_acc: 0.2750\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 351us/sample - loss: 1.0457 - acc: 0.4396 - val_loss: 1.2829 - val_acc: 0.2750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 1.0376 - acc: 0.4396 - val_loss: 1.2759 - val_acc: 0.3000\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.0336 - acc: 0.4505 - val_loss: 1.2663 - val_acc: 0.3000\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 355us/sample - loss: 1.0285 - acc: 0.4615 - val_loss: 1.2571 - val_acc: 0.3000\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 1.0215 - acc: 0.4505 - val_loss: 1.2515 - val_acc: 0.3000\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.0170 - acc: 0.4396 - val_loss: 1.2389 - val_acc: 0.3000\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 497us/sample - loss: 1.0136 - acc: 0.4615 - val_loss: 1.2347 - val_acc: 0.3000\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 1.0102 - acc: 0.4396 - val_loss: 1.2286 - val_acc: 0.3000\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.0057 - acc: 0.4396 - val_loss: 1.2129 - val_acc: 0.3000\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 340us/sample - loss: 0.9994 - acc: 0.4615 - val_loss: 1.2037 - val_acc: 0.3000\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 360us/sample - loss: 0.9970 - acc: 0.4615 - val_loss: 1.1985 - val_acc: 0.3000\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 357us/sample - loss: 0.9926 - acc: 0.4725 - val_loss: 1.1942 - val_acc: 0.3000\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 2.7749 - acc: 0.2198 - val_loss: 2.1473 - val_acc: 0.3000\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 450us/sample - loss: 2.4043 - acc: 0.2198 - val_loss: 1.9198 - val_acc: 0.2750\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 420us/sample - loss: 2.1171 - acc: 0.2308 - val_loss: 1.7532 - val_acc: 0.3500\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 435us/sample - loss: 1.9145 - acc: 0.2527 - val_loss: 1.6314 - val_acc: 0.3500\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 356us/sample - loss: 1.7592 - acc: 0.2637 - val_loss: 1.5412 - val_acc: 0.3500\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 1.6379 - acc: 0.3187 - val_loss: 1.4890 - val_acc: 0.3500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 357us/sample - loss: 1.5398 - acc: 0.3516 - val_loss: 1.4502 - val_acc: 0.3750\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 1.4673 - acc: 0.3516 - val_loss: 1.4230 - val_acc: 0.3750\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 1.4075 - acc: 0.3736 - val_loss: 1.3990 - val_acc: 0.3500\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 1.3639 - acc: 0.3736 - val_loss: 1.3652 - val_acc: 0.3500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 1.3064 - acc: 0.3736 - val_loss: 1.3464 - val_acc: 0.4000\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 1.2743 - acc: 0.3846 - val_loss: 1.3344 - val_acc: 0.3750\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 442us/sample - loss: 1.2464 - acc: 0.3846 - val_loss: 1.3211 - val_acc: 0.4000\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 1.2199 - acc: 0.3846 - val_loss: 1.3092 - val_acc: 0.4000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 337us/sample - loss: 1.1994 - acc: 0.3956 - val_loss: 1.3013 - val_acc: 0.4000\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 323us/sample - loss: 1.1816 - acc: 0.4176 - val_loss: 1.2932 - val_acc: 0.4000\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 362us/sample - loss: 1.1637 - acc: 0.4066 - val_loss: 1.2841 - val_acc: 0.4250\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 1.1505 - acc: 0.4286 - val_loss: 1.2758 - val_acc: 0.4250\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 1.1377 - acc: 0.4176 - val_loss: 1.2682 - val_acc: 0.4000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.1264 - acc: 0.4396 - val_loss: 1.2622 - val_acc: 0.4000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 1.1167 - acc: 0.4396 - val_loss: 1.2570 - val_acc: 0.4000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 1.1065 - acc: 0.4396 - val_loss: 1.2535 - val_acc: 0.4250\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 1.0958 - acc: 0.4396 - val_loss: 1.2508 - val_acc: 0.4000\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.0873 - acc: 0.4396 - val_loss: 1.2489 - val_acc: 0.4000\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 1.0779 - acc: 0.4396 - val_loss: 1.2481 - val_acc: 0.3750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 1.0700 - acc: 0.4505 - val_loss: 1.2445 - val_acc: 0.3750\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 1.0628 - acc: 0.4505 - val_loss: 1.2392 - val_acc: 0.3750\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 1.0556 - acc: 0.4505 - val_loss: 1.2378 - val_acc: 0.3750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 1.0496 - acc: 0.4396 - val_loss: 1.2365 - val_acc: 0.3750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 333us/sample - loss: 1.0443 - acc: 0.4286 - val_loss: 1.2339 - val_acc: 0.3750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 1.0393 - acc: 0.4286 - val_loss: 1.2293 - val_acc: 0.3750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 362us/sample - loss: 1.0332 - acc: 0.4286 - val_loss: 1.2245 - val_acc: 0.3750\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 1.0297 - acc: 0.4176 - val_loss: 1.2228 - val_acc: 0.3750\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 356us/sample - loss: 1.0256 - acc: 0.4176 - val_loss: 1.2221 - val_acc: 0.3750\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 353us/sample - loss: 1.0218 - acc: 0.4176 - val_loss: 1.2202 - val_acc: 0.3750\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 1.0173 - acc: 0.4286 - val_loss: 1.2159 - val_acc: 0.3750\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 1.0128 - acc: 0.4286 - val_loss: 1.2140 - val_acc: 0.3750\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 1.0095 - acc: 0.4396 - val_loss: 1.2129 - val_acc: 0.3750\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 1.0071 - acc: 0.4396 - val_loss: 1.2094 - val_acc: 0.3750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 1.0045 - acc: 0.4396 - val_loss: 1.2058 - val_acc: 0.3750\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 1.0021 - acc: 0.4286 - val_loss: 1.2033 - val_acc: 0.3500\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9990 - acc: 0.4396 - val_loss: 1.2024 - val_acc: 0.3500\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9974 - acc: 0.4396 - val_loss: 1.1999 - val_acc: 0.3500\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 371us/sample - loss: 0.9939 - acc: 0.4286 - val_loss: 1.1962 - val_acc: 0.3500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 0.9925 - acc: 0.4396 - val_loss: 1.1790 - val_acc: 0.3500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 365us/sample - loss: 0.9921 - acc: 0.4396 - val_loss: 1.1745 - val_acc: 0.3500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 365us/sample - loss: 0.9896 - acc: 0.4176 - val_loss: 1.1778 - val_acc: 0.3250\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 365us/sample - loss: 0.9874 - acc: 0.4176 - val_loss: 1.1787 - val_acc: 0.3250\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9846 - acc: 0.4176 - val_loss: 1.1849 - val_acc: 0.3500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9813 - acc: 0.4396 - val_loss: 1.1864 - val_acc: 0.3750\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 995us/sample - loss: 4.3858 - acc: 0.2527 - val_loss: 2.3718 - val_acc: 0.3250\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 3.7686 - acc: 0.2747 - val_loss: 2.0685 - val_acc: 0.3500\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 350us/sample - loss: 3.2291 - acc: 0.2747 - val_loss: 1.8687 - val_acc: 0.3500\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 356us/sample - loss: 2.8372 - acc: 0.2527 - val_loss: 1.7263 - val_acc: 0.3500\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 2.5013 - acc: 0.2637 - val_loss: 1.6106 - val_acc: 0.3500\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 357us/sample - loss: 2.2289 - acc: 0.2637 - val_loss: 1.5172 - val_acc: 0.3500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.9824 - acc: 0.3077 - val_loss: 1.4391 - val_acc: 0.3750\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 349us/sample - loss: 1.7489 - acc: 0.3407 - val_loss: 1.3985 - val_acc: 0.3250\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.5976 - acc: 0.3516 - val_loss: 1.3620 - val_acc: 0.3250\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 1.4866 - acc: 0.3736 - val_loss: 1.3487 - val_acc: 0.3750\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 1.4086 - acc: 0.3846 - val_loss: 1.3487 - val_acc: 0.4000\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 778us/sample - loss: 1.3455 - acc: 0.3846 - val_loss: 1.3536 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 420us/sample - loss: 1.2848 - acc: 0.4505 - val_loss: 1.3618 - val_acc: 0.4750\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 1.2389 - acc: 0.4615 - val_loss: 1.3761 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.2036 - acc: 0.4615 - val_loss: 1.3827 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.1781 - acc: 0.5055 - val_loss: 1.3835 - val_acc: 0.4750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.1532 - acc: 0.5165 - val_loss: 1.3817 - val_acc: 0.4750\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 1.1320 - acc: 0.5165 - val_loss: 1.3718 - val_acc: 0.4750\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 1.1150 - acc: 0.5385 - val_loss: 1.3665 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 357us/sample - loss: 1.1013 - acc: 0.5385 - val_loss: 1.3636 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 1.0875 - acc: 0.5385 - val_loss: 1.3589 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 1.0713 - acc: 0.5495 - val_loss: 1.3533 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 1.0607 - acc: 0.5495 - val_loss: 1.3480 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 349us/sample - loss: 1.0486 - acc: 0.5604 - val_loss: 1.3420 - val_acc: 0.4750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 369us/sample - loss: 1.0397 - acc: 0.5604 - val_loss: 1.3483 - val_acc: 0.4750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 446us/sample - loss: 1.0300 - acc: 0.5714 - val_loss: 1.3447 - val_acc: 0.4750\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 1.0206 - acc: 0.5604 - val_loss: 1.3294 - val_acc: 0.4750\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 1.0101 - acc: 0.5495 - val_loss: 1.3260 - val_acc: 0.4750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 357us/sample - loss: 1.0028 - acc: 0.5604 - val_loss: 1.3208 - val_acc: 0.4750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 0.9961 - acc: 0.5714 - val_loss: 1.3125 - val_acc: 0.4750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 371us/sample - loss: 0.9891 - acc: 0.5495 - val_loss: 1.3054 - val_acc: 0.4750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9819 - acc: 0.5714 - val_loss: 1.2981 - val_acc: 0.4750\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9758 - acc: 0.5604 - val_loss: 1.2939 - val_acc: 0.4750\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 452us/sample - loss: 0.9696 - acc: 0.5604 - val_loss: 1.2874 - val_acc: 0.4500\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 0.9625 - acc: 0.5604 - val_loss: 1.2844 - val_acc: 0.4500\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 0.9570 - acc: 0.5604 - val_loss: 1.2815 - val_acc: 0.4500\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 462us/sample - loss: 0.9513 - acc: 0.5604 - val_loss: 1.2729 - val_acc: 0.4250\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9471 - acc: 0.5604 - val_loss: 1.2736 - val_acc: 0.4000\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9441 - acc: 0.5604 - val_loss: 1.2713 - val_acc: 0.4000\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9397 - acc: 0.5604 - val_loss: 1.2592 - val_acc: 0.4000\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9360 - acc: 0.5604 - val_loss: 1.2582 - val_acc: 0.4000\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9326 - acc: 0.5495 - val_loss: 1.2564 - val_acc: 0.4000\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 478us/sample - loss: 0.9276 - acc: 0.5495 - val_loss: 1.2529 - val_acc: 0.4000\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 0.9240 - acc: 0.5495 - val_loss: 1.2478 - val_acc: 0.4000\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 0.9212 - acc: 0.5495 - val_loss: 1.2443 - val_acc: 0.4000\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9173 - acc: 0.5604 - val_loss: 1.2431 - val_acc: 0.4000\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 0.9141 - acc: 0.5604 - val_loss: 1.2442 - val_acc: 0.4000\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9107 - acc: 0.5604 - val_loss: 1.2381 - val_acc: 0.4000\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9080 - acc: 0.5495 - val_loss: 1.2361 - val_acc: 0.4000\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9040 - acc: 0.5495 - val_loss: 1.2334 - val_acc: 0.3750\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.1658 - acc: 0.4286 - val_loss: 1.2432 - val_acc: 0.4750\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 1.1248 - acc: 0.4505 - val_loss: 1.2121 - val_acc: 0.4750\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.0871 - acc: 0.4945 - val_loss: 1.1906 - val_acc: 0.4500\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 364us/sample - loss: 1.0614 - acc: 0.5275 - val_loss: 1.1754 - val_acc: 0.4500\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 1.0421 - acc: 0.5055 - val_loss: 1.1618 - val_acc: 0.4500\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 360us/sample - loss: 1.0253 - acc: 0.4835 - val_loss: 1.1552 - val_acc: 0.4250\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 356us/sample - loss: 1.0141 - acc: 0.4945 - val_loss: 1.1474 - val_acc: 0.4000\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 360us/sample - loss: 1.0061 - acc: 0.5055 - val_loss: 1.1408 - val_acc: 0.4000\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9978 - acc: 0.5165 - val_loss: 1.1372 - val_acc: 0.4250\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9937 - acc: 0.5385 - val_loss: 1.1394 - val_acc: 0.4500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9883 - acc: 0.5604 - val_loss: 1.1383 - val_acc: 0.4500\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 366us/sample - loss: 0.9846 - acc: 0.5604 - val_loss: 1.1334 - val_acc: 0.4500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 0.9813 - acc: 0.5604 - val_loss: 1.1286 - val_acc: 0.4500\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9783 - acc: 0.5604 - val_loss: 1.1258 - val_acc: 0.4500\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 0.9765 - acc: 0.5824 - val_loss: 1.1233 - val_acc: 0.4500\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9747 - acc: 0.5604 - val_loss: 1.1136 - val_acc: 0.4500\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9717 - acc: 0.5495 - val_loss: 1.1103 - val_acc: 0.4500\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9701 - acc: 0.5604 - val_loss: 1.1090 - val_acc: 0.4500\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9681 - acc: 0.5714 - val_loss: 1.1040 - val_acc: 0.4250\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 423us/sample - loss: 0.9680 - acc: 0.5824 - val_loss: 1.1028 - val_acc: 0.4250\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 0.9658 - acc: 0.5714 - val_loss: 1.1025 - val_acc: 0.4250\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 410us/sample - loss: 0.9633 - acc: 0.5824 - val_loss: 1.1023 - val_acc: 0.4500\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9626 - acc: 0.5824 - val_loss: 1.1049 - val_acc: 0.4500\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 0.9623 - acc: 0.5824 - val_loss: 1.1041 - val_acc: 0.4500\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9600 - acc: 0.5714 - val_loss: 1.1026 - val_acc: 0.4500\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9589 - acc: 0.5714 - val_loss: 1.0975 - val_acc: 0.4500\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 0.9577 - acc: 0.5824 - val_loss: 1.0978 - val_acc: 0.4500\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9561 - acc: 0.5824 - val_loss: 1.1018 - val_acc: 0.4500\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.9558 - acc: 0.5824 - val_loss: 1.0959 - val_acc: 0.4500\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9553 - acc: 0.5824 - val_loss: 1.0942 - val_acc: 0.4500\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9537 - acc: 0.5934 - val_loss: 1.0956 - val_acc: 0.4500\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 0.9522 - acc: 0.5934 - val_loss: 1.0975 - val_acc: 0.4500\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 436us/sample - loss: 0.9523 - acc: 0.6044 - val_loss: 1.0976 - val_acc: 0.4500\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 347us/sample - loss: 0.9503 - acc: 0.5714 - val_loss: 1.0981 - val_acc: 0.4500\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 356us/sample - loss: 0.9491 - acc: 0.5934 - val_loss: 1.0959 - val_acc: 0.4750\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9480 - acc: 0.5824 - val_loss: 1.0952 - val_acc: 0.4750\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 346us/sample - loss: 0.9477 - acc: 0.5824 - val_loss: 1.0970 - val_acc: 0.4500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 354us/sample - loss: 0.9466 - acc: 0.6044 - val_loss: 1.0981 - val_acc: 0.4500\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9459 - acc: 0.6154 - val_loss: 1.0970 - val_acc: 0.4750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9447 - acc: 0.5824 - val_loss: 1.0958 - val_acc: 0.4750\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9436 - acc: 0.5714 - val_loss: 1.0957 - val_acc: 0.4750\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9424 - acc: 0.5604 - val_loss: 1.0993 - val_acc: 0.4750\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 442us/sample - loss: 0.9427 - acc: 0.5934 - val_loss: 1.1001 - val_acc: 0.4750\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9423 - acc: 0.5934 - val_loss: 1.0993 - val_acc: 0.4750\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9402 - acc: 0.5934 - val_loss: 1.1001 - val_acc: 0.4750\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9409 - acc: 0.5934 - val_loss: 1.1022 - val_acc: 0.4500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 359us/sample - loss: 0.9386 - acc: 0.6044 - val_loss: 1.1006 - val_acc: 0.4750\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 354us/sample - loss: 0.9379 - acc: 0.5934 - val_loss: 1.1003 - val_acc: 0.4750\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9381 - acc: 0.5934 - val_loss: 1.1009 - val_acc: 0.4750\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 0.9381 - acc: 0.6154 - val_loss: 1.0959 - val_acc: 0.4500\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.3979 - acc: 0.4396 - val_loss: 1.7465 - val_acc: 0.4250\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 1.3574 - acc: 0.4615 - val_loss: 1.7337 - val_acc: 0.4250\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 1.3216 - acc: 0.4725 - val_loss: 1.7169 - val_acc: 0.4000\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 1.2948 - acc: 0.4725 - val_loss: 1.6963 - val_acc: 0.4000\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 443us/sample - loss: 1.2685 - acc: 0.4725 - val_loss: 1.6773 - val_acc: 0.4000\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 428us/sample - loss: 1.2456 - acc: 0.5055 - val_loss: 1.6614 - val_acc: 0.4000\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 1.2253 - acc: 0.4835 - val_loss: 1.6424 - val_acc: 0.4000\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 1.2068 - acc: 0.4835 - val_loss: 1.6228 - val_acc: 0.4000\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.1913 - acc: 0.4725 - val_loss: 1.6099 - val_acc: 0.4000\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 351us/sample - loss: 1.1758 - acc: 0.5055 - val_loss: 1.5961 - val_acc: 0.4000\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.1625 - acc: 0.4945 - val_loss: 1.5823 - val_acc: 0.4000\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 1.1493 - acc: 0.5055 - val_loss: 1.5672 - val_acc: 0.3750\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 344us/sample - loss: 1.1330 - acc: 0.4945 - val_loss: 1.5514 - val_acc: 0.3750\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 1.1232 - acc: 0.4945 - val_loss: 1.5451 - val_acc: 0.3750\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 1.1139 - acc: 0.5275 - val_loss: 1.5408 - val_acc: 0.3250\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 1.1045 - acc: 0.5385 - val_loss: 1.5347 - val_acc: 0.3500\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 1.0959 - acc: 0.5604 - val_loss: 1.5293 - val_acc: 0.3250\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 1.0875 - acc: 0.5604 - val_loss: 1.5214 - val_acc: 0.4250\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 358us/sample - loss: 1.0792 - acc: 0.5604 - val_loss: 1.5017 - val_acc: 0.4000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 1.0700 - acc: 0.5604 - val_loss: 1.4874 - val_acc: 0.3750\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 356us/sample - loss: 1.0629 - acc: 0.5714 - val_loss: 1.4827 - val_acc: 0.4000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 1.0547 - acc: 0.5714 - val_loss: 1.4702 - val_acc: 0.4000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 365us/sample - loss: 1.0426 - acc: 0.5714 - val_loss: 1.4642 - val_acc: 0.4000\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 1.0366 - acc: 0.5824 - val_loss: 1.4535 - val_acc: 0.3750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 364us/sample - loss: 1.0298 - acc: 0.5714 - val_loss: 1.4435 - val_acc: 0.4000\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 348us/sample - loss: 1.0255 - acc: 0.5714 - val_loss: 1.4320 - val_acc: 0.4000\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 1.0190 - acc: 0.5495 - val_loss: 1.4294 - val_acc: 0.3500\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 1.0137 - acc: 0.5824 - val_loss: 1.4211 - val_acc: 0.3500\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 429us/sample - loss: 1.0076 - acc: 0.5714 - val_loss: 1.4105 - val_acc: 0.3750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 1.0029 - acc: 0.5714 - val_loss: 1.3990 - val_acc: 0.3750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 468us/sample - loss: 0.9984 - acc: 0.5714 - val_loss: 1.3911 - val_acc: 0.3750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 0.9933 - acc: 0.5495 - val_loss: 1.3838 - val_acc: 0.4000\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9896 - acc: 0.5495 - val_loss: 1.3796 - val_acc: 0.4000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.9848 - acc: 0.5714 - val_loss: 1.3763 - val_acc: 0.3750\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 432us/sample - loss: 0.9814 - acc: 0.5714 - val_loss: 1.3599 - val_acc: 0.4000\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9753 - acc: 0.5495 - val_loss: 1.3339 - val_acc: 0.4250\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 453us/sample - loss: 0.9738 - acc: 0.5495 - val_loss: 1.3290 - val_acc: 0.4000\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 358us/sample - loss: 0.9688 - acc: 0.5495 - val_loss: 1.3252 - val_acc: 0.4000\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 343us/sample - loss: 0.9650 - acc: 0.5385 - val_loss: 1.3225 - val_acc: 0.4000\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 354us/sample - loss: 0.9607 - acc: 0.5275 - val_loss: 1.3191 - val_acc: 0.4250\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9570 - acc: 0.5495 - val_loss: 1.3147 - val_acc: 0.4000\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9534 - acc: 0.5385 - val_loss: 1.3113 - val_acc: 0.4000\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9487 - acc: 0.5495 - val_loss: 1.3078 - val_acc: 0.4000\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 436us/sample - loss: 0.9463 - acc: 0.5495 - val_loss: 1.3035 - val_acc: 0.4000\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 0.9435 - acc: 0.5275 - val_loss: 1.2967 - val_acc: 0.4000\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9406 - acc: 0.5385 - val_loss: 1.2916 - val_acc: 0.4000\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 0.9365 - acc: 0.5495 - val_loss: 1.2884 - val_acc: 0.4000\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 365us/sample - loss: 0.9349 - acc: 0.5495 - val_loss: 1.2902 - val_acc: 0.4000\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 452us/sample - loss: 0.9308 - acc: 0.5495 - val_loss: 1.2876 - val_acc: 0.4000\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 519us/sample - loss: 0.9280 - acc: 0.5495 - val_loss: 1.2846 - val_acc: 0.4500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 0af23bc6f83d6bd6aa9b5d33990d2311</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.45500001311302185</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 1e-05</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.5131 - acc: 0.2967 - val_loss: 1.3754 - val_acc: 0.3250\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 1.3817 - acc: 0.2967 - val_loss: 1.3155 - val_acc: 0.3250\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 351us/sample - loss: 1.2695 - acc: 0.3407 - val_loss: 1.2782 - val_acc: 0.3250\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 410us/sample - loss: 1.1861 - acc: 0.3297 - val_loss: 1.2588 - val_acc: 0.3500\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.1347 - acc: 0.3407 - val_loss: 1.2456 - val_acc: 0.3750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 1.1031 - acc: 0.3736 - val_loss: 1.2345 - val_acc: 0.4000\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 417us/sample - loss: 1.0812 - acc: 0.3956 - val_loss: 1.2299 - val_acc: 0.3750\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 351us/sample - loss: 1.0607 - acc: 0.4176 - val_loss: 1.2248 - val_acc: 0.3750\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 365us/sample - loss: 1.0476 - acc: 0.4286 - val_loss: 1.2177 - val_acc: 0.3750\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 360us/sample - loss: 1.0372 - acc: 0.4396 - val_loss: 1.2111 - val_acc: 0.3750\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 342us/sample - loss: 1.0283 - acc: 0.4396 - val_loss: 1.2026 - val_acc: 0.3750\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 1.0246 - acc: 0.4396 - val_loss: 1.1955 - val_acc: 0.3750\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 1.0176 - acc: 0.4396 - val_loss: 1.1928 - val_acc: 0.3750\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 369us/sample - loss: 1.0104 - acc: 0.4396 - val_loss: 1.1853 - val_acc: 0.4000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 1.0051 - acc: 0.4396 - val_loss: 1.1809 - val_acc: 0.4000\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9990 - acc: 0.4396 - val_loss: 1.1781 - val_acc: 0.4000\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 0.9962 - acc: 0.4505 - val_loss: 1.1776 - val_acc: 0.4000\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9912 - acc: 0.4615 - val_loss: 1.1732 - val_acc: 0.3750\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 0.9876 - acc: 0.4615 - val_loss: 1.1753 - val_acc: 0.4000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 0.9851 - acc: 0.4725 - val_loss: 1.1742 - val_acc: 0.3750\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 0.9807 - acc: 0.4505 - val_loss: 1.1700 - val_acc: 0.3750\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9800 - acc: 0.4615 - val_loss: 1.1665 - val_acc: 0.4000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 546us/sample - loss: 0.9753 - acc: 0.4725 - val_loss: 1.1639 - val_acc: 0.4500\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 0.9727 - acc: 0.4835 - val_loss: 1.1645 - val_acc: 0.4250\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 0.9695 - acc: 0.4945 - val_loss: 1.1644 - val_acc: 0.4250\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 359us/sample - loss: 0.9706 - acc: 0.4835 - val_loss: 1.1594 - val_acc: 0.4250\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 343us/sample - loss: 0.9671 - acc: 0.4835 - val_loss: 1.1545 - val_acc: 0.4250\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 0.9633 - acc: 0.5055 - val_loss: 1.1541 - val_acc: 0.4250\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 435us/sample - loss: 0.9613 - acc: 0.4945 - val_loss: 1.1523 - val_acc: 0.4250\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9604 - acc: 0.4945 - val_loss: 1.1504 - val_acc: 0.4250\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 0.9584 - acc: 0.5055 - val_loss: 1.1484 - val_acc: 0.4250\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 444us/sample - loss: 0.9570 - acc: 0.5165 - val_loss: 1.1489 - val_acc: 0.4250\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9560 - acc: 0.5165 - val_loss: 1.1487 - val_acc: 0.4250\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 0.9544 - acc: 0.5165 - val_loss: 1.1484 - val_acc: 0.4250\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9533 - acc: 0.5275 - val_loss: 1.1477 - val_acc: 0.4250\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9530 - acc: 0.5385 - val_loss: 1.1475 - val_acc: 0.4250\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 360us/sample - loss: 0.9501 - acc: 0.5495 - val_loss: 1.1432 - val_acc: 0.4250\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 0.9490 - acc: 0.5495 - val_loss: 1.1424 - val_acc: 0.4250\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 354us/sample - loss: 0.9484 - acc: 0.5385 - val_loss: 1.1429 - val_acc: 0.4250\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 355us/sample - loss: 0.9465 - acc: 0.5385 - val_loss: 1.1423 - val_acc: 0.4250\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 469us/sample - loss: 0.9454 - acc: 0.5495 - val_loss: 1.1407 - val_acc: 0.4250\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 364us/sample - loss: 0.9454 - acc: 0.5385 - val_loss: 1.1412 - val_acc: 0.4500\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9427 - acc: 0.5495 - val_loss: 1.1403 - val_acc: 0.4500\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 0.9422 - acc: 0.5495 - val_loss: 1.1394 - val_acc: 0.4500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9413 - acc: 0.5714 - val_loss: 1.1341 - val_acc: 0.4500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9396 - acc: 0.5495 - val_loss: 1.1326 - val_acc: 0.4500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 0.9391 - acc: 0.5714 - val_loss: 1.1337 - val_acc: 0.4500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.9401 - acc: 0.5604 - val_loss: 1.1336 - val_acc: 0.4500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 335us/sample - loss: 0.9372 - acc: 0.5714 - val_loss: 1.1347 - val_acc: 0.4250\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 348us/sample - loss: 0.9364 - acc: 0.5714 - val_loss: 1.1394 - val_acc: 0.4250\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 2.7201 - acc: 0.3516 - val_loss: 1.6361 - val_acc: 0.3250\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 2.3522 - acc: 0.3736 - val_loss: 1.4368 - val_acc: 0.3250\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 334us/sample - loss: 2.0291 - acc: 0.3516 - val_loss: 1.2717 - val_acc: 0.3000\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 471us/sample - loss: 1.6864 - acc: 0.3077 - val_loss: 1.1847 - val_acc: 0.3750\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 469us/sample - loss: 1.3996 - acc: 0.3297 - val_loss: 1.1730 - val_acc: 0.4500\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 824us/sample - loss: 1.2147 - acc: 0.4396 - val_loss: 1.1961 - val_acc: 0.4750\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 451us/sample - loss: 1.1033 - acc: 0.5055 - val_loss: 1.2281 - val_acc: 0.5250\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 362us/sample - loss: 1.0536 - acc: 0.5275 - val_loss: 1.2507 - val_acc: 0.5250\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 1.0271 - acc: 0.5604 - val_loss: 1.2653 - val_acc: 0.5250\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 1.0097 - acc: 0.5824 - val_loss: 1.2795 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9945 - acc: 0.5824 - val_loss: 1.2894 - val_acc: 0.5250\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9843 - acc: 0.5824 - val_loss: 1.3084 - val_acc: 0.5250\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9747 - acc: 0.5934 - val_loss: 1.3110 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9687 - acc: 0.5824 - val_loss: 1.3014 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 470us/sample - loss: 0.9626 - acc: 0.5824 - val_loss: 1.2977 - val_acc: 0.5000\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9545 - acc: 0.5824 - val_loss: 1.2887 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9532 - acc: 0.5934 - val_loss: 1.2856 - val_acc: 0.5000\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9477 - acc: 0.5824 - val_loss: 1.2817 - val_acc: 0.4750\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 0.9407 - acc: 0.5934 - val_loss: 1.2804 - val_acc: 0.4500\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 510us/sample - loss: 0.9377 - acc: 0.6044 - val_loss: 1.2828 - val_acc: 0.4500\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 0.9332 - acc: 0.6044 - val_loss: 1.2926 - val_acc: 0.4500\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 0.9298 - acc: 0.5934 - val_loss: 1.2899 - val_acc: 0.4500\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9254 - acc: 0.6044 - val_loss: 1.2793 - val_acc: 0.4500\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 0.9237 - acc: 0.6154 - val_loss: 1.2778 - val_acc: 0.4500\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 0.9201 - acc: 0.6044 - val_loss: 1.2705 - val_acc: 0.4500\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 0.9161 - acc: 0.6154 - val_loss: 1.2720 - val_acc: 0.4500\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9132 - acc: 0.6154 - val_loss: 1.2713 - val_acc: 0.4500\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 0.9103 - acc: 0.6154 - val_loss: 1.2865 - val_acc: 0.4500\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9091 - acc: 0.5934 - val_loss: 1.2835 - val_acc: 0.4500\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 0.9040 - acc: 0.6154 - val_loss: 1.2741 - val_acc: 0.4500\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9026 - acc: 0.5934 - val_loss: 1.2664 - val_acc: 0.4500\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 462us/sample - loss: 0.8989 - acc: 0.6044 - val_loss: 1.2626 - val_acc: 0.4500\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 0.9001 - acc: 0.6044 - val_loss: 1.2624 - val_acc: 0.4500\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.8947 - acc: 0.6044 - val_loss: 1.2631 - val_acc: 0.4500\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.8931 - acc: 0.6154 - val_loss: 1.2586 - val_acc: 0.4500\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 362us/sample - loss: 0.8920 - acc: 0.6154 - val_loss: 1.2545 - val_acc: 0.4500\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 450us/sample - loss: 0.8877 - acc: 0.6154 - val_loss: 1.2538 - val_acc: 0.4500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.8870 - acc: 0.6154 - val_loss: 1.2528 - val_acc: 0.4500\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.8851 - acc: 0.6044 - val_loss: 1.2539 - val_acc: 0.4500\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 0.8832 - acc: 0.6044 - val_loss: 1.2524 - val_acc: 0.4500\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 0.8810 - acc: 0.6154 - val_loss: 1.2521 - val_acc: 0.4500\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.8802 - acc: 0.6044 - val_loss: 1.2497 - val_acc: 0.4500\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 0.8786 - acc: 0.6154 - val_loss: 1.2501 - val_acc: 0.4500\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 514us/sample - loss: 0.8775 - acc: 0.6154 - val_loss: 1.2435 - val_acc: 0.4500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.8760 - acc: 0.6044 - val_loss: 1.2452 - val_acc: 0.4500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 0.8732 - acc: 0.6044 - val_loss: 1.2571 - val_acc: 0.4500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 0.8732 - acc: 0.6044 - val_loss: 1.2710 - val_acc: 0.4500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 0.8707 - acc: 0.6044 - val_loss: 1.2745 - val_acc: 0.4500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.8725 - acc: 0.6044 - val_loss: 1.2666 - val_acc: 0.4500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 0.8698 - acc: 0.6044 - val_loss: 1.2187 - val_acc: 0.4500\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.9604 - acc: 0.2857 - val_loss: 1.8785 - val_acc: 0.3000\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 1.8049 - acc: 0.3077 - val_loss: 1.7538 - val_acc: 0.3000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.6804 - acc: 0.3187 - val_loss: 1.6379 - val_acc: 0.3000\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.5604 - acc: 0.3407 - val_loss: 1.5449 - val_acc: 0.3000\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.4736 - acc: 0.3297 - val_loss: 1.4757 - val_acc: 0.3250\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 464us/sample - loss: 1.4079 - acc: 0.3187 - val_loss: 1.4176 - val_acc: 0.3250\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.3478 - acc: 0.3407 - val_loss: 1.3666 - val_acc: 0.3250\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 1.2975 - acc: 0.3407 - val_loss: 1.3189 - val_acc: 0.3500\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 343us/sample - loss: 1.2526 - acc: 0.3516 - val_loss: 1.2825 - val_acc: 0.3750\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 369us/sample - loss: 1.2156 - acc: 0.3516 - val_loss: 1.2547 - val_acc: 0.4500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 1.1847 - acc: 0.3516 - val_loss: 1.2353 - val_acc: 0.4000\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 1.1544 - acc: 0.3516 - val_loss: 1.2144 - val_acc: 0.4500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 423us/sample - loss: 1.1291 - acc: 0.3846 - val_loss: 1.1930 - val_acc: 0.4500\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 1.1088 - acc: 0.4066 - val_loss: 1.1776 - val_acc: 0.4250\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.0887 - acc: 0.4505 - val_loss: 1.1667 - val_acc: 0.3750\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 1.0724 - acc: 0.4396 - val_loss: 1.1553 - val_acc: 0.3750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 354us/sample - loss: 1.0554 - acc: 0.3956 - val_loss: 1.1465 - val_acc: 0.4000\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 1.0425 - acc: 0.4286 - val_loss: 1.1402 - val_acc: 0.4000\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 1.0318 - acc: 0.4725 - val_loss: 1.1354 - val_acc: 0.4000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.0210 - acc: 0.4725 - val_loss: 1.1326 - val_acc: 0.4000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.0122 - acc: 0.4835 - val_loss: 1.1296 - val_acc: 0.4000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 359us/sample - loss: 1.0039 - acc: 0.5165 - val_loss: 1.1237 - val_acc: 0.4250\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 434us/sample - loss: 0.9950 - acc: 0.5275 - val_loss: 1.1206 - val_acc: 0.4250\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 0.9878 - acc: 0.5165 - val_loss: 1.1203 - val_acc: 0.4250\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9813 - acc: 0.5165 - val_loss: 1.1185 - val_acc: 0.4250\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9766 - acc: 0.5275 - val_loss: 1.1170 - val_acc: 0.4250\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9709 - acc: 0.5275 - val_loss: 1.1175 - val_acc: 0.4000\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 0.9661 - acc: 0.5495 - val_loss: 1.1178 - val_acc: 0.4000\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9613 - acc: 0.5385 - val_loss: 1.1184 - val_acc: 0.4000\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9567 - acc: 0.5385 - val_loss: 1.1171 - val_acc: 0.3750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9531 - acc: 0.5385 - val_loss: 1.1192 - val_acc: 0.4000\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9495 - acc: 0.5385 - val_loss: 1.1215 - val_acc: 0.4000\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 0.9469 - acc: 0.5385 - val_loss: 1.1234 - val_acc: 0.4000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 0.9425 - acc: 0.5385 - val_loss: 1.1230 - val_acc: 0.4000\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 0.9405 - acc: 0.5385 - val_loss: 1.1256 - val_acc: 0.4000\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9381 - acc: 0.5385 - val_loss: 1.1261 - val_acc: 0.4000\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.9362 - acc: 0.5495 - val_loss: 1.1275 - val_acc: 0.4000\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 0.9339 - acc: 0.5385 - val_loss: 1.1282 - val_acc: 0.4000\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9319 - acc: 0.5495 - val_loss: 1.1240 - val_acc: 0.3750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9303 - acc: 0.5385 - val_loss: 1.1247 - val_acc: 0.3750\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9275 - acc: 0.5495 - val_loss: 1.1281 - val_acc: 0.4000\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9258 - acc: 0.5495 - val_loss: 1.1311 - val_acc: 0.4000\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9247 - acc: 0.5495 - val_loss: 1.1336 - val_acc: 0.4000\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9226 - acc: 0.5604 - val_loss: 1.1368 - val_acc: 0.4000\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9212 - acc: 0.5604 - val_loss: 1.1366 - val_acc: 0.3750\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 0.9194 - acc: 0.5604 - val_loss: 1.1400 - val_acc: 0.3500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 0.9182 - acc: 0.5604 - val_loss: 1.1450 - val_acc: 0.3500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 494us/sample - loss: 0.9164 - acc: 0.5495 - val_loss: 1.1463 - val_acc: 0.3500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 0.9150 - acc: 0.5495 - val_loss: 1.1484 - val_acc: 0.3500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9131 - acc: 0.5495 - val_loss: 1.1496 - val_acc: 0.3500\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.1865 - acc: 0.4505 - val_loss: 1.1082 - val_acc: 0.5750\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.1502 - acc: 0.4505 - val_loss: 1.1098 - val_acc: 0.5500\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 1.1205 - acc: 0.4945 - val_loss: 1.1104 - val_acc: 0.5750\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.0989 - acc: 0.5055 - val_loss: 1.1113 - val_acc: 0.5500\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 1.0803 - acc: 0.4945 - val_loss: 1.1127 - val_acc: 0.5250\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 1.0630 - acc: 0.4945 - val_loss: 1.1141 - val_acc: 0.5500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 1.0501 - acc: 0.5055 - val_loss: 1.1157 - val_acc: 0.5500\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 1.0378 - acc: 0.5055 - val_loss: 1.1165 - val_acc: 0.5750\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 1.0260 - acc: 0.5055 - val_loss: 1.1187 - val_acc: 0.5750\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 1.0165 - acc: 0.5385 - val_loss: 1.1210 - val_acc: 0.5750\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.0081 - acc: 0.5604 - val_loss: 1.1230 - val_acc: 0.5750\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 430us/sample - loss: 1.0002 - acc: 0.5824 - val_loss: 1.1241 - val_acc: 0.5500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 0.9938 - acc: 0.5714 - val_loss: 1.1248 - val_acc: 0.5750\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 419us/sample - loss: 0.9863 - acc: 0.5934 - val_loss: 1.1219 - val_acc: 0.5750\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9810 - acc: 0.5824 - val_loss: 1.1204 - val_acc: 0.5750\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.9768 - acc: 0.5934 - val_loss: 1.1205 - val_acc: 0.5500\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9721 - acc: 0.5934 - val_loss: 1.1207 - val_acc: 0.5500\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9679 - acc: 0.5714 - val_loss: 1.1208 - val_acc: 0.5500\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 0.9648 - acc: 0.5934 - val_loss: 1.1210 - val_acc: 0.5250\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 0.9614 - acc: 0.5934 - val_loss: 1.1139 - val_acc: 0.5750\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 369us/sample - loss: 0.9601 - acc: 0.5604 - val_loss: 1.1125 - val_acc: 0.5500\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9577 - acc: 0.5604 - val_loss: 1.1146 - val_acc: 0.5250\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 0.9538 - acc: 0.5824 - val_loss: 1.1165 - val_acc: 0.5250\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 476us/sample - loss: 0.9513 - acc: 0.5714 - val_loss: 1.1149 - val_acc: 0.5250\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 0.9507 - acc: 0.5934 - val_loss: 1.1120 - val_acc: 0.5250\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9505 - acc: 0.5934 - val_loss: 1.1150 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9484 - acc: 0.5934 - val_loss: 1.1181 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 0.9463 - acc: 0.5934 - val_loss: 1.1168 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.9441 - acc: 0.5934 - val_loss: 1.1172 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 0.9427 - acc: 0.5824 - val_loss: 1.1163 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 0.9410 - acc: 0.5934 - val_loss: 1.1170 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 0.9399 - acc: 0.5934 - val_loss: 1.1122 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 444us/sample - loss: 0.9381 - acc: 0.5934 - val_loss: 1.1099 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 0.9348 - acc: 0.5714 - val_loss: 1.1135 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9334 - acc: 0.5824 - val_loss: 1.1160 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 0.9328 - acc: 0.5824 - val_loss: 1.1167 - val_acc: 0.5500\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 366us/sample - loss: 0.9306 - acc: 0.5824 - val_loss: 1.1167 - val_acc: 0.5500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 0.9287 - acc: 0.5934 - val_loss: 1.1193 - val_acc: 0.5500\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 0.9277 - acc: 0.5714 - val_loss: 1.1184 - val_acc: 0.5500\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9267 - acc: 0.5934 - val_loss: 1.1168 - val_acc: 0.5500\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9252 - acc: 0.5934 - val_loss: 1.1133 - val_acc: 0.5500\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 0.9247 - acc: 0.5934 - val_loss: 1.1137 - val_acc: 0.5500\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9239 - acc: 0.5824 - val_loss: 1.1139 - val_acc: 0.5500\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 0.9224 - acc: 0.5824 - val_loss: 1.1125 - val_acc: 0.5500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 435us/sample - loss: 0.9208 - acc: 0.5824 - val_loss: 1.1114 - val_acc: 0.5500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9192 - acc: 0.5824 - val_loss: 1.1131 - val_acc: 0.5500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9182 - acc: 0.5824 - val_loss: 1.1151 - val_acc: 0.5500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 378us/sample - loss: 0.9167 - acc: 0.5824 - val_loss: 1.1192 - val_acc: 0.5500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 426us/sample - loss: 0.9162 - acc: 0.5824 - val_loss: 1.1206 - val_acc: 0.5500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 364us/sample - loss: 0.9151 - acc: 0.5824 - val_loss: 1.1057 - val_acc: 0.5500\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 991us/sample - loss: 1.6388 - acc: 0.4835 - val_loss: 1.5460 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 1.5620 - acc: 0.4945 - val_loss: 1.4901 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 446us/sample - loss: 1.4946 - acc: 0.5055 - val_loss: 1.4456 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.4378 - acc: 0.4945 - val_loss: 1.4012 - val_acc: 0.4750\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 1.3853 - acc: 0.4835 - val_loss: 1.3586 - val_acc: 0.4750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.3390 - acc: 0.4835 - val_loss: 1.3252 - val_acc: 0.4750\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 1.2967 - acc: 0.4835 - val_loss: 1.2945 - val_acc: 0.4750\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 1.2623 - acc: 0.4835 - val_loss: 1.2674 - val_acc: 0.4750\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 1.2254 - acc: 0.4835 - val_loss: 1.2438 - val_acc: 0.4750\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 1.1973 - acc: 0.4835 - val_loss: 1.2205 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.1633 - acc: 0.4835 - val_loss: 1.1992 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.1369 - acc: 0.4835 - val_loss: 1.1812 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.1190 - acc: 0.4725 - val_loss: 1.1662 - val_acc: 0.5000\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 1.0989 - acc: 0.4945 - val_loss: 1.1535 - val_acc: 0.5000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 1.0831 - acc: 0.5055 - val_loss: 1.1436 - val_acc: 0.5500\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.0695 - acc: 0.5275 - val_loss: 1.1351 - val_acc: 0.5500\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 1.0570 - acc: 0.5275 - val_loss: 1.1264 - val_acc: 0.5750\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 1.0446 - acc: 0.5275 - val_loss: 1.1183 - val_acc: 0.5750\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 1.0340 - acc: 0.5165 - val_loss: 1.1114 - val_acc: 0.5750\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 850us/sample - loss: 1.0248 - acc: 0.5165 - val_loss: 1.1030 - val_acc: 0.6000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 474us/sample - loss: 1.0124 - acc: 0.5495 - val_loss: 1.0801 - val_acc: 0.6000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 366us/sample - loss: 1.0005 - acc: 0.5495 - val_loss: 1.0676 - val_acc: 0.5750\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 0.9901 - acc: 0.5385 - val_loss: 1.0633 - val_acc: 0.5750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 359us/sample - loss: 0.9813 - acc: 0.5495 - val_loss: 1.0588 - val_acc: 0.5750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9745 - acc: 0.5385 - val_loss: 1.0547 - val_acc: 0.5750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9680 - acc: 0.5385 - val_loss: 1.0543 - val_acc: 0.5750\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9616 - acc: 0.5495 - val_loss: 1.0516 - val_acc: 0.5750\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9565 - acc: 0.5714 - val_loss: 1.0483 - val_acc: 0.5750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9511 - acc: 0.5495 - val_loss: 1.0475 - val_acc: 0.5500\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 0.9466 - acc: 0.5604 - val_loss: 1.0468 - val_acc: 0.5250\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 585us/sample - loss: 0.9431 - acc: 0.5604 - val_loss: 1.0454 - val_acc: 0.5250\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9379 - acc: 0.5604 - val_loss: 1.0437 - val_acc: 0.5250\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9347 - acc: 0.5604 - val_loss: 1.0420 - val_acc: 0.5250\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 428us/sample - loss: 0.9319 - acc: 0.5714 - val_loss: 1.0404 - val_acc: 0.5250\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 419us/sample - loss: 0.9295 - acc: 0.5714 - val_loss: 1.0395 - val_acc: 0.5500\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 0.9259 - acc: 0.5714 - val_loss: 1.0384 - val_acc: 0.5500\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 0.9235 - acc: 0.5714 - val_loss: 1.0373 - val_acc: 0.5500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9213 - acc: 0.5714 - val_loss: 1.0364 - val_acc: 0.5500\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 375us/sample - loss: 0.9191 - acc: 0.5604 - val_loss: 1.0363 - val_acc: 0.5500\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9164 - acc: 0.5604 - val_loss: 1.0358 - val_acc: 0.5500\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9140 - acc: 0.5714 - val_loss: 1.0344 - val_acc: 0.5750\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 469us/sample - loss: 0.9121 - acc: 0.5714 - val_loss: 1.0337 - val_acc: 0.5750\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9102 - acc: 0.5714 - val_loss: 1.0338 - val_acc: 0.5500\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9082 - acc: 0.5714 - val_loss: 1.0325 - val_acc: 0.5500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9065 - acc: 0.5714 - val_loss: 1.0323 - val_acc: 0.5500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9050 - acc: 0.5714 - val_loss: 1.0323 - val_acc: 0.5500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9036 - acc: 0.5714 - val_loss: 1.0326 - val_acc: 0.5500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 0.9026 - acc: 0.5714 - val_loss: 1.0330 - val_acc: 0.5500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 0.9012 - acc: 0.5714 - val_loss: 1.0336 - val_acc: 0.5500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.8997 - acc: 0.5714 - val_loss: 1.0339 - val_acc: 0.5500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9542909cfa6e57f247be950874b2f515</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5199999809265137</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 1e-07</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 2.2055 - acc: 0.2747 - val_loss: 1.4071 - val_acc: 0.4000\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 473us/sample - loss: 2.0013 - acc: 0.2637 - val_loss: 1.3466 - val_acc: 0.4250\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 482us/sample - loss: 1.8284 - acc: 0.2527 - val_loss: 1.2930 - val_acc: 0.4500\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 461us/sample - loss: 1.6903 - acc: 0.2747 - val_loss: 1.2513 - val_acc: 0.4250\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 461us/sample - loss: 1.5698 - acc: 0.2747 - val_loss: 1.2241 - val_acc: 0.4000\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 1.4854 - acc: 0.2967 - val_loss: 1.2036 - val_acc: 0.4250\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 364us/sample - loss: 1.4161 - acc: 0.2967 - val_loss: 1.1842 - val_acc: 0.4500\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 450us/sample - loss: 1.3554 - acc: 0.3187 - val_loss: 1.1696 - val_acc: 0.4750\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 1.3058 - acc: 0.3297 - val_loss: 1.1605 - val_acc: 0.4750\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 442us/sample - loss: 1.2630 - acc: 0.3077 - val_loss: 1.1512 - val_acc: 0.4750\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 452us/sample - loss: 1.2209 - acc: 0.3187 - val_loss: 1.1446 - val_acc: 0.4500\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 1.1887 - acc: 0.3187 - val_loss: 1.1401 - val_acc: 0.4750\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 1.1585 - acc: 0.3077 - val_loss: 1.1368 - val_acc: 0.4750\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 1.1325 - acc: 0.3187 - val_loss: 1.1357 - val_acc: 0.4750\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.1132 - acc: 0.3077 - val_loss: 1.1350 - val_acc: 0.4500\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 371us/sample - loss: 1.0923 - acc: 0.3077 - val_loss: 1.1328 - val_acc: 0.4500\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 1.0762 - acc: 0.3187 - val_loss: 1.1316 - val_acc: 0.4750\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 1.0607 - acc: 0.3516 - val_loss: 1.1326 - val_acc: 0.4750\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 1.0484 - acc: 0.3516 - val_loss: 1.1350 - val_acc: 0.4750\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 535us/sample - loss: 1.0366 - acc: 0.3736 - val_loss: 1.1374 - val_acc: 0.5250\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 1.0266 - acc: 0.3626 - val_loss: 1.1403 - val_acc: 0.5250\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.0174 - acc: 0.3956 - val_loss: 1.1422 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 423us/sample - loss: 1.0091 - acc: 0.3846 - val_loss: 1.1354 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 1.0026 - acc: 0.3956 - val_loss: 1.1348 - val_acc: 0.4500\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 0.9974 - acc: 0.4396 - val_loss: 1.1388 - val_acc: 0.4750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9910 - acc: 0.4725 - val_loss: 1.1438 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 0.9834 - acc: 0.5055 - val_loss: 1.1463 - val_acc: 0.4750\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 0.9784 - acc: 0.5055 - val_loss: 1.1480 - val_acc: 0.4750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 0.9741 - acc: 0.5055 - val_loss: 1.1514 - val_acc: 0.4750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 445us/sample - loss: 0.9693 - acc: 0.5165 - val_loss: 1.1541 - val_acc: 0.4750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 0.9656 - acc: 0.5275 - val_loss: 1.1564 - val_acc: 0.4500\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 367us/sample - loss: 0.9623 - acc: 0.5275 - val_loss: 1.1577 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 0.9592 - acc: 0.5385 - val_loss: 1.1595 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9570 - acc: 0.5385 - val_loss: 1.1602 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.9544 - acc: 0.5275 - val_loss: 1.1571 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 0.9541 - acc: 0.5385 - val_loss: 1.1582 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.9503 - acc: 0.5385 - val_loss: 1.1532 - val_acc: 0.4500\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 0.9487 - acc: 0.5385 - val_loss: 1.1536 - val_acc: 0.4500\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9472 - acc: 0.5385 - val_loss: 1.1550 - val_acc: 0.4500\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9453 - acc: 0.5275 - val_loss: 1.1571 - val_acc: 0.4750\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 402us/sample - loss: 0.9428 - acc: 0.5275 - val_loss: 1.1622 - val_acc: 0.4750\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 444us/sample - loss: 0.9407 - acc: 0.5275 - val_loss: 1.1667 - val_acc: 0.4500\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 360us/sample - loss: 0.9383 - acc: 0.5275 - val_loss: 1.1677 - val_acc: 0.4750\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 370us/sample - loss: 0.9360 - acc: 0.5275 - val_loss: 1.1698 - val_acc: 0.4750\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9346 - acc: 0.5275 - val_loss: 1.1718 - val_acc: 0.4500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9335 - acc: 0.5165 - val_loss: 1.1730 - val_acc: 0.4500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 0.9317 - acc: 0.5275 - val_loss: 1.1758 - val_acc: 0.4500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 451us/sample - loss: 0.9298 - acc: 0.5275 - val_loss: 1.1796 - val_acc: 0.4500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 0.9287 - acc: 0.5275 - val_loss: 1.1832 - val_acc: 0.4500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9270 - acc: 0.5275 - val_loss: 1.1853 - val_acc: 0.4000\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 2.3738 - acc: 0.2198 - val_loss: 1.4684 - val_acc: 0.3750\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 369us/sample - loss: 2.0172 - acc: 0.2308 - val_loss: 1.4020 - val_acc: 0.4000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 1.7846 - acc: 0.2747 - val_loss: 1.3944 - val_acc: 0.4000\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 1.6348 - acc: 0.2857 - val_loss: 1.4000 - val_acc: 0.4000\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 371us/sample - loss: 1.5356 - acc: 0.3297 - val_loss: 1.3992 - val_acc: 0.3750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 440us/sample - loss: 1.4632 - acc: 0.3626 - val_loss: 1.3933 - val_acc: 0.3500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 362us/sample - loss: 1.4108 - acc: 0.3736 - val_loss: 1.3797 - val_acc: 0.3750\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 428us/sample - loss: 1.3637 - acc: 0.4066 - val_loss: 1.3673 - val_acc: 0.4000\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 354us/sample - loss: 1.3283 - acc: 0.4066 - val_loss: 1.3583 - val_acc: 0.4000\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.2926 - acc: 0.4615 - val_loss: 1.3750 - val_acc: 0.3500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 1.2608 - acc: 0.5165 - val_loss: 1.3552 - val_acc: 0.4000\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 453us/sample - loss: 1.2360 - acc: 0.5165 - val_loss: 1.3452 - val_acc: 0.4000\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 451us/sample - loss: 1.2147 - acc: 0.5165 - val_loss: 1.3242 - val_acc: 0.4000\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 418us/sample - loss: 1.1921 - acc: 0.5165 - val_loss: 1.3017 - val_acc: 0.4000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 394us/sample - loss: 1.1758 - acc: 0.5165 - val_loss: 1.2922 - val_acc: 0.4250\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 1.1538 - acc: 0.5165 - val_loss: 1.2799 - val_acc: 0.4250\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 396us/sample - loss: 1.1377 - acc: 0.5165 - val_loss: 1.2392 - val_acc: 0.4250\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 473us/sample - loss: 1.1271 - acc: 0.5165 - val_loss: 1.2379 - val_acc: 0.4250\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 1.1118 - acc: 0.5165 - val_loss: 1.2384 - val_acc: 0.4250\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 425us/sample - loss: 1.0980 - acc: 0.5165 - val_loss: 1.2398 - val_acc: 0.4250\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 1.0858 - acc: 0.5275 - val_loss: 1.2391 - val_acc: 0.4250\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 359us/sample - loss: 1.0737 - acc: 0.5275 - val_loss: 1.2384 - val_acc: 0.4250\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.0661 - acc: 0.5165 - val_loss: 1.2282 - val_acc: 0.4250\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 1.0572 - acc: 0.5275 - val_loss: 1.2199 - val_acc: 0.4250\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 401us/sample - loss: 1.0483 - acc: 0.5165 - val_loss: 1.2174 - val_acc: 0.4250\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 439us/sample - loss: 1.0395 - acc: 0.5275 - val_loss: 1.2154 - val_acc: 0.4250\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.0319 - acc: 0.5165 - val_loss: 1.2092 - val_acc: 0.4250\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.0238 - acc: 0.5165 - val_loss: 1.2104 - val_acc: 0.4250\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.0180 - acc: 0.5055 - val_loss: 1.2106 - val_acc: 0.4250\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 1.0117 - acc: 0.5055 - val_loss: 1.2328 - val_acc: 0.4250\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 1.0078 - acc: 0.5165 - val_loss: 1.2271 - val_acc: 0.4250\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 395us/sample - loss: 1.0003 - acc: 0.5165 - val_loss: 1.2145 - val_acc: 0.4250\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 439us/sample - loss: 0.9948 - acc: 0.5165 - val_loss: 1.2125 - val_acc: 0.4250\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9876 - acc: 0.5165 - val_loss: 1.2300 - val_acc: 0.4250\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 0.9847 - acc: 0.5275 - val_loss: 1.2277 - val_acc: 0.4250\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9791 - acc: 0.5165 - val_loss: 1.2220 - val_acc: 0.4250\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 0.9750 - acc: 0.5275 - val_loss: 1.2045 - val_acc: 0.4250\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9708 - acc: 0.5275 - val_loss: 1.1943 - val_acc: 0.4250\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 374us/sample - loss: 0.9690 - acc: 0.5275 - val_loss: 1.1922 - val_acc: 0.4250\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9647 - acc: 0.5385 - val_loss: 1.2063 - val_acc: 0.4250\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 0.9630 - acc: 0.5495 - val_loss: 1.1972 - val_acc: 0.4250\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 453us/sample - loss: 0.9593 - acc: 0.5495 - val_loss: 1.1934 - val_acc: 0.4250\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 413us/sample - loss: 0.9561 - acc: 0.5495 - val_loss: 1.2041 - val_acc: 0.4250\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 420us/sample - loss: 0.9540 - acc: 0.5275 - val_loss: 1.2049 - val_acc: 0.4500\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.9504 - acc: 0.5275 - val_loss: 1.2023 - val_acc: 0.4500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 0.9484 - acc: 0.5385 - val_loss: 1.1994 - val_acc: 0.4500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 378us/sample - loss: 0.9451 - acc: 0.5385 - val_loss: 1.1973 - val_acc: 0.4500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 427us/sample - loss: 0.9429 - acc: 0.5385 - val_loss: 1.1988 - val_acc: 0.4500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 0.9426 - acc: 0.5495 - val_loss: 1.2087 - val_acc: 0.4500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 0.9389 - acc: 0.5495 - val_loss: 1.2065 - val_acc: 0.4500\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 2.1901 - acc: 0.2418 - val_loss: 1.7341 - val_acc: 0.3250\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 1.7842 - acc: 0.2857 - val_loss: 1.4855 - val_acc: 0.3500\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 1.5492 - acc: 0.3626 - val_loss: 1.3472 - val_acc: 0.3500\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 1.3764 - acc: 0.4066 - val_loss: 1.2632 - val_acc: 0.4000\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 1.2670 - acc: 0.4396 - val_loss: 1.2413 - val_acc: 0.3750\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 393us/sample - loss: 1.1818 - acc: 0.4945 - val_loss: 1.2249 - val_acc: 0.4000\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 426us/sample - loss: 1.1413 - acc: 0.5165 - val_loss: 1.2167 - val_acc: 0.4000\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 1.1110 - acc: 0.5385 - val_loss: 1.2062 - val_acc: 0.3750\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 1.0885 - acc: 0.5385 - val_loss: 1.1985 - val_acc: 0.3750\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 1.0743 - acc: 0.5385 - val_loss: 1.2029 - val_acc: 0.3750\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 1.0640 - acc: 0.5495 - val_loss: 1.2162 - val_acc: 0.4000\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.0542 - acc: 0.5385 - val_loss: 1.2066 - val_acc: 0.4000\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 467us/sample - loss: 1.0466 - acc: 0.5385 - val_loss: 1.1926 - val_acc: 0.4000\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 420us/sample - loss: 1.0386 - acc: 0.5385 - val_loss: 1.1824 - val_acc: 0.4000\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 1.0341 - acc: 0.5385 - val_loss: 1.1883 - val_acc: 0.3750\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 1.0271 - acc: 0.5495 - val_loss: 1.1936 - val_acc: 0.3750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 1.0218 - acc: 0.5275 - val_loss: 1.1951 - val_acc: 0.4000\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 433us/sample - loss: 1.0198 - acc: 0.5385 - val_loss: 1.2054 - val_acc: 0.4000\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 1.0144 - acc: 0.5495 - val_loss: 1.2416 - val_acc: 0.4000\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 397us/sample - loss: 1.0140 - acc: 0.5495 - val_loss: 1.2197 - val_acc: 0.4000\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 1.0086 - acc: 0.5275 - val_loss: 1.2077 - val_acc: 0.4000\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 350us/sample - loss: 1.0040 - acc: 0.5385 - val_loss: 1.2117 - val_acc: 0.4000\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 0.9992 - acc: 0.5385 - val_loss: 1.2043 - val_acc: 0.4000\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 356us/sample - loss: 0.9968 - acc: 0.5495 - val_loss: 1.2049 - val_acc: 0.4250\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9933 - acc: 0.5385 - val_loss: 1.1905 - val_acc: 0.4250\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 437us/sample - loss: 0.9906 - acc: 0.5495 - val_loss: 1.1933 - val_acc: 0.4250\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 422us/sample - loss: 0.9871 - acc: 0.5495 - val_loss: 1.1826 - val_acc: 0.4250\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 471us/sample - loss: 0.9851 - acc: 0.5385 - val_loss: 1.1846 - val_acc: 0.4250\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 467us/sample - loss: 0.9810 - acc: 0.5604 - val_loss: 1.1823 - val_acc: 0.4250\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 478us/sample - loss: 0.9795 - acc: 0.5385 - val_loss: 1.1942 - val_acc: 0.4250\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 0.9770 - acc: 0.5495 - val_loss: 1.1979 - val_acc: 0.4250\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 363us/sample - loss: 0.9736 - acc: 0.5604 - val_loss: 1.1940 - val_acc: 0.4250\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9709 - acc: 0.5604 - val_loss: 1.1919 - val_acc: 0.4250\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9694 - acc: 0.5714 - val_loss: 1.1906 - val_acc: 0.4250\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 392us/sample - loss: 0.9663 - acc: 0.5714 - val_loss: 1.1925 - val_acc: 0.4250\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9636 - acc: 0.5604 - val_loss: 1.1874 - val_acc: 0.4250\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 454us/sample - loss: 0.9649 - acc: 0.5495 - val_loss: 1.1878 - val_acc: 0.4250\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 0.9620 - acc: 0.5604 - val_loss: 1.1863 - val_acc: 0.4250\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 441us/sample - loss: 0.9610 - acc: 0.5495 - val_loss: 1.1907 - val_acc: 0.4250\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 543us/sample - loss: 0.9612 - acc: 0.5604 - val_loss: 1.1899 - val_acc: 0.4250\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 562us/sample - loss: 0.9564 - acc: 0.5495 - val_loss: 1.1908 - val_acc: 0.4250\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 361us/sample - loss: 0.9538 - acc: 0.5495 - val_loss: 1.1892 - val_acc: 0.4250\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 423us/sample - loss: 0.9546 - acc: 0.5495 - val_loss: 1.1850 - val_acc: 0.4250\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 0.9531 - acc: 0.5495 - val_loss: 1.1780 - val_acc: 0.4250\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 368us/sample - loss: 0.9488 - acc: 0.5385 - val_loss: 1.1738 - val_acc: 0.4250\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 0.9478 - acc: 0.5385 - val_loss: 1.1524 - val_acc: 0.4500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9485 - acc: 0.5604 - val_loss: 1.1449 - val_acc: 0.4500\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9480 - acc: 0.5495 - val_loss: 1.1469 - val_acc: 0.4500\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 0.9451 - acc: 0.5604 - val_loss: 1.1583 - val_acc: 0.4500\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9431 - acc: 0.5495 - val_loss: 1.1627 - val_acc: 0.4500\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.3143 - acc: 0.4835 - val_loss: 1.8783 - val_acc: 0.4000\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 416us/sample - loss: 1.2539 - acc: 0.4945 - val_loss: 1.8138 - val_acc: 0.4500\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 1.2076 - acc: 0.5055 - val_loss: 1.7573 - val_acc: 0.4500\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 431us/sample - loss: 1.1673 - acc: 0.5055 - val_loss: 1.7064 - val_acc: 0.4500\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.1276 - acc: 0.5055 - val_loss: 1.6601 - val_acc: 0.4500\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 1.0994 - acc: 0.5165 - val_loss: 1.6208 - val_acc: 0.4500\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 423us/sample - loss: 1.0655 - acc: 0.5385 - val_loss: 1.5824 - val_acc: 0.4500\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 450us/sample - loss: 1.0467 - acc: 0.5604 - val_loss: 1.5531 - val_acc: 0.4500\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 1.0324 - acc: 0.5824 - val_loss: 1.5174 - val_acc: 0.4500\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 1.0155 - acc: 0.5604 - val_loss: 1.4913 - val_acc: 0.4500\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 1.0056 - acc: 0.5824 - val_loss: 1.4712 - val_acc: 0.4500\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 446us/sample - loss: 0.9981 - acc: 0.5824 - val_loss: 1.4567 - val_acc: 0.4500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 418us/sample - loss: 0.9901 - acc: 0.5824 - val_loss: 1.4459 - val_acc: 0.4500\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9851 - acc: 0.5934 - val_loss: 1.4347 - val_acc: 0.4500\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9795 - acc: 0.5824 - val_loss: 1.4262 - val_acc: 0.4750\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 0.9728 - acc: 0.5934 - val_loss: 1.4077 - val_acc: 0.4750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 377us/sample - loss: 0.9695 - acc: 0.5824 - val_loss: 1.3981 - val_acc: 0.4750\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 406us/sample - loss: 0.9655 - acc: 0.5824 - val_loss: 1.3862 - val_acc: 0.4750\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 458us/sample - loss: 0.9616 - acc: 0.5824 - val_loss: 1.3827 - val_acc: 0.4750\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 0.9616 - acc: 0.5824 - val_loss: 1.3797 - val_acc: 0.4750\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9582 - acc: 0.5934 - val_loss: 1.3753 - val_acc: 0.4750\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9551 - acc: 0.5824 - val_loss: 1.3648 - val_acc: 0.4750\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 379us/sample - loss: 0.9532 - acc: 0.5824 - val_loss: 1.3626 - val_acc: 0.4750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 0.9511 - acc: 0.5934 - val_loss: 1.3603 - val_acc: 0.4750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9498 - acc: 0.5934 - val_loss: 1.3552 - val_acc: 0.4750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9464 - acc: 0.5934 - val_loss: 1.3490 - val_acc: 0.4750\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 533us/sample - loss: 0.9438 - acc: 0.5824 - val_loss: 1.3505 - val_acc: 0.4750\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 399us/sample - loss: 0.9431 - acc: 0.5934 - val_loss: 1.3547 - val_acc: 0.4750\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 464us/sample - loss: 0.9420 - acc: 0.6044 - val_loss: 1.3489 - val_acc: 0.4750\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 0.9386 - acc: 0.6154 - val_loss: 1.3430 - val_acc: 0.4750\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 403us/sample - loss: 0.9373 - acc: 0.6044 - val_loss: 1.3284 - val_acc: 0.4750\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9365 - acc: 0.6154 - val_loss: 1.3239 - val_acc: 0.4750\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 407us/sample - loss: 0.9364 - acc: 0.6044 - val_loss: 1.3244 - val_acc: 0.4750\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9335 - acc: 0.6154 - val_loss: 1.3176 - val_acc: 0.4750\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 389us/sample - loss: 0.9332 - acc: 0.6154 - val_loss: 1.3221 - val_acc: 0.4750\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9305 - acc: 0.6264 - val_loss: 1.3239 - val_acc: 0.4750\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 0.9285 - acc: 0.6154 - val_loss: 1.3252 - val_acc: 0.4750\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 0.9277 - acc: 0.6154 - val_loss: 1.3140 - val_acc: 0.4750\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 429us/sample - loss: 0.9261 - acc: 0.6264 - val_loss: 1.3162 - val_acc: 0.4750\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 0.9251 - acc: 0.6154 - val_loss: 1.3270 - val_acc: 0.4750\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 450us/sample - loss: 0.9255 - acc: 0.6044 - val_loss: 1.3247 - val_acc: 0.4750\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 447us/sample - loss: 0.9229 - acc: 0.6044 - val_loss: 1.3174 - val_acc: 0.4750\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 452us/sample - loss: 0.9232 - acc: 0.5934 - val_loss: 1.3181 - val_acc: 0.4750\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 456us/sample - loss: 0.9225 - acc: 0.6154 - val_loss: 1.3140 - val_acc: 0.4750\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 0.9197 - acc: 0.6044 - val_loss: 1.2955 - val_acc: 0.4750\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 0.9180 - acc: 0.6154 - val_loss: 1.2934 - val_acc: 0.4750\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9176 - acc: 0.6044 - val_loss: 1.2946 - val_acc: 0.4750\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 412us/sample - loss: 0.9165 - acc: 0.6154 - val_loss: 1.2964 - val_acc: 0.4750\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 456us/sample - loss: 0.9171 - acc: 0.6044 - val_loss: 1.3037 - val_acc: 0.4750\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 497us/sample - loss: 0.9160 - acc: 0.6044 - val_loss: 1.2824 - val_acc: 0.4750\n",
            "Train on 91 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 0s 1ms/sample - loss: 1.6522 - acc: 0.5165 - val_loss: 2.4731 - val_acc: 0.4500\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 558us/sample - loss: 1.5462 - acc: 0.5275 - val_loss: 2.3184 - val_acc: 0.4500\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 472us/sample - loss: 1.4607 - acc: 0.5275 - val_loss: 2.1746 - val_acc: 0.4250\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 478us/sample - loss: 1.3900 - acc: 0.5165 - val_loss: 2.0373 - val_acc: 0.4250\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 380us/sample - loss: 1.3231 - acc: 0.5385 - val_loss: 1.9186 - val_acc: 0.4250\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 1.2764 - acc: 0.5165 - val_loss: 1.8250 - val_acc: 0.4250\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 448us/sample - loss: 1.2415 - acc: 0.5165 - val_loss: 1.7460 - val_acc: 0.4250\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 415us/sample - loss: 1.2114 - acc: 0.5055 - val_loss: 1.6815 - val_acc: 0.4250\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 452us/sample - loss: 1.1867 - acc: 0.4945 - val_loss: 1.6400 - val_acc: 0.4250\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 454us/sample - loss: 1.1741 - acc: 0.4945 - val_loss: 1.5910 - val_acc: 0.4250\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 414us/sample - loss: 1.1510 - acc: 0.4945 - val_loss: 1.5553 - val_acc: 0.4250\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 362us/sample - loss: 1.1338 - acc: 0.4945 - val_loss: 1.5246 - val_acc: 0.4500\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 1.1166 - acc: 0.5055 - val_loss: 1.4986 - val_acc: 0.4500\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.1044 - acc: 0.4945 - val_loss: 1.4700 - val_acc: 0.4750\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.0891 - acc: 0.5275 - val_loss: 1.4468 - val_acc: 0.4750\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 390us/sample - loss: 1.0800 - acc: 0.5275 - val_loss: 1.4267 - val_acc: 0.4750\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 1.0691 - acc: 0.5385 - val_loss: 1.3944 - val_acc: 0.4750\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 424us/sample - loss: 1.0602 - acc: 0.5385 - val_loss: 1.3689 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 376us/sample - loss: 1.0516 - acc: 0.5604 - val_loss: 1.3624 - val_acc: 0.4750\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 365us/sample - loss: 1.0429 - acc: 0.5495 - val_loss: 1.3501 - val_acc: 0.4750\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 440us/sample - loss: 1.0361 - acc: 0.5495 - val_loss: 1.3512 - val_acc: 0.4750\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 421us/sample - loss: 1.0308 - acc: 0.5604 - val_loss: 1.3366 - val_acc: 0.4750\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 1.0235 - acc: 0.5275 - val_loss: 1.3149 - val_acc: 0.4750\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 409us/sample - loss: 1.0154 - acc: 0.5495 - val_loss: 1.3055 - val_acc: 0.4750\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 404us/sample - loss: 1.0084 - acc: 0.5714 - val_loss: 1.2992 - val_acc: 0.4750\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 400us/sample - loss: 1.0041 - acc: 0.5934 - val_loss: 1.2904 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 448us/sample - loss: 0.9989 - acc: 0.5934 - val_loss: 1.2677 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 383us/sample - loss: 0.9958 - acc: 0.5714 - val_loss: 1.2650 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 398us/sample - loss: 0.9883 - acc: 0.6044 - val_loss: 1.2586 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 411us/sample - loss: 0.9838 - acc: 0.6044 - val_loss: 1.2483 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9812 - acc: 0.6044 - val_loss: 1.2480 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 382us/sample - loss: 0.9768 - acc: 0.6044 - val_loss: 1.2459 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 371us/sample - loss: 0.9731 - acc: 0.6044 - val_loss: 1.2422 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 372us/sample - loss: 0.9704 - acc: 0.5934 - val_loss: 1.2388 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 387us/sample - loss: 0.9672 - acc: 0.6154 - val_loss: 1.2380 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 384us/sample - loss: 0.9644 - acc: 0.6044 - val_loss: 1.2511 - val_acc: 0.4750\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 468us/sample - loss: 0.9644 - acc: 0.6044 - val_loss: 1.2488 - val_acc: 0.4750\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 405us/sample - loss: 0.9608 - acc: 0.6044 - val_loss: 1.2426 - val_acc: 0.4750\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 352us/sample - loss: 0.9587 - acc: 0.6044 - val_loss: 1.2310 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 386us/sample - loss: 0.9550 - acc: 0.6044 - val_loss: 1.2193 - val_acc: 0.5250\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 341us/sample - loss: 0.9521 - acc: 0.6154 - val_loss: 1.2078 - val_acc: 0.5250\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 373us/sample - loss: 0.9493 - acc: 0.6154 - val_loss: 1.2041 - val_acc: 0.5250\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 378us/sample - loss: 0.9489 - acc: 0.6044 - val_loss: 1.2026 - val_acc: 0.5250\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 385us/sample - loss: 0.9456 - acc: 0.6154 - val_loss: 1.2152 - val_acc: 0.5250\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 874us/sample - loss: 0.9457 - acc: 0.6154 - val_loss: 1.1972 - val_acc: 0.5500\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 408us/sample - loss: 0.9429 - acc: 0.5934 - val_loss: 1.1888 - val_acc: 0.5500\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 391us/sample - loss: 0.9412 - acc: 0.6044 - val_loss: 1.1721 - val_acc: 0.5250\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 381us/sample - loss: 0.9382 - acc: 0.6154 - val_loss: 1.1679 - val_acc: 0.5250\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 423us/sample - loss: 0.9354 - acc: 0.6044 - val_loss: 1.1696 - val_acc: 0.5250\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 388us/sample - loss: 0.9338 - acc: 0.5934 - val_loss: 1.1562 - val_acc: 0.5250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: b16d0677aa7435f4a053752e725a083c</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.49000000953674316</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 1e-08</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23JI0eA1OFOX",
        "colab_type": "code",
        "outputId": "1da4d3a2-29ed-4f45-a638-a2ea89118f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "tuner.search_space_summary()\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">decay (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0001, 1e-05, 1e-06, 1e-07, 1e-08]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxpvAxjHSaP6",
        "colab_type": "code",
        "outputId": "246cd72a-bc15-49df-cf10-82fa63ca3a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        }
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Results in /content/my_dir/RandomSearch</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective(name='val_acc', direction='max')</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9542909cfa6e57f247be950874b2f515</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5199999809265137</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 1e-07</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 33ff0bffe206a2f57d8e40877e91a17b</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5099999904632568</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 1e-06</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: b16d0677aa7435f4a053752e725a083c</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.49000000953674316</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 1e-08</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 9d2f08afe8b3fed19c6e38f7e3d5be14</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.48000001907348633</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 0af23bc6f83d6bd6aa9b5d33990d2311</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.45500001311302185</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-decay: 1e-05</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reyZM6rGXHIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_params=tuner.get_best_hyperparameters()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJpBGIEvVkpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_model = tuner.hypermodel.build(random_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QAOJ7PuXvwK",
        "colab_type": "code",
        "outputId": "8f609e27-af26-4d91-880b-415f0a3a7e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'decay': 1e-07}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYGZFhmPYZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = tuner.get_best_models()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVIumnBQEUq3",
        "colab_type": "code",
        "outputId": "96db555f-6073-4c3d-fdac-dcdc2fb1954a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "best_model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4)                 32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 15        \n",
            "=================================================================\n",
            "Total params: 47\n",
            "Trainable params: 47\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wJxr25jOew_",
        "colab_type": "text"
      },
      "source": [
        "##Train the best model RandomSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8w96YVEB_IW",
        "colab_type": "text"
      },
      "source": [
        "Per la valutazione del modello ottimizzato sul validation set uso la Stratified K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1apcZ19gFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBDM-PtBx5V",
        "colab_type": "code",
        "outputId": "82b1005c-3f0d-497e-a82f-12917381d9c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "skf.get_n_splits(train_data_stand_pca, train_labels_dec)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "daf2886d-2182-4889-a89e-75eec570f7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "for train_index, test_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  1   2   4   5   6   8  10  11  12  13  14  15  16  17  20  21  22  23\n",
            "  24  25  26  27  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
            "  43  46  47  48  49  50  52  55  58  59  60  61  62  63  64  65  67  68\n",
            "  69  70  71  73  74  75  76  77  78  79  81  82  83  84  85  86  87  88\n",
            "  89  91  92  93  94  96  97  98  99 100 101 102 103 104 106 107 108 110\n",
            " 113 115 116 117 118 119 121 122 123 124 126 127 129 130] TEST: [  0   3   7   9  18  19  28  44  45  51  53  54  56  57  66  72  80  90\n",
            "  95 105 109 111 112 114 120 125 128]\n",
            "TRAIN: [  0   1   2   3   5   7   8   9  10  11  12  13  14  17  18  19  20  21\n",
            "  22  23  24  25  26  27  28  29  30  31  33  34  37  38  39  40  41  42\n",
            "  44  45  46  47  48  49  51  53  54  55  56  57  58  61  62  63  64  66\n",
            "  67  69  70  71  72  73  75  77  79  80  81  82  83  84  85  87  88  89\n",
            "  90  92  94  95  96  97  98  99 100 101 103 105 106 107 109 110 111 112\n",
            " 114 115 116 117 118 119 120 121 122 124 125 126 127 128 129] TEST: [  4   6  15  16  32  35  36  43  50  52  59  60  65  68  74  76  78  86\n",
            "  91  93 102 104 108 113 123 130]\n",
            "TRAIN: [  0   1   3   4   5   6   7   8   9  10  13  14  15  16  17  18  19  20\n",
            "  22  23  24  25  28  29  30  31  32  33  35  36  37  39  40  43  44  45\n",
            "  46  47  49  50  51  52  53  54  55  56  57  58  59  60  63  64  65  66\n",
            "  67  68  71  72  73  74  75  76  78  79  80  81  82  84  85  86  88  89\n",
            "  90  91  92  93  94  95  98  99 100 101 102 104 105 106 108 109 110 111\n",
            " 112 113 114 115 117 118 120 122 123 125 126 127 128 129 130] TEST: [  2  11  12  21  26  27  34  38  41  42  48  61  62  69  70  77  83  87\n",
            "  96  97 103 107 116 119 121 124]\n",
            "TRAIN: [  0   1   2   3   4   6   7   8   9  10  11  12  15  16  17  18  19  20\n",
            "  21  23  25  26  27  28  31  32  33  34  35  36  37  38  39  40  41  42\n",
            "  43  44  45  48  50  51  52  53  54  56  57  59  60  61  62  64  65  66\n",
            "  67  68  69  70  72  73  74  76  77  78  80  81  83  84  86  87  89  90\n",
            "  91  92  93  95  96  97  98  99 101 102 103 104 105 107 108 109 111 112\n",
            " 113 114 115 116 117 118 119 120 121 122 123 124 125 128 130] TEST: [  5  13  14  22  24  29  30  46  47  49  55  58  63  71  75  79  82  85\n",
            "  88  94 100 106 110 126 127 129]\n",
            "TRAIN: [  0   2   3   4   5   6   7   9  11  12  13  14  15  16  18  19  21  22\n",
            "  24  26  27  28  29  30  32  34  35  36  38  41  42  43  44  45  46  47\n",
            "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  65  66\n",
            "  68  69  70  71  72  74  75  76  77  78  79  80  82  83  85  86  87  88\n",
            "  90  91  93  94  95  96  97 100 102 103 104 105 106 107 108 109 110 111\n",
            " 112 113 114 116 119 120 121 123 124 125 126 127 128 129 130] TEST: [  1   8  10  17  20  23  25  31  33  37  39  40  64  67  73  81  84  89\n",
            "  92  98  99 101 115 117 118 122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8a1I3yU9FS",
        "colab_type": "code",
        "outputId": "43c270c6-6439-4afe-99af-65ade9fb17cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#num_epochs = 50\n",
        "all_acc_histories_RS = []\n",
        "all_loss_histories_RS = []\n",
        "all_val_acc_histories_RS = []\n",
        "all_val_loss_histories_RS = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        " \n",
        "  history_RS = best_model.fit(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=5)\n",
        "  \n",
        "  acc_history_RS = history_RS.history['acc']\n",
        "  all_acc_histories_RS.append(acc_history_RS)\n",
        "\n",
        "  loss_history_RS = history_RS.history['loss']\n",
        "  all_loss_histories_RS.append(loss_history_RS)\n",
        "\n",
        "  acc_val_history_RS = history_RS.history['val_acc']\n",
        "  all_val_acc_histories_RS.append(acc_val_history_RS)\n",
        "\n",
        "  loss_val_history_RS = history_RS.history['val_loss']\n",
        "  all_val_loss_histories_RS.append(loss_val_history_RS)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali è una lista lunga num_epochs,\n",
        "#ogni elemento può essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 104 samples, validate on 27 samples\n",
            "Epoch 1/50\n",
            "104/104 [==============================] - 0s 947us/sample - loss: 0.9630 - acc: 0.5769 - val_loss: 1.3303 - val_acc: 0.4815\n",
            "Epoch 2/50\n",
            "104/104 [==============================] - 0s 405us/sample - loss: 0.9563 - acc: 0.5673 - val_loss: 1.3227 - val_acc: 0.4815\n",
            "Epoch 3/50\n",
            "104/104 [==============================] - 0s 371us/sample - loss: 0.9505 - acc: 0.5577 - val_loss: 1.3162 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9443 - acc: 0.5577 - val_loss: 1.3084 - val_acc: 0.4444\n",
            "Epoch 5/50\n",
            "104/104 [==============================] - 0s 304us/sample - loss: 0.9397 - acc: 0.5577 - val_loss: 1.3004 - val_acc: 0.4444\n",
            "Epoch 6/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9356 - acc: 0.5577 - val_loss: 1.2933 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9313 - acc: 0.5577 - val_loss: 1.2858 - val_acc: 0.4815\n",
            "Epoch 8/50\n",
            "104/104 [==============================] - 0s 362us/sample - loss: 0.9273 - acc: 0.5673 - val_loss: 1.2786 - val_acc: 0.4815\n",
            "Epoch 9/50\n",
            "104/104 [==============================] - 0s 336us/sample - loss: 0.9244 - acc: 0.5769 - val_loss: 1.2738 - val_acc: 0.4815\n",
            "Epoch 10/50\n",
            "104/104 [==============================] - 0s 315us/sample - loss: 0.9215 - acc: 0.5769 - val_loss: 1.2669 - val_acc: 0.4815\n",
            "Epoch 11/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.9182 - acc: 0.5769 - val_loss: 1.2622 - val_acc: 0.4815\n",
            "Epoch 12/50\n",
            "104/104 [==============================] - 0s 361us/sample - loss: 0.9149 - acc: 0.5769 - val_loss: 1.2574 - val_acc: 0.4815\n",
            "Epoch 13/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.9126 - acc: 0.5769 - val_loss: 1.2533 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "104/104 [==============================] - 0s 355us/sample - loss: 0.9101 - acc: 0.5769 - val_loss: 1.2497 - val_acc: 0.4815\n",
            "Epoch 15/50\n",
            "104/104 [==============================] - 0s 326us/sample - loss: 0.9083 - acc: 0.5577 - val_loss: 1.2459 - val_acc: 0.4815\n",
            "Epoch 16/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.9062 - acc: 0.5673 - val_loss: 1.2428 - val_acc: 0.4815\n",
            "Epoch 17/50\n",
            "104/104 [==============================] - 0s 374us/sample - loss: 0.9045 - acc: 0.5673 - val_loss: 1.2398 - val_acc: 0.4815\n",
            "Epoch 18/50\n",
            "104/104 [==============================] - 0s 346us/sample - loss: 0.9032 - acc: 0.5673 - val_loss: 1.2376 - val_acc: 0.4815\n",
            "Epoch 19/50\n",
            "104/104 [==============================] - 0s 333us/sample - loss: 0.9011 - acc: 0.5673 - val_loss: 1.2357 - val_acc: 0.4815\n",
            "Epoch 20/50\n",
            "104/104 [==============================] - 0s 339us/sample - loss: 0.9000 - acc: 0.5673 - val_loss: 1.2335 - val_acc: 0.4815\n",
            "Epoch 21/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8985 - acc: 0.5673 - val_loss: 1.2323 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "104/104 [==============================] - 0s 347us/sample - loss: 0.8969 - acc: 0.5673 - val_loss: 1.2293 - val_acc: 0.4815\n",
            "Epoch 23/50\n",
            "104/104 [==============================] - 0s 365us/sample - loss: 0.8958 - acc: 0.5673 - val_loss: 1.2278 - val_acc: 0.4815\n",
            "Epoch 24/50\n",
            "104/104 [==============================] - 0s 358us/sample - loss: 0.8944 - acc: 0.5673 - val_loss: 1.2257 - val_acc: 0.4815\n",
            "Epoch 25/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.8938 - acc: 0.5673 - val_loss: 1.2235 - val_acc: 0.4815\n",
            "Epoch 26/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.8923 - acc: 0.5673 - val_loss: 1.2204 - val_acc: 0.4815\n",
            "Epoch 27/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8908 - acc: 0.5673 - val_loss: 1.2195 - val_acc: 0.4815\n",
            "Epoch 28/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.8905 - acc: 0.5673 - val_loss: 1.2186 - val_acc: 0.4815\n",
            "Epoch 29/50\n",
            "104/104 [==============================] - 0s 323us/sample - loss: 0.8897 - acc: 0.5673 - val_loss: 1.2158 - val_acc: 0.4815\n",
            "Epoch 30/50\n",
            "104/104 [==============================] - 0s 322us/sample - loss: 0.8888 - acc: 0.5673 - val_loss: 1.2151 - val_acc: 0.4815\n",
            "Epoch 31/50\n",
            "104/104 [==============================] - 0s 320us/sample - loss: 0.8875 - acc: 0.5673 - val_loss: 1.2146 - val_acc: 0.4815\n",
            "Epoch 32/50\n",
            "104/104 [==============================] - 0s 376us/sample - loss: 0.8865 - acc: 0.5673 - val_loss: 1.2138 - val_acc: 0.4815\n",
            "Epoch 33/50\n",
            "104/104 [==============================] - 0s 415us/sample - loss: 0.8850 - acc: 0.5673 - val_loss: 1.2124 - val_acc: 0.4815\n",
            "Epoch 34/50\n",
            "104/104 [==============================] - 0s 350us/sample - loss: 0.8846 - acc: 0.5673 - val_loss: 1.2104 - val_acc: 0.4815\n",
            "Epoch 35/50\n",
            "104/104 [==============================] - 0s 330us/sample - loss: 0.8841 - acc: 0.5673 - val_loss: 1.2092 - val_acc: 0.4815\n",
            "Epoch 36/50\n",
            "104/104 [==============================] - 0s 309us/sample - loss: 0.8838 - acc: 0.5769 - val_loss: 1.2076 - val_acc: 0.4815\n",
            "Epoch 37/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.8825 - acc: 0.5769 - val_loss: 1.2067 - val_acc: 0.4815\n",
            "Epoch 38/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.8822 - acc: 0.5769 - val_loss: 1.2050 - val_acc: 0.4815\n",
            "Epoch 39/50\n",
            "104/104 [==============================] - 0s 370us/sample - loss: 0.8806 - acc: 0.5769 - val_loss: 1.2049 - val_acc: 0.4815\n",
            "Epoch 40/50\n",
            "104/104 [==============================] - 0s 364us/sample - loss: 0.8800 - acc: 0.5769 - val_loss: 1.2040 - val_acc: 0.4815\n",
            "Epoch 41/50\n",
            "104/104 [==============================] - 0s 328us/sample - loss: 0.8799 - acc: 0.5769 - val_loss: 1.2035 - val_acc: 0.4815\n",
            "Epoch 42/50\n",
            "104/104 [==============================] - 0s 302us/sample - loss: 0.8785 - acc: 0.5865 - val_loss: 1.2026 - val_acc: 0.4815\n",
            "Epoch 43/50\n",
            "104/104 [==============================] - 0s 311us/sample - loss: 0.8784 - acc: 0.5769 - val_loss: 1.2027 - val_acc: 0.4815\n",
            "Epoch 44/50\n",
            "104/104 [==============================] - 0s 310us/sample - loss: 0.8774 - acc: 0.5865 - val_loss: 1.2025 - val_acc: 0.4815\n",
            "Epoch 45/50\n",
            "104/104 [==============================] - 0s 305us/sample - loss: 0.8774 - acc: 0.5865 - val_loss: 1.2025 - val_acc: 0.4815\n",
            "Epoch 46/50\n",
            "104/104 [==============================] - 0s 313us/sample - loss: 0.8771 - acc: 0.5769 - val_loss: 1.2017 - val_acc: 0.4815\n",
            "Epoch 47/50\n",
            "104/104 [==============================] - 0s 345us/sample - loss: 0.8758 - acc: 0.5769 - val_loss: 1.2027 - val_acc: 0.4815\n",
            "Epoch 48/50\n",
            "104/104 [==============================] - 0s 284us/sample - loss: 0.8759 - acc: 0.5865 - val_loss: 1.2025 - val_acc: 0.4815\n",
            "Epoch 49/50\n",
            "104/104 [==============================] - 0s 312us/sample - loss: 0.8747 - acc: 0.5865 - val_loss: 1.2024 - val_acc: 0.4815\n",
            "Epoch 50/50\n",
            "104/104 [==============================] - 0s 332us/sample - loss: 0.8743 - acc: 0.5865 - val_loss: 1.2024 - val_acc: 0.4815\n",
            "Train on 105 samples, validate on 26 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9451 - acc: 0.5619 - val_loss: 0.9254 - val_acc: 0.5769\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 447us/sample - loss: 0.9379 - acc: 0.5524 - val_loss: 0.9335 - val_acc: 0.5769\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 349us/sample - loss: 0.9316 - acc: 0.5524 - val_loss: 0.9417 - val_acc: 0.5769\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 299us/sample - loss: 0.9270 - acc: 0.5619 - val_loss: 0.9500 - val_acc: 0.5769\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 311us/sample - loss: 0.9221 - acc: 0.5619 - val_loss: 0.9587 - val_acc: 0.5769\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 272us/sample - loss: 0.9183 - acc: 0.5714 - val_loss: 0.9665 - val_acc: 0.5385\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 321us/sample - loss: 0.9150 - acc: 0.5810 - val_loss: 0.9745 - val_acc: 0.5385\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 358us/sample - loss: 0.9115 - acc: 0.5810 - val_loss: 0.9812 - val_acc: 0.5385\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 318us/sample - loss: 0.9091 - acc: 0.5714 - val_loss: 0.9881 - val_acc: 0.5385\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 416us/sample - loss: 0.9061 - acc: 0.5714 - val_loss: 0.9952 - val_acc: 0.5385\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 320us/sample - loss: 0.9037 - acc: 0.5714 - val_loss: 1.0021 - val_acc: 0.5385\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 317us/sample - loss: 0.9021 - acc: 0.5810 - val_loss: 1.0077 - val_acc: 0.5385\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 0.9002 - acc: 0.5810 - val_loss: 1.0137 - val_acc: 0.5385\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 318us/sample - loss: 0.8978 - acc: 0.5810 - val_loss: 1.0187 - val_acc: 0.5385\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 318us/sample - loss: 0.8961 - acc: 0.5905 - val_loss: 1.0235 - val_acc: 0.5385\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 333us/sample - loss: 0.8950 - acc: 0.6000 - val_loss: 1.0275 - val_acc: 0.5385\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 0.8937 - acc: 0.6000 - val_loss: 1.0318 - val_acc: 0.5385\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.8927 - acc: 0.5905 - val_loss: 1.0367 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 326us/sample - loss: 0.8923 - acc: 0.5905 - val_loss: 1.0391 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 394us/sample - loss: 0.8906 - acc: 0.5905 - val_loss: 1.0424 - val_acc: 0.5000\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 368us/sample - loss: 0.8895 - acc: 0.5905 - val_loss: 1.0460 - val_acc: 0.5000\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.8887 - acc: 0.5810 - val_loss: 1.0487 - val_acc: 0.5000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 389us/sample - loss: 0.8884 - acc: 0.5905 - val_loss: 1.0517 - val_acc: 0.5000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 465us/sample - loss: 0.8880 - acc: 0.5905 - val_loss: 1.0539 - val_acc: 0.5000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 367us/sample - loss: 0.8866 - acc: 0.5905 - val_loss: 1.0566 - val_acc: 0.5000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 345us/sample - loss: 0.8855 - acc: 0.5905 - val_loss: 1.0585 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 307us/sample - loss: 0.8853 - acc: 0.5905 - val_loss: 1.0611 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 309us/sample - loss: 0.8845 - acc: 0.5905 - val_loss: 1.0636 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 303us/sample - loss: 0.8839 - acc: 0.5905 - val_loss: 1.0654 - val_acc: 0.5000\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 0.8836 - acc: 0.5905 - val_loss: 1.0668 - val_acc: 0.5000\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 326us/sample - loss: 0.8826 - acc: 0.5905 - val_loss: 1.0691 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 314us/sample - loss: 0.8828 - acc: 0.5905 - val_loss: 1.0715 - val_acc: 0.5000\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 0.8824 - acc: 0.5905 - val_loss: 1.0733 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.8814 - acc: 0.5905 - val_loss: 1.0754 - val_acc: 0.5000\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 400us/sample - loss: 0.8809 - acc: 0.5905 - val_loss: 1.0769 - val_acc: 0.5000\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 293us/sample - loss: 0.8806 - acc: 0.5905 - val_loss: 1.0790 - val_acc: 0.5000\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 325us/sample - loss: 0.8801 - acc: 0.5905 - val_loss: 1.0806 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 317us/sample - loss: 0.8799 - acc: 0.5905 - val_loss: 1.0819 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 315us/sample - loss: 0.8792 - acc: 0.5905 - val_loss: 1.0833 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 327us/sample - loss: 0.8789 - acc: 0.5905 - val_loss: 1.0847 - val_acc: 0.5000\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 319us/sample - loss: 0.8788 - acc: 0.5905 - val_loss: 1.0861 - val_acc: 0.5000\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 316us/sample - loss: 0.8782 - acc: 0.5905 - val_loss: 1.0881 - val_acc: 0.5000\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 387us/sample - loss: 0.8781 - acc: 0.5905 - val_loss: 1.0897 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 314us/sample - loss: 0.8776 - acc: 0.5905 - val_loss: 1.0908 - val_acc: 0.5000\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 330us/sample - loss: 0.8773 - acc: 0.5905 - val_loss: 1.0924 - val_acc: 0.5000\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 320us/sample - loss: 0.8766 - acc: 0.5905 - val_loss: 1.0934 - val_acc: 0.5000\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 314us/sample - loss: 0.8765 - acc: 0.5905 - val_loss: 1.0947 - val_acc: 0.5000\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 0.8756 - acc: 0.5905 - val_loss: 1.0962 - val_acc: 0.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.8760 - acc: 0.5810 - val_loss: 1.0974 - val_acc: 0.5000\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 331us/sample - loss: 0.8754 - acc: 0.5810 - val_loss: 1.0989 - val_acc: 0.5000\n",
            "Train on 105 samples, validate on 26 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 333us/sample - loss: 0.9700 - acc: 0.5429 - val_loss: 0.7165 - val_acc: 0.6923\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 383us/sample - loss: 0.9671 - acc: 0.5333 - val_loss: 0.7197 - val_acc: 0.6923\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.9642 - acc: 0.5333 - val_loss: 0.7223 - val_acc: 0.6923\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 315us/sample - loss: 0.9621 - acc: 0.5333 - val_loss: 0.7256 - val_acc: 0.6923\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 312us/sample - loss: 0.9597 - acc: 0.5333 - val_loss: 0.7281 - val_acc: 0.6923\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 0.9576 - acc: 0.5429 - val_loss: 0.7309 - val_acc: 0.6923\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 333us/sample - loss: 0.9560 - acc: 0.5429 - val_loss: 0.7337 - val_acc: 0.6923\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 402us/sample - loss: 0.9543 - acc: 0.5429 - val_loss: 0.7362 - val_acc: 0.6923\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.9532 - acc: 0.5429 - val_loss: 0.7385 - val_acc: 0.6923\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 344us/sample - loss: 0.9516 - acc: 0.5429 - val_loss: 0.7409 - val_acc: 0.6923\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 370us/sample - loss: 0.9509 - acc: 0.5429 - val_loss: 0.7434 - val_acc: 0.6923\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.9498 - acc: 0.5429 - val_loss: 0.7459 - val_acc: 0.6923\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 0.9485 - acc: 0.5429 - val_loss: 0.7482 - val_acc: 0.6923\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9476 - acc: 0.5429 - val_loss: 0.7505 - val_acc: 0.6923\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 337us/sample - loss: 0.9469 - acc: 0.5429 - val_loss: 0.7528 - val_acc: 0.6923\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 359us/sample - loss: 0.9458 - acc: 0.5429 - val_loss: 0.7547 - val_acc: 0.6923\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 335us/sample - loss: 0.9449 - acc: 0.5429 - val_loss: 0.7565 - val_acc: 0.6923\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 338us/sample - loss: 0.9444 - acc: 0.5429 - val_loss: 0.7585 - val_acc: 0.6923\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.9437 - acc: 0.5333 - val_loss: 0.7605 - val_acc: 0.6923\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 325us/sample - loss: 0.9431 - acc: 0.5429 - val_loss: 0.7622 - val_acc: 0.6923\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 338us/sample - loss: 0.9423 - acc: 0.5429 - val_loss: 0.7642 - val_acc: 0.6923\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 357us/sample - loss: 0.9419 - acc: 0.5429 - val_loss: 0.7658 - val_acc: 0.6923\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 325us/sample - loss: 0.9408 - acc: 0.5429 - val_loss: 0.7674 - val_acc: 0.6923\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 355us/sample - loss: 0.9404 - acc: 0.5333 - val_loss: 0.7688 - val_acc: 0.6923\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 330us/sample - loss: 0.9403 - acc: 0.5238 - val_loss: 0.7704 - val_acc: 0.6923\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 325us/sample - loss: 0.9396 - acc: 0.5333 - val_loss: 0.7717 - val_acc: 0.6923\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 327us/sample - loss: 0.9396 - acc: 0.5429 - val_loss: 0.7734 - val_acc: 0.6923\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 385us/sample - loss: 0.9391 - acc: 0.5143 - val_loss: 0.7746 - val_acc: 0.6923\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9387 - acc: 0.5238 - val_loss: 0.7761 - val_acc: 0.6923\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.9380 - acc: 0.5238 - val_loss: 0.7772 - val_acc: 0.6923\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 335us/sample - loss: 0.9374 - acc: 0.5143 - val_loss: 0.7782 - val_acc: 0.6923\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 329us/sample - loss: 0.9375 - acc: 0.5143 - val_loss: 0.7794 - val_acc: 0.6923\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 348us/sample - loss: 0.9372 - acc: 0.5238 - val_loss: 0.7804 - val_acc: 0.6923\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 0.9369 - acc: 0.5238 - val_loss: 0.7816 - val_acc: 0.6923\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 352us/sample - loss: 0.9364 - acc: 0.5238 - val_loss: 0.7829 - val_acc: 0.6923\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 399us/sample - loss: 0.9359 - acc: 0.5143 - val_loss: 0.7835 - val_acc: 0.6923\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 365us/sample - loss: 0.9359 - acc: 0.5143 - val_loss: 0.7846 - val_acc: 0.6923\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 339us/sample - loss: 0.9357 - acc: 0.5238 - val_loss: 0.7857 - val_acc: 0.6923\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 356us/sample - loss: 0.9357 - acc: 0.5143 - val_loss: 0.7863 - val_acc: 0.6923\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 331us/sample - loss: 0.9350 - acc: 0.5238 - val_loss: 0.7870 - val_acc: 0.6923\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 356us/sample - loss: 0.9346 - acc: 0.5238 - val_loss: 0.7883 - val_acc: 0.6923\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 0.9340 - acc: 0.5238 - val_loss: 0.7892 - val_acc: 0.6923\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 373us/sample - loss: 0.9342 - acc: 0.5238 - val_loss: 0.7899 - val_acc: 0.6923\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 330us/sample - loss: 0.9340 - acc: 0.5238 - val_loss: 0.7906 - val_acc: 0.6923\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 334us/sample - loss: 0.9336 - acc: 0.5238 - val_loss: 0.7913 - val_acc: 0.6923\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 319us/sample - loss: 0.9335 - acc: 0.5333 - val_loss: 0.7921 - val_acc: 0.6923\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 331us/sample - loss: 0.9329 - acc: 0.5238 - val_loss: 0.7928 - val_acc: 0.6923\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.9325 - acc: 0.5333 - val_loss: 0.7939 - val_acc: 0.6923\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 340us/sample - loss: 0.9325 - acc: 0.5429 - val_loss: 0.7944 - val_acc: 0.6923\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 342us/sample - loss: 0.9321 - acc: 0.5238 - val_loss: 0.7952 - val_acc: 0.6923\n",
            "Train on 105 samples, validate on 26 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 321us/sample - loss: 0.9154 - acc: 0.5429 - val_loss: 0.8624 - val_acc: 0.6154\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 324us/sample - loss: 0.9141 - acc: 0.5619 - val_loss: 0.8640 - val_acc: 0.6154\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 319us/sample - loss: 0.9136 - acc: 0.5619 - val_loss: 0.8657 - val_acc: 0.6154\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 333us/sample - loss: 0.9121 - acc: 0.5524 - val_loss: 0.8672 - val_acc: 0.6154\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 0.9119 - acc: 0.5524 - val_loss: 0.8689 - val_acc: 0.6154\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 381us/sample - loss: 0.9107 - acc: 0.5524 - val_loss: 0.8709 - val_acc: 0.6154\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 344us/sample - loss: 0.9100 - acc: 0.5619 - val_loss: 0.8725 - val_acc: 0.6154\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 306us/sample - loss: 0.9092 - acc: 0.5524 - val_loss: 0.8743 - val_acc: 0.6154\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.9086 - acc: 0.5619 - val_loss: 0.8760 - val_acc: 0.6154\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 316us/sample - loss: 0.9078 - acc: 0.5619 - val_loss: 0.8775 - val_acc: 0.6154\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 324us/sample - loss: 0.9073 - acc: 0.5619 - val_loss: 0.8790 - val_acc: 0.6154\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 320us/sample - loss: 0.9068 - acc: 0.5619 - val_loss: 0.8807 - val_acc: 0.6154\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 328us/sample - loss: 0.9061 - acc: 0.5714 - val_loss: 0.8824 - val_acc: 0.6154\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 328us/sample - loss: 0.9056 - acc: 0.5619 - val_loss: 0.8840 - val_acc: 0.6154\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 0.9051 - acc: 0.5905 - val_loss: 0.8854 - val_acc: 0.6154\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 379us/sample - loss: 0.9047 - acc: 0.5714 - val_loss: 0.8871 - val_acc: 0.6154\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 310us/sample - loss: 0.9041 - acc: 0.5714 - val_loss: 0.8885 - val_acc: 0.6154\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 0.9034 - acc: 0.5810 - val_loss: 0.8900 - val_acc: 0.6154\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 348us/sample - loss: 0.9030 - acc: 0.5905 - val_loss: 0.8914 - val_acc: 0.6154\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 324us/sample - loss: 0.9024 - acc: 0.6000 - val_loss: 0.8928 - val_acc: 0.6154\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 386us/sample - loss: 0.9023 - acc: 0.5905 - val_loss: 0.8946 - val_acc: 0.5769\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 373us/sample - loss: 0.9020 - acc: 0.6000 - val_loss: 0.8961 - val_acc: 0.5769\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 0.9020 - acc: 0.5905 - val_loss: 0.8976 - val_acc: 0.5769\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 0.9015 - acc: 0.6000 - val_loss: 0.8988 - val_acc: 0.5769\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 338us/sample - loss: 0.9006 - acc: 0.6000 - val_loss: 0.8999 - val_acc: 0.5769\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 406us/sample - loss: 0.9001 - acc: 0.6095 - val_loss: 0.9012 - val_acc: 0.5769\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 417us/sample - loss: 0.9000 - acc: 0.6000 - val_loss: 0.9026 - val_acc: 0.5769\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 386us/sample - loss: 0.8996 - acc: 0.6000 - val_loss: 0.9043 - val_acc: 0.5769\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 340us/sample - loss: 0.8996 - acc: 0.5905 - val_loss: 0.9055 - val_acc: 0.5769\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 357us/sample - loss: 0.8992 - acc: 0.6095 - val_loss: 0.9070 - val_acc: 0.5769\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 0.8989 - acc: 0.6095 - val_loss: 0.9079 - val_acc: 0.5769\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 0.8987 - acc: 0.5905 - val_loss: 0.9092 - val_acc: 0.5769\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 370us/sample - loss: 0.8983 - acc: 0.6000 - val_loss: 0.9104 - val_acc: 0.5769\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 0.8980 - acc: 0.5905 - val_loss: 0.9122 - val_acc: 0.5769\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 409us/sample - loss: 0.8978 - acc: 0.5905 - val_loss: 0.9134 - val_acc: 0.5769\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 334us/sample - loss: 0.8976 - acc: 0.6000 - val_loss: 0.9142 - val_acc: 0.5769\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 337us/sample - loss: 0.8977 - acc: 0.5810 - val_loss: 0.9156 - val_acc: 0.5769\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 370us/sample - loss: 0.8968 - acc: 0.6000 - val_loss: 0.9162 - val_acc: 0.5769\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 362us/sample - loss: 0.8966 - acc: 0.5810 - val_loss: 0.9171 - val_acc: 0.5769\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 0.8968 - acc: 0.6000 - val_loss: 0.9185 - val_acc: 0.5769\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 334us/sample - loss: 0.8965 - acc: 0.5905 - val_loss: 0.9197 - val_acc: 0.5769\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 326us/sample - loss: 0.8960 - acc: 0.6000 - val_loss: 0.9209 - val_acc: 0.5769\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 335us/sample - loss: 0.8958 - acc: 0.6000 - val_loss: 0.9220 - val_acc: 0.5769\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 425us/sample - loss: 0.8957 - acc: 0.6000 - val_loss: 0.9235 - val_acc: 0.5769\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 387us/sample - loss: 0.8955 - acc: 0.6000 - val_loss: 0.9243 - val_acc: 0.5769\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 381us/sample - loss: 0.8955 - acc: 0.6000 - val_loss: 0.9252 - val_acc: 0.5769\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 369us/sample - loss: 0.8955 - acc: 0.6000 - val_loss: 0.9263 - val_acc: 0.5769\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 337us/sample - loss: 0.8949 - acc: 0.6000 - val_loss: 0.9275 - val_acc: 0.5769\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 362us/sample - loss: 0.8954 - acc: 0.6000 - val_loss: 0.9277 - val_acc: 0.5769\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 389us/sample - loss: 0.8951 - acc: 0.6000 - val_loss: 0.9288 - val_acc: 0.5769\n",
            "Train on 105 samples, validate on 26 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 383us/sample - loss: 0.9039 - acc: 0.5905 - val_loss: 0.8925 - val_acc: 0.5769\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.9020 - acc: 0.6000 - val_loss: 0.8948 - val_acc: 0.5769\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 0.9008 - acc: 0.6000 - val_loss: 0.8968 - val_acc: 0.5769\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 339us/sample - loss: 0.8995 - acc: 0.6000 - val_loss: 0.8989 - val_acc: 0.5769\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 396us/sample - loss: 0.8985 - acc: 0.6000 - val_loss: 0.9006 - val_acc: 0.5769\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 419us/sample - loss: 0.8971 - acc: 0.5905 - val_loss: 0.9021 - val_acc: 0.5769\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 357us/sample - loss: 0.8967 - acc: 0.5905 - val_loss: 0.9039 - val_acc: 0.5769\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 332us/sample - loss: 0.8960 - acc: 0.5905 - val_loss: 0.9057 - val_acc: 0.5769\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.8951 - acc: 0.5905 - val_loss: 0.9067 - val_acc: 0.5769\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 322us/sample - loss: 0.8947 - acc: 0.6000 - val_loss: 0.9085 - val_acc: 0.5769\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 378us/sample - loss: 0.8940 - acc: 0.5905 - val_loss: 0.9101 - val_acc: 0.5769\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 0.8933 - acc: 0.5905 - val_loss: 0.9114 - val_acc: 0.5769\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 404us/sample - loss: 0.8926 - acc: 0.5905 - val_loss: 0.9130 - val_acc: 0.5769\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 369us/sample - loss: 0.8922 - acc: 0.5905 - val_loss: 0.9146 - val_acc: 0.5769\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.8913 - acc: 0.5905 - val_loss: 0.9162 - val_acc: 0.5769\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 338us/sample - loss: 0.8909 - acc: 0.5905 - val_loss: 0.9176 - val_acc: 0.5769\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.8907 - acc: 0.5905 - val_loss: 0.9191 - val_acc: 0.5769\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 383us/sample - loss: 0.8901 - acc: 0.5905 - val_loss: 0.9205 - val_acc: 0.5769\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 0.8899 - acc: 0.5905 - val_loss: 0.9219 - val_acc: 0.5769\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 328us/sample - loss: 0.8900 - acc: 0.5905 - val_loss: 0.9235 - val_acc: 0.5769\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 0.8888 - acc: 0.5905 - val_loss: 0.9245 - val_acc: 0.5769\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 342us/sample - loss: 0.8886 - acc: 0.5905 - val_loss: 0.9260 - val_acc: 0.5769\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 342us/sample - loss: 0.8878 - acc: 0.5905 - val_loss: 0.9270 - val_acc: 0.5769\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 306us/sample - loss: 0.8879 - acc: 0.5905 - val_loss: 0.9285 - val_acc: 0.5385\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 339us/sample - loss: 0.8878 - acc: 0.5905 - val_loss: 0.9299 - val_acc: 0.5385\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 379us/sample - loss: 0.8874 - acc: 0.5905 - val_loss: 0.9307 - val_acc: 0.5385\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 0.8867 - acc: 0.5905 - val_loss: 0.9322 - val_acc: 0.5385\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 0.8868 - acc: 0.5905 - val_loss: 0.9327 - val_acc: 0.5385\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 330us/sample - loss: 0.8864 - acc: 0.5905 - val_loss: 0.9338 - val_acc: 0.5385\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 344us/sample - loss: 0.8859 - acc: 0.5905 - val_loss: 0.9353 - val_acc: 0.5385\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 349us/sample - loss: 0.8851 - acc: 0.5905 - val_loss: 0.9361 - val_acc: 0.5385\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 311us/sample - loss: 0.8852 - acc: 0.5905 - val_loss: 0.9370 - val_acc: 0.5385\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 363us/sample - loss: 0.8850 - acc: 0.5905 - val_loss: 0.9384 - val_acc: 0.5385\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 375us/sample - loss: 0.8847 - acc: 0.5905 - val_loss: 0.9392 - val_acc: 0.5385\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 0.8845 - acc: 0.5905 - val_loss: 0.9403 - val_acc: 0.5385\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 425us/sample - loss: 0.8841 - acc: 0.6000 - val_loss: 0.9414 - val_acc: 0.5385\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 389us/sample - loss: 0.8840 - acc: 0.5905 - val_loss: 0.9427 - val_acc: 0.5385\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 0.8838 - acc: 0.6000 - val_loss: 0.9437 - val_acc: 0.5385\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.8835 - acc: 0.6000 - val_loss: 0.9444 - val_acc: 0.5385\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 388us/sample - loss: 0.8834 - acc: 0.6000 - val_loss: 0.9454 - val_acc: 0.5385\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 374us/sample - loss: 0.8832 - acc: 0.6000 - val_loss: 0.9461 - val_acc: 0.5385\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 388us/sample - loss: 0.8826 - acc: 0.6000 - val_loss: 0.9473 - val_acc: 0.5385\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 356us/sample - loss: 0.8830 - acc: 0.6000 - val_loss: 0.9481 - val_acc: 0.5385\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 372us/sample - loss: 0.8821 - acc: 0.6000 - val_loss: 0.9490 - val_acc: 0.5385\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 344us/sample - loss: 0.8819 - acc: 0.6000 - val_loss: 0.9499 - val_acc: 0.5385\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 0.8820 - acc: 0.6000 - val_loss: 0.9509 - val_acc: 0.5385\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 0.8819 - acc: 0.6000 - val_loss: 0.9516 - val_acc: 0.5385\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 339us/sample - loss: 0.8813 - acc: 0.6000 - val_loss: 0.9527 - val_acc: 0.5000\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 356us/sample - loss: 0.8811 - acc: 0.6000 - val_loss: 0.9536 - val_acc: 0.5385\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 399us/sample - loss: 0.8809 - acc: 0.6000 - val_loss: 0.9543 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkjHWfuvSRXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history_RS.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5o_DnOySStG",
        "colab_type": "code",
        "outputId": "beae134a-8d52-4964-e2de-613c22a8e498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UhSxIaHtuO",
        "colab_type": "text"
      },
      "source": [
        "##Plotting training and validation loss RandomSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zsienD5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJizyjnaIPhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, num_epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z_pSVTWwtybS",
        "colab": {}
      },
      "source": [
        "average_acc_history_RS = [np.mean([x[i] for x in all_acc_histories_RS]) for i in range(num_epochs)]\n",
        "average_loss_history_RS = [np.mean([x[i] for x in all_loss_histories_RS]) for i in range(num_epochs)]\n",
        "average_val_acc_history_RS = [np.mean([x[i] for x in all_val_acc_histories_RS]) for i in range(num_epochs)]\n",
        "average_val_loss_history_RS = [np.mean([x[i] for x in all_val_loss_histories_RS]) for i in range(num_epochs)]\n",
        "#media per epoca degli score ottenuti per tutte le k-fold\n",
        "#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\n",
        "#e si fa questo per tutte le epoche"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEHEYLgIQUQ",
        "colab_type": "code",
        "outputId": "5fd86beb-6fd7-4e6d-81a4-977e8ac493aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs, average_loss_history_RS, 'b', label='training loss')\n",
        "plt.plot(epochs, average_val_loss_history_RS, 'r', label='validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7652e2a240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc4wMjfI97j",
        "colab_type": "text"
      },
      "source": [
        "##Plotting train and validation accuracy RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi7VzbFIbtJ",
        "colab_type": "code",
        "outputId": "3afa88ac-c944-44d9-d14c-b3e9eaf70e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs, average_acc_history_RS, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, average_val_acc_history_RS, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend() "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7652954eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIaSeCIiIhGEjgiIqKRBI6IiGjkX8e83Q8wLANfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}