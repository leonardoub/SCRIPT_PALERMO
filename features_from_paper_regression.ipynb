{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "features_from_paper_regression.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxTDgSuD+KzWxs7uxV48WE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/features_from_paper_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knZxcJw4cD9T",
        "colab_type": "text"
      },
      "source": [
        "The resulting radiomic signature consisted of (I) ‘Statistics\n",
        "Energy’ (Supplementary Methods Feature 1) describing the\n",
        "overall density of the tumour volume, (II) ‘Shape Compactness’\n",
        "(Feature 16) quantifying how compact the tumour shape is, (III)\n",
        "‘Grey Level Nonuniformity’ (Feature 48) a measure for\n",
        "intratumour heterogeneity and (IV) wavelet ‘Grey Level Nonuniformity HLH’ (Feature Group 4), also describing\n",
        "intratumour heterogeneity after decomposing the image in mid-\n",
        "frequencies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjK8mJsY3Ddt",
        "colab_type": "text"
      },
      "source": [
        " Energy c'è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mO95KDl129G",
        "colab_type": "text"
      },
      "source": [
        "Compactness non c'è, anche se c'è tra le features di pyradiomics. Tuttavia sulla documentazione di Pyradiomics c'è scritto che Compactness è correlata a Sphericity, potremmo prendere quest'ultima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOqAi8P4djlV",
        "colab_type": "text"
      },
      "source": [
        "From Gray-Level Run-Length matrix based features.\n",
        "GrayLevelNonUniformity c'è, ma ce ne sono più di uno probabilmente vengono fuori da gruppi di features diversi, come faccio a sapere quale prendere?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNbxKNU42186",
        "colab_type": "text"
      },
      "source": [
        "Grey Level Nonuniformity HLH non c'è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VawOmy3bdbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DME-inQ4ke_",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hq45TSf3WcR",
        "colab_type": "code",
        "outputId": "dfb9c955-72f2-439c-9d0f-19f05cfd8294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I5MNxeW3j2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLxDyFPo3sU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXU_B2k03uYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1YCrOMP3_4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWj1mwjV4Mzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKdS4Low4PHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_targets = df_train.Surv_time_months"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6EsAdEt4RNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_targets = df_test.Surv_time_months"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtDlYlFL-Z-6",
        "colab_type": "text"
      },
      "source": [
        "#Selezionare le features contenute nel paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjD96oog8AHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_importanti = ['Energy', 'Sphericity', 'GrayLevelNonUniformity']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZqLveBU-oo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_selected = df_train[features_importanti]   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR9eba7cC464",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4155c213-a5ec-4ee7-e63a-5431257f554b"
      },
      "source": [
        "train_data_selected"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Energy</th>\n",
              "      <th>Sphericity</th>\n",
              "      <th>GrayLevelNonUniformity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.412564e+08</td>\n",
              "      <td>0.649258</td>\n",
              "      <td>5312.127441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.167783e+08</td>\n",
              "      <td>0.572236</td>\n",
              "      <td>351.846858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.515276e+08</td>\n",
              "      <td>0.675497</td>\n",
              "      <td>1023.136953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.814647e+08</td>\n",
              "      <td>0.733411</td>\n",
              "      <td>511.504912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.254831e+09</td>\n",
              "      <td>0.617296</td>\n",
              "      <td>3232.154350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>2.770444e+08</td>\n",
              "      <td>0.545823</td>\n",
              "      <td>4218.711339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>1.562369e+09</td>\n",
              "      <td>0.479193</td>\n",
              "      <td>3179.829927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>1.527687e+09</td>\n",
              "      <td>0.589729</td>\n",
              "      <td>10782.227668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>2.795981e+08</td>\n",
              "      <td>0.604034</td>\n",
              "      <td>66.087986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>2.992214e+08</td>\n",
              "      <td>0.574105</td>\n",
              "      <td>535.381003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>131 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Energy  Sphericity  GrayLevelNonUniformity\n",
              "0    1.412564e+08    0.649258             5312.127441\n",
              "1    2.167783e+08    0.572236              351.846858\n",
              "2    3.515276e+08    0.675497             1023.136953\n",
              "3    5.814647e+08    0.733411              511.504912\n",
              "4    2.254831e+09    0.617296             3232.154350\n",
              "..            ...         ...                     ...\n",
              "126  2.770444e+08    0.545823             4218.711339\n",
              "127  1.562369e+09    0.479193             3179.829927\n",
              "128  1.527687e+09    0.589729            10782.227668\n",
              "129  2.795981e+08    0.604034               66.087986\n",
              "130  2.992214e+08    0.574105              535.381003\n",
              "\n",
              "[131 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data_selected.mean(axis=0)\n",
        "train_data_stand = train_data_selected - mean\n",
        "std = train_data_selected.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbTkIoxLDYPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a9715709-7cdc-4d39-cacc-261230b1369f"
      },
      "source": [
        "train_data_stand"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Energy</th>\n",
              "      <th>Sphericity</th>\n",
              "      <th>GrayLevelNonUniformity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.565212</td>\n",
              "      <td>0.561642</td>\n",
              "      <td>0.334305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.525687</td>\n",
              "      <td>-0.209052</td>\n",
              "      <td>-0.715397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.455166</td>\n",
              "      <td>0.824200</td>\n",
              "      <td>-0.573338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.334829</td>\n",
              "      <td>1.403699</td>\n",
              "      <td>-0.681610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.540926</td>\n",
              "      <td>0.241827</td>\n",
              "      <td>-0.105862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>-0.494147</td>\n",
              "      <td>-0.473343</td>\n",
              "      <td>0.102915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>0.178526</td>\n",
              "      <td>-1.140051</td>\n",
              "      <td>-0.116935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.160376</td>\n",
              "      <td>-0.034011</td>\n",
              "      <td>1.491896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>-0.492811</td>\n",
              "      <td>0.109129</td>\n",
              "      <td>-0.775870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>-0.482541</td>\n",
              "      <td>-0.190348</td>\n",
              "      <td>-0.676557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>131 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Energy  Sphericity  GrayLevelNonUniformity\n",
              "0   -0.565212    0.561642                0.334305\n",
              "1   -0.525687   -0.209052               -0.715397\n",
              "2   -0.455166    0.824200               -0.573338\n",
              "3   -0.334829    1.403699               -0.681610\n",
              "4    0.540926    0.241827               -0.105862\n",
              "..        ...         ...                     ...\n",
              "126 -0.494147   -0.473343                0.102915\n",
              "127  0.178526   -1.140051               -0.116935\n",
              "128  0.160376   -0.034011                1.491896\n",
              "129 -0.492811    0.109129               -0.775870\n",
              "130 -0.482541   -0.190348               -0.676557\n",
              "\n",
              "[131 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSKvSu4s5ip",
        "colab_type": "text"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tX_y6KKs3pM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "14eaa0b9-2d18-4c2b-b9bc-4ff012a46038"
      },
      "source": [
        "from keras import models"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TwsrdWbKOif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(2, activation='relu', input_shape=(3,)))\n",
        "  model.add(layers.Dense(1))\n",
        "  #rmsp=RMSprop(lr=0.05)\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA7Ye1SZDUXB",
        "colab_type": "text"
      },
      "source": [
        "Note that you compile the network with the mse loss function—mean squared error,\n",
        "the square of the difference between the predictions and the targets. This is a widely\n",
        "used loss function for regression problems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXmq-i3sDXQA",
        "colab_type": "text"
      },
      "source": [
        "You’re also monitoring a new metric during training: mean absolute error (MAE). It’s\n",
        "the absolute value of the difference between the predictions and the targets. For\n",
        "instance, an MAE of 0.5 on this problem would mean your predictions are off by $500\n",
        "on average."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL7aYuEc_I-q",
        "colab_type": "text"
      },
      "source": [
        "#K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYsyGVcJ_Ir8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXE1vJIW_bbm",
        "colab_type": "code",
        "outputId": "ad7cd796-e7b4-49d8-8620-f1651fa808e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kf = KFold(n_splits=3, shuffle=True, random_state=1)\n",
        "kf.get_n_splits(train_data_stand, train_targets)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6nlpLXDXmPK",
        "colab_type": "code",
        "outputId": "e490487b-96b2-4281-877c-fdf2f01cd092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data_stand)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tBB6DNfHH0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_np = train_data_stand.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQMu83JBMJ-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_targets_np = train_targets.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "e6d21b18-0328-4228-bb0e-2bc673935b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "for train_index, test_index in kf.split(train_data_stand_np, train_targets_np):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  0   1   3   6   7   8   9  10  11  13  14  15  16  18  19  20  21  22\n",
            "  23  24  25  26  27  28  29  30  32  34  36  37  38  39  41  43  47  49\n",
            "  50  52  57  60  61  63  64  65  67  68  69  70  71  72  74  76  77  78\n",
            "  79  81  83  84  86  87  88  90  92  94  95  96  99 100 101 103 105 106\n",
            " 107 108 109 112 113 115 117 119 120 122 123 125 127 129 130] TEST: [  2   4   5  12  17  31  33  35  40  42  44  45  46  48  51  53  54  55\n",
            "  56  58  59  62  66  73  75  80  82  85  89  91  93  97  98 102 104 110\n",
            " 111 114 116 118 121 124 126 128]\n",
            "TRAIN: [  0   1   2   4   5   6   7   8   9  11  12  13  14  16  17  18  20  22\n",
            "  25  28  29  31  33  35  37  40  42  44  45  46  48  50  51  53  54  55\n",
            "  56  57  58  59  60  61  62  63  64  66  68  71  72  73  75  76  79  80\n",
            "  81  82  84  85  86  87  88  89  91  93  94  96  97  98 101 102 104 105\n",
            " 106 107 109 110 111 114 116 117 118 119 121 124 125 126 128] TEST: [  3  10  15  19  21  23  24  26  27  30  32  34  36  38  39  41  43  47\n",
            "  49  52  65  67  69  70  74  77  78  83  90  92  95  99 100 103 108 112\n",
            " 113 115 120 122 123 127 129 130]\n",
            "TRAIN: [  2   3   4   5  10  12  15  17  19  21  23  24  26  27  30  31  32  33\n",
            "  34  35  36  38  39  40  41  42  43  44  45  46  47  48  49  51  52  53\n",
            "  54  55  56  58  59  62  65  66  67  69  70  73  74  75  77  78  80  82\n",
            "  83  85  89  90  91  92  93  95  97  98  99 100 102 103 104 108 110 111\n",
            " 112 113 114 115 116 118 120 121 122 123 124 126 127 128 129 130] TEST: [  0   1   6   7   8   9  11  13  14  16  18  20  22  25  28  29  37  50\n",
            "  57  60  61  63  64  68  71  72  76  79  81  84  86  87  88  94  96 101\n",
            " 105 106 107 109 117 119 125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf2aaDwz75lc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNHd1cgxCVmE",
        "colab_type": "code",
        "outputId": "db00d2ca-c327-4f94-c6b4-bff57eab95aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "num_epochs = 100\n",
        "all_mae_histories = []\n",
        "all_mae_val_histories = []\n",
        "all_loss_histories = []\n",
        "all_loss_val_histories = []\n",
        "\n",
        "for train_index, val_index in kf.split(train_data_stand_np, train_targets_np):\n",
        "  partial_train_data = np.array([train_data_stand_np[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_data_stand_np[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_np[i] for i in val_index])\n",
        "  val_targets = np.array([train_targets_np[i] for i in val_index])\n",
        "\n",
        "  model = build_model()\n",
        "  history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), \n",
        "                      epochs= num_epochs, batch_size=1)\n",
        "  \n",
        "  mae_history = history.history['mean_absolute_error']\n",
        "  all_mae_histories.append(mae_history)\n",
        "\n",
        "  mae_val_history = history.history['val_mean_absolute_error']\n",
        "  all_mae_val_histories.append(mae_val_history)\n",
        "\n",
        "  loss_history = history.history['loss']\n",
        "  all_loss_histories.append(loss_history)\n",
        "\n",
        "  loss_val_history = history.history['val_loss']\n",
        "  all_loss_val_histories.append(loss_val_history)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-46accb5b3979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), \n\u001b[0;32m---> 16\u001b[0;31m                       epochs= num_epochs, batch_size=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mmae_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_2 to have shape (1,) but got array with shape (3,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK31MqxIL_tl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d32e0dcf-4a0a-4af7-e835-cd339f362b09"
      },
      "source": [
        "type(train_targets)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94CEJ7oXFbBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "9e81c7bc-5772-4854-d532-a50e58a21d2d"
      },
      "source": [
        "history_dict = history.history"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-197cf7b44c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHuCip1WFiSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyn-f0ZACLwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_mae_val_history = [np.mean([x[i] for x in all_mae_val_histories]) for i in range(num_epochs)]\n",
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
        "average_loss_val_history = [np.mean([x[i] for x in all_loss_val_histories]) for i in range(num_epochs)]\n",
        "average_loss_history = [np.mean([x[i] for x in all_loss_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JFcHa2LGPXj",
        "colab_type": "text"
      },
      "source": [
        "#Plotting training and validation mae"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13s5AsNnFQ7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, len(average_mae_val_history) + 1), average_mae_val_history, 'r', label='Validation mae')\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history, 'b', label='Training mae')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "723BbzxdJtj-",
        "colab_type": "text"
      },
      "source": [
        "#Plotting training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tezhzHbMGguv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, len(average_loss_val_history) + 1), average_loss_val_history, 'r', label='Validation loss')\n",
        "plt.plot(range(1, len(average_loss_history) + 1), average_loss_history, 'b', label='Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation LOSS')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}