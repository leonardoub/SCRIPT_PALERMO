{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Network_classification_histology.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/Network_classification_histology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck9uZtF_gzU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "df86e883-2bc4-4201-847c-1ec3a5a0c92b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-87QSVhqhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSbeCedhuxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbcwLGg3iNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQdR4izXiT0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5wIylYmsQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = df_test.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data_stand = train_data - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVOoNOvm0Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_stand = test_data - mean\n",
        "test_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00VohsAyokpq",
        "colab_type": "text"
      },
      "source": [
        "##Vettorizzare i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvS_9ISpxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={'adenocarcinoma':0, 'large cell':1, 'squamous cell carcinoma':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPW9U0XrWY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_dec = [word_index[label] for label in train_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4SBiKFQsKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels_dec = [word_index[label] for label in test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMbTYR7okJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Frv4FDNn6Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels_dec)\n",
        "one_hot_test_labels = to_categorical(test_labels_dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn0tkOGc3LKN",
        "colab_type": "text"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS76u6iu3Seg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjC4zqJ3bui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.9, svd_solver='full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLUCf9qX4p_e",
        "colab_type": "code",
        "outputId": "74b8648b-a150-4591-ce17-48a31d274ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pca.fit(train_data_stand)"
      ],
      "execution_count": 593,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 593
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyaKgNZ44o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_pca = pca.transform(train_data_stand)\n",
        "test_data_stand_pca = pca.transform(test_data_stand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9C4nl05b_g",
        "colab_type": "code",
        "outputId": "00366b1a-946f-45dc-ae9a-e09343c8f51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_data_stand_pca.shape"
      ],
      "execution_count": 595,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 595
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSKvSu4s5ip",
        "colab_type": "text"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTbHiq0D-4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAzbu7P1VylY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqbUCK5wOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(layers.Dense(5, activation='relu', input_shape=(9,)))\n",
        "\n",
        "  #model.add(layers.Dropout(rate=0.5))\n",
        "\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "  \n",
        "  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIxDu50pBeiz",
        "colab_type": "text"
      },
      "source": [
        "#Stratified k-fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyLcvedUBpxA",
        "colab_type": "text"
      },
      "source": [
        "This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1apcZ19gFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBDM-PtBx5V",
        "colab_type": "code",
        "outputId": "1f4a3358-444a-4a86-a8ab-5b6e3e234aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "skf.get_n_splits(train_data_stand_pca, train_labels_dec)"
      ],
      "execution_count": 602,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 602
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "84a57b21-d9ad-437c-b4f0-1489ed86c3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "for train_index, test_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 603,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  0   1   4   5   8   9  11  12  14  15  16  17  19  20  22  23  24  25\n",
            "  27  29  30  33  34  36  37  38  39  40  41  42  44  45  46  48  51  52\n",
            "  53  56  57  58  59  60  62  63  65  66  67  69  72  76  77  78  79  80\n",
            "  81  83  84  85  87  88  89  90  92  96  97  98 100 101 102 103 104 105\n",
            " 107 109 110 111 113 115 117 120 121 122 124 125 127 128] TEST: [  2   3   6   7  10  13  18  21  26  28  31  32  35  43  47  49  50  54\n",
            "  55  61  64  68  70  71  73  74  75  82  86  91  93  94  95  99 106 108\n",
            " 112 114 116 118 119 123 126 129 130]\n",
            "TRAIN: [  2   3   5   6   7   8   9  10  11  12  13  18  20  21  25  26  27  28\n",
            "  29  30  31  32  34  35  36  38  39  43  44  45  46  47  48  49  50  53\n",
            "  54  55  57  58  61  63  64  65  66  68  70  71  73  74  75  76  78  82\n",
            "  84  85  86  87  90  91  92  93  94  95  96  99 100 101 102 105 106 108\n",
            " 109 111 112 114 115 116 118 119 122 123 124 125 126 127 129 130] TEST: [  0   1   4  14  15  16  17  19  22  23  24  33  37  40  41  42  51  52\n",
            "  56  59  60  62  67  69  72  77  79  80  81  83  88  89  97  98 103 104\n",
            " 107 110 113 117 120 121 128]\n",
            "TRAIN: [  0   1   2   3   4   6   7  10  13  14  15  16  17  18  19  21  22  23\n",
            "  24  26  28  31  32  33  35  37  40  41  42  43  47  49  50  51  52  54\n",
            "  55  56  59  60  61  62  64  67  68  69  70  71  72  73  74  75  77  79\n",
            "  80  81  82  83  86  88  89  91  93  94  95  97  98  99 103 104 106 107\n",
            " 108 110 112 113 114 116 117 118 119 120 121 123 126 128 129 130] TEST: [  5   8   9  11  12  20  25  27  29  30  34  36  38  39  44  45  46  48\n",
            "  53  57  58  63  65  66  76  78  84  85  87  90  92  96 100 101 102 105\n",
            " 109 111 115 122 124 125 127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgdGK-8FK-U_",
        "colab_type": "code",
        "outputId": "fb4ca0bf-8c0d-4fc5-8d9a-0a9cccea613d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels_dec[125]"
      ],
      "execution_count": 604,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 604
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJg0XD4Shhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Sq8r9GEPx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "#  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "#  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "\n",
        "#  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "#  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "#  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "#  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        "#  model = build_model()\n",
        "#  model.fit(partial_train_data, one_hot_partial_train_targets, epochs = num_epochs, batch_size=1)\n",
        "\n",
        "#  val_loss, val_accuracy = model.evaluate(val_data, one_hot_val_targets)\n",
        "#  all_scores.append(val_accuracy)\n",
        "#I parametri per la valutazione vengono calcolati una volta per ogni k-fold, per ogni set di validazione, quindi k volte"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X5B3lasRcsR",
        "colab_type": "text"
      },
      "source": [
        "C'è un problema: keras.utils.to_categorical produces a one-hot encoded class vector, i.e. the multilabel-indicator mentioned in the error message. StratifiedKFold is not designed to work with such input; i.e. your y must be a 1-D array of your class labels.\n",
        "Essentially, what you have to do is simply to invert the order of the operations: split first (using your intial y_train), and convert to_categorical afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Sl23XX-uUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8a1I3yU9FS",
        "colab_type": "code",
        "outputId": "7c7f52f4-90a9-4d3f-85d9-479f206021b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 50\n",
        "all_acc_histories = []\n",
        "all_loss_histories = []\n",
        "all_val_acc_histories = []\n",
        "all_val_loss_histories = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        " \n",
        "  model = build_model()\n",
        "  history = model.fit(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=10)\n",
        "  \n",
        "  acc_history = history.history['acc']\n",
        "  all_acc_histories.append(acc_history)\n",
        "\n",
        "  loss_history = history.history['loss']\n",
        "  all_loss_histories.append(loss_history)\n",
        "\n",
        "  acc_val_history = history.history['val_acc']\n",
        "  all_val_acc_histories.append(acc_val_history)\n",
        "\n",
        "  loss_val_history = history.history['val_loss']\n",
        "  all_val_loss_histories.append(loss_val_history)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali è una lista lunga num_epochs,\n",
        "#ogni elemento può essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 608,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 1.4601 - acc: 0.2791 - val_loss: 1.1103 - val_acc: 0.4222\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 231us/step - loss: 1.2277 - acc: 0.3721 - val_loss: 1.0678 - val_acc: 0.4000\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 236us/step - loss: 1.1429 - acc: 0.4419 - val_loss: 1.0475 - val_acc: 0.4444\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 231us/step - loss: 1.0924 - acc: 0.4419 - val_loss: 1.0238 - val_acc: 0.4667\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 221us/step - loss: 1.0570 - acc: 0.4651 - val_loss: 1.0130 - val_acc: 0.4667\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 228us/step - loss: 1.0364 - acc: 0.5116 - val_loss: 1.0118 - val_acc: 0.4444\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 258us/step - loss: 1.0098 - acc: 0.5233 - val_loss: 1.0047 - val_acc: 0.4667\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 251us/step - loss: 0.9900 - acc: 0.5233 - val_loss: 1.0072 - val_acc: 0.4667\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 232us/step - loss: 0.9751 - acc: 0.5233 - val_loss: 1.0152 - val_acc: 0.4667\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 227us/step - loss: 0.9667 - acc: 0.5349 - val_loss: 1.0144 - val_acc: 0.4667\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 245us/step - loss: 0.9587 - acc: 0.5233 - val_loss: 1.0206 - val_acc: 0.4667\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 265us/step - loss: 0.9527 - acc: 0.5233 - val_loss: 1.0250 - val_acc: 0.4667\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 244us/step - loss: 0.9433 - acc: 0.5349 - val_loss: 1.0283 - val_acc: 0.4667\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 243us/step - loss: 0.9410 - acc: 0.5233 - val_loss: 1.0355 - val_acc: 0.4667\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 258us/step - loss: 0.9359 - acc: 0.5581 - val_loss: 1.0368 - val_acc: 0.4667\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 221us/step - loss: 0.9280 - acc: 0.5349 - val_loss: 1.0377 - val_acc: 0.4667\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 236us/step - loss: 0.9213 - acc: 0.5581 - val_loss: 1.0358 - val_acc: 0.4667\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 254us/step - loss: 0.9163 - acc: 0.5698 - val_loss: 1.0496 - val_acc: 0.5111\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 265us/step - loss: 0.9135 - acc: 0.5698 - val_loss: 1.0525 - val_acc: 0.5111\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 233us/step - loss: 0.9088 - acc: 0.5698 - val_loss: 1.0482 - val_acc: 0.5333\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 255us/step - loss: 0.9024 - acc: 0.5930 - val_loss: 1.0467 - val_acc: 0.5111\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 243us/step - loss: 0.8947 - acc: 0.5698 - val_loss: 1.0404 - val_acc: 0.5111\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 248us/step - loss: 0.8872 - acc: 0.5930 - val_loss: 1.0468 - val_acc: 0.5333\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 275us/step - loss: 0.8840 - acc: 0.5814 - val_loss: 1.0517 - val_acc: 0.5333\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 301us/step - loss: 0.8781 - acc: 0.6047 - val_loss: 1.0439 - val_acc: 0.5111\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 294us/step - loss: 0.8711 - acc: 0.5930 - val_loss: 1.0500 - val_acc: 0.5333\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 246us/step - loss: 0.8630 - acc: 0.5930 - val_loss: 1.0539 - val_acc: 0.5333\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 257us/step - loss: 0.8558 - acc: 0.6047 - val_loss: 1.0614 - val_acc: 0.5333\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 253us/step - loss: 0.8522 - acc: 0.5930 - val_loss: 1.0728 - val_acc: 0.5333\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 264us/step - loss: 0.8514 - acc: 0.6163 - val_loss: 1.0680 - val_acc: 0.5333\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 255us/step - loss: 0.8403 - acc: 0.6047 - val_loss: 1.0772 - val_acc: 0.5111\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 248us/step - loss: 0.8371 - acc: 0.6163 - val_loss: 1.0727 - val_acc: 0.5111\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 241us/step - loss: 0.8336 - acc: 0.6279 - val_loss: 1.0748 - val_acc: 0.5111\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 232us/step - loss: 0.8301 - acc: 0.6163 - val_loss: 1.0796 - val_acc: 0.5111\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 242us/step - loss: 0.8315 - acc: 0.6279 - val_loss: 1.0704 - val_acc: 0.5333\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 248us/step - loss: 0.8222 - acc: 0.6163 - val_loss: 1.0715 - val_acc: 0.5333\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 235us/step - loss: 0.8207 - acc: 0.6279 - val_loss: 1.0806 - val_acc: 0.5111\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 235us/step - loss: 0.8138 - acc: 0.6395 - val_loss: 1.0881 - val_acc: 0.5111\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 277us/step - loss: 0.8146 - acc: 0.6279 - val_loss: 1.0853 - val_acc: 0.5333\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 245us/step - loss: 0.8092 - acc: 0.6395 - val_loss: 1.0813 - val_acc: 0.5333\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 262us/step - loss: 0.8032 - acc: 0.6512 - val_loss: 1.0965 - val_acc: 0.5333\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 248us/step - loss: 0.8059 - acc: 0.6395 - val_loss: 1.1053 - val_acc: 0.5333\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 251us/step - loss: 0.8014 - acc: 0.6744 - val_loss: 1.1125 - val_acc: 0.5333\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 261us/step - loss: 0.8010 - acc: 0.6628 - val_loss: 1.1209 - val_acc: 0.5333\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 282us/step - loss: 0.7976 - acc: 0.6744 - val_loss: 1.1191 - val_acc: 0.5333\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 264us/step - loss: 0.7882 - acc: 0.6860 - val_loss: 1.1260 - val_acc: 0.5111\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 243us/step - loss: 0.7909 - acc: 0.6628 - val_loss: 1.1253 - val_acc: 0.5333\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 244us/step - loss: 0.7870 - acc: 0.6744 - val_loss: 1.1258 - val_acc: 0.5111\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 251us/step - loss: 0.7822 - acc: 0.6744 - val_loss: 1.1195 - val_acc: 0.4889\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 253us/step - loss: 0.7815 - acc: 0.6744 - val_loss: 1.1239 - val_acc: 0.4889\n",
            "Train on 88 samples, validate on 43 samples\n",
            "Epoch 1/50\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 2.4432 - acc: 0.2727 - val_loss: 1.5713 - val_acc: 0.3953\n",
            "Epoch 2/50\n",
            "88/88 [==============================] - 0s 240us/step - loss: 1.4735 - acc: 0.4091 - val_loss: 1.3778 - val_acc: 0.4419\n",
            "Epoch 3/50\n",
            "88/88 [==============================] - 0s 343us/step - loss: 1.2079 - acc: 0.4886 - val_loss: 1.3942 - val_acc: 0.3721\n",
            "Epoch 4/50\n",
            "88/88 [==============================] - 0s 321us/step - loss: 1.1014 - acc: 0.5455 - val_loss: 1.3966 - val_acc: 0.3953\n",
            "Epoch 5/50\n",
            "88/88 [==============================] - 0s 305us/step - loss: 1.0519 - acc: 0.5682 - val_loss: 1.3571 - val_acc: 0.4419\n",
            "Epoch 6/50\n",
            "88/88 [==============================] - 0s 284us/step - loss: 1.0074 - acc: 0.5682 - val_loss: 1.3385 - val_acc: 0.4419\n",
            "Epoch 7/50\n",
            "88/88 [==============================] - 0s 349us/step - loss: 0.9888 - acc: 0.5682 - val_loss: 1.2948 - val_acc: 0.4419\n",
            "Epoch 8/50\n",
            "88/88 [==============================] - 0s 328us/step - loss: 0.9742 - acc: 0.5227 - val_loss: 1.3013 - val_acc: 0.4186\n",
            "Epoch 9/50\n",
            "88/88 [==============================] - 0s 352us/step - loss: 0.9541 - acc: 0.5341 - val_loss: 1.2912 - val_acc: 0.4186\n",
            "Epoch 10/50\n",
            "88/88 [==============================] - 0s 295us/step - loss: 0.9456 - acc: 0.5341 - val_loss: 1.2903 - val_acc: 0.4419\n",
            "Epoch 11/50\n",
            "88/88 [==============================] - 0s 418us/step - loss: 0.9417 - acc: 0.5341 - val_loss: 1.2769 - val_acc: 0.4419\n",
            "Epoch 12/50\n",
            "88/88 [==============================] - 0s 320us/step - loss: 0.9340 - acc: 0.5227 - val_loss: 1.2998 - val_acc: 0.4419\n",
            "Epoch 13/50\n",
            "88/88 [==============================] - 0s 257us/step - loss: 0.9188 - acc: 0.5227 - val_loss: 1.2757 - val_acc: 0.4419\n",
            "Epoch 14/50\n",
            "88/88 [==============================] - 0s 381us/step - loss: 0.9178 - acc: 0.5341 - val_loss: 1.2855 - val_acc: 0.4419\n",
            "Epoch 15/50\n",
            "88/88 [==============================] - 0s 494us/step - loss: 0.9070 - acc: 0.5455 - val_loss: 1.2806 - val_acc: 0.4419\n",
            "Epoch 16/50\n",
            "88/88 [==============================] - 0s 366us/step - loss: 0.9060 - acc: 0.5682 - val_loss: 1.2765 - val_acc: 0.4419\n",
            "Epoch 17/50\n",
            "88/88 [==============================] - 0s 253us/step - loss: 0.9013 - acc: 0.5795 - val_loss: 1.2819 - val_acc: 0.4419\n",
            "Epoch 18/50\n",
            "88/88 [==============================] - 0s 284us/step - loss: 0.9063 - acc: 0.5568 - val_loss: 1.2733 - val_acc: 0.4419\n",
            "Epoch 19/50\n",
            "88/88 [==============================] - 0s 246us/step - loss: 0.8988 - acc: 0.5568 - val_loss: 1.2665 - val_acc: 0.4419\n",
            "Epoch 20/50\n",
            "88/88 [==============================] - 0s 253us/step - loss: 0.8923 - acc: 0.5568 - val_loss: 1.2456 - val_acc: 0.4419\n",
            "Epoch 21/50\n",
            "88/88 [==============================] - 0s 274us/step - loss: 0.8892 - acc: 0.5682 - val_loss: 1.2599 - val_acc: 0.4651\n",
            "Epoch 22/50\n",
            "88/88 [==============================] - 0s 276us/step - loss: 0.8755 - acc: 0.5682 - val_loss: 1.2514 - val_acc: 0.4651\n",
            "Epoch 23/50\n",
            "88/88 [==============================] - 0s 382us/step - loss: 0.8758 - acc: 0.5682 - val_loss: 1.2575 - val_acc: 0.4651\n",
            "Epoch 24/50\n",
            "88/88 [==============================] - 0s 321us/step - loss: 0.8776 - acc: 0.5795 - val_loss: 1.2488 - val_acc: 0.4651\n",
            "Epoch 25/50\n",
            "88/88 [==============================] - 0s 387us/step - loss: 0.8702 - acc: 0.5795 - val_loss: 1.2371 - val_acc: 0.4419\n",
            "Epoch 26/50\n",
            "88/88 [==============================] - 0s 314us/step - loss: 0.8722 - acc: 0.5795 - val_loss: 1.2697 - val_acc: 0.4651\n",
            "Epoch 27/50\n",
            "88/88 [==============================] - 0s 251us/step - loss: 0.8690 - acc: 0.5682 - val_loss: 1.2539 - val_acc: 0.4419\n",
            "Epoch 28/50\n",
            "88/88 [==============================] - 0s 257us/step - loss: 0.8661 - acc: 0.5568 - val_loss: 1.2426 - val_acc: 0.4419\n",
            "Epoch 29/50\n",
            "88/88 [==============================] - 0s 258us/step - loss: 0.8590 - acc: 0.5568 - val_loss: 1.2536 - val_acc: 0.4419\n",
            "Epoch 30/50\n",
            "88/88 [==============================] - 0s 247us/step - loss: 0.8566 - acc: 0.5909 - val_loss: 1.2539 - val_acc: 0.4419\n",
            "Epoch 31/50\n",
            "88/88 [==============================] - 0s 277us/step - loss: 0.8578 - acc: 0.5795 - val_loss: 1.2745 - val_acc: 0.4419\n",
            "Epoch 32/50\n",
            "88/88 [==============================] - 0s 266us/step - loss: 0.8620 - acc: 0.5682 - val_loss: 1.2586 - val_acc: 0.4419\n",
            "Epoch 33/50\n",
            "88/88 [==============================] - 0s 261us/step - loss: 0.8513 - acc: 0.5682 - val_loss: 1.2435 - val_acc: 0.4419\n",
            "Epoch 34/50\n",
            "88/88 [==============================] - 0s 316us/step - loss: 0.8559 - acc: 0.5682 - val_loss: 1.2365 - val_acc: 0.4651\n",
            "Epoch 35/50\n",
            "88/88 [==============================] - 0s 300us/step - loss: 0.8484 - acc: 0.5682 - val_loss: 1.2554 - val_acc: 0.4419\n",
            "Epoch 36/50\n",
            "88/88 [==============================] - 0s 273us/step - loss: 0.8441 - acc: 0.5795 - val_loss: 1.2478 - val_acc: 0.4419\n",
            "Epoch 37/50\n",
            "88/88 [==============================] - 0s 281us/step - loss: 0.8500 - acc: 0.5682 - val_loss: 1.2618 - val_acc: 0.4419\n",
            "Epoch 38/50\n",
            "88/88 [==============================] - 0s 360us/step - loss: 0.8427 - acc: 0.5682 - val_loss: 1.2605 - val_acc: 0.4419\n",
            "Epoch 39/50\n",
            "88/88 [==============================] - 0s 345us/step - loss: 0.8390 - acc: 0.5795 - val_loss: 1.2874 - val_acc: 0.4419\n",
            "Epoch 40/50\n",
            "88/88 [==============================] - 0s 312us/step - loss: 0.8510 - acc: 0.5909 - val_loss: 1.2935 - val_acc: 0.4186\n",
            "Epoch 41/50\n",
            "88/88 [==============================] - 0s 273us/step - loss: 0.8388 - acc: 0.5568 - val_loss: 1.2874 - val_acc: 0.4186\n",
            "Epoch 42/50\n",
            "88/88 [==============================] - 0s 284us/step - loss: 0.8309 - acc: 0.5909 - val_loss: 1.2751 - val_acc: 0.4419\n",
            "Epoch 43/50\n",
            "88/88 [==============================] - 0s 350us/step - loss: 0.8272 - acc: 0.6023 - val_loss: 1.2682 - val_acc: 0.4186\n",
            "Epoch 44/50\n",
            "88/88 [==============================] - 0s 397us/step - loss: 0.8265 - acc: 0.5795 - val_loss: 1.2624 - val_acc: 0.4186\n",
            "Epoch 45/50\n",
            "88/88 [==============================] - 0s 263us/step - loss: 0.8260 - acc: 0.5909 - val_loss: 1.2644 - val_acc: 0.4186\n",
            "Epoch 46/50\n",
            "88/88 [==============================] - 0s 263us/step - loss: 0.8230 - acc: 0.5682 - val_loss: 1.2759 - val_acc: 0.3953\n",
            "Epoch 47/50\n",
            "88/88 [==============================] - 0s 307us/step - loss: 0.8145 - acc: 0.5795 - val_loss: 1.2579 - val_acc: 0.3721\n",
            "Epoch 48/50\n",
            "88/88 [==============================] - 0s 292us/step - loss: 0.8207 - acc: 0.5909 - val_loss: 1.2669 - val_acc: 0.3721\n",
            "Epoch 49/50\n",
            "88/88 [==============================] - 0s 252us/step - loss: 0.8154 - acc: 0.5909 - val_loss: 1.2769 - val_acc: 0.3721\n",
            "Epoch 50/50\n",
            "88/88 [==============================] - 0s 281us/step - loss: 0.8118 - acc: 0.5795 - val_loss: 1.2710 - val_acc: 0.3721\n",
            "Train on 88 samples, validate on 43 samples\n",
            "Epoch 1/50\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 2.3793 - acc: 0.3523 - val_loss: 1.9121 - val_acc: 0.3721\n",
            "Epoch 2/50\n",
            "88/88 [==============================] - 0s 248us/step - loss: 1.4257 - acc: 0.4205 - val_loss: 1.4645 - val_acc: 0.3488\n",
            "Epoch 3/50\n",
            "88/88 [==============================] - 0s 263us/step - loss: 1.1688 - acc: 0.4659 - val_loss: 1.3142 - val_acc: 0.3023\n",
            "Epoch 4/50\n",
            "88/88 [==============================] - 0s 234us/step - loss: 1.0631 - acc: 0.5341 - val_loss: 1.2492 - val_acc: 0.3256\n",
            "Epoch 5/50\n",
            "88/88 [==============================] - 0s 231us/step - loss: 1.0191 - acc: 0.5114 - val_loss: 1.2023 - val_acc: 0.3721\n",
            "Epoch 6/50\n",
            "88/88 [==============================] - 0s 250us/step - loss: 0.9875 - acc: 0.5000 - val_loss: 1.1734 - val_acc: 0.3953\n",
            "Epoch 7/50\n",
            "88/88 [==============================] - 0s 238us/step - loss: 0.9868 - acc: 0.5114 - val_loss: 1.1448 - val_acc: 0.4419\n",
            "Epoch 8/50\n",
            "88/88 [==============================] - 0s 228us/step - loss: 0.9568 - acc: 0.5227 - val_loss: 1.1213 - val_acc: 0.4186\n",
            "Epoch 9/50\n",
            "88/88 [==============================] - 0s 230us/step - loss: 0.9463 - acc: 0.5341 - val_loss: 1.1104 - val_acc: 0.4186\n",
            "Epoch 10/50\n",
            "88/88 [==============================] - 0s 250us/step - loss: 0.9327 - acc: 0.5341 - val_loss: 1.1012 - val_acc: 0.4186\n",
            "Epoch 11/50\n",
            "88/88 [==============================] - 0s 278us/step - loss: 0.9270 - acc: 0.5000 - val_loss: 1.0937 - val_acc: 0.4419\n",
            "Epoch 12/50\n",
            "88/88 [==============================] - 0s 235us/step - loss: 0.9142 - acc: 0.5455 - val_loss: 1.0816 - val_acc: 0.4419\n",
            "Epoch 13/50\n",
            "88/88 [==============================] - 0s 228us/step - loss: 0.9070 - acc: 0.5341 - val_loss: 1.0719 - val_acc: 0.4419\n",
            "Epoch 14/50\n",
            "88/88 [==============================] - 0s 256us/step - loss: 0.9087 - acc: 0.4773 - val_loss: 1.0707 - val_acc: 0.4419\n",
            "Epoch 15/50\n",
            "88/88 [==============================] - 0s 281us/step - loss: 0.9023 - acc: 0.5341 - val_loss: 1.0678 - val_acc: 0.4419\n",
            "Epoch 16/50\n",
            "88/88 [==============================] - 0s 270us/step - loss: 0.9080 - acc: 0.5568 - val_loss: 1.0628 - val_acc: 0.4419\n",
            "Epoch 17/50\n",
            "88/88 [==============================] - 0s 250us/step - loss: 0.8976 - acc: 0.5227 - val_loss: 1.0620 - val_acc: 0.4884\n",
            "Epoch 18/50\n",
            "88/88 [==============================] - 0s 248us/step - loss: 0.8989 - acc: 0.5341 - val_loss: 1.0575 - val_acc: 0.4884\n",
            "Epoch 19/50\n",
            "88/88 [==============================] - 0s 230us/step - loss: 0.8956 - acc: 0.5341 - val_loss: 1.0511 - val_acc: 0.5116\n",
            "Epoch 20/50\n",
            "88/88 [==============================] - 0s 253us/step - loss: 0.8948 - acc: 0.5341 - val_loss: 1.0510 - val_acc: 0.5116\n",
            "Epoch 21/50\n",
            "88/88 [==============================] - 0s 250us/step - loss: 0.8875 - acc: 0.5000 - val_loss: 1.0591 - val_acc: 0.5116\n",
            "Epoch 22/50\n",
            "88/88 [==============================] - 0s 228us/step - loss: 0.8884 - acc: 0.5455 - val_loss: 1.0568 - val_acc: 0.5116\n",
            "Epoch 23/50\n",
            "88/88 [==============================] - 0s 244us/step - loss: 0.8924 - acc: 0.5341 - val_loss: 1.0585 - val_acc: 0.4884\n",
            "Epoch 24/50\n",
            "88/88 [==============================] - 0s 264us/step - loss: 0.8918 - acc: 0.5341 - val_loss: 1.0539 - val_acc: 0.5116\n",
            "Epoch 25/50\n",
            "88/88 [==============================] - 0s 233us/step - loss: 0.8861 - acc: 0.5455 - val_loss: 1.0581 - val_acc: 0.5116\n",
            "Epoch 26/50\n",
            "88/88 [==============================] - 0s 231us/step - loss: 0.8869 - acc: 0.5568 - val_loss: 1.0547 - val_acc: 0.5116\n",
            "Epoch 27/50\n",
            "88/88 [==============================] - 0s 241us/step - loss: 0.8841 - acc: 0.5227 - val_loss: 1.0560 - val_acc: 0.5116\n",
            "Epoch 28/50\n",
            "88/88 [==============================] - 0s 234us/step - loss: 0.8838 - acc: 0.5341 - val_loss: 1.0624 - val_acc: 0.5116\n",
            "Epoch 29/50\n",
            "88/88 [==============================] - 0s 247us/step - loss: 0.8833 - acc: 0.5568 - val_loss: 1.0596 - val_acc: 0.5349\n",
            "Epoch 30/50\n",
            "88/88 [==============================] - 0s 229us/step - loss: 0.8741 - acc: 0.5568 - val_loss: 1.0570 - val_acc: 0.5116\n",
            "Epoch 31/50\n",
            "88/88 [==============================] - 0s 254us/step - loss: 0.8774 - acc: 0.5568 - val_loss: 1.0543 - val_acc: 0.5116\n",
            "Epoch 32/50\n",
            "88/88 [==============================] - 0s 296us/step - loss: 0.8754 - acc: 0.5455 - val_loss: 1.0577 - val_acc: 0.5116\n",
            "Epoch 33/50\n",
            "88/88 [==============================] - 0s 333us/step - loss: 0.8792 - acc: 0.5455 - val_loss: 1.0560 - val_acc: 0.5116\n",
            "Epoch 34/50\n",
            "88/88 [==============================] - 0s 293us/step - loss: 0.8740 - acc: 0.5682 - val_loss: 1.0589 - val_acc: 0.5116\n",
            "Epoch 35/50\n",
            "88/88 [==============================] - 0s 373us/step - loss: 0.8743 - acc: 0.5455 - val_loss: 1.0608 - val_acc: 0.5116\n",
            "Epoch 36/50\n",
            "88/88 [==============================] - 0s 288us/step - loss: 0.8721 - acc: 0.5455 - val_loss: 1.0637 - val_acc: 0.5116\n",
            "Epoch 37/50\n",
            "88/88 [==============================] - 0s 306us/step - loss: 0.8758 - acc: 0.5455 - val_loss: 1.0614 - val_acc: 0.5349\n",
            "Epoch 38/50\n",
            "88/88 [==============================] - 0s 289us/step - loss: 0.8818 - acc: 0.5682 - val_loss: 1.0593 - val_acc: 0.5116\n",
            "Epoch 39/50\n",
            "88/88 [==============================] - 0s 238us/step - loss: 0.8707 - acc: 0.5341 - val_loss: 1.0619 - val_acc: 0.5116\n",
            "Epoch 40/50\n",
            "88/88 [==============================] - 0s 268us/step - loss: 0.8700 - acc: 0.5909 - val_loss: 1.0579 - val_acc: 0.5349\n",
            "Epoch 41/50\n",
            "88/88 [==============================] - 0s 244us/step - loss: 0.8740 - acc: 0.5909 - val_loss: 1.0616 - val_acc: 0.5116\n",
            "Epoch 42/50\n",
            "88/88 [==============================] - 0s 234us/step - loss: 0.8698 - acc: 0.5341 - val_loss: 1.0589 - val_acc: 0.5116\n",
            "Epoch 43/50\n",
            "88/88 [==============================] - 0s 261us/step - loss: 0.8646 - acc: 0.5795 - val_loss: 1.0573 - val_acc: 0.5116\n",
            "Epoch 44/50\n",
            "88/88 [==============================] - 0s 264us/step - loss: 0.8614 - acc: 0.5568 - val_loss: 1.0587 - val_acc: 0.5116\n",
            "Epoch 45/50\n",
            "88/88 [==============================] - 0s 242us/step - loss: 0.8636 - acc: 0.5568 - val_loss: 1.0645 - val_acc: 0.5116\n",
            "Epoch 46/50\n",
            "88/88 [==============================] - 0s 240us/step - loss: 0.8659 - acc: 0.6023 - val_loss: 1.0630 - val_acc: 0.5116\n",
            "Epoch 47/50\n",
            "88/88 [==============================] - 0s 329us/step - loss: 0.8654 - acc: 0.5909 - val_loss: 1.0687 - val_acc: 0.5116\n",
            "Epoch 48/50\n",
            "88/88 [==============================] - 0s 347us/step - loss: 0.8620 - acc: 0.5682 - val_loss: 1.0688 - val_acc: 0.5116\n",
            "Epoch 49/50\n",
            "88/88 [==============================] - 0s 274us/step - loss: 0.8619 - acc: 0.5795 - val_loss: 1.0685 - val_acc: 0.5116\n",
            "Epoch 50/50\n",
            "88/88 [==============================] - 0s 267us/step - loss: 0.8620 - acc: 0.5909 - val_loss: 1.0654 - val_acc: 0.5349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2eeOHoYbina",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDN2PrRc36l",
        "colab_type": "code",
        "outputId": "f3637bab-e058-4c08-c062-3cc3d3e8c85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 610,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 610
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tss7vRUEgAcz",
        "colab_type": "code",
        "outputId": "9bc4d3bf-a62e-4ec6-f1f7-a4e25a5bc720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_acc_histories[2])"
      ],
      "execution_count": 611,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 611
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpKE3iTJBHzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_acc_history = [np.mean([x[i] for x in all_acc_histories]) for i in range(num_epochs)]\n",
        "#media per epoca degli score ottenuti per tutte le k-fold\n",
        "#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\n",
        "#e si fa questo per tutte le epoche\n",
        "average_loss_history = [np.mean([x[i] for x in all_loss_histories]) for i in range(num_epochs)]\n",
        "average_val_acc_history = [np.mean([x[i] for x in all_val_acc_histories]) for i in range(num_epochs)]\n",
        "average_val_loss_history = [np.mean([x[i] for x in all_val_loss_histories]) for i in range(num_epochs)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQrkCEMUD2RI",
        "colab_type": "code",
        "outputId": "d39dfd23-3c14-4760-9b5c-0e33f33ce52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(average_val_acc_history)"
      ],
      "execution_count": 613,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 613
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UhSxIaHtuO",
        "colab_type": "text"
      },
      "source": [
        "##Plotting training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zsienD5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJizyjnaIPhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, num_epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEHEYLgIQUQ",
        "colab_type": "code",
        "outputId": "613dac32-049b-4383-ec97-c494e8eea215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs, average_loss_history, 'bo', label='training loss')\n",
        "plt.plot(epochs, average_val_loss_history, 'b', label='validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 616,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4fc89c0e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 616
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoHCdA7bwQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc4wMjfI97j",
        "colab_type": "text"
      },
      "source": [
        "##Plotting train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi7VzbFIbtJ",
        "colab_type": "code",
        "outputId": "5d1fe417-950a-49e3-a04d-0892de61a5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(epochs, average_acc_history, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, average_val_acc_history, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend() "
      ],
      "execution_count": 617,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4fc89a6400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 617
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3hUZfrw8e9NQKkiIjYghKYYIGCI\ngFJEFMUG1h8oKkUWsbJ2Vty1rOjayy7uir6irlFEEYxtWQtWViVUBaVIQEHA0EIVArnfP54zYRJm\nJjPJTCaZuT/XNdfMeU57zmQy95yniqpijDHGlFYj3hkwxhhTNVmAMMYYE5AFCGOMMQFZgDDGGBOQ\nBQhjjDEBWYAwxhgTkAUIEzYRSRGR7SKSGs1t40lE2ohI1Nt6i8jpIrLSb3mJiPQKZ9tynOt5Ebmz\nvPsbE0zNeGfAxI6IbPdbrAvsBvZ5y1eranYkx1PVfUD9aG+bDFT1uGgcR0RGAperah+/Y4+MxrGN\nKc0CRAJT1eIvaO8X6khV/SjY9iJSU1X3VkbejCmLfR7jz4qYkpiI3C8ir4vIayKyDbhcRE4Ska9F\nZIuIrBWRp0Wklrd9TRFREUnzll/x1n8gIttE5H8i0jLSbb31Z4nIUhEpEJG/i8hXIjIsSL7DyePV\nIrJcRDaLyNN++6aIyBMislFEVgD9Q7w/40Rkcqm0CSLyuPd6pIj84F3PT96v+2DHWi0ifbzXdUXk\n317eFgFdSm17l4is8I67SEQGeOkdgX8Avbziuw1+7+09fvuP9q59o4hMF5Gjw3lvInmfffkRkY9E\nZJOIrBOR2/3O82fvPdkqIrkickyg4jwR+dL3d/bez8+982wC7hKRtiIy0zvHBu99a+i3fwvvGvO9\n9U+JSG0vz8f7bXe0iOwUkcbBrtcEoKr2SIIHsBI4vVTa/cAe4Dzcj4U6wIlAN9zdZStgKXC9t31N\nQIE0b/kVYAOQBdQCXgdeKce2RwDbgIHeupuBQmBYkGsJJ49vAw2BNGCT79qB64FFQDOgMfC5+zcI\neJ5WwHagnt+xfwOyvOXzvG0E6AvsAjK8dacDK/2OtRro471+FPgUaAS0ABaX2vb/gKO9v8llXh6O\n9NaNBD4tlc9XgHu812d4eewM1AaeAT4J572J8H1uCKwHxgAHA4cAXb11fwIWAG29a+gMHAa0Kf1e\nA1/6/s7ete0FrgFScJ/HY4HTgIO8z8lXwKN+1/O9937W87bv4a2bCIz3O88twLR4/x9Wt0fcM2CP\nSvpDBw8Qn5Sx363AG97rQF/6//LbdgDwfTm2HQF84bdOgLUECRBh5rG73/q3gFu915/jitp8684u\n/aVV6thfA5d5r88CloTY9l3gOu91qADxs//fArjWf9sAx/0eOMd7XVaAeAl4wG/dIbh6p2ZlvTcR\nvs9XALODbPeTL7+l0sMJECvKyMPFvvMCvYB1QEqA7XoAeYB4y/OBC6P9f5XoDytiMr/4L4hIOxF5\nzysy2ArcBxweYv91fq93ErpiOti2x/jnQ91/9OpgBwkzj2GdC1gVIr8ArwKXeq8v85Z9+ThXRL7x\nij+24H69h3qvfI4OlQcRGSYiC7xiki1AuzCPC+76io+nqluBzUBTv23C+puV8T43xwWCQEKtK0vp\nz+NRIjJFRNZ4eXixVB5WqmsQUYKqfoW7G+kpIh2AVOC9cuYpaVmAMKWbeD6L+8XaRlUPAf6C+0Uf\nS2txv3ABEBGh5BdaaRXJ41rcF4tPWc1wpwCni0hTXBHYq14e6wBvAg/iin8OBf4bZj7WBcuDiLQC\n/okrZmnsHfdHv+OW1ST3V1yxle94DXBFWWvCyFdpod7nX4DWQfYLtm6Hl6e6fmlHldqm9PU9hGt9\n19HLw7BSeWghIilB8vEycDnubmeKqu4Osp0JwgKEKa0BUADs8Cr5rq6Ec74LZIrIeSJSE1eu3SRG\neZwC/FFEmnoVlneE2lhV1+GKQV7EFS8t81YdjCsXzwf2ici5uLLycPNwp4gcKq6fyPV+6+rjviTz\ncbHyD7g7CJ/1QDP/yuJSXgOuEpEMETkYF8C+UNWgd2QhhHqfc4BUEbleRA4WkUNEpKu37nngfhFp\nLU5nETkMFxjX4RpDpIjIKPyCWYg87AAKRKQ5rpjL53/ARuABcRX/dUSkh9/6f+OKpC7DBQsTIQsQ\nprRbgKG4SuNncZXJMaWq64FBwOO4f/jWwDzcL8do5/GfwMfAd8Bs3F1AWV7F1SkUFy+p6hbgJmAa\nrqL3YlygC8fduDuZlcAH+H15qepC4O/At942xwHf+O37IbAMWC8i/kVFvv3/gysKmubtnwoMCTNf\npQV9n1W1AOgHXIQLWkuBU7zVjwDTce/zVlyFcW2v6PAPwJ24BgttSl1bIHcDXXGBKgeY6peHvcC5\nwPG4u4mfcX8H3/qVuL/zblWdFeG1G/ZX4BhTZXhFBr8CF6vqF/HOj6m+RORlXMX3PfHOS3VkHeVM\nlSAi/XEthnbhmkkW4n5FG1MuXn3OQKBjvPNSXVkRk6kqegIrcGXvZwIXWKWiKS8ReRDXF+MBVf05\n3vmprqyIyRhjTEB2B2GMMSaghKmDOPzwwzUtLS3e2TDGmGplzpw5G1Q1YLPyhAkQaWlp5Obmxjsb\nxhhTrYhI0NEErIjJGGNMQBYgjDHGBGQBwhhjTEAJUwcRSGFhIatXr+b333+Pd1ZMFVK7dm2aNWtG\nrVrBhjMyxkCCB4jVq1fToEED0tLScAOEmmSnqmzcuJHVq1fTsmXLsncwJokldBHT77//TuPGjS04\nmGIiQuPGje2u0gSVnQ1paVCjhnvOzo7vceIpoe8gAAsO5gD2mTDBZGfDqFGwc6dbXrXKLQMMiWBM\n3GgdJ94S+g7CGGMiMW7c/i91n507XXo8jhNvFiBiaOPGjXTu3JnOnTtz1FFH0bRp0+LlPXv2hHWM\n4cOHs2TJkpDbTJgwgezqeP9qTBXzc5Bh/YKlx/o4PsGKq2JejBXvSbGj9ejSpYuWtnjx4gPSQnnl\nFdUWLVRF3PMrr0S0e0h33323PvLIIwekFxUV6b59+6J3omqisLAwrueP9LNhkkOLFqpw4KNFi/gc\nR9V9D9WtW/I4deuqXnNN4PRIv7eAXA3yvWp3EB5fmeGqVe6t9pUZxuKH+fLly0lPT2fIkCG0b9+e\ntWvXMmrUKLKysmjfvj333Xdf8bY9e/Zk/vz57N27l0MPPZSxY8fSqVMnTjrpJH777TcA7rrrLp58\n8sni7ceOHUvXrl057rjjmDXLTaS1Y8cOLrroItLT07n44ovJyspi/vz5B+Tt7rvv5sQTT6RDhw6M\nHj0a9Ub7Xbp0KX379qVTp05kZmaycuVKAB544AE6duxIp06dGOfdP/vyDLBu3TratGkDwPPPP8/5\n55/PqaeeyplnnsnWrVvp27cvmZmZZGRk8O67+ydkmzRpEhkZGXTq1Inhw4dTUFBAq1at2Lt3LwCb\nN28usWxMNIwfD3XrlkyrW9elR+s4oX71B1oXrLhq4sRKKMYKFjmq26OidxDRjPiB+N9BLFu2TEVE\nZ8+eXbx+48aNqup+Wffs2VMXLVqkqqo9evTQefPmaWFhoQL6/vvvq6rqTTfdpA8++KCqqo4bN06f\neOKJ4u1vv/12VVV9++239cwzz1RV1QcffFCvvfZaVVWdP3++1qhRQ+fNm3dAPn35KCoq0sGDBxef\nLzMzU3NyclRVddeuXbpjxw7NycnRnj176s6dO0vs68uzquratWu1devWqqr63HPPaWpqqm7atElV\nVffs2aMFBQWqqrp+/Xpt06ZNcf6OO+644uP5ni+//HJ95513VFV1woQJxddZHnYHYYKJVklCoOME\nuxsItS7Q91Koh0hk+cTuIMoW7TLDsrRu3ZqsrKzi5ddee43MzEwyMzP54YcfWLx48QH71KlTh7PO\nOguALl26FP+KL+3CCy88YJsvv/ySwYMHA9CpUyfat28fcN+PP/6Yrl270qlTJz777DMWLVrE5s2b\n2bBhA+eddx7gOprVrVuXjz76iBEjRlCnTh0ADjvssDKv+4wzzqBRo0aA+3EyduxYMjIyOOOMM/jl\nl1/YsGEDn3zyCYMGDSo+nu955MiRTJo0CXB3GMOHDy/zfMZEasgQWLkSiorcc1mtjoLdEQQ6TqjK\n62DrUlICnzdYempq6PxGwgKEJ9ibGs0321+9evWKXy9btoynnnqKTz75hIULF9K/f/+A7fQPOuig\n4tcpKSlBi1cOPvjgMrcJZOfOnVx//fVMmzaNhQsXMmLEiHL1F6hZsyZFRUUAB+zvf90vv/wyBQUF\nzJ07l/nz53P44YeHPN8pp5zC0qVLmTlzJrVq1aJdu3YR580kpnj1OYi0aDrUD9Fg6/btC1xcNWpU\ndIrDQrEA4YlW2WN5bN26lQYNGnDIIYewdu1aZsyYEfVz9OjRgylTpgDw3XffBbxD2bVrFzVq1ODw\nww9n27ZtTJ06FYBGjRrRpEkT3nnnHcB96e/cuZN+/frxwgsvsGvXLgA2bdoEuKHX58yZA8Cbb74Z\nNE8FBQUcccQR1KxZkw8//JA1a9YA0LdvX15//fXi4/meAS6//HKGDBlidw+mWGXWH5YWaXPWUD9E\ng61r0cLVN7RoASL7l595JnB6NPtZWIDwDBkS+zc7mMzMTNLT02nXrh1XXnklPXr0iPo5brjhBtas\nWUN6ejr33nsv6enpNGzYsMQ2jRs3ZujQoaSnp3PWWWfRrVu34nXZ2dk89thjZGRk0LNnT/Lz8zn3\n3HPp378/WVlZdO7cmSeeeAKA2267jaeeeorMzEw2b94cNE9XXHEFs2bNomPHjkyePJm2bdsCrgjs\n9ttvp3fv3nTu3JnbbruteJ8hQ4ZQUFDAoEGDovn2mGosnn0OIi2aDvVDNNS6YMVekRaHRSxY5UR1\ne0SjmWsiKyws1F27dqmq6tKlSzUtLS3uTU3L47XXXtNhw4ZV+Dj22UgcItGprC2P8jRuCVUJHsum\n9sEQopI6pl/aQH9gCbAcGBtkm/8DFgOLgFf90ocCy7zH0LLOZQEitM2bN2tmZqZmZGRox44ddcaM\nGfHOUsRGjx6tbdq00eXLl1f4WPbZSByhvqSj+YUbaauk6iIuAQJIAX4CWgEHAQuA9FLbtAXmAY28\n5SO858OAFd5zI+91o1DnswBhImGfjcQR645koc7hCxKV/as/mkIFiFjWQXQFlqvqClXdA0wGBpba\n5g/ABFXdDKCqv3npZwIfquomb92HuLsRY4wpIVj94fvvR69uIlQ9R8zrAeIolgGiKfCL3/JqL83f\nscCxIvKViHwtIv0j2BcRGSUiuSKSm5+fH8WsG2Oqk0Bf0tHs21TZ/aSqini3YqqJK2bqA1wKPCci\nh4a7s6pOVNUsVc1q0qRJjLJojKmOotm3qbL7SVUVsQwQa4DmfsvNvDR/q4EcVS1U1TxgKS5ghLOv\nMSYBRavTWzT7NsWzn1Q8xTJAzAbaikhLETkIGAzklNpmOu7uARE5HFfktAKYAZwhIo1EpBFwhpdW\nrZx66qkHdHp78sknueaaa0LuV79+fQB+/fVXLr744oDb9OnTh9zc3JDHefLJJ9npV3B69tlns2XL\nlnCybkxcRLPTWzT7NsWzn1RcBau9jsYDOBt3V/ATMM5Luw8Y4L0W4HFcM9fvgMF++47ANY9dDgwv\n61xVsRXTs88+e0Cb/W7duulnn30Wcr969eqVeexTTjmlxGB/gbRo0ULz8/PLzmgVFcuh0OP92YiV\n6t6iJtaDZvpU9/cpmohXP4jKfFTFALFx40Zt0qSJ7t69W1VV8/LytHnz5lpUVKTbtm3Tvn376gkn\nnKAdOnTQ6dOnF+/nCxB5eXnavn17VVXduXOnDho0SNu1a6fnn3++du3atThAjB49Wrt06aLp6en6\nl7/8RVVVn3rqKa1Vq5Z26NBB+/Tpo6olA8Zjjz2m7du31/bt2xePBJuXl6ft2rXTkSNHanp6uvbr\n1694pFZ/OTk52rVrV+3cubOedtppum7dOlVV3bZtmw4bNkw7dOigHTt21DfffFNVVT/44AM94YQT\nNCMjQ/v27auqB86P0b59e83Ly9O8vDw99thj9YorrtD09HRduXJlwOtTVf3222/1pJNO0oyMDD3x\nxBN169at2qtXrxKj1Pbo0UPnz59/wDXE+7MRC4nQJr8yOr0lwvsUTRYgVHXMGNVTTonuY8yYst56\n1XPOOaf4y//BBx/UW265RVVdz2bfUNf5+fnaunVrLSoqUtXAAeKxxx7T4cOHq6rqggULNCUlpThA\n+IbD3rt3r55yyim6YMECVT3wDsK3nJubqx06dNDt27frtm3bND09XefOnat5eXmakpJS/AV7ySWX\n6L///e8DrmnTpk3FeX3uuef05ptvVlXV22+/Xcf4vSmbNm3S3377TZs1a6YrVqwokddQAUJE9H//\n+1/xukDXt3v3bm3ZsqV+++23qqpaUFCghYWF+uKLLxbnYcmSJRroc6GamAGisn59x1JlXEMivE/R\nFCpAxLsVU8K79NJLmTx5MgCTJ0/m0ksvBVxgvvPOO8nIyOD0009nzZo1rF+/PuhxPv/8cy6//HIA\nMjIyyMjIKF43ZcoUMjMzOeGEE1i0aFHAgfj8ffnll1xwwQXUq1eP+vXrc+GFF/LFF18A0LJlSzp3\n7gwEH1J89erVnHnmmXTs2JFHHnmERYsWAfDRRx9x3XXXFW/XqFEjvv76a3r37k3Lli2B8IYEb9Gi\nBd27dw95fUuWLOHoo4/mxBNPBOCQQw6hZs2aXHLJJbz77rsUFhbywgsvMGzYsDLPlygqqylmLEdO\nrYzK4GRtsloeNeOdgcriTbhW6QYOHMhNN93E3Llz2blzJ126dAHc4Hf5+fnMmTOHWrVqkZaWVq6h\ntfPy8nj00UeZPXs2jRo1YtiwYeU6jo9vqHBww4X7Rmr1d8MNN3DzzTczYMAAPv30U+65556Iz+M/\nJDiUHBbcf0jwSK+vbt269OvXj7fffpspU6YUjyqbDFJTXaVuoPRo8VUi+9o++CqRIToVtr5jjBvn\nvrBTU/cPVhctlfE+JQq7g4ix+vXrc+qppzJixIjiuwfYP9R1rVq1mDlzJqsCfWL99O7dm1dffRWA\n77//noULFwJuqPB69erRsGFD1q9fzwcffFC8T4MGDdi2bdsBx+rVqxfTp09n586d7Nixg2nTptGr\nV6+wr6mgoICmTV2/xZdeeqk4vV+/fkyYMKF4efPmzXTv3p3PP/+cvLw8oOSQ4HPnzgVg7ty5xetL\nC3Z9xx13HGvXrmX27NkAbNu2rXjui5EjR3LjjTdy4oknFk9OlAzKO81lIMG2D9WjONg+kaaH6pkc\njbuXZG2yWi7Byp6q26MqVlL7TJs2TQH94YcfitPy8/O1e/fu2qFDBx02bJi2a9dO8/LyVLXsSuoL\nLrigRCX10KFDtW3bttq3b1+94IILdNKkSaqq+vTTT+uxxx4bUSW173yqqo888ojefffdB1zP9OnT\ntWXLlpqZmam33nqrnnLKKarqKqmvvPJKbd++vWZkZOjUqVNVVfX999/Xzp07a0ZGhp5++unF19Ov\nXz9NT0/X4cOHF19/6TyEur5vv/1Wu3XrphkZGdqtWzfdtm1b8T7HHXecfvDBB0H/JlXlsxFt0RhQ\nLtT2wSqRA02PGWo8pPKMkxTNymVrxbQfIeogxK2v/rKysrR0v4AffviB448/Pk45MvHy66+/0qdP\nH3788Udq1Ah8k5xMn420tMBFKi1auF/okWwPgdelpLiZzyqaHixPZeUr2D6mbCIyR1WzAq2zIiaT\nUF5++WW6devG+PHjgwaHWIu0SCXWQlXKBspTqO2DFc8E+rKHyNNDVRRb5XIcBLu1qG6PqlzEZKqe\nWH02KmPo6UgFa9bZuHHgPDVuHHh7XzPQQMUzwc6RkhJZeqimptY8NTZI5maumiBFaCZ6YvmZCFaJ\nO3Fi/KbFDPar35eH0nnyX++/va8SN1AlcrBzjBoVWXqoimKrXI6DYJGjuj0C3UGsWLFC8/Pzizt1\nGVNUVKT5+fnFHfeiLVQlbqx7CIcS6Fd/qF7L5anEDbZPpOnlOYcpP5K1krqwsJDVq1dXqF+ASTy1\na9emWbNm1KpVK+rHDlaRWp5K2VCysyveV8AqfQ2ErqRO6I5ytWrVKu7Ba0xlGD++ZEcycMUgQ4fC\nSy8dmF6e4pFodVYLllcrsjE+CV8HYUxlCjYs9DPPRG+46FCd1aKR14QfwtqEzQKEMSGEapoaaU/g\nSOcuDnb8aDb3TOT5lE3FJXQRkzEVEaooB2I7JlGoc9tYQqay2B2EMQT+tR6qKCdaxTzlObc19zSV\nJaFbMRkTjtK/1sF94Zb+gvYRcc+B/nVEXHFNLM9dVBSdVkzGQOhWTBYgTNIrT9NUiE4T0cpqFmtM\nMEnbzNWYcASr3N2378Bf8/5FOdFoIlrecxtTGawOwiS9YJW7vmafgZqBRquJaHnObUylCdbFuro9\ngs09bKqeaA3JEGrYhUj2ieck9vE8tzGqoYfaiPsXe7QeFiCqh0hHOy3PhDPlGVE1nmP82PhCJp5C\nBYiYVlKLSH/gKSAFeF5V/1Zq/TDgEWCNl/QPVX3eW7cP+M5L/1lVB4Q6l1VSVw+RVsqWZ8IZsIpf\nY8IVl0pqEUkBJgD9gNXAbBHJUdXFpTZ9XVWvD3CIXaraOVb5M/ERqlI2GumhehOXZx9jklksK6m7\nAstVdYWq7gEmAwNjeD5TDQSrlE1JiU56amrk57AeyMYEFssA0RT4xW95tZdW2kUislBE3hSR5n7p\ntUUkV0S+FpHzA51AREZ52+Tm5+dHMesmGgL1EI7WxDKhJpyJ9BzWdNSYIIJVTlT0AVyMq3fwLV+B\nq2Pw36YxcLD3+mrgE791Tb3nVsBKoHWo81klddUSqnVOVWvFZEwyIx6V1CJyEnCPqp7pLf/JC0gP\nBtk+Bdikqg0DrHsReFdV3wx2PqukrlpsMhpjqodQldSxLGKaDbQVkZYichAwGMgplbGj/RYHAD94\n6Y1E5GDv9eFAD6B05bapwqI5JLUxJj5i1opJVfeKyPXADFwz1xdUdZGI3Ie7pckBbhSRAcBeYBMw\nzNv9eOBZESnCBbG/6YGtn0wVZkNSG1P92WB9JiaCjVJqw0UYU7XEq4jJJDGbztKY6s8CRBUUaprL\neB4rUjadpTHVmw33XcWEmmoy0i/YaB7LGJN87A6iiinPVJbB7hKieax43okYY+LD7iCqmEibh4a6\nS4jWsb76Cl56ye5EjEk21oqpiom0g1mo7SE6x7JRUI1JXNaKqYqKZKyiYOMFhbpLiNaxbBRUY5KT\nBYg48RXnrFrlRiryL7aJpHlosI5nqamRNzW1UVCNMf4sQMRJqArkYM1Dy3PHEUlTUxsF1RjjzwJE\nnJS3ArmidxyhBLvjeOYZ6/RmTDKySuo4iWZldHkqirOz3d3Kzz+7oqLx4+0L35hkZJXUVVA0K6Mj\nFexuxPo2GGP8WYCIk2hVIJenorg8HeiMMcnHAkQlCNYLORoVyOWpKLa5Gowx4bAAEWPRKs6J5uio\n0bwbMcYkLgsQMRbN4pxojY4azbsRG6PJmMRlASLGqmJxTrTuRqyy25jEZs1cYyzazVOrkkS+NmOS\nhTVzrQTBilqiWZxT1VTFuyNjTPTYcN9REM7EPInYKS01NfAdhFV2G5MYrIgpCpK1qKV0YAR3d2TD\ncBhTfVgRU4wla1FLNJveGmOqnpgGCBHpLyJLRGS5iIwNsH6YiOSLyHzvMdJv3VARWeY9hsYynxWV\nzP0KotX0tjr69Ve4+27YsCH8fV5/3T0qKj/fFVsuWVLxYxkTlKrG5AGkAD8BrYCDgAVAeqlthgH/\nCLDvYcAK77mR97pRqPN16dJF4+WVV1Tr1lV1jT3do25dl24S06efqh55pPtbX3JJePvk5qqmpLh9\nrrpKddeu8p37669VmzVzx6lfX/WNN8p3HGNUVYFcDfK9Gss7iK7AclVdoap7gMnAwDD3PRP4UFU3\nqepm4EOgf4zyWWFW1JI8VOHRR+G006BRI7jmGnjjDZg6NfR+e/bA8OFwxBFw++3w//4f9OgBeXmR\nnfuf/4RevaBmTXjnHWjfHi65BG69Ffburdi1GXOAYJGjog/gYuB5v+UrKHW3gLuDWAssBN4Emnvp\ntwJ3+W33Z+DWAOcYBeQCuampqbEJr8Z4CgpUL7zQ/XK/+GLVrVtV9+xRzcxUPeII1fz84Pvec4/b\nLyfHLefkqDZsqNqoker775d97h07VK+4wh3jrLNUN2506bt3q153nUvv3Vt17dqKX6dJLsTpDiIc\n7wBpqpqBu0t4KZKdVXWiqmapalaTJk1ikkFjABYtghNPhLffhscegylToEEDqFULJk2CTZvgj38M\nvO/ChXD//e6O8rzzXNp558GcOa6e6pxzXF1GsLm/ly+H7t3hlVfg3nvh3XfhsMPcuoMOgn/8w62b\nPRtOOAG+/DL612+SUyz7QawBmvstN/PSiqnqRr/F54GH/fbtU2rfT6OeQ5Owli2Dm2+GX36BXbtK\nPn7/PfiXcUoK1K4NdeqUfCxb5gLCJ59A794l98nIcBXG994LgwbtDwLgin2GD3df6E89VXK/1q1h\n1iy49lq47z5XeX3ooQfmafFiF4jefx/6ByloHTLE5ePCC6FPH3joIXf9ImG/ZWF7+234wx+goODA\n96lOHVf8FUhhYcm/ge91kybw0kuu2K4sP/0Et9wC69YFXt+/P9x1V/A8+HvjDXjtNfdetW1b9vbJ\nKGb9IESkJrAUOA33hT8buExVF/ltc7SqrvVeXwDcoardReQwYA6Q6W06F+iiqpuCna+qDrVhKt9r\nr7n+GbVqufL60l9gtWsH/wLZu7fkl5fvceih8OCDcMwxgffbsweyslyLpsWL93/R/+1v8Kc/wZtv\nwkUXBd5X1d2FvPGGe13aYYfBAw+4/jZlKSiAESPgrbfg3HPhxRehceOy9wvH3r3uy/ehh6BLFzj9\n9APfp127ggffmjVL/g18r995B3780d1l3XGHG40gkDfegJEj3fpu3Q5cv307fPUVnHoqTJ7s6nsC\nKSx09UBPPukCaIMG8PLLMMduKTkAABpbSURBVDDcGtIEE6ofRMzqILzAczYuSPwEjPPS7gMGeK8f\nBBbhWjjNBNr57TsCWO49hpd1rni2YjJVw44dqn/4gyuPP/lk1VWrKvf8vlZKw4e75cWLVQ86yNVX\nVKaiItW//92du1kz1S++qPgx169X7dvXvbdXX636++8VP6bPtm2qgwe7Yw8YoLp5c8n1u3apXnON\nW9+tm2peXvBjTZqkWru2atOmqrNmHbj+119Ve/Z0x7rxRtVly1Szstzy2LGqhYXRu67qghB1EOF8\nyd9AGU1Mq8LDAkRyW7xYtUMH94n+059c5XE8jB3r8vDee6rdu6s2bqy6bl188jJnjmqbNi5ojR+v\num9f+Y4za5b7wq1dW/XFF6ObR5+iItWnn1atWVO1dWvVBQtc+o8/qmZkuPf0ttvC+7vOm6faqpVq\nrVouUBYVufTPPlM96ijXBP3VV/dvv2uX6qhR7hx9+7pgmEwqGiDu937FT8E1NZWy9onHwwJE8nrx\nRfdP36SJ6n/+E9+87Nql2q6d+/UOqtnZ8c1PQcH+X+f9+rmg8f334T+efNJ90bZqpTp/fuzz+9VX\nqscco1qnjurNN6vWq6d6+OHhtfTyt2mT6rnnuuu+7DLVhx92gfLYY1W/+y7wPv53H//7X4Uvpdqo\nUIBw+yO4vgmTvWDxANA6nH0r62EBIvns3Kk6YoT7FJ96quqaNfHOkTNrlqqI6nnn7f/1Gk9FRarP\nPee+/Pw7c4b7OO+8A4t9YmndOtU+fdy5e/VSXb26fMfZt0/1/vvd3wJcE+WCgtD7zJun2rKl26de\nvcgeV19dNf7ekQoVIMKupBaRTsBw7y5iJtAd15nt9rAOEGNWSZ1cVqyAiy+GefP2tyBKSYl3rvb7\n/nvXSqlOnXjnZL+ffoK5cyPb55BDoF+/4BXHsbJ3r6tw7tEjvBZJoXz2mfu8DBsWXquuzZvh6adh\n27bwz5GX5xoGvP46/N//lTurcRGqkrrMACEiY4ArgQ24pqjTVbVQRGoAy1S1dbQzXB4WIJLH++/v\n76X+73+71jrGxNPevXDSSW5U50WLXNPd6qKio7keBlyoqmeq6huqWgigqkWA/WuaSrNvH/zlL65j\nWVqa62hmwcFUBTVruqbKW7bAjTfGOzfRE06A+AAo7n8gIoeISDcAVf0hVhkzxt+mTS4w/PWvrqhg\n1ixo1SreuTJmvw4d4M9/dn0wpk+Pd26iI5wA8U9gu9/ydi/NmEqhCldcATNnwrPPwgsvVK2yfWN8\nxo6FTp3cII6bN8c7NxUXToAQ9auo8IqWbKpSU2lefNHVOzz8sOshHYvhI4yJBt/YXPn5cNNN8c5N\nxYUTIFaIyI0iUst7jMHNz2BMzP3yixsEr3dvuOGGeOfGmLKdcIK7k3jpJfjgg3jnpmLCCRCjgZNx\n4ymtBrrhhtk2JqZU4aqrXOX0pEmV39TSmPL6858hPd3d8W7dGu/clF+ZRUWq+hswuBLyYkwJzz0H\nH34IzzxjFdKmejn4YFdXdvLJboTf3r0PHKjwqKPcYJJVucg0nH4QtYGrgPZAbV+6qo6IbdYiY/0g\nEsvKldCxoxu187//tbsHUz2NH++aZhcVBV5/ySXuh1DDhpWbL38V7Qfxb+Ao3FAbn+HmZoigj6Ex\nkSkqckNWi7ipOS04mOpq3DjXiW7XLtdUe80a16P9++/d8PFvveXqLGbPjndOAwvnX6+Nqv4Z2KGq\nLwHn4OohklJ2tuukVaOGe87OjneOEs8//+matD7+uJvf25jqTMQVKzVq5OYTadXKzSU+dix8/rmr\nY+vRA554IvB8IPEUToAo9J63iEgHoCEQZCqOxJad7SqdVq1yf8hVq9yyBYnoWb7cTebSv7+roDYm\nkZ18shtP7Oyz3QyAAwfCxo1l7+evqAh27IhN/sIJEBNFpBFwF5ADLAYeik12qrZx42DnzpJpO3e6\ndFNxRUUuKNSq5cplq3LlnTHRcthhMG2am5L2P/+Bzp3dQIXh2LIFLrjA1WUEq+eoiJABwhuQb6uq\nblbVz1W1laoeoarPRj8rVd/PP0eWbiLz3HPulvuxx6BZs3jnxpjKI+LGcJo1Cw46CE45xdVRhPrS\nX7jQTXPrm6s8Fj+oQgYIr9d0lRjOuypITY0s3YRvzRpXtNS3r6ugNiYZZWW5IdkvugjuvBPOOgt+\n++3A7V5+Gbp3d5Xfn37qgkulBwjPRyJyq4g0F5HDfI/oZ6XqGz8e6tYtmVa3rks35acK114Le/bA\nxIlWtGSSW8OGbsC/Z591d9SdOrlGGwC7d7txnoYOha5dXTDp0SN2eQlnTKVB3vN1fmkKJF3XJd8c\nBOPGuWKl1FQXHHzppnzefBNyctxYS62rxOwixsSXiGsA072762h32mlwxx3wySfw7bdw223wwAMV\nn0ypzHyEO6NcVWcd5aqnTZvg+OOheXP4+uvYf+CNqW62b4frr3djOzVo4AavvPDC6B0/VEe5Mv8d\nReTKQOmq+nJFM2bMLbe4Zn0zZlhwMCaQ+vVdULj0UmjTpnLvssOpgzjR79ELuAcYEM7BRaS/iCwR\nkeUiMjbEdheJiIpIlrecJiK7RGS+9/hXOOcz1cuHH7oP/u23u6Z9xpjgzjyz8otgwxmsr8QgyyJy\nKDC5rP1EJAWYAPTDjQI7W0RyVHVxqe0aAGOAb0od4idVta+NBLVjB1x9NbRt60a+NMZUPeW5qd8B\ntAxju67AclVdASAik4GBuI52/v6K63h3WznykrByc92tZbt2sTm+KkyZ4gbFi4dvvoG8PPjsM5sd\nzpiqKpw6iHdwrZbAFUmlA1PCOHZT4Be/Zd9cEv7HzgSaq+p7IlI6QLQUkXnAVuAuVf0iQN5G4c1N\nkZpAnRG2b4d+/dz4LYsXuzFcomnbNtfX4M03o3vcSN16qxsG2RhTNYVzB/Go3+u9wCpVXV3RE3u9\ntB8HhgVYvRZIVdWNItIFmC4i7VW1xNQbqjoRmAiuFVNF81RVvPyy60Iv4pqzPf989I69eLFrAbF8\nOTzyiOt/EI9+B74BzIwxVVc4AeJnYK2q/g4gInVEJE1VV5ax3xqgud9yMy/NpwHQAfhU3DfUUUCO\niAxQ1VxgN4CqzhGRn4BjgYRvx1pUBE8/7XpUnnYaPPQQXHaZ62FcUa+/7sY6ql8fPv7Ydec3xphg\nwmnF9AbgPyLIPi+tLLOBtiLSUkQOws1Kl+NbqaoFqnq4qqapahrwNTBAVXNFpIlXyY2ItALakiTz\nYM+YAUuWuHmY777bNWv7wx8OHCQwEoWF7niDB7vWQnPnWnAwxpQtnABRU1X3+Ba81weVtZOq7gWu\nB2YAPwBTVHWRiNwnImU1k+0NLBSR+cCbwGhV3RRGXqu9p56Co492ozPWqeMGsFuxAu65p3zH+/VX\nOPVUd9w//tF12T/mmKhm2RiToMIpYsr3in1yAERkILAhnIOr6vvA+6XS/hJk2z5+r6cCU8M5RyL5\n4Qd3B/HXv7oRHQH69HF3EI895rrcd+kS/vE+/dTts2OHG9tl0KAydzHGmGLh3EGMBu4UkZ9F5Gfg\nDuDq2GYrOT39tJvs/OpS7+7DD8ORR7r6g8LCwPv6U3UV0Kef7saa//ZbCw7GmMiVGSBU9SdV7Y5r\n3pquqier6vLYZy25bNrkxloZMgSaNCm57tBD4ZlnYMECePTRwPv7bN0KF1/seidfcIELDunpscu3\nMSZxlRkgROQBETlUVber6nYRaSQi91dG5pLJ88+7sd3HjAm8/vzz3Rjx997rKrED+f571/rp7bdd\nkdSUKW5wL2OMKY8yR3MVkXmqekKptLmqmhnTnEWoOo/munevm8i8TRs3nG8w69a5kU8PPhiOOurA\n9UuXurHkX3/dOqAZY8JTodFcgRQROVhVd3sHqwMcHM0MJrtp0+CXX+Dvfw+93VFHubuCZ55x9Qyl\ndekC99/vWkEZY0xFhRMgsoGPRWQSILiezy/FMlPJ5skn3R3EueeWvW2/fu5hjDGxFs5org+JyALg\ndNyYTDOAFrHOWLLIzXUTlT/xBKSkxDs3xhizX7ijua7HBYdLgDySsI9CRam6Jqq7du1//P47/O1v\nriJ5xIh459AYY0oKGiBE5FjgUu+xAXgdV6l9aiXlLWH8+KObYHzbtsDrx4yBQw6p3DwZY0xZQt1B\n/Ah8AZzr6/cgIjdVSq4STHa26818331Qr54bQqN2bfdcr150BuIzxphoCxUgLsQNsDdTRP6Dm0Uu\nDgNDV39vveUGx7OZ04wx1UnQjnKqOl1VBwPtgJnAH4EjROSfInJGZWWwuvvxx/1zMBhjTHUSzlAb\nO1T1VVU9DzenwzzceEwmDG+95Z4vuCC++TDGmEiFM1hfMVXdrKoTVfW0WGUo0UydCt27Q9Om8c6J\nMcZEJqIAYSKzcqWbnOeii+KdE2OMiZwFiBiaNs09W/GSMaY6sgARQ1OnQqdO0Lp1vHNijDGRswAR\nI2vXuiE0rHjJGFNdWYCIkbffdsNrWPNWY0x1ZQEiRqZOhWOPtdncjDHVlwWIGNi0CWbOdMVLYn3P\njTHVlAWIGHjnHdi3z4qXjDHVW0wDhIj0F5ElIrJcRMaG2O4iEVERyfJL+5O33xIROTOW+QwkOxvS\n0qBGDfecnR3+vlOnQmqqm+HNGGOqq3Dng4iYiKQAE4B+wGpgtojkqOriUts1AMYA3/ilpeMGCmwP\nHAN8JCLHquq+WOXXX3Y2jBoFO3e65VWr3DLAkCGh9922Df77X7jmGiteMsZUb7G8g+gKLFfVFaq6\nBzca7MAA2/0VeAj43S9tIDBZVXerah6w3DtepRg3bn9w8Nm506WX5f33YfduK14yxlR/sQwQTYFf\n/JZXe2nFRCQTaK6q70W6r7f/KBHJFZHc/Pz86OQa+PnnyNL9vfUWHHkknHxy1LJjjDFxEbMiprKI\nSA3gcWBYeY+hqhOBiQBZWVlanmPs2wfr1pWcBvSII2D9+gO3TU0Nfazff4f33oPLL7f5pY0x1V8s\nA8QaoLnfcjMvzacB0AH4VFxh/VFAjogMCGPfqNmwAZo1K3u7unVh/PjQ2/z3v27mOCteMsYkglgG\niNlAWxFpiftyHwxc5lupqgXA4b5lEfkUuFVVc0VkF/CqiDyOq6RuC3wbi0weeig8+6yb/tP3qF0b\nPv8cnnjCVTofcww8/HDZFdQTJ7q7j1Nt1m5jTAKIWYBQ1b0icj0wA0gBXlDVRSJyH5Crqjkh9l0k\nIlOAxcBe4LpYtWA6+OD9LZT8nXYajB7tipUGDSo7OCxd6oqX7r4batWKRU6NMaZyiWq5iu6rnKys\nLM3NzY36cQcPhhkzYM0aV8wUzA03uDuIVavgqKOing1jjIkJEZmjqlmB1llP6jJcdx1s2QKvvRZ8\nmy1bYNIkF0wsOBhjEoUFiDL07AkdOsCECW501kBeeMFVTo8ZU7l5M8aYWLIAUQYRdxcxbx58882B\n6/ftg7//HXr1gszMys+fMcbEigWIMFx+OTRo4O4iSsvJcXNP//GPlZ4tY4yJKQsQYahfH4YOhSlT\n4LffSq578klo0QIGBhpExBhjqjELEGG69lrYs8fVN/jMm+f6S9xwg/WcNsYkHgsQYTr+eOjbF/71\nL1fvAPDUU1CvHlx1VXzzZowxsWABIgLXXuv6Obz3nhur6bXXYNgw1xvbGGMSTdwG66uOBg6Epk3h\nmWdc8dKePa54yRhjEpEFiAjUrAlXXw1/+Ytr8nr22XDccfHOlTHGxIYVMUVo5EgXKLZssY5xxpjE\nZncQETr6aLjySliwAPr1i3dujDEmdixAlMNzz7lhN2zOaWNMIrMAUQ41rGDOGJME7KvOGGNMQBYg\njDHGBGQBwhhjTEAWIIwxxgRkAcIYY0xAFiCMMcYEZAHCGGNMQBYgjDHGBBTTACEi/UVkiYgsF5Gx\nAdaPFpHvRGS+iHwpIuleepqI7PLS54vIv2KZT2OMMQeKWU9qEUkBJgD9gNXAbBHJUdXFfpu9qqr/\n8rYfADwO9PfW/aSqnWOVP2OMMaHF8g6iK7BcVVeo6h5gMlBi5mZV3eq3WA/QGObHGGNMBGIZIJoC\nv/gtr/bSShCR60TkJ+Bh4Ea/VS1FZJ6IfCYivWKYT2OMMQHEvZJaVSeoamvgDuAuL3ktkKqqJwA3\nA6+KyCGl9xWRUSKSKyK5+fn5lZdpY4xJArEMEGuA5n7Lzby0YCYD5wOo6m5V3ei9ngP8BBxbegdV\nnaiqWaqa1aRJk6hl3BhjTGwDxGygrYi0FJGDgMFAjv8GItLWb/EcYJmX3sSr5EZEWgFtgRUxzKsx\nxphSYtaKSVX3isj1wAwgBXhBVReJyH1ArqrmANeLyOlAIbAZGOrt3hu4T0QKgSJgtKpuilVejTHG\nHEhUE6PhUFZWlubm5sY7G8YYU62IyBxVzQq0Lu6V1MYYY6omCxDGGGMCsgBhjDEmIAsQxhhjArIA\nYYwxJiALEMYYYwKyAGGMMSYgCxDGGGMCsgBhjDEmIAsQxhhjArIAYYwxJiALEMYYYwKyAGGMMSYg\nCxDGGGMCsgBhjDEmIAsQxhhjArIAYYwxJiALEMYYYwKyAGGMMSYgCxDGGGMCsgBhjDEmIAsQxhhj\nAkr6AJGdDWlpUKOGe87OjneOjDGmaohpgBCR/iKyRESWi8jYAOtHi8h3IjJfRL4UkXS/dX/y9lsi\nImfGIn/Z2TBqFKxaBaruedQoCxLGGAMgqhqbA4ukAEuBfsBqYDZwqaou9tvmEFXd6r0eAFyrqv29\nQPEa0BU4BvgIOFZV9wU7X1ZWlubm5kaUx7Q0FxRKa9ECVq6M6FDGGFMticgcVc0KtC6WdxBdgeWq\nukJV9wCTgYH+G/iCg6ce4ItWA4HJqrpbVfOA5d7xournnyNLN8aYZBLLANEU+MVvebWXVoKIXCci\nPwEPAzdGuO8oEckVkdz8/PyIM5iaGlm6McYkk7hXUqvqBFVtDdwB3BXhvhNVNUtVs5o0aRLxuceP\nh7p1S6bVrevSjTEm2cUyQKwBmvstN/PSgpkMnF/OfctlyBCYONHVOYi454kTXboxxiS7WAaI2UBb\nEWkpIgcBg4Ec/w1EpK3f4jnAMu91DjBYRA4WkZZAW+DbWGRyyBBXIV1U5J4tOBhjjFMzVgdW1b0i\ncj0wA0gBXlDVRSJyH5CrqjnA9SJyOlAIbAaGevsuEpEpwGJgL3BdqBZMxhhjoi9mzVwrW3mauRpj\nTLKLVzNXY4wx1ZgFCGOMMQFZgDDGGBNQwtRBiEg+EGDgjBIOBzZUQnaqomS9drvu5GLXHbkWqhqw\nI1nCBIhwiEhusMqYRJes127XnVzsuqPLipiMMcYEZAHCGGNMQMkWICbGOwNxlKzXbtedXOy6oyip\n6iCMMcaEL9nuIIwxxoTJAoQxxpiAkiZAlDU/dqIQkRdE5DcR+d4v7TAR+VBElnnPjeKZx1gQkeYi\nMlNEFovIIhEZ46Un9LWLSG0R+VZEFnjXfa+X3lJEvvE+7697IyonHBFJEZF5IvKut5ws171SRL4T\nkfkikuulRf2znhQBwpsfewJwFpAOXOrNe52IXgT6l0obC3ysqm2Bj73lRLMXuEVV04HuwHXe3zjR\nr3030FdVOwGdgf4i0h14CHhCVdvgRkq+Ko55jKUxwA9+y8ly3QCnqmpnv/4PUf+sJ0WAIIz5sROF\nqn4ObCqVPBB4yXv9EvsnZkoYqrpWVed6r7fhvjSakuDXrs52b7GW91CgL/Cml55w1w0gIs1w88g8\n7y0LSXDdIUT9s54sASKsOa4T2JGqutZ7vQ44Mp6ZiTURSQNOAL4hCa7dK2aZD/wGfAj8BGxR1b3e\nJon6eX8SuB0o8pYbkxzXDe5HwH9FZI6IjPLSov5Zj9mEQaZqUlUVkYRt2ywi9YGpwB9Vdav7Uekk\n6rV7k2l1FpFDgWlAuzhnKeZE5FzgN1WdIyJ94p2fOOipqmtE5AjgQxH50X9ltD7ryXIHUSlzXFdh\n60XkaADv+bc45ycmRKQWLjhkq+pbXnJSXDuAqm4BZgInAYeKiO8HYCJ+3nsAA0RkJa7IuC/wFIl/\n3QCo6hrv+Tfcj4KuxOCzniwBosz5sRNcDt50rt7z23HMS0x45c//D/hBVR/3W5XQ1y4iTbw7B0Sk\nDtAPV/8yE7jY2yzhrltV/6SqzVQ1Dff//ImqDiHBrxtAROqJSAPfa+AM4Hti8FlPmp7UInI2rszS\nNz/2+DhnKSZE5DWgD2743/XA3cB0YAqQihsS/f9UtXRFdrUmIj2BL4Dv2F8mfSeuHiJhr11EMnAV\nkim4H3xTVPU+EWmF+2V9GDAPuFxVd8cvp7HjFTHdqqrnJsN1e9c4zVusCbyqquNFpDFR/qwnTYAw\nxhgTmWQpYjLGGBMhCxDGGGMCsgBhjDEmIAsQxhhjArIAYYwxJiALEMaUQUT2eaNm+h5RG/BPRNL8\nR941piqxoTaMKdsuVe0c70wYU9nsDsKYcvLG5H/YG5f/WxFp46WnicgnIrJQRD4WkVQv/UgRmebN\n3bBARE72DpUiIs958zn81+sRjYjc6M1vsVBEJsfpMk0SswBhTNnqlCpiGuS3rkBVOwL/wPXUB/g7\n8JKqZgDZwNNe+tPAZ97cDZnAIi+9LTBBVdsDW4CLvPSxwAnecUbH6uKMCcZ6UhtTBhHZrqr1A6Sv\nxE3Ws8IbKHCdqjYWkQ3A0apa6KWvVdXDRSQfaOY/9IM3NPmH3iQviMgdQC1VvV9E/gNsxw2VMt1v\n3gdjKoXdQRhTMRrkdST8xwrax/66wXNwMyFmArP9Rik1plJYgDCmYgb5Pf/Pez0LN8IowBDcIILg\npoG8Boon+WkY7KAiUgNorqozgTuAhsABdzHGxJL9IjGmbHW8Gdt8/qOqvqaujURkIe4u4FIv7QZg\nkojcBuQDw730McBEEbkKd6dwDbCWwFKAV7wgIsDT3nwPxlQaq4Mwppy8OogsVd0Q77wYEwtWxGSM\nMSYgu4MwxhgTkN1BGGOMCcgChDHGmIAsQBhjjAnIAoQxxpiALEAYY4wJ6P8Dj70ti9TdsnEAAAAA\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgN-E84SUPUq",
        "colab_type": "text"
      },
      "source": [
        "#Performances on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VokWFUNPJOsJ",
        "colab_type": "code",
        "outputId": "5ac2f97f-a9b5-477f-96f3-1d7a2f30a26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " model = build_model()\n",
        " model.fit(train_data_stand_pca, one_hot_train_labels, epochs= num_epochs, batch_size=10, shuffle=True)\n",
        " test_loss, test_acc = model.evaluate(test_data_stand_pca, one_hot_test_labels)\n",
        "  "
      ],
      "execution_count": 618,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "131/131 [==============================] - 2s 18ms/step - loss: 2.2930 - acc: 0.2672\n",
            "Epoch 2/50\n",
            "131/131 [==============================] - 0s 224us/step - loss: 1.3035 - acc: 0.4122\n",
            "Epoch 3/50\n",
            "131/131 [==============================] - 0s 191us/step - loss: 1.0881 - acc: 0.4962\n",
            "Epoch 4/50\n",
            "131/131 [==============================] - 0s 196us/step - loss: 1.0283 - acc: 0.5038\n",
            "Epoch 5/50\n",
            "131/131 [==============================] - 0s 168us/step - loss: 0.9960 - acc: 0.5038\n",
            "Epoch 6/50\n",
            "131/131 [==============================] - 0s 193us/step - loss: 0.9733 - acc: 0.5267\n",
            "Epoch 7/50\n",
            "131/131 [==============================] - 0s 222us/step - loss: 0.9603 - acc: 0.5573\n",
            "Epoch 8/50\n",
            "131/131 [==============================] - 0s 251us/step - loss: 0.9432 - acc: 0.5344\n",
            "Epoch 9/50\n",
            "131/131 [==============================] - 0s 254us/step - loss: 0.9422 - acc: 0.5573\n",
            "Epoch 10/50\n",
            "131/131 [==============================] - 0s 224us/step - loss: 0.9300 - acc: 0.5573\n",
            "Epoch 11/50\n",
            "131/131 [==============================] - 0s 208us/step - loss: 0.9289 - acc: 0.5649\n",
            "Epoch 12/50\n",
            "131/131 [==============================] - 0s 188us/step - loss: 0.9261 - acc: 0.5573\n",
            "Epoch 13/50\n",
            "131/131 [==============================] - 0s 196us/step - loss: 0.9183 - acc: 0.5573\n",
            "Epoch 14/50\n",
            "131/131 [==============================] - 0s 178us/step - loss: 0.9288 - acc: 0.5878\n",
            "Epoch 15/50\n",
            "131/131 [==============================] - 0s 219us/step - loss: 0.9152 - acc: 0.5954\n",
            "Epoch 16/50\n",
            "131/131 [==============================] - 0s 239us/step - loss: 0.9012 - acc: 0.6031\n",
            "Epoch 17/50\n",
            "131/131 [==============================] - 0s 216us/step - loss: 0.9043 - acc: 0.6031\n",
            "Epoch 18/50\n",
            "131/131 [==============================] - 0s 196us/step - loss: 0.8949 - acc: 0.6107\n",
            "Epoch 19/50\n",
            "131/131 [==============================] - 0s 209us/step - loss: 0.9089 - acc: 0.5878\n",
            "Epoch 20/50\n",
            "131/131 [==============================] - 0s 179us/step - loss: 0.9058 - acc: 0.5878\n",
            "Epoch 21/50\n",
            "131/131 [==============================] - 0s 158us/step - loss: 0.8828 - acc: 0.6183\n",
            "Epoch 22/50\n",
            "131/131 [==============================] - 0s 198us/step - loss: 0.8960 - acc: 0.5954\n",
            "Epoch 23/50\n",
            "131/131 [==============================] - 0s 229us/step - loss: 0.8746 - acc: 0.6183\n",
            "Epoch 24/50\n",
            "131/131 [==============================] - 0s 171us/step - loss: 0.8710 - acc: 0.6565\n",
            "Epoch 25/50\n",
            "131/131 [==============================] - 0s 161us/step - loss: 0.8713 - acc: 0.6336\n",
            "Epoch 26/50\n",
            "131/131 [==============================] - 0s 173us/step - loss: 0.8789 - acc: 0.6183\n",
            "Epoch 27/50\n",
            "131/131 [==============================] - 0s 168us/step - loss: 0.8800 - acc: 0.5649\n",
            "Epoch 28/50\n",
            "131/131 [==============================] - 0s 180us/step - loss: 0.8776 - acc: 0.5954\n",
            "Epoch 29/50\n",
            "131/131 [==============================] - 0s 243us/step - loss: 0.8532 - acc: 0.6412\n",
            "Epoch 30/50\n",
            "131/131 [==============================] - 0s 170us/step - loss: 0.8509 - acc: 0.6183\n",
            "Epoch 31/50\n",
            "131/131 [==============================] - 0s 165us/step - loss: 0.8461 - acc: 0.6260\n",
            "Epoch 32/50\n",
            "131/131 [==============================] - 0s 195us/step - loss: 0.8586 - acc: 0.6107\n",
            "Epoch 33/50\n",
            "131/131 [==============================] - 0s 189us/step - loss: 0.8404 - acc: 0.6489\n",
            "Epoch 34/50\n",
            "131/131 [==============================] - 0s 193us/step - loss: 0.8495 - acc: 0.6183\n",
            "Epoch 35/50\n",
            "131/131 [==============================] - 0s 169us/step - loss: 0.8407 - acc: 0.6260\n",
            "Epoch 36/50\n",
            "131/131 [==============================] - 0s 173us/step - loss: 0.8439 - acc: 0.6107\n",
            "Epoch 37/50\n",
            "131/131 [==============================] - 0s 166us/step - loss: 0.8534 - acc: 0.6107\n",
            "Epoch 38/50\n",
            "131/131 [==============================] - 0s 226us/step - loss: 0.8256 - acc: 0.6183\n",
            "Epoch 39/50\n",
            "131/131 [==============================] - 0s 177us/step - loss: 0.8270 - acc: 0.6107\n",
            "Epoch 40/50\n",
            "131/131 [==============================] - 0s 181us/step - loss: 0.8262 - acc: 0.6260\n",
            "Epoch 41/50\n",
            "131/131 [==============================] - 0s 180us/step - loss: 0.8350 - acc: 0.6260\n",
            "Epoch 42/50\n",
            "131/131 [==============================] - 0s 181us/step - loss: 0.8252 - acc: 0.6412\n",
            "Epoch 43/50\n",
            "131/131 [==============================] - 0s 163us/step - loss: 0.8138 - acc: 0.6260\n",
            "Epoch 44/50\n",
            "131/131 [==============================] - 0s 176us/step - loss: 0.8176 - acc: 0.6489\n",
            "Epoch 45/50\n",
            "131/131 [==============================] - 0s 180us/step - loss: 0.8104 - acc: 0.6336\n",
            "Epoch 46/50\n",
            "131/131 [==============================] - 0s 257us/step - loss: 0.8220 - acc: 0.6031\n",
            "Epoch 47/50\n",
            "131/131 [==============================] - 0s 194us/step - loss: 0.8644 - acc: 0.5649\n",
            "Epoch 48/50\n",
            "131/131 [==============================] - 0s 205us/step - loss: 0.8255 - acc: 0.6107\n",
            "Epoch 49/50\n",
            "131/131 [==============================] - 0s 180us/step - loss: 0.8257 - acc: 0.6183\n",
            "Epoch 50/50\n",
            "131/131 [==============================] - 0s 193us/step - loss: 0.8151 - acc: 0.6031\n",
            "34/34 [==============================] - 1s 28ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-tXqN8teV_6",
        "colab_type": "code",
        "outputId": "7ffff157-d287-41bd-f009-621d235bd68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 619,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'acc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 619
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLqboU_IeYu-",
        "colab_type": "code",
        "outputId": "7296de38-edf7-43fd-b3e3-f3beb02bd486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_acc\n"
      ],
      "execution_count": 620,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23529411764705882"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 620
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpouJxJrfHYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6vvp8uohTYg",
        "colab_type": "code",
        "outputId": "4d9f9c9f-19df-4f40-9a6e-69f108803791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "14*8+8*8+8*3+19"
      ],
      "execution_count": 621,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "219"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 621
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8rJQZmahXMe",
        "colab_type": "code",
        "outputId": "19586da9-1d81-4d75-fcab-2e5139c580bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "14*8"
      ],
      "execution_count": 622,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 622
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxm3zpcahZBc",
        "colab_type": "code",
        "outputId": "8504ceb9-6bf9-4aba-9dc3-2ce44150d43e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "112+25+24"
      ],
      "execution_count": 623,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 623
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uhxnKishcW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ2Es3qdtMT0",
        "colab_type": "code",
        "outputId": "c1f0799d-4590-498a-bd8e-c74faad0590c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip list"
      ],
      "execution_count": 624,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Package                  Version    \n",
            "------------------------ -----------\n",
            "absl-py                  0.8.1      \n",
            "alabaster                0.7.12     \n",
            "albumentations           0.1.12     \n",
            "altair                   4.0.0      \n",
            "asgiref                  3.2.3      \n",
            "astor                    0.8.1      \n",
            "astropy                  3.0.5      \n",
            "atari-py                 0.2.6      \n",
            "atomicwrites             1.3.0      \n",
            "attrs                    19.3.0     \n",
            "audioread                2.1.8      \n",
            "autograd                 1.3        \n",
            "Babel                    2.7.0      \n",
            "backcall                 0.1.0      \n",
            "backports.tempfile       1.0        \n",
            "backports.weakref        1.0.post1  \n",
            "beautifulsoup4           4.6.3      \n",
            "bleach                   3.1.0      \n",
            "blis                     0.2.4      \n",
            "bokeh                    1.0.4      \n",
            "boto                     2.49.0     \n",
            "boto3                    1.10.40    \n",
            "botocore                 1.13.40    \n",
            "Bottleneck               1.3.1      \n",
            "branca                   0.3.1      \n",
            "bs4                      0.0.1      \n",
            "bz2file                  0.98       \n",
            "cachetools               4.0.0      \n",
            "certifi                  2019.11.28 \n",
            "cffi                     1.13.2     \n",
            "chainer                  6.5.0      \n",
            "chardet                  3.0.4      \n",
            "chart-studio             1.0.0      \n",
            "Click                    7.0        \n",
            "cloudpickle              1.2.2      \n",
            "cmake                    3.12.0     \n",
            "colorlover               0.3.0      \n",
            "community                1.0.0b1    \n",
            "contextlib2              0.5.5      \n",
            "convertdate              2.2.0      \n",
            "coverage                 3.7.1      \n",
            "coveralls                0.5        \n",
            "crcmod                   1.7        \n",
            "cufflinks                0.17.0     \n",
            "cvxopt                   1.2.3      \n",
            "cvxpy                    1.0.25     \n",
            "cycler                   0.10.0     \n",
            "cymem                    2.0.3      \n",
            "Cython                   0.29.14    \n",
            "daft                     0.0.4      \n",
            "dask                     1.1.5      \n",
            "dataclasses              0.7        \n",
            "datascience              0.10.6     \n",
            "decorator                4.4.1      \n",
            "defusedxml               0.6.0      \n",
            "descartes                1.1.0      \n",
            "dill                     0.3.1.1    \n",
            "distributed              1.25.3     \n",
            "Django                   3.0        \n",
            "dlib                     19.18.0    \n",
            "dm-sonnet                1.35       \n",
            "docopt                   0.6.2      \n",
            "docutils                 0.15.2     \n",
            "dopamine-rl              1.0.5      \n",
            "earthengine-api          0.1.208    \n",
            "easydict                 1.9        \n",
            "ecos                     2.0.7.post1\n",
            "editdistance             0.5.3      \n",
            "en-core-web-sm           2.1.0      \n",
            "entrypoints              0.3        \n",
            "et-xmlfile               1.0.1      \n",
            "fa2                      0.3.5      \n",
            "fancyimpute              0.4.3      \n",
            "fastai                   1.0.59     \n",
            "fastcache                1.1.0      \n",
            "fastdtw                  0.3.4      \n",
            "fastprogress             0.1.22     \n",
            "fastrlock                0.4        \n",
            "fbprophet                0.5        \n",
            "feather-format           0.4.0      \n",
            "featuretools             0.4.1      \n",
            "filelock                 3.0.12     \n",
            "fix-yahoo-finance        0.0.22     \n",
            "Flask                    1.1.1      \n",
            "folium                   0.8.3      \n",
            "fsspec                   0.6.2      \n",
            "future                   0.16.0     \n",
            "gast                     0.2.2      \n",
            "GDAL                     2.2.2      \n",
            "gdown                    3.6.4      \n",
            "gensim                   3.6.0      \n",
            "geographiclib            1.50       \n",
            "geopy                    1.17.0     \n",
            "gevent                   1.4.0      \n",
            "gin-config               0.2.1      \n",
            "glob2                    0.7        \n",
            "google                   2.0.3      \n",
            "google-api-core          1.15.0     \n",
            "google-api-python-client 1.7.11     \n",
            "google-auth              1.4.2      \n",
            "google-auth-httplib2     0.0.3      \n",
            "google-auth-oauthlib     0.4.1      \n",
            "google-cloud-bigquery    1.21.0     \n",
            "google-cloud-core        1.0.3      \n",
            "google-cloud-datastore   1.8.0      \n",
            "google-cloud-language    1.2.0      \n",
            "google-cloud-storage     1.16.2     \n",
            "google-cloud-translate   1.5.0      \n",
            "google-colab             1.0.0      \n",
            "google-pasta             0.1.8      \n",
            "google-resumable-media   0.4.1      \n",
            "googleapis-common-protos 1.6.0      \n",
            "googledrivedownloader    0.4        \n",
            "graph-nets               1.0.5      \n",
            "graphviz                 0.10.1     \n",
            "greenlet                 0.4.15     \n",
            "grpcio                   1.15.0     \n",
            "gspread                  3.0.1      \n",
            "gspread-dataframe        3.0.3      \n",
            "gunicorn                 20.0.4     \n",
            "gym                      0.15.4     \n",
            "h5py                     2.8.0      \n",
            "HeapDict                 1.0.1      \n",
            "holidays                 0.9.11     \n",
            "html5lib                 1.0.1      \n",
            "httpimport               0.5.18     \n",
            "httplib2                 0.11.3     \n",
            "humanize                 0.5.1      \n",
            "hyperopt                 0.1.2      \n",
            "ideep4py                 2.0.0.post3\n",
            "idna                     2.8        \n",
            "image                    1.5.27     \n",
            "imageio                  2.4.1      \n",
            "imagesize                1.1.0      \n",
            "imbalanced-learn         0.4.3      \n",
            "imblearn                 0.0        \n",
            "imgaug                   0.2.9      \n",
            "importlib-metadata       1.3.0      \n",
            "imutils                  0.5.3      \n",
            "inflect                  2.1.0      \n",
            "intel-openmp             2020.0.133 \n",
            "intervaltree             2.1.0      \n",
            "ipykernel                4.6.1      \n",
            "ipython                  5.5.0      \n",
            "ipython-genutils         0.2.0      \n",
            "ipython-sql              0.3.9      \n",
            "ipywidgets               7.5.1      \n",
            "itsdangerous             1.1.0      \n",
            "jax                      0.1.52     \n",
            "jaxlib                   0.1.36     \n",
            "jdcal                    1.4.1      \n",
            "jedi                     0.15.1     \n",
            "jieba                    0.39       \n",
            "Jinja2                   2.10.3     \n",
            "jmespath                 0.9.4      \n",
            "joblib                   0.14.1     \n",
            "jpeg4py                  0.1.4      \n",
            "jsonschema               2.6.0      \n",
            "jupyter                  1.0.0      \n",
            "jupyter-client           5.3.4      \n",
            "jupyter-console          5.2.0      \n",
            "jupyter-core             4.6.1      \n",
            "kaggle                   1.5.6      \n",
            "kapre                    0.1.3.1    \n",
            "Keras                    2.2.5      \n",
            "Keras-Applications       1.0.8      \n",
            "Keras-Preprocessing      1.1.0      \n",
            "keras-vis                0.4.1      \n",
            "kfac                     0.2.0      \n",
            "kiwisolver               1.1.0      \n",
            "knnimpute                0.1.0      \n",
            "librosa                  0.6.3      \n",
            "lightgbm                 2.2.3      \n",
            "llvmlite                 0.30.0     \n",
            "lmdb                     0.98       \n",
            "lucid                    0.3.8      \n",
            "lunardate                0.2.0      \n",
            "lxml                     4.2.6      \n",
            "magenta                  0.3.19     \n",
            "Markdown                 3.1.1      \n",
            "MarkupSafe               1.1.1      \n",
            "matplotlib               3.1.2      \n",
            "matplotlib-venn          0.11.5     \n",
            "mesh-tensorflow          0.1.7      \n",
            "mido                     1.2.6      \n",
            "mir-eval                 0.5        \n",
            "missingno                0.4.2      \n",
            "mistune                  0.8.4      \n",
            "mizani                   0.5.4      \n",
            "mkl                      2019.0     \n",
            "mlxtend                  0.14.0     \n",
            "more-itertools           8.0.2      \n",
            "moviepy                  0.2.3.5    \n",
            "mpi4py                   3.0.3      \n",
            "mpmath                   1.1.0      \n",
            "msgpack                  0.5.6      \n",
            "multiprocess             0.70.9     \n",
            "multitasking             0.0.9      \n",
            "murmurhash               1.0.2      \n",
            "music21                  5.5.0      \n",
            "natsort                  5.5.0      \n",
            "nbconvert                5.6.1      \n",
            "nbformat                 4.4.0      \n",
            "networkx                 2.4        \n",
            "nibabel                  2.3.3      \n",
            "nltk                     3.2.5      \n",
            "notebook                 5.2.2      \n",
            "np-utils                 0.5.12.1   \n",
            "numba                    0.40.1     \n",
            "numexpr                  2.7.0      \n",
            "numpy                    1.17.4     \n",
            "nvidia-ml-py3            7.352.0    \n",
            "oauth2client             4.1.3      \n",
            "oauthlib                 3.1.0      \n",
            "okgrade                  0.4.3      \n",
            "olefile                  0.46       \n",
            "opencv-contrib-python    4.1.2.30   \n",
            "opencv-python            4.1.2.30   \n",
            "openpyxl                 2.5.9      \n",
            "opt-einsum               3.1.0      \n",
            "osqp                     0.6.1      \n",
            "packaging                19.2       \n",
            "palettable               3.3.0      \n",
            "pandas                   0.25.3     \n",
            "pandas-datareader        0.7.4      \n",
            "pandas-gbq               0.11.0     \n",
            "pandas-profiling         1.4.1      \n",
            "pandocfilters            1.4.2      \n",
            "parso                    0.5.2      \n",
            "pathlib                  1.0.1      \n",
            "patsy                    0.5.1      \n",
            "pexpect                  4.7.0      \n",
            "pickleshare              0.7.5      \n",
            "Pillow                   4.3.0      \n",
            "pip                      19.3.1     \n",
            "pip-tools                4.2.0      \n",
            "plac                     0.9.6      \n",
            "plotly                   4.1.1      \n",
            "plotnine                 0.5.1      \n",
            "pluggy                   0.7.1      \n",
            "portpicker               1.2.0      \n",
            "prefetch-generator       1.0.1      \n",
            "preshed                  2.0.1      \n",
            "pretty-midi              0.2.8      \n",
            "prettytable              0.7.2      \n",
            "progressbar2             3.38.0     \n",
            "prometheus-client        0.7.1      \n",
            "promise                  2.2.1      \n",
            "prompt-toolkit           1.0.18     \n",
            "protobuf                 3.10.0     \n",
            "psutil                   5.4.8      \n",
            "psycopg2                 2.7.6.1    \n",
            "ptyprocess               0.6.0      \n",
            "py                       1.8.0      \n",
            "pyarrow                  0.14.1     \n",
            "pyasn1                   0.4.8      \n",
            "pyasn1-modules           0.2.7      \n",
            "pycocotools              2.0.0      \n",
            "pycparser                2.19       \n",
            "pydata-google-auth       0.2.1      \n",
            "pydot                    1.3.0      \n",
            "pydot-ng                 2.0.0      \n",
            "pydotplus                2.0.2      \n",
            "PyDrive                  1.3.1      \n",
            "pyemd                    0.5.1      \n",
            "pyglet                   1.3.2      \n",
            "Pygments                 2.1.3      \n",
            "pygobject                3.26.1     \n",
            "pymc3                    3.7        \n",
            "PyMeeus                  0.3.6      \n",
            "pymongo                  3.10.0     \n",
            "pymystem3                0.2.0      \n",
            "PyOpenGL                 3.1.4      \n",
            "pyparsing                2.4.5      \n",
            "pypng                    0.0.20     \n",
            "pyrsistent               0.15.6     \n",
            "pysndfile                1.3.8      \n",
            "PySocks                  1.7.1      \n",
            "pystan                   2.19.1.1   \n",
            "pytest                   3.6.4      \n",
            "python-apt               1.6.4      \n",
            "python-chess             0.23.11    \n",
            "python-dateutil          2.6.1      \n",
            "python-louvain           0.13       \n",
            "python-rtmidi            1.3.1      \n",
            "python-slugify           4.0.0      \n",
            "python-utils             2.3.0      \n",
            "pytz                     2018.9     \n",
            "PyWavelets               1.1.1      \n",
            "PyYAML                   3.13       \n",
            "pyzmq                    17.0.0     \n",
            "qtconsole                4.6.0      \n",
            "regex                    2019.12.9  \n",
            "requests                 2.21.0     \n",
            "requests-oauthlib        1.3.0      \n",
            "resampy                  0.2.2      \n",
            "retrying                 1.3.3      \n",
            "rpy2                     2.9.5      \n",
            "rsa                      4.0        \n",
            "s3fs                     0.4.0      \n",
            "s3transfer               0.2.1      \n",
            "scikit-image             0.15.0     \n",
            "scikit-learn             0.21.3     \n",
            "scipy                    1.3.3      \n",
            "screen-resolution-extra  0.0.0      \n",
            "scs                      2.1.1.post2\n",
            "seaborn                  0.9.0      \n",
            "semantic-version         2.8.3      \n",
            "Send2Trash               1.5.0      \n",
            "setuptools               42.0.2     \n",
            "setuptools-git           1.2        \n",
            "Shapely                  1.6.4.post2\n",
            "simplegeneric            0.8.1      \n",
            "six                      1.12.0     \n",
            "sklearn                  0.0        \n",
            "sklearn-pandas           1.8.0      \n",
            "smart-open               1.9.0      \n",
            "snowballstemmer          2.0.0      \n",
            "sortedcontainers         2.1.0      \n",
            "spacy                    2.1.9      \n",
            "Sphinx                   1.8.5      \n",
            "sphinxcontrib-websupport 1.1.2      \n",
            "SQLAlchemy               1.3.12     \n",
            "sqlparse                 0.3.0      \n",
            "srsly                    0.2.0      \n",
            "stable-baselines         2.2.1      \n",
            "statsmodels              0.10.2     \n",
            "sympy                    1.1.1      \n",
            "tables                   3.4.4      \n",
            "tabulate                 0.8.6      \n",
            "tblib                    1.6.0      \n",
            "tensor2tensor            1.14.1     \n",
            "tensorboard              1.15.0     \n",
            "tensorboardcolab         0.0.22     \n",
            "tensorflow               1.15.0     \n",
            "tensorflow-datasets      1.3.2      \n",
            "tensorflow-estimator     1.15.1     \n",
            "tensorflow-gan           2.0.0      \n",
            "tensorflow-hub           0.7.0      \n",
            "tensorflow-metadata      0.15.1     \n",
            "tensorflow-privacy       0.2.2      \n",
            "tensorflow-probability   0.7.0      \n",
            "termcolor                1.1.0      \n",
            "terminado                0.8.3      \n",
            "testpath                 0.4.4      \n",
            "text-unidecode           1.3        \n",
            "textblob                 0.15.3     \n",
            "textgenrnn               1.4.1      \n",
            "tflearn                  0.3.2      \n",
            "Theano                   1.0.4      \n",
            "thinc                    7.0.8      \n",
            "toolz                    0.10.0     \n",
            "torch                    1.3.1      \n",
            "torchsummary             1.5.1      \n",
            "torchtext                0.3.1      \n",
            "torchvision              0.4.2      \n",
            "tornado                  4.5.3      \n",
            "tqdm                     4.28.1     \n",
            "traitlets                4.3.3      \n",
            "tweepy                   3.6.0      \n",
            "typing                   3.6.6      \n",
            "typing-extensions        3.6.6      \n",
            "tzlocal                  1.5.1      \n",
            "umap-learn               0.3.10     \n",
            "uritemplate              3.0.0      \n",
            "urllib3                  1.24.3     \n",
            "vega-datasets            0.7.0      \n",
            "wasabi                   0.4.2      \n",
            "wcwidth                  0.1.7      \n",
            "webencodings             0.5.1      \n",
            "Werkzeug                 0.16.0     \n",
            "wheel                    0.33.6     \n",
            "widgetsnbextension       3.5.1      \n",
            "wordcloud                1.5.0      \n",
            "wrapt                    1.11.2     \n",
            "xarray                   0.11.3     \n",
            "xgboost                  0.90       \n",
            "xkit                     0.0.0      \n",
            "xlrd                     1.1.0      \n",
            "xlwt                     1.3.0      \n",
            "yellowbrick              0.9.1      \n",
            "zict                     1.0.0      \n",
            "zipp                     0.6.0      \n",
            "zmq                      0.0.0      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_62EAOsnEUl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}