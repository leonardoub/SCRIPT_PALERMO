{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_optimization_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/Hyperparameter_optimization_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YN6Hc9lFNNk",
        "colab_type": "text"
      },
      "source": [
        "#Optimization of hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py6sopCQLbAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab62dfc8-d881-46d5-890a-9df1c9e42ae0"
      },
      "source": [
        "!pip install -U keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/93/5db8ac61f6547ce94b534a1cf614961a6e302559f0cdd1b37248052c9761/keras_tuner-1.0.0-py2.py3-none-any.whl (88kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.21.3)\n",
            "Collecting tensorflow>=2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/44/4e8cc8c84cf235628ee919ba97ee029f2d080fa3573e26fe726973d004b4/tensorflow-2.1.0rc2-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.6)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.28.1)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (3.10.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.1.8)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow>=2.0.0-beta1->keras-tuner) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.4.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=2.0.0-beta1->keras-tuner) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.4.8)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15354 sha256=003bd9dad3f4d433ff3f26a10eaa258b3a54d8e7b340804d3c97ece1c026de43\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built terminaltables\n",
            "\u001b[31mERROR: tensorflow 2.1.0rc2 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow, colorama, terminaltables, keras-tuner\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed colorama-0.4.3 google-auth-1.10.0 keras-tuner-1.0.0 tensorboard-2.1.0 tensorflow-2.1.0rc2 tensorflow-estimator-2.1.0 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck9uZtF_gzU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "ef5d651b-9762-4978-bd28-fbbcf68d4f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-87QSVhqhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSbeCedhuxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbcwLGg3iNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQdR4izXiT0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5wIylYmsQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = df_test.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data_stand = train_data - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVOoNOvm0Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_stand = test_data - mean\n",
        "test_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00VohsAyokpq",
        "colab_type": "text"
      },
      "source": [
        "##Vettorizzare i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvS_9ISpxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={'adenocarcinoma':0, 'large cell':1, 'squamous cell carcinoma':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPW9U0XrWY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_dec = [word_index[label] for label in train_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4SBiKFQsKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels_dec = [word_index[label] for label in test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMbTYR7okJq",
        "colab_type": "code",
        "outputId": "da2c10fe-0864-489e-ce85-39f92158883e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Frv4FDNn6Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels_dec)\n",
        "one_hot_test_labels = to_categorical(test_labels_dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn0tkOGc3LKN",
        "colab_type": "text"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS76u6iu3Seg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjC4zqJ3bui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.9, svd_solver='full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLUCf9qX4p_e",
        "colab_type": "code",
        "outputId": "c795e550-b221-4ad4-b86a-719df2969313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pca.fit(train_data_stand)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyaKgNZ44o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_pca = pca.transform(train_data_stand)\n",
        "test_data_stand_pca = pca.transform(test_data_stand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9C4nl05b_g",
        "colab_type": "code",
        "outputId": "8ab8e7c8-e5c4-4f2f-a7f5-62047b7fa241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_data_stand_pca.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSKvSu4s5ip",
        "colab_type": "text"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osgm8ZvLpZh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTbHiq0D-4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAzbu7P1VylY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqbUCK5wOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KutkQ9Noj5mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hp):\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(layers.Dense(units=(hp.Int('units', min_value=3, max_value=8, step=1)), \n",
        "                         activation='relu', input_shape=(9,)))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIxDu50pBeiz",
        "colab_type": "text"
      },
      "source": [
        "#Stratified k-fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyLcvedUBpxA",
        "colab_type": "text"
      },
      "source": [
        "This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1apcZ19gFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBDM-PtBx5V",
        "colab_type": "code",
        "outputId": "67ed7dcb-4f38-4ffc-ad36-d722e42b55cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "skf.get_n_splits(train_data_stand_pca, train_labels_dec)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "0c066549-ba97-45e9-b1f7-2d6805440a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "for train_index, test_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  0   1   4   5   8   9  11  12  14  15  16  17  19  20  22  23  24  25\n",
            "  27  29  30  33  34  36  37  38  39  40  41  42  44  45  46  48  51  52\n",
            "  53  56  57  58  59  60  62  63  65  66  67  69  72  76  77  78  79  80\n",
            "  81  83  84  85  87  88  89  90  92  96  97  98 100 101 102 103 104 105\n",
            " 107 109 110 111 113 115 117 120 121 122 124 125 127 128] TEST: [  2   3   6   7  10  13  18  21  26  28  31  32  35  43  47  49  50  54\n",
            "  55  61  64  68  70  71  73  74  75  82  86  91  93  94  95  99 106 108\n",
            " 112 114 116 118 119 123 126 129 130]\n",
            "TRAIN: [  2   3   5   6   7   8   9  10  11  12  13  18  20  21  25  26  27  28\n",
            "  29  30  31  32  34  35  36  38  39  43  44  45  46  47  48  49  50  53\n",
            "  54  55  57  58  61  63  64  65  66  68  70  71  73  74  75  76  78  82\n",
            "  84  85  86  87  90  91  92  93  94  95  96  99 100 101 102 105 106 108\n",
            " 109 111 112 114 115 116 118 119 122 123 124 125 126 127 129 130] TEST: [  0   1   4  14  15  16  17  19  22  23  24  33  37  40  41  42  51  52\n",
            "  56  59  60  62  67  69  72  77  79  80  81  83  88  89  97  98 103 104\n",
            " 107 110 113 117 120 121 128]\n",
            "TRAIN: [  0   1   2   3   4   6   7  10  13  14  15  16  17  18  19  21  22  23\n",
            "  24  26  28  31  32  33  35  37  40  41  42  43  47  49  50  51  52  54\n",
            "  55  56  59  60  61  62  64  67  68  69  70  71  72  73  74  75  77  79\n",
            "  80  81  82  83  86  88  89  91  93  94  95  97  98  99 103 104 106 107\n",
            " 108 110 112 113 114 116 117 118 119 120 121 123 126 128 129 130] TEST: [  5   8   9  11  12  20  25  27  29  30  34  36  38  39  44  45  46  48\n",
            "  53  57  58  63  65  66  76  78  84  85  87  90  92  96 100 101 102 105\n",
            " 109 111 115 122 124 125 127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgdGK-8FK-U_",
        "colab_type": "code",
        "outputId": "3f96db52-83b8-43e5-a085-e2e4942d45b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels_dec[125]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJg0XD4Shhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Sq8r9GEPx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "#  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "#  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "\n",
        "#  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "#  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "#  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "#  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        "#  model = build_model()\n",
        "#  model.fit(partial_train_data, one_hot_partial_train_targets, epochs = num_epochs, batch_size=1)\n",
        "\n",
        "#  val_loss, val_accuracy = model.evaluate(val_data, one_hot_val_targets)\n",
        "#  all_scores.append(val_accuracy)\n",
        "#I parametri per la valutazione vengono calcolati una volta per ogni k-fold, per ogni set di validazione, quindi k volte"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X5B3lasRcsR",
        "colab_type": "text"
      },
      "source": [
        "C'è un problema: keras.utils.to_categorical produces a one-hot encoded class vector, i.e. the multilabel-indicator mentioned in the error message. StratifiedKFold is not designed to work with such input; i.e. your y must be a 1-D array of your class labels.\n",
        "Essentially, what you have to do is simply to invert the order of the operations: split first (using your intial y_train), and convert to_categorical afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8a1I3yU9FS",
        "colab_type": "code",
        "outputId": "60ede8be-0a67-4f1b-8c51-aabaaaaa0411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 50\n",
        "all_acc_histories = []\n",
        "all_loss_histories = []\n",
        "all_val_acc_histories = []\n",
        "all_val_loss_histories = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        " \n",
        "  tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=5, \n",
        "                       executions_per_trial=3, directory='/content/my_dir', project_name='helloworld')\n",
        "  \n",
        "  tuner.search_space_summary()\n",
        "\n",
        "  tuner.search(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=10)\n",
        "  \n",
        "\n",
        "#  acc_history = history.history['acc']\n",
        "#  all_acc_histories.append(acc_history)\n",
        "\n",
        "#  loss_history = history.history['loss']\n",
        "#  all_loss_histories.append(loss_history)\n",
        "\n",
        "#  acc_val_history = history.history['val_acc']\n",
        "#  all_val_acc_histories.append(acc_val_history)\n",
        "\n",
        "#  loss_val_history = history.history['val_loss']\n",
        "#  all_val_loss_histories.append(loss_val_history)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali è una lista lunga num_epochs,\n",
        "#ogni elemento può essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-max_value: 8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-min_value: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-sampling: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-step: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.1728 - accuracy: 0.5000 - val_loss: 2.4077 - val_accuracy: 0.3111\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 2.0917 - accuracy: 0.5000 - val_loss: 2.3247 - val_accuracy: 0.3111\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 374us/sample - loss: 2.0118 - accuracy: 0.5000 - val_loss: 2.2488 - val_accuracy: 0.3111\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.9415 - accuracy: 0.5116 - val_loss: 2.1745 - val_accuracy: 0.3111\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.8734 - accuracy: 0.5116 - val_loss: 2.1077 - val_accuracy: 0.2889\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.8121 - accuracy: 0.5000 - val_loss: 2.0476 - val_accuracy: 0.2889\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 1.7569 - accuracy: 0.4884 - val_loss: 1.9918 - val_accuracy: 0.3111\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 508us/sample - loss: 1.7039 - accuracy: 0.4767 - val_loss: 1.9409 - val_accuracy: 0.3111\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.6565 - accuracy: 0.4884 - val_loss: 1.8923 - val_accuracy: 0.3111\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.6139 - accuracy: 0.4884 - val_loss: 1.8472 - val_accuracy: 0.3111\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 1.5751 - accuracy: 0.4884 - val_loss: 1.8062 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 1.5379 - accuracy: 0.5116 - val_loss: 1.7676 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 657us/sample - loss: 1.5051 - accuracy: 0.5116 - val_loss: 1.7302 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.4747 - accuracy: 0.5116 - val_loss: 1.6971 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 357us/sample - loss: 1.4471 - accuracy: 0.5116 - val_loss: 1.6682 - val_accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.4215 - accuracy: 0.5116 - val_loss: 1.6396 - val_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 518us/sample - loss: 1.3954 - accuracy: 0.5116 - val_loss: 1.6103 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.3709 - accuracy: 0.5116 - val_loss: 1.5833 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 1.3499 - accuracy: 0.5116 - val_loss: 1.5591 - val_accuracy: 0.3333\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.3300 - accuracy: 0.5116 - val_loss: 1.5352 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.3112 - accuracy: 0.5233 - val_loss: 1.5124 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.2952 - accuracy: 0.5233 - val_loss: 1.4913 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 534us/sample - loss: 1.2798 - accuracy: 0.5233 - val_loss: 1.4734 - val_accuracy: 0.3556\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 1.2652 - accuracy: 0.5233 - val_loss: 1.4564 - val_accuracy: 0.3556\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 502us/sample - loss: 1.2518 - accuracy: 0.5116 - val_loss: 1.4390 - val_accuracy: 0.3778\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 516us/sample - loss: 1.2399 - accuracy: 0.5233 - val_loss: 1.4229 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.2291 - accuracy: 0.5233 - val_loss: 1.4074 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.2178 - accuracy: 0.5233 - val_loss: 1.3944 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 1.2075 - accuracy: 0.5349 - val_loss: 1.3814 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.1972 - accuracy: 0.5233 - val_loss: 1.3683 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 527us/sample - loss: 1.1884 - accuracy: 0.5233 - val_loss: 1.3559 - val_accuracy: 0.4222\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.1791 - accuracy: 0.5116 - val_loss: 1.3447 - val_accuracy: 0.4222\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 514us/sample - loss: 1.1687 - accuracy: 0.5116 - val_loss: 1.3345 - val_accuracy: 0.4444\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 1.1621 - accuracy: 0.5116 - val_loss: 1.3240 - val_accuracy: 0.4444\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.1544 - accuracy: 0.5116 - val_loss: 1.3139 - val_accuracy: 0.4444\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 1.1461 - accuracy: 0.5233 - val_loss: 1.3041 - val_accuracy: 0.4444\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 1.1388 - accuracy: 0.5233 - val_loss: 1.2956 - val_accuracy: 0.4444\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.1317 - accuracy: 0.5233 - val_loss: 1.2882 - val_accuracy: 0.4444\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.1250 - accuracy: 0.5233 - val_loss: 1.2812 - val_accuracy: 0.4444\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.1177 - accuracy: 0.5233 - val_loss: 1.2729 - val_accuracy: 0.4444\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.1117 - accuracy: 0.5233 - val_loss: 1.2653 - val_accuracy: 0.4444\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.1053 - accuracy: 0.5233 - val_loss: 1.2584 - val_accuracy: 0.4444\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 382us/sample - loss: 1.1001 - accuracy: 0.5233 - val_loss: 1.2518 - val_accuracy: 0.4444\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.0951 - accuracy: 0.5233 - val_loss: 1.2451 - val_accuracy: 0.4444\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.0888 - accuracy: 0.5116 - val_loss: 1.2379 - val_accuracy: 0.4444\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.0841 - accuracy: 0.5116 - val_loss: 1.2310 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 1.0806 - accuracy: 0.5116 - val_loss: 1.2247 - val_accuracy: 0.4444\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 1.0745 - accuracy: 0.5116 - val_loss: 1.2184 - val_accuracy: 0.4444\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 515us/sample - loss: 1.0699 - accuracy: 0.5116 - val_loss: 1.2120 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.0646 - accuracy: 0.5116 - val_loss: 1.2062 - val_accuracy: 0.4667\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 1.7029 - accuracy: 0.3837 - val_loss: 2.0058 - val_accuracy: 0.4222\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 1.6379 - accuracy: 0.3953 - val_loss: 1.9293 - val_accuracy: 0.4222\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.5782 - accuracy: 0.4070 - val_loss: 1.8644 - val_accuracy: 0.4222\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.5281 - accuracy: 0.4186 - val_loss: 1.8054 - val_accuracy: 0.4222\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.4833 - accuracy: 0.4186 - val_loss: 1.7529 - val_accuracy: 0.4222\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 1.4453 - accuracy: 0.4186 - val_loss: 1.7062 - val_accuracy: 0.4222\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.4105 - accuracy: 0.4186 - val_loss: 1.6658 - val_accuracy: 0.4222\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.3809 - accuracy: 0.4302 - val_loss: 1.6311 - val_accuracy: 0.4222\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 1.3515 - accuracy: 0.4302 - val_loss: 1.6019 - val_accuracy: 0.4222\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.3272 - accuracy: 0.4419 - val_loss: 1.5745 - val_accuracy: 0.4444\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.3026 - accuracy: 0.4419 - val_loss: 1.5443 - val_accuracy: 0.4444\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.2792 - accuracy: 0.4651 - val_loss: 1.5163 - val_accuracy: 0.4444\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.2571 - accuracy: 0.4651 - val_loss: 1.4901 - val_accuracy: 0.4444\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.2394 - accuracy: 0.4651 - val_loss: 1.4688 - val_accuracy: 0.4444\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.2219 - accuracy: 0.4651 - val_loss: 1.4506 - val_accuracy: 0.4444\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.2055 - accuracy: 0.4651 - val_loss: 1.4324 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.1916 - accuracy: 0.4651 - val_loss: 1.4167 - val_accuracy: 0.4889\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.1787 - accuracy: 0.4535 - val_loss: 1.4018 - val_accuracy: 0.4889\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 1.1670 - accuracy: 0.4535 - val_loss: 1.3879 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 1.1557 - accuracy: 0.4419 - val_loss: 1.3764 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 1.1441 - accuracy: 0.4535 - val_loss: 1.3672 - val_accuracy: 0.4889\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 1.1347 - accuracy: 0.4535 - val_loss: 1.3559 - val_accuracy: 0.5111\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.1248 - accuracy: 0.4419 - val_loss: 1.3455 - val_accuracy: 0.5111\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.1169 - accuracy: 0.4419 - val_loss: 1.3377 - val_accuracy: 0.5111\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.1083 - accuracy: 0.4535 - val_loss: 1.3306 - val_accuracy: 0.5111\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.1006 - accuracy: 0.4535 - val_loss: 1.3228 - val_accuracy: 0.5111\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0939 - accuracy: 0.4535 - val_loss: 1.3138 - val_accuracy: 0.5111\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.0868 - accuracy: 0.4535 - val_loss: 1.3058 - val_accuracy: 0.5111\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 1.0797 - accuracy: 0.4419 - val_loss: 1.2996 - val_accuracy: 0.5111\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 1.0749 - accuracy: 0.4651 - val_loss: 1.2938 - val_accuracy: 0.5111\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 1.0682 - accuracy: 0.4767 - val_loss: 1.2876 - val_accuracy: 0.5111\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 1.0627 - accuracy: 0.4884 - val_loss: 1.2825 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.0582 - accuracy: 0.4884 - val_loss: 1.2781 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.0535 - accuracy: 0.4884 - val_loss: 1.2727 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.0487 - accuracy: 0.4767 - val_loss: 1.2677 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.0449 - accuracy: 0.4767 - val_loss: 1.2623 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.0404 - accuracy: 0.4767 - val_loss: 1.2571 - val_accuracy: 0.4889\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 1.0368 - accuracy: 0.4767 - val_loss: 1.2535 - val_accuracy: 0.4889\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.0331 - accuracy: 0.4884 - val_loss: 1.2510 - val_accuracy: 0.4889\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 1.0300 - accuracy: 0.4767 - val_loss: 1.2468 - val_accuracy: 0.4889\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0261 - accuracy: 0.4651 - val_loss: 1.2428 - val_accuracy: 0.4889\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.0231 - accuracy: 0.4884 - val_loss: 1.2377 - val_accuracy: 0.5111\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.0202 - accuracy: 0.4884 - val_loss: 1.2344 - val_accuracy: 0.5111\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 1.0170 - accuracy: 0.4767 - val_loss: 1.2313 - val_accuracy: 0.5111\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.0145 - accuracy: 0.4767 - val_loss: 1.2290 - val_accuracy: 0.5111\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.0109 - accuracy: 0.4884 - val_loss: 1.2253 - val_accuracy: 0.5111\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 1.0084 - accuracy: 0.4767 - val_loss: 1.2215 - val_accuracy: 0.5111\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 1.0064 - accuracy: 0.4884 - val_loss: 1.2182 - val_accuracy: 0.4889\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.0029 - accuracy: 0.5116 - val_loss: 1.2150 - val_accuracy: 0.4889\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.0013 - accuracy: 0.5233 - val_loss: 1.2128 - val_accuracy: 0.4889\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 3.3042 - accuracy: 0.2442 - val_loss: 2.3973 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 3.0599 - accuracy: 0.2442 - val_loss: 2.2872 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 2.8281 - accuracy: 0.2674 - val_loss: 2.2057 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 2.6291 - accuracy: 0.2791 - val_loss: 2.1477 - val_accuracy: 0.3778\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 2.4547 - accuracy: 0.2907 - val_loss: 2.0897 - val_accuracy: 0.3778\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 2.3094 - accuracy: 0.3372 - val_loss: 2.0410 - val_accuracy: 0.4222\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 388us/sample - loss: 2.1925 - accuracy: 0.3488 - val_loss: 1.9952 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 2.0920 - accuracy: 0.3605 - val_loss: 1.9524 - val_accuracy: 0.4222\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 2.0063 - accuracy: 0.3953 - val_loss: 1.9184 - val_accuracy: 0.4444\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 374us/sample - loss: 1.9280 - accuracy: 0.4070 - val_loss: 1.8869 - val_accuracy: 0.4444\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.8635 - accuracy: 0.4419 - val_loss: 1.8548 - val_accuracy: 0.4667\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.8057 - accuracy: 0.4419 - val_loss: 1.8253 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.7516 - accuracy: 0.4302 - val_loss: 1.7932 - val_accuracy: 0.4667\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.7038 - accuracy: 0.4302 - val_loss: 1.7644 - val_accuracy: 0.4667\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.6611 - accuracy: 0.4302 - val_loss: 1.7376 - val_accuracy: 0.4667\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.6218 - accuracy: 0.4186 - val_loss: 1.7132 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.5836 - accuracy: 0.4186 - val_loss: 1.6876 - val_accuracy: 0.4667\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 1.5522 - accuracy: 0.4302 - val_loss: 1.6628 - val_accuracy: 0.4222\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.5215 - accuracy: 0.4302 - val_loss: 1.6383 - val_accuracy: 0.4222\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.4895 - accuracy: 0.4535 - val_loss: 1.6154 - val_accuracy: 0.4222\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.4619 - accuracy: 0.4535 - val_loss: 1.5915 - val_accuracy: 0.4444\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.4390 - accuracy: 0.4535 - val_loss: 1.5676 - val_accuracy: 0.4444\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.4122 - accuracy: 0.4651 - val_loss: 1.5466 - val_accuracy: 0.4444\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.3917 - accuracy: 0.4651 - val_loss: 1.5278 - val_accuracy: 0.4444\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 388us/sample - loss: 1.3678 - accuracy: 0.4651 - val_loss: 1.5094 - val_accuracy: 0.4444\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.3452 - accuracy: 0.4767 - val_loss: 1.4928 - val_accuracy: 0.4444\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.3260 - accuracy: 0.4651 - val_loss: 1.4748 - val_accuracy: 0.4444\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 1.3062 - accuracy: 0.4651 - val_loss: 1.4584 - val_accuracy: 0.4444\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.2905 - accuracy: 0.4767 - val_loss: 1.4436 - val_accuracy: 0.4444\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.2722 - accuracy: 0.4884 - val_loss: 1.4276 - val_accuracy: 0.4667\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.2566 - accuracy: 0.4884 - val_loss: 1.4111 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.2408 - accuracy: 0.4767 - val_loss: 1.3963 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.2276 - accuracy: 0.4767 - val_loss: 1.3831 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.2140 - accuracy: 0.5000 - val_loss: 1.3698 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.2013 - accuracy: 0.5000 - val_loss: 1.3589 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.1877 - accuracy: 0.5233 - val_loss: 1.3493 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 489us/sample - loss: 1.1769 - accuracy: 0.5233 - val_loss: 1.3377 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 575us/sample - loss: 1.1660 - accuracy: 0.5233 - val_loss: 1.3264 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 1.1562 - accuracy: 0.5116 - val_loss: 1.3147 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.1456 - accuracy: 0.5116 - val_loss: 1.3038 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 1.1355 - accuracy: 0.5116 - val_loss: 1.2948 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.1280 - accuracy: 0.5000 - val_loss: 1.2857 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.1203 - accuracy: 0.5116 - val_loss: 1.2775 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.1120 - accuracy: 0.5116 - val_loss: 1.2688 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.1048 - accuracy: 0.5233 - val_loss: 1.2612 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.0967 - accuracy: 0.5233 - val_loss: 1.2535 - val_accuracy: 0.4667\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.0903 - accuracy: 0.5233 - val_loss: 1.2457 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.0852 - accuracy: 0.5233 - val_loss: 1.2389 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.0778 - accuracy: 0.5233 - val_loss: 1.2319 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.0702 - accuracy: 0.5233 - val_loss: 1.2254 - val_accuracy: 0.4667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 5</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.48148152232170105</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.1155 - accuracy: 0.3372 - val_loss: 1.6294 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 2.0154 - accuracy: 0.3256 - val_loss: 1.5843 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.9289 - accuracy: 0.3256 - val_loss: 1.5428 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 366us/sample - loss: 1.8520 - accuracy: 0.3605 - val_loss: 1.5052 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.7864 - accuracy: 0.3488 - val_loss: 1.4737 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.7311 - accuracy: 0.3721 - val_loss: 1.4448 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.6801 - accuracy: 0.3837 - val_loss: 1.4194 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.6377 - accuracy: 0.4186 - val_loss: 1.3959 - val_accuracy: 0.3778\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 1.5963 - accuracy: 0.4186 - val_loss: 1.3724 - val_accuracy: 0.3778\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.5583 - accuracy: 0.4070 - val_loss: 1.3505 - val_accuracy: 0.3556\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.5188 - accuracy: 0.4302 - val_loss: 1.3312 - val_accuracy: 0.3556\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 1.4854 - accuracy: 0.4535 - val_loss: 1.3144 - val_accuracy: 0.3556\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.4536 - accuracy: 0.4651 - val_loss: 1.2992 - val_accuracy: 0.3556\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 357us/sample - loss: 1.4239 - accuracy: 0.4651 - val_loss: 1.2847 - val_accuracy: 0.3556\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.3972 - accuracy: 0.4651 - val_loss: 1.2708 - val_accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.3736 - accuracy: 0.4535 - val_loss: 1.2586 - val_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.3490 - accuracy: 0.4651 - val_loss: 1.2471 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 352us/sample - loss: 1.3285 - accuracy: 0.4767 - val_loss: 1.2390 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.3088 - accuracy: 0.4767 - val_loss: 1.2323 - val_accuracy: 0.3556\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.2900 - accuracy: 0.4884 - val_loss: 1.2272 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.2729 - accuracy: 0.4651 - val_loss: 1.2215 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.2544 - accuracy: 0.4767 - val_loss: 1.2162 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.2417 - accuracy: 0.4767 - val_loss: 1.2101 - val_accuracy: 0.3333\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 1.2285 - accuracy: 0.4651 - val_loss: 1.2050 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 1.2154 - accuracy: 0.4651 - val_loss: 1.2012 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 360us/sample - loss: 1.2052 - accuracy: 0.4651 - val_loss: 1.1969 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 380us/sample - loss: 1.1949 - accuracy: 0.4535 - val_loss: 1.1935 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.1843 - accuracy: 0.4535 - val_loss: 1.1903 - val_accuracy: 0.3333\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.1760 - accuracy: 0.4535 - val_loss: 1.1866 - val_accuracy: 0.3333\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.1680 - accuracy: 0.4419 - val_loss: 1.1842 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 1.1594 - accuracy: 0.4535 - val_loss: 1.1817 - val_accuracy: 0.3333\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.1516 - accuracy: 0.4535 - val_loss: 1.1778 - val_accuracy: 0.3333\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.1459 - accuracy: 0.4651 - val_loss: 1.1744 - val_accuracy: 0.3556\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.1374 - accuracy: 0.4651 - val_loss: 1.1720 - val_accuracy: 0.3556\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 1.1310 - accuracy: 0.4419 - val_loss: 1.1698 - val_accuracy: 0.3778\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.1242 - accuracy: 0.4419 - val_loss: 1.1678 - val_accuracy: 0.3778\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1171 - accuracy: 0.4419 - val_loss: 1.1659 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 370us/sample - loss: 1.1117 - accuracy: 0.4302 - val_loss: 1.1637 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.1064 - accuracy: 0.4302 - val_loss: 1.1616 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 505us/sample - loss: 1.1029 - accuracy: 0.4302 - val_loss: 1.1596 - val_accuracy: 0.4222\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.0972 - accuracy: 0.4419 - val_loss: 1.1575 - val_accuracy: 0.4222\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0928 - accuracy: 0.4419 - val_loss: 1.1559 - val_accuracy: 0.4222\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.0879 - accuracy: 0.4419 - val_loss: 1.1540 - val_accuracy: 0.4222\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.0841 - accuracy: 0.4535 - val_loss: 1.1522 - val_accuracy: 0.4222\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.0806 - accuracy: 0.4419 - val_loss: 1.1507 - val_accuracy: 0.4222\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.0761 - accuracy: 0.4651 - val_loss: 1.1491 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.0715 - accuracy: 0.4651 - val_loss: 1.1477 - val_accuracy: 0.4444\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.0679 - accuracy: 0.4884 - val_loss: 1.1460 - val_accuracy: 0.4444\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.0644 - accuracy: 0.4767 - val_loss: 1.1444 - val_accuracy: 0.4444\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 1.0611 - accuracy: 0.4884 - val_loss: 1.1429 - val_accuracy: 0.4444\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.5038 - accuracy: 0.3837 - val_loss: 2.7938 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 2.3720 - accuracy: 0.3837 - val_loss: 2.6361 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 349us/sample - loss: 2.2425 - accuracy: 0.3953 - val_loss: 2.4920 - val_accuracy: 0.4222\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 2.1288 - accuracy: 0.3953 - val_loss: 2.3678 - val_accuracy: 0.4444\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 386us/sample - loss: 2.0294 - accuracy: 0.3837 - val_loss: 2.2570 - val_accuracy: 0.4444\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.9436 - accuracy: 0.4070 - val_loss: 2.1638 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.8635 - accuracy: 0.4070 - val_loss: 2.0783 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.7888 - accuracy: 0.4070 - val_loss: 2.0007 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.7152 - accuracy: 0.4186 - val_loss: 1.9248 - val_accuracy: 0.4444\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 1.6530 - accuracy: 0.4302 - val_loss: 1.8596 - val_accuracy: 0.4222\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.5934 - accuracy: 0.4419 - val_loss: 1.7999 - val_accuracy: 0.4222\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.5429 - accuracy: 0.4419 - val_loss: 1.7438 - val_accuracy: 0.4222\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 363us/sample - loss: 1.4926 - accuracy: 0.4535 - val_loss: 1.6913 - val_accuracy: 0.4222\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 372us/sample - loss: 1.4504 - accuracy: 0.4535 - val_loss: 1.6466 - val_accuracy: 0.4222\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 370us/sample - loss: 1.4117 - accuracy: 0.4535 - val_loss: 1.6056 - val_accuracy: 0.4222\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 361us/sample - loss: 1.3768 - accuracy: 0.4767 - val_loss: 1.5691 - val_accuracy: 0.4444\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 364us/sample - loss: 1.3481 - accuracy: 0.4767 - val_loss: 1.5389 - val_accuracy: 0.4444\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 364us/sample - loss: 1.3229 - accuracy: 0.4767 - val_loss: 1.5112 - val_accuracy: 0.4444\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 347us/sample - loss: 1.3004 - accuracy: 0.4767 - val_loss: 1.4836 - val_accuracy: 0.4444\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 356us/sample - loss: 1.2752 - accuracy: 0.4884 - val_loss: 1.4602 - val_accuracy: 0.4444\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.2577 - accuracy: 0.4884 - val_loss: 1.4451 - val_accuracy: 0.4444\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 1.2429 - accuracy: 0.4884 - val_loss: 1.4315 - val_accuracy: 0.4444\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 1.2289 - accuracy: 0.5116 - val_loss: 1.4178 - val_accuracy: 0.4667\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.2141 - accuracy: 0.5116 - val_loss: 1.4069 - val_accuracy: 0.4667\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 376us/sample - loss: 1.2009 - accuracy: 0.5465 - val_loss: 1.3959 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 366us/sample - loss: 1.1888 - accuracy: 0.5465 - val_loss: 1.3861 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.1789 - accuracy: 0.5465 - val_loss: 1.3797 - val_accuracy: 0.4667\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 1.1688 - accuracy: 0.5349 - val_loss: 1.3738 - val_accuracy: 0.4667\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.1598 - accuracy: 0.5349 - val_loss: 1.3686 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.1519 - accuracy: 0.5233 - val_loss: 1.3634 - val_accuracy: 0.4444\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.1438 - accuracy: 0.5233 - val_loss: 1.3582 - val_accuracy: 0.4444\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.1341 - accuracy: 0.5233 - val_loss: 1.3536 - val_accuracy: 0.4444\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.1286 - accuracy: 0.5233 - val_loss: 1.3490 - val_accuracy: 0.4444\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 386us/sample - loss: 1.1200 - accuracy: 0.5233 - val_loss: 1.3451 - val_accuracy: 0.4444\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.1115 - accuracy: 0.5233 - val_loss: 1.3424 - val_accuracy: 0.4444\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 1.1056 - accuracy: 0.5233 - val_loss: 1.3401 - val_accuracy: 0.4444\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 376us/sample - loss: 1.0982 - accuracy: 0.5116 - val_loss: 1.3380 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.0899 - accuracy: 0.5116 - val_loss: 1.3358 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.0846 - accuracy: 0.5116 - val_loss: 1.3318 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.0794 - accuracy: 0.5116 - val_loss: 1.3273 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 1.0733 - accuracy: 0.5116 - val_loss: 1.3233 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.0666 - accuracy: 0.5116 - val_loss: 1.3214 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.0618 - accuracy: 0.5116 - val_loss: 1.3181 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.0573 - accuracy: 0.5116 - val_loss: 1.3163 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.0517 - accuracy: 0.5116 - val_loss: 1.3152 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.0460 - accuracy: 0.5116 - val_loss: 1.3139 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 1.0409 - accuracy: 0.5116 - val_loss: 1.3125 - val_accuracy: 0.4444\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.0381 - accuracy: 0.5116 - val_loss: 1.3112 - val_accuracy: 0.4444\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.0317 - accuracy: 0.5116 - val_loss: 1.3089 - val_accuracy: 0.4444\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.0292 - accuracy: 0.5233 - val_loss: 1.3077 - val_accuracy: 0.4444\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 3.3313 - accuracy: 0.3953 - val_loss: 2.3149 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 3.0707 - accuracy: 0.4070 - val_loss: 2.1551 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 371us/sample - loss: 2.8366 - accuracy: 0.4070 - val_loss: 2.0154 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 2.6273 - accuracy: 0.3953 - val_loss: 1.8907 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 2.4415 - accuracy: 0.3953 - val_loss: 1.7835 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 2.2832 - accuracy: 0.3953 - val_loss: 1.6931 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 2.1455 - accuracy: 0.3953 - val_loss: 1.6125 - val_accuracy: 0.4222\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 2.0168 - accuracy: 0.3953 - val_loss: 1.5406 - val_accuracy: 0.4222\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.8979 - accuracy: 0.3953 - val_loss: 1.4767 - val_accuracy: 0.4222\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 1.7951 - accuracy: 0.4070 - val_loss: 1.4256 - val_accuracy: 0.4222\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.7101 - accuracy: 0.4070 - val_loss: 1.3843 - val_accuracy: 0.4667\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 514us/sample - loss: 1.6360 - accuracy: 0.4186 - val_loss: 1.3496 - val_accuracy: 0.5111\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.5756 - accuracy: 0.4535 - val_loss: 1.3192 - val_accuracy: 0.5111\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.5234 - accuracy: 0.4535 - val_loss: 1.2934 - val_accuracy: 0.5111\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.4811 - accuracy: 0.4651 - val_loss: 1.2696 - val_accuracy: 0.5111\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.4432 - accuracy: 0.4884 - val_loss: 1.2492 - val_accuracy: 0.5111\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.4127 - accuracy: 0.4651 - val_loss: 1.2298 - val_accuracy: 0.5111\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 1.3847 - accuracy: 0.4767 - val_loss: 1.2122 - val_accuracy: 0.5333\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.3604 - accuracy: 0.4884 - val_loss: 1.1972 - val_accuracy: 0.5333\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.3396 - accuracy: 0.5000 - val_loss: 1.1834 - val_accuracy: 0.5333\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.3212 - accuracy: 0.5000 - val_loss: 1.1714 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 1.3032 - accuracy: 0.5000 - val_loss: 1.1597 - val_accuracy: 0.5111\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.2860 - accuracy: 0.5000 - val_loss: 1.1493 - val_accuracy: 0.5111\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 357us/sample - loss: 1.2717 - accuracy: 0.4884 - val_loss: 1.1392 - val_accuracy: 0.5333\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 348us/sample - loss: 1.2584 - accuracy: 0.4884 - val_loss: 1.1295 - val_accuracy: 0.5111\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 1.2441 - accuracy: 0.5000 - val_loss: 1.1212 - val_accuracy: 0.4889\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.2345 - accuracy: 0.4884 - val_loss: 1.1134 - val_accuracy: 0.4889\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 2ms/sample - loss: 1.2203 - accuracy: 0.5000 - val_loss: 1.1066 - val_accuracy: 0.4889\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 867us/sample - loss: 1.2089 - accuracy: 0.5000 - val_loss: 1.1004 - val_accuracy: 0.4889\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 710us/sample - loss: 1.1984 - accuracy: 0.5000 - val_loss: 1.0945 - val_accuracy: 0.4889\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 984us/sample - loss: 1.1901 - accuracy: 0.4884 - val_loss: 1.0885 - val_accuracy: 0.4889\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 752us/sample - loss: 1.1786 - accuracy: 0.5000 - val_loss: 1.0823 - val_accuracy: 0.4889\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 2ms/sample - loss: 1.1652 - accuracy: 0.5000 - val_loss: 1.0769 - val_accuracy: 0.4889\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 3ms/sample - loss: 1.1579 - accuracy: 0.5000 - val_loss: 1.0721 - val_accuracy: 0.4889\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 3ms/sample - loss: 1.1453 - accuracy: 0.5000 - val_loss: 1.0674 - val_accuracy: 0.4889\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 2ms/sample - loss: 1.1360 - accuracy: 0.5116 - val_loss: 1.0620 - val_accuracy: 0.4889\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 3ms/sample - loss: 1.1274 - accuracy: 0.5116 - val_loss: 1.0566 - val_accuracy: 0.4889\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.1189 - accuracy: 0.5233 - val_loss: 1.0518 - val_accuracy: 0.4889\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.1114 - accuracy: 0.5116 - val_loss: 1.0472 - val_accuracy: 0.4889\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.0998 - accuracy: 0.5116 - val_loss: 1.0434 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 1.0945 - accuracy: 0.5233 - val_loss: 1.0402 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 1.0846 - accuracy: 0.5233 - val_loss: 1.0370 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.0782 - accuracy: 0.5233 - val_loss: 1.0339 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 2ms/sample - loss: 1.0712 - accuracy: 0.5116 - val_loss: 1.0312 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 2ms/sample - loss: 1.0649 - accuracy: 0.5233 - val_loss: 1.0283 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 1.0574 - accuracy: 0.5116 - val_loss: 1.0250 - val_accuracy: 0.4667\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.0511 - accuracy: 0.5233 - val_loss: 1.0222 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.0459 - accuracy: 0.5116 - val_loss: 1.0197 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 1.0386 - accuracy: 0.5116 - val_loss: 1.0171 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.0340 - accuracy: 0.5116 - val_loss: 1.0144 - val_accuracy: 0.4667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 7</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.4814814627170563</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.7649 - accuracy: 0.2442 - val_loss: 2.0909 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 2.5993 - accuracy: 0.2442 - val_loss: 1.9986 - val_accuracy: 0.4222\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 2.4388 - accuracy: 0.2558 - val_loss: 1.9104 - val_accuracy: 0.4222\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 357us/sample - loss: 2.2901 - accuracy: 0.2558 - val_loss: 1.8302 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 2.1534 - accuracy: 0.2674 - val_loss: 1.7520 - val_accuracy: 0.4222\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 405us/sample - loss: 2.0297 - accuracy: 0.2791 - val_loss: 1.6833 - val_accuracy: 0.4222\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.9140 - accuracy: 0.2907 - val_loss: 1.6207 - val_accuracy: 0.4222\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.8139 - accuracy: 0.2791 - val_loss: 1.5644 - val_accuracy: 0.4222\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 1.7236 - accuracy: 0.2907 - val_loss: 1.5164 - val_accuracy: 0.4222\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.6384 - accuracy: 0.2907 - val_loss: 1.4722 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 385us/sample - loss: 1.5666 - accuracy: 0.2674 - val_loss: 1.4363 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 1.5059 - accuracy: 0.2791 - val_loss: 1.4053 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.4518 - accuracy: 0.2907 - val_loss: 1.3763 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 1.4075 - accuracy: 0.2791 - val_loss: 1.3521 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.3714 - accuracy: 0.2907 - val_loss: 1.3328 - val_accuracy: 0.3778\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 1.3395 - accuracy: 0.3023 - val_loss: 1.3150 - val_accuracy: 0.4222\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 370us/sample - loss: 1.3131 - accuracy: 0.3140 - val_loss: 1.3010 - val_accuracy: 0.4222\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 489us/sample - loss: 1.2903 - accuracy: 0.3488 - val_loss: 1.2895 - val_accuracy: 0.4444\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.2707 - accuracy: 0.3605 - val_loss: 1.2790 - val_accuracy: 0.4222\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.2548 - accuracy: 0.4302 - val_loss: 1.2706 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 375us/sample - loss: 1.2419 - accuracy: 0.4419 - val_loss: 1.2632 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.2290 - accuracy: 0.4419 - val_loss: 1.2559 - val_accuracy: 0.3778\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.2187 - accuracy: 0.4651 - val_loss: 1.2489 - val_accuracy: 0.3778\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.2089 - accuracy: 0.4651 - val_loss: 1.2413 - val_accuracy: 0.3778\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.2013 - accuracy: 0.4651 - val_loss: 1.2343 - val_accuracy: 0.3778\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.1933 - accuracy: 0.4651 - val_loss: 1.2271 - val_accuracy: 0.3778\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.1865 - accuracy: 0.4767 - val_loss: 1.2205 - val_accuracy: 0.3778\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.1802 - accuracy: 0.4884 - val_loss: 1.2153 - val_accuracy: 0.3778\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 369us/sample - loss: 1.1743 - accuracy: 0.5000 - val_loss: 1.2097 - val_accuracy: 0.3778\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.1682 - accuracy: 0.5000 - val_loss: 1.2047 - val_accuracy: 0.3778\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 358us/sample - loss: 1.1623 - accuracy: 0.4767 - val_loss: 1.2000 - val_accuracy: 0.3778\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.1564 - accuracy: 0.5000 - val_loss: 1.1951 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 376us/sample - loss: 1.1507 - accuracy: 0.5000 - val_loss: 1.1902 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 375us/sample - loss: 1.1458 - accuracy: 0.5116 - val_loss: 1.1857 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 351us/sample - loss: 1.1415 - accuracy: 0.5233 - val_loss: 1.1808 - val_accuracy: 0.4222\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.1367 - accuracy: 0.5233 - val_loss: 1.1769 - val_accuracy: 0.4222\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 366us/sample - loss: 1.1321 - accuracy: 0.5233 - val_loss: 1.1730 - val_accuracy: 0.4222\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.1275 - accuracy: 0.5233 - val_loss: 1.1692 - val_accuracy: 0.4222\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 366us/sample - loss: 1.1242 - accuracy: 0.5233 - val_loss: 1.1646 - val_accuracy: 0.4222\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 1.1196 - accuracy: 0.5233 - val_loss: 1.1603 - val_accuracy: 0.4222\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 405us/sample - loss: 1.1137 - accuracy: 0.5349 - val_loss: 1.1566 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 372us/sample - loss: 1.1103 - accuracy: 0.5349 - val_loss: 1.1535 - val_accuracy: 0.4222\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 360us/sample - loss: 1.1083 - accuracy: 0.5349 - val_loss: 1.1512 - val_accuracy: 0.4444\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.1030 - accuracy: 0.5349 - val_loss: 1.1483 - val_accuracy: 0.4222\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.1001 - accuracy: 0.5465 - val_loss: 1.1452 - val_accuracy: 0.4222\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 371us/sample - loss: 1.0957 - accuracy: 0.5465 - val_loss: 1.1415 - val_accuracy: 0.4222\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 347us/sample - loss: 1.0926 - accuracy: 0.5465 - val_loss: 1.1385 - val_accuracy: 0.4222\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 360us/sample - loss: 1.0903 - accuracy: 0.5465 - val_loss: 1.1359 - val_accuracy: 0.4222\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 363us/sample - loss: 1.0866 - accuracy: 0.5349 - val_loss: 1.1337 - val_accuracy: 0.4222\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 365us/sample - loss: 1.0841 - accuracy: 0.5465 - val_loss: 1.1314 - val_accuracy: 0.4222\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.9524 - accuracy: 0.3023 - val_loss: 2.5263 - val_accuracy: 0.3778\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 2.6762 - accuracy: 0.3372 - val_loss: 2.3416 - val_accuracy: 0.3778\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 385us/sample - loss: 2.4645 - accuracy: 0.3488 - val_loss: 2.1913 - val_accuracy: 0.3556\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 2.2957 - accuracy: 0.3605 - val_loss: 2.0710 - val_accuracy: 0.3556\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 2.1529 - accuracy: 0.3488 - val_loss: 1.9678 - val_accuracy: 0.3556\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 385us/sample - loss: 2.0288 - accuracy: 0.3372 - val_loss: 1.8838 - val_accuracy: 0.3556\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 1.9263 - accuracy: 0.3488 - val_loss: 1.8113 - val_accuracy: 0.3778\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.8302 - accuracy: 0.3488 - val_loss: 1.7506 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.7528 - accuracy: 0.3605 - val_loss: 1.6975 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 386us/sample - loss: 1.6804 - accuracy: 0.3605 - val_loss: 1.6490 - val_accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.6142 - accuracy: 0.3605 - val_loss: 1.6070 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 1.5585 - accuracy: 0.3721 - val_loss: 1.5714 - val_accuracy: 0.3111\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.5091 - accuracy: 0.3605 - val_loss: 1.5386 - val_accuracy: 0.3111\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 367us/sample - loss: 1.4643 - accuracy: 0.3605 - val_loss: 1.5072 - val_accuracy: 0.3111\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.4225 - accuracy: 0.3488 - val_loss: 1.4796 - val_accuracy: 0.2889\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.3861 - accuracy: 0.3721 - val_loss: 1.4550 - val_accuracy: 0.3111\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 375us/sample - loss: 1.3513 - accuracy: 0.3837 - val_loss: 1.4312 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.3191 - accuracy: 0.3605 - val_loss: 1.4097 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.2932 - accuracy: 0.3721 - val_loss: 1.3905 - val_accuracy: 0.3333\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 1.2682 - accuracy: 0.3837 - val_loss: 1.3729 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.2470 - accuracy: 0.3837 - val_loss: 1.3582 - val_accuracy: 0.3556\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.2251 - accuracy: 0.3953 - val_loss: 1.3434 - val_accuracy: 0.3556\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.2056 - accuracy: 0.3953 - val_loss: 1.3299 - val_accuracy: 0.3556\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 671us/sample - loss: 1.1881 - accuracy: 0.3953 - val_loss: 1.3167 - val_accuracy: 0.3556\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.1709 - accuracy: 0.3953 - val_loss: 1.3041 - val_accuracy: 0.3778\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 1.1570 - accuracy: 0.4070 - val_loss: 1.2920 - val_accuracy: 0.3778\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.1425 - accuracy: 0.4070 - val_loss: 1.2810 - val_accuracy: 0.3778\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.1309 - accuracy: 0.4186 - val_loss: 1.2711 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.1181 - accuracy: 0.4186 - val_loss: 1.2618 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 369us/sample - loss: 1.1077 - accuracy: 0.4186 - val_loss: 1.2520 - val_accuracy: 0.4222\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.0962 - accuracy: 0.4186 - val_loss: 1.2422 - val_accuracy: 0.4222\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 362us/sample - loss: 1.0847 - accuracy: 0.4070 - val_loss: 1.2338 - val_accuracy: 0.4222\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.0759 - accuracy: 0.4070 - val_loss: 1.2257 - val_accuracy: 0.4222\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 1.0669 - accuracy: 0.4070 - val_loss: 1.2181 - val_accuracy: 0.4222\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.0593 - accuracy: 0.4302 - val_loss: 1.2115 - val_accuracy: 0.4222\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.0507 - accuracy: 0.4302 - val_loss: 1.2050 - val_accuracy: 0.4222\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.0423 - accuracy: 0.4302 - val_loss: 1.1988 - val_accuracy: 0.4444\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.0357 - accuracy: 0.4302 - val_loss: 1.1935 - val_accuracy: 0.4444\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 523us/sample - loss: 1.0285 - accuracy: 0.4419 - val_loss: 1.1879 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 1.0228 - accuracy: 0.4535 - val_loss: 1.1822 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 380us/sample - loss: 1.0163 - accuracy: 0.4535 - val_loss: 1.1766 - val_accuracy: 0.4444\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 380us/sample - loss: 1.0111 - accuracy: 0.4535 - val_loss: 1.1715 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.0065 - accuracy: 0.4767 - val_loss: 1.1675 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0012 - accuracy: 0.4767 - val_loss: 1.1631 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 0.9967 - accuracy: 0.4767 - val_loss: 1.1591 - val_accuracy: 0.4444\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 0.9928 - accuracy: 0.4767 - val_loss: 1.1551 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9875 - accuracy: 0.4767 - val_loss: 1.1516 - val_accuracy: 0.4444\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 0.9852 - accuracy: 0.4767 - val_loss: 1.1481 - val_accuracy: 0.4444\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.9800 - accuracy: 0.4767 - val_loss: 1.1448 - val_accuracy: 0.4444\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.9762 - accuracy: 0.5000 - val_loss: 1.1415 - val_accuracy: 0.4000\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 3.2566 - accuracy: 0.3023 - val_loss: 2.1619 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 2.9995 - accuracy: 0.3023 - val_loss: 2.0249 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 2.7506 - accuracy: 0.2907 - val_loss: 1.9004 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 388us/sample - loss: 2.5334 - accuracy: 0.3023 - val_loss: 1.7949 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 348us/sample - loss: 2.3474 - accuracy: 0.2907 - val_loss: 1.7063 - val_accuracy: 0.4222\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 372us/sample - loss: 2.1922 - accuracy: 0.3140 - val_loss: 1.6363 - val_accuracy: 0.4222\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 2.0742 - accuracy: 0.3256 - val_loss: 1.5779 - val_accuracy: 0.4222\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.9731 - accuracy: 0.3372 - val_loss: 1.5277 - val_accuracy: 0.4222\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 1.8852 - accuracy: 0.3605 - val_loss: 1.4837 - val_accuracy: 0.4444\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.8112 - accuracy: 0.3256 - val_loss: 1.4458 - val_accuracy: 0.4444\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 376us/sample - loss: 1.7501 - accuracy: 0.3256 - val_loss: 1.4125 - val_accuracy: 0.4222\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.6977 - accuracy: 0.3140 - val_loss: 1.3817 - val_accuracy: 0.4222\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.6497 - accuracy: 0.3256 - val_loss: 1.3544 - val_accuracy: 0.4222\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 1.6080 - accuracy: 0.3372 - val_loss: 1.3296 - val_accuracy: 0.4222\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.5666 - accuracy: 0.3256 - val_loss: 1.3071 - val_accuracy: 0.4444\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.5298 - accuracy: 0.3256 - val_loss: 1.2860 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.4955 - accuracy: 0.3488 - val_loss: 1.2669 - val_accuracy: 0.4444\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.4658 - accuracy: 0.3488 - val_loss: 1.2483 - val_accuracy: 0.4444\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.4335 - accuracy: 0.3605 - val_loss: 1.2306 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.4053 - accuracy: 0.3721 - val_loss: 1.2149 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.3811 - accuracy: 0.3721 - val_loss: 1.2009 - val_accuracy: 0.4667\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 386us/sample - loss: 1.3576 - accuracy: 0.3605 - val_loss: 1.1874 - val_accuracy: 0.4667\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.3368 - accuracy: 0.3605 - val_loss: 1.1750 - val_accuracy: 0.4667\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.3151 - accuracy: 0.3488 - val_loss: 1.1643 - val_accuracy: 0.4667\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 405us/sample - loss: 1.2965 - accuracy: 0.3488 - val_loss: 1.1542 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.2799 - accuracy: 0.3488 - val_loss: 1.1454 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.2635 - accuracy: 0.3372 - val_loss: 1.1368 - val_accuracy: 0.4667\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.2496 - accuracy: 0.3605 - val_loss: 1.1293 - val_accuracy: 0.4667\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.2349 - accuracy: 0.3605 - val_loss: 1.1225 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.2223 - accuracy: 0.3488 - val_loss: 1.1162 - val_accuracy: 0.4667\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.2094 - accuracy: 0.3605 - val_loss: 1.1098 - val_accuracy: 0.4444\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 1.1971 - accuracy: 0.3837 - val_loss: 1.1041 - val_accuracy: 0.4222\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.1869 - accuracy: 0.3953 - val_loss: 1.0985 - val_accuracy: 0.4222\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.1765 - accuracy: 0.3721 - val_loss: 1.0933 - val_accuracy: 0.4222\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 368us/sample - loss: 1.1695 - accuracy: 0.3837 - val_loss: 1.0889 - val_accuracy: 0.4222\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 1.1592 - accuracy: 0.3953 - val_loss: 1.0847 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.1510 - accuracy: 0.3837 - val_loss: 1.0806 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 1.1415 - accuracy: 0.3837 - val_loss: 1.0771 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1346 - accuracy: 0.3953 - val_loss: 1.0732 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.1277 - accuracy: 0.4070 - val_loss: 1.0688 - val_accuracy: 0.3778\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.1204 - accuracy: 0.3953 - val_loss: 1.0649 - val_accuracy: 0.3778\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.1156 - accuracy: 0.3837 - val_loss: 1.0621 - val_accuracy: 0.3556\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.1079 - accuracy: 0.3953 - val_loss: 1.0602 - val_accuracy: 0.3778\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.1021 - accuracy: 0.3953 - val_loss: 1.0584 - val_accuracy: 0.3778\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.0972 - accuracy: 0.3953 - val_loss: 1.0559 - val_accuracy: 0.3778\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 375us/sample - loss: 1.0917 - accuracy: 0.3953 - val_loss: 1.0540 - val_accuracy: 0.3778\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.0861 - accuracy: 0.3837 - val_loss: 1.0522 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.0815 - accuracy: 0.4070 - val_loss: 1.0503 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.0773 - accuracy: 0.3953 - val_loss: 1.0487 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.0736 - accuracy: 0.3837 - val_loss: 1.0473 - val_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 6</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.4592592716217041</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.2098 - accuracy: 0.3372 - val_loss: 2.4400 - val_accuracy: 0.3778\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 2.0920 - accuracy: 0.3372 - val_loss: 2.3508 - val_accuracy: 0.3556\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 1.9904 - accuracy: 0.3372 - val_loss: 2.2669 - val_accuracy: 0.3556\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.9018 - accuracy: 0.3488 - val_loss: 2.1892 - val_accuracy: 0.3556\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 382us/sample - loss: 1.8216 - accuracy: 0.3721 - val_loss: 2.1273 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.7538 - accuracy: 0.3721 - val_loss: 2.0759 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 368us/sample - loss: 1.7013 - accuracy: 0.3605 - val_loss: 2.0291 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 1.6529 - accuracy: 0.3605 - val_loss: 1.9867 - val_accuracy: 0.3556\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 374us/sample - loss: 1.6076 - accuracy: 0.3837 - val_loss: 1.9473 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.5628 - accuracy: 0.3837 - val_loss: 1.9113 - val_accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 375us/sample - loss: 1.5256 - accuracy: 0.3837 - val_loss: 1.8817 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 1.4931 - accuracy: 0.3953 - val_loss: 1.8557 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 1.4617 - accuracy: 0.4070 - val_loss: 1.8333 - val_accuracy: 0.3111\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 1.4333 - accuracy: 0.3953 - val_loss: 1.8136 - val_accuracy: 0.3111\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 495us/sample - loss: 1.4086 - accuracy: 0.4186 - val_loss: 1.7935 - val_accuracy: 0.3111\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.3836 - accuracy: 0.4419 - val_loss: 1.7738 - val_accuracy: 0.3111\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 1.3623 - accuracy: 0.4302 - val_loss: 1.7565 - val_accuracy: 0.3778\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.3412 - accuracy: 0.4535 - val_loss: 1.7402 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.3238 - accuracy: 0.4535 - val_loss: 1.7234 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.3030 - accuracy: 0.4651 - val_loss: 1.7083 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 1.2889 - accuracy: 0.4535 - val_loss: 1.6930 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.2715 - accuracy: 0.4535 - val_loss: 1.6779 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 1.2564 - accuracy: 0.4535 - val_loss: 1.6637 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 1.2425 - accuracy: 0.4651 - val_loss: 1.6516 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.2284 - accuracy: 0.4767 - val_loss: 1.6391 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.2156 - accuracy: 0.4884 - val_loss: 1.6276 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 1.2023 - accuracy: 0.4767 - val_loss: 1.6164 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.1902 - accuracy: 0.4767 - val_loss: 1.6054 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.1789 - accuracy: 0.4884 - val_loss: 1.5929 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.1660 - accuracy: 0.4884 - val_loss: 1.5815 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 536us/sample - loss: 1.1562 - accuracy: 0.4884 - val_loss: 1.5715 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 597us/sample - loss: 1.1463 - accuracy: 0.4884 - val_loss: 1.5623 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.1349 - accuracy: 0.4884 - val_loss: 1.5539 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 1.1254 - accuracy: 0.4884 - val_loss: 1.5457 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 1.1175 - accuracy: 0.4884 - val_loss: 1.5375 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.1101 - accuracy: 0.4884 - val_loss: 1.5297 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 1.1013 - accuracy: 0.4884 - val_loss: 1.5219 - val_accuracy: 0.4222\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.0942 - accuracy: 0.4884 - val_loss: 1.5149 - val_accuracy: 0.4222\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.0884 - accuracy: 0.5000 - val_loss: 1.5071 - val_accuracy: 0.4222\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 1.0803 - accuracy: 0.5000 - val_loss: 1.4980 - val_accuracy: 0.4444\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.0728 - accuracy: 0.5000 - val_loss: 1.4893 - val_accuracy: 0.4444\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.0655 - accuracy: 0.5000 - val_loss: 1.4817 - val_accuracy: 0.4444\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 1.0608 - accuracy: 0.5000 - val_loss: 1.4748 - val_accuracy: 0.4444\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 539us/sample - loss: 1.0553 - accuracy: 0.5000 - val_loss: 1.4671 - val_accuracy: 0.4444\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 1.0505 - accuracy: 0.5000 - val_loss: 1.4604 - val_accuracy: 0.4444\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.0454 - accuracy: 0.5000 - val_loss: 1.4547 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.0413 - accuracy: 0.5000 - val_loss: 1.4487 - val_accuracy: 0.4222\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.0382 - accuracy: 0.5000 - val_loss: 1.4423 - val_accuracy: 0.4222\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.0333 - accuracy: 0.5000 - val_loss: 1.4363 - val_accuracy: 0.4222\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.0306 - accuracy: 0.4884 - val_loss: 1.4304 - val_accuracy: 0.4222\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.4341 - accuracy: 0.2791 - val_loss: 1.4525 - val_accuracy: 0.4444\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 2.2832 - accuracy: 0.3023 - val_loss: 1.4028 - val_accuracy: 0.4444\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 2.1434 - accuracy: 0.2907 - val_loss: 1.3630 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 2.0267 - accuracy: 0.2791 - val_loss: 1.3323 - val_accuracy: 0.4444\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.9312 - accuracy: 0.2791 - val_loss: 1.3071 - val_accuracy: 0.4444\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.8494 - accuracy: 0.2791 - val_loss: 1.2848 - val_accuracy: 0.4444\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.7788 - accuracy: 0.3023 - val_loss: 1.2641 - val_accuracy: 0.4444\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.7155 - accuracy: 0.2907 - val_loss: 1.2458 - val_accuracy: 0.4222\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.6595 - accuracy: 0.2907 - val_loss: 1.2287 - val_accuracy: 0.4222\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.6105 - accuracy: 0.3140 - val_loss: 1.2135 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 1.5689 - accuracy: 0.3140 - val_loss: 1.1993 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 374us/sample - loss: 1.5242 - accuracy: 0.3140 - val_loss: 1.1873 - val_accuracy: 0.3778\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 382us/sample - loss: 1.4870 - accuracy: 0.3140 - val_loss: 1.1777 - val_accuracy: 0.3778\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.4544 - accuracy: 0.3140 - val_loss: 1.1686 - val_accuracy: 0.3778\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.4219 - accuracy: 0.3140 - val_loss: 1.1601 - val_accuracy: 0.3778\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.3935 - accuracy: 0.3140 - val_loss: 1.1531 - val_accuracy: 0.3778\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 1.3679 - accuracy: 0.3372 - val_loss: 1.1459 - val_accuracy: 0.3778\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.3453 - accuracy: 0.3372 - val_loss: 1.1395 - val_accuracy: 0.3778\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.3248 - accuracy: 0.3372 - val_loss: 1.1331 - val_accuracy: 0.3778\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.3037 - accuracy: 0.3372 - val_loss: 1.1278 - val_accuracy: 0.3778\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.2856 - accuracy: 0.3372 - val_loss: 1.1235 - val_accuracy: 0.3778\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.2696 - accuracy: 0.3372 - val_loss: 1.1196 - val_accuracy: 0.3778\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 1.2545 - accuracy: 0.3488 - val_loss: 1.1157 - val_accuracy: 0.3778\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 1.2379 - accuracy: 0.3488 - val_loss: 1.1122 - val_accuracy: 0.3778\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 382us/sample - loss: 1.2260 - accuracy: 0.3488 - val_loss: 1.1093 - val_accuracy: 0.3778\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.2136 - accuracy: 0.3488 - val_loss: 1.1071 - val_accuracy: 0.3556\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 362us/sample - loss: 1.2035 - accuracy: 0.3488 - val_loss: 1.1050 - val_accuracy: 0.3556\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.1924 - accuracy: 0.3256 - val_loss: 1.1037 - val_accuracy: 0.3556\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.1824 - accuracy: 0.3372 - val_loss: 1.1026 - val_accuracy: 0.3556\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 356us/sample - loss: 1.1742 - accuracy: 0.3372 - val_loss: 1.1013 - val_accuracy: 0.3556\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.1653 - accuracy: 0.3372 - val_loss: 1.1006 - val_accuracy: 0.3556\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 385us/sample - loss: 1.1581 - accuracy: 0.3372 - val_loss: 1.1013 - val_accuracy: 0.3556\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.1499 - accuracy: 0.3372 - val_loss: 1.1016 - val_accuracy: 0.3556\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 370us/sample - loss: 1.1434 - accuracy: 0.3372 - val_loss: 1.1020 - val_accuracy: 0.3333\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.1364 - accuracy: 0.3372 - val_loss: 1.1022 - val_accuracy: 0.3556\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 356us/sample - loss: 1.1307 - accuracy: 0.3488 - val_loss: 1.1023 - val_accuracy: 0.3556\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.1250 - accuracy: 0.3372 - val_loss: 1.1019 - val_accuracy: 0.3778\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 345us/sample - loss: 1.1190 - accuracy: 0.3372 - val_loss: 1.1010 - val_accuracy: 0.3556\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.1150 - accuracy: 0.3372 - val_loss: 1.1011 - val_accuracy: 0.3556\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 375us/sample - loss: 1.1107 - accuracy: 0.3488 - val_loss: 1.1005 - val_accuracy: 0.3556\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 1.1073 - accuracy: 0.3488 - val_loss: 1.0997 - val_accuracy: 0.3556\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.1023 - accuracy: 0.3488 - val_loss: 1.0995 - val_accuracy: 0.3778\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.0985 - accuracy: 0.3488 - val_loss: 1.0997 - val_accuracy: 0.3778\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 374us/sample - loss: 1.0947 - accuracy: 0.3488 - val_loss: 1.0993 - val_accuracy: 0.3778\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.0914 - accuracy: 0.3605 - val_loss: 1.0988 - val_accuracy: 0.3778\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 1.0892 - accuracy: 0.3953 - val_loss: 1.0990 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.0860 - accuracy: 0.3953 - val_loss: 1.0992 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.0838 - accuracy: 0.4070 - val_loss: 1.0991 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 359us/sample - loss: 1.0806 - accuracy: 0.4070 - val_loss: 1.0981 - val_accuracy: 0.4222\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.0782 - accuracy: 0.4070 - val_loss: 1.0973 - val_accuracy: 0.4667\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 1.3009 - accuracy: 0.5000 - val_loss: 1.4739 - val_accuracy: 0.3778\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.2829 - accuracy: 0.5000 - val_loss: 1.4501 - val_accuracy: 0.3778\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.2664 - accuracy: 0.5000 - val_loss: 1.4293 - val_accuracy: 0.3778\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 1.2496 - accuracy: 0.5000 - val_loss: 1.4100 - val_accuracy: 0.3778\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.2355 - accuracy: 0.5116 - val_loss: 1.3928 - val_accuracy: 0.3778\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.2219 - accuracy: 0.5116 - val_loss: 1.3762 - val_accuracy: 0.3778\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.2095 - accuracy: 0.5000 - val_loss: 1.3607 - val_accuracy: 0.3778\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.1985 - accuracy: 0.5000 - val_loss: 1.3457 - val_accuracy: 0.3778\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 367us/sample - loss: 1.1872 - accuracy: 0.5116 - val_loss: 1.3317 - val_accuracy: 0.3778\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.1771 - accuracy: 0.5233 - val_loss: 1.3186 - val_accuracy: 0.3778\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.1672 - accuracy: 0.5116 - val_loss: 1.3066 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.1576 - accuracy: 0.5000 - val_loss: 1.2943 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 361us/sample - loss: 1.1484 - accuracy: 0.5116 - val_loss: 1.2829 - val_accuracy: 0.4222\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 382us/sample - loss: 1.1398 - accuracy: 0.5233 - val_loss: 1.2731 - val_accuracy: 0.4222\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.1323 - accuracy: 0.5233 - val_loss: 1.2635 - val_accuracy: 0.4222\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.1254 - accuracy: 0.5233 - val_loss: 1.2541 - val_accuracy: 0.4222\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.1182 - accuracy: 0.5233 - val_loss: 1.2450 - val_accuracy: 0.4222\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.1114 - accuracy: 0.5349 - val_loss: 1.2374 - val_accuracy: 0.4222\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.1053 - accuracy: 0.5349 - val_loss: 1.2298 - val_accuracy: 0.4222\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.0995 - accuracy: 0.5349 - val_loss: 1.2225 - val_accuracy: 0.4222\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.0945 - accuracy: 0.5349 - val_loss: 1.2154 - val_accuracy: 0.4222\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.0883 - accuracy: 0.5349 - val_loss: 1.2085 - val_accuracy: 0.4222\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.0838 - accuracy: 0.5465 - val_loss: 1.2021 - val_accuracy: 0.4222\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.0787 - accuracy: 0.5581 - val_loss: 1.1958 - val_accuracy: 0.4222\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.0743 - accuracy: 0.5581 - val_loss: 1.1893 - val_accuracy: 0.4222\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.0708 - accuracy: 0.5581 - val_loss: 1.1831 - val_accuracy: 0.4222\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.0655 - accuracy: 0.5581 - val_loss: 1.1774 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 380us/sample - loss: 1.0613 - accuracy: 0.5581 - val_loss: 1.1723 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.0576 - accuracy: 0.5581 - val_loss: 1.1671 - val_accuracy: 0.4222\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.0537 - accuracy: 0.5581 - val_loss: 1.1622 - val_accuracy: 0.4222\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.0496 - accuracy: 0.5581 - val_loss: 1.1571 - val_accuracy: 0.4222\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.0465 - accuracy: 0.5581 - val_loss: 1.1530 - val_accuracy: 0.4222\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.0430 - accuracy: 0.5581 - val_loss: 1.1485 - val_accuracy: 0.4222\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.0392 - accuracy: 0.5581 - val_loss: 1.1444 - val_accuracy: 0.4222\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 372us/sample - loss: 1.0363 - accuracy: 0.5581 - val_loss: 1.1406 - val_accuracy: 0.4222\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 374us/sample - loss: 1.0334 - accuracy: 0.5581 - val_loss: 1.1366 - val_accuracy: 0.4222\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 353us/sample - loss: 1.0308 - accuracy: 0.5581 - val_loss: 1.1324 - val_accuracy: 0.4222\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.0276 - accuracy: 0.5581 - val_loss: 1.1284 - val_accuracy: 0.4222\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.0246 - accuracy: 0.5581 - val_loss: 1.1249 - val_accuracy: 0.4222\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.0220 - accuracy: 0.5581 - val_loss: 1.1216 - val_accuracy: 0.4222\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.0198 - accuracy: 0.5698 - val_loss: 1.1182 - val_accuracy: 0.4222\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 1.0173 - accuracy: 0.5698 - val_loss: 1.1151 - val_accuracy: 0.4222\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.0148 - accuracy: 0.5581 - val_loss: 1.1124 - val_accuracy: 0.4222\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 365us/sample - loss: 1.0129 - accuracy: 0.5698 - val_loss: 1.1102 - val_accuracy: 0.4222\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.0106 - accuracy: 0.5698 - val_loss: 1.1082 - val_accuracy: 0.4222\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.0092 - accuracy: 0.5698 - val_loss: 1.1063 - val_accuracy: 0.4222\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 369us/sample - loss: 1.0071 - accuracy: 0.5581 - val_loss: 1.1041 - val_accuracy: 0.4222\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.0047 - accuracy: 0.5581 - val_loss: 1.1020 - val_accuracy: 0.4222\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.0024 - accuracy: 0.5698 - val_loss: 1.0997 - val_accuracy: 0.4222\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.0005 - accuracy: 0.5698 - val_loss: 1.0969 - val_accuracy: 0.4222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.4444444477558136</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.2588 - accuracy: 0.4302 - val_loss: 1.8225 - val_accuracy: 0.4222\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 2.0413 - accuracy: 0.4186 - val_loss: 1.7223 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.8559 - accuracy: 0.4302 - val_loss: 1.6463 - val_accuracy: 0.4222\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.7094 - accuracy: 0.4767 - val_loss: 1.5889 - val_accuracy: 0.4222\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.6117 - accuracy: 0.4651 - val_loss: 1.5507 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.5325 - accuracy: 0.4884 - val_loss: 1.5236 - val_accuracy: 0.4222\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.4777 - accuracy: 0.5000 - val_loss: 1.5054 - val_accuracy: 0.4222\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.4396 - accuracy: 0.4884 - val_loss: 1.4904 - val_accuracy: 0.4222\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 500us/sample - loss: 1.4054 - accuracy: 0.4884 - val_loss: 1.4770 - val_accuracy: 0.4444\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 513us/sample - loss: 1.3789 - accuracy: 0.4767 - val_loss: 1.4655 - val_accuracy: 0.4444\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 346us/sample - loss: 1.3567 - accuracy: 0.4884 - val_loss: 1.4553 - val_accuracy: 0.4222\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 386us/sample - loss: 1.3364 - accuracy: 0.5000 - val_loss: 1.4461 - val_accuracy: 0.4222\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.3205 - accuracy: 0.4884 - val_loss: 1.4375 - val_accuracy: 0.4222\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.3041 - accuracy: 0.4884 - val_loss: 1.4288 - val_accuracy: 0.4222\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.2892 - accuracy: 0.5000 - val_loss: 1.4213 - val_accuracy: 0.4222\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 382us/sample - loss: 1.2740 - accuracy: 0.5000 - val_loss: 1.4138 - val_accuracy: 0.4222\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.2614 - accuracy: 0.5000 - val_loss: 1.4068 - val_accuracy: 0.4222\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.2502 - accuracy: 0.5116 - val_loss: 1.3995 - val_accuracy: 0.4444\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.2370 - accuracy: 0.5116 - val_loss: 1.3930 - val_accuracy: 0.4444\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.2250 - accuracy: 0.5116 - val_loss: 1.3865 - val_accuracy: 0.4222\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.2133 - accuracy: 0.5116 - val_loss: 1.3817 - val_accuracy: 0.4444\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 357us/sample - loss: 1.2028 - accuracy: 0.5116 - val_loss: 1.3759 - val_accuracy: 0.4444\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 1.1931 - accuracy: 0.5233 - val_loss: 1.3708 - val_accuracy: 0.4444\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 386us/sample - loss: 1.1824 - accuracy: 0.5116 - val_loss: 1.3649 - val_accuracy: 0.4444\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.1745 - accuracy: 0.5233 - val_loss: 1.3585 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 352us/sample - loss: 1.1676 - accuracy: 0.5233 - val_loss: 1.3536 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.1568 - accuracy: 0.5349 - val_loss: 1.3482 - val_accuracy: 0.4667\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.1505 - accuracy: 0.5233 - val_loss: 1.3436 - val_accuracy: 0.4667\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.1418 - accuracy: 0.5349 - val_loss: 1.3400 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 516us/sample - loss: 1.1346 - accuracy: 0.5349 - val_loss: 1.3357 - val_accuracy: 0.4889\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.1279 - accuracy: 0.5233 - val_loss: 1.3315 - val_accuracy: 0.4889\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.1213 - accuracy: 0.5349 - val_loss: 1.3273 - val_accuracy: 0.5111\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.1137 - accuracy: 0.5465 - val_loss: 1.3234 - val_accuracy: 0.5111\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 366us/sample - loss: 1.1085 - accuracy: 0.5233 - val_loss: 1.3188 - val_accuracy: 0.5111\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.0998 - accuracy: 0.5465 - val_loss: 1.3139 - val_accuracy: 0.5333\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.0953 - accuracy: 0.5465 - val_loss: 1.3097 - val_accuracy: 0.5333\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 1.0888 - accuracy: 0.5465 - val_loss: 1.3056 - val_accuracy: 0.5556\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.0811 - accuracy: 0.5465 - val_loss: 1.3019 - val_accuracy: 0.5556\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.0753 - accuracy: 0.5349 - val_loss: 1.2974 - val_accuracy: 0.5556\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 546us/sample - loss: 1.0680 - accuracy: 0.5581 - val_loss: 1.2928 - val_accuracy: 0.5778\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.0616 - accuracy: 0.5698 - val_loss: 1.2881 - val_accuracy: 0.5778\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.0550 - accuracy: 0.5581 - val_loss: 1.2843 - val_accuracy: 0.5556\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 349us/sample - loss: 1.0499 - accuracy: 0.5581 - val_loss: 1.2816 - val_accuracy: 0.5556\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 375us/sample - loss: 1.0438 - accuracy: 0.5698 - val_loss: 1.2778 - val_accuracy: 0.5556\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 365us/sample - loss: 1.0394 - accuracy: 0.5698 - val_loss: 1.2751 - val_accuracy: 0.5556\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 380us/sample - loss: 1.0335 - accuracy: 0.5581 - val_loss: 1.2724 - val_accuracy: 0.5556\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 369us/sample - loss: 1.0283 - accuracy: 0.5698 - val_loss: 1.2682 - val_accuracy: 0.5556\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.0221 - accuracy: 0.5698 - val_loss: 1.2638 - val_accuracy: 0.5778\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.0171 - accuracy: 0.5814 - val_loss: 1.2607 - val_accuracy: 0.5556\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.0125 - accuracy: 0.5698 - val_loss: 1.2575 - val_accuracy: 0.5556\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 1.6697 - accuracy: 0.3953 - val_loss: 1.3012 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 470us/sample - loss: 1.6321 - accuracy: 0.3721 - val_loss: 1.2900 - val_accuracy: 0.3778\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 1.6028 - accuracy: 0.4186 - val_loss: 1.2783 - val_accuracy: 0.3778\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 1.5671 - accuracy: 0.4419 - val_loss: 1.2673 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 1.5355 - accuracy: 0.4302 - val_loss: 1.2566 - val_accuracy: 0.3778\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 1.5055 - accuracy: 0.4419 - val_loss: 1.2477 - val_accuracy: 0.3778\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.4794 - accuracy: 0.5000 - val_loss: 1.2386 - val_accuracy: 0.3778\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 1.4542 - accuracy: 0.5000 - val_loss: 1.2301 - val_accuracy: 0.3778\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.4296 - accuracy: 0.5000 - val_loss: 1.2222 - val_accuracy: 0.3778\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.4073 - accuracy: 0.5000 - val_loss: 1.2147 - val_accuracy: 0.3778\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 1.3854 - accuracy: 0.5000 - val_loss: 1.2077 - val_accuracy: 0.3778\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.3647 - accuracy: 0.5116 - val_loss: 1.2005 - val_accuracy: 0.3778\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.3450 - accuracy: 0.5116 - val_loss: 1.1939 - val_accuracy: 0.3778\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.3271 - accuracy: 0.5116 - val_loss: 1.1877 - val_accuracy: 0.3778\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.3086 - accuracy: 0.5116 - val_loss: 1.1823 - val_accuracy: 0.3778\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 1.2947 - accuracy: 0.5116 - val_loss: 1.1767 - val_accuracy: 0.3778\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 362us/sample - loss: 1.2753 - accuracy: 0.5233 - val_loss: 1.1713 - val_accuracy: 0.3778\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 341us/sample - loss: 1.2600 - accuracy: 0.5233 - val_loss: 1.1659 - val_accuracy: 0.3778\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.2456 - accuracy: 0.5233 - val_loss: 1.1607 - val_accuracy: 0.3778\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.2310 - accuracy: 0.5233 - val_loss: 1.1553 - val_accuracy: 0.3778\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.2141 - accuracy: 0.5349 - val_loss: 1.1500 - val_accuracy: 0.3778\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 1.2009 - accuracy: 0.5349 - val_loss: 1.1451 - val_accuracy: 0.3778\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.1894 - accuracy: 0.5349 - val_loss: 1.1410 - val_accuracy: 0.3778\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.1763 - accuracy: 0.5233 - val_loss: 1.1365 - val_accuracy: 0.3778\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.1631 - accuracy: 0.5349 - val_loss: 1.1320 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.1524 - accuracy: 0.5349 - val_loss: 1.1278 - val_accuracy: 0.3778\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.1401 - accuracy: 0.5349 - val_loss: 1.1238 - val_accuracy: 0.3778\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 374us/sample - loss: 1.1309 - accuracy: 0.5349 - val_loss: 1.1207 - val_accuracy: 0.3778\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 1.1219 - accuracy: 0.5349 - val_loss: 1.1176 - val_accuracy: 0.3778\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 361us/sample - loss: 1.1131 - accuracy: 0.5349 - val_loss: 1.1146 - val_accuracy: 0.3778\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 380us/sample - loss: 1.1062 - accuracy: 0.5349 - val_loss: 1.1116 - val_accuracy: 0.3778\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 368us/sample - loss: 1.1008 - accuracy: 0.5465 - val_loss: 1.1084 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.0933 - accuracy: 0.5581 - val_loss: 1.1057 - val_accuracy: 0.4222\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.0876 - accuracy: 0.5581 - val_loss: 1.1029 - val_accuracy: 0.4222\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.0836 - accuracy: 0.5581 - val_loss: 1.1004 - val_accuracy: 0.4444\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.0771 - accuracy: 0.5581 - val_loss: 1.0980 - val_accuracy: 0.4444\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.0699 - accuracy: 0.5581 - val_loss: 1.0960 - val_accuracy: 0.4444\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 1.0652 - accuracy: 0.5581 - val_loss: 1.0937 - val_accuracy: 0.4444\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.0607 - accuracy: 0.5581 - val_loss: 1.0918 - val_accuracy: 0.4444\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.0573 - accuracy: 0.5581 - val_loss: 1.0899 - val_accuracy: 0.4444\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.0530 - accuracy: 0.5698 - val_loss: 1.0885 - val_accuracy: 0.4444\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.0488 - accuracy: 0.5698 - val_loss: 1.0870 - val_accuracy: 0.4444\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 386us/sample - loss: 1.0457 - accuracy: 0.5814 - val_loss: 1.0856 - val_accuracy: 0.4444\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.0422 - accuracy: 0.5814 - val_loss: 1.0841 - val_accuracy: 0.4444\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 359us/sample - loss: 1.0391 - accuracy: 0.5814 - val_loss: 1.0823 - val_accuracy: 0.4444\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 381us/sample - loss: 1.0352 - accuracy: 0.5814 - val_loss: 1.0808 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 349us/sample - loss: 1.0330 - accuracy: 0.5930 - val_loss: 1.0792 - val_accuracy: 0.4444\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 385us/sample - loss: 1.0292 - accuracy: 0.5814 - val_loss: 1.0779 - val_accuracy: 0.4444\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 365us/sample - loss: 1.0264 - accuracy: 0.5814 - val_loss: 1.0765 - val_accuracy: 0.4444\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.0231 - accuracy: 0.5930 - val_loss: 1.0753 - val_accuracy: 0.4444\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 1.4951 - accuracy: 0.4302 - val_loss: 1.2562 - val_accuracy: 0.5556\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 0s 380us/sample - loss: 1.4622 - accuracy: 0.4651 - val_loss: 1.2500 - val_accuracy: 0.5556\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.4339 - accuracy: 0.4651 - val_loss: 1.2445 - val_accuracy: 0.5556\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.4101 - accuracy: 0.4535 - val_loss: 1.2397 - val_accuracy: 0.5778\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.3878 - accuracy: 0.4767 - val_loss: 1.2364 - val_accuracy: 0.5556\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 0s 341us/sample - loss: 1.3723 - accuracy: 0.4884 - val_loss: 1.2331 - val_accuracy: 0.5556\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 0s 373us/sample - loss: 1.3566 - accuracy: 0.4884 - val_loss: 1.2305 - val_accuracy: 0.5556\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 0s 386us/sample - loss: 1.3429 - accuracy: 0.4884 - val_loss: 1.2282 - val_accuracy: 0.5556\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 0s 351us/sample - loss: 1.3312 - accuracy: 0.5000 - val_loss: 1.2251 - val_accuracy: 0.5556\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 0s 359us/sample - loss: 1.3185 - accuracy: 0.5000 - val_loss: 1.2226 - val_accuracy: 0.5556\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 0s 330us/sample - loss: 1.3076 - accuracy: 0.5233 - val_loss: 1.2209 - val_accuracy: 0.5556\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 0s 330us/sample - loss: 1.2949 - accuracy: 0.5116 - val_loss: 1.2189 - val_accuracy: 0.5556\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 0s 384us/sample - loss: 1.2858 - accuracy: 0.5116 - val_loss: 1.2178 - val_accuracy: 0.5556\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 0s 356us/sample - loss: 1.2776 - accuracy: 0.5233 - val_loss: 1.2168 - val_accuracy: 0.5778\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.2694 - accuracy: 0.5233 - val_loss: 1.2158 - val_accuracy: 0.5556\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.2615 - accuracy: 0.5233 - val_loss: 1.2148 - val_accuracy: 0.5556\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.2556 - accuracy: 0.5233 - val_loss: 1.2142 - val_accuracy: 0.5556\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.2486 - accuracy: 0.5349 - val_loss: 1.2127 - val_accuracy: 0.5333\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.2437 - accuracy: 0.5233 - val_loss: 1.2104 - val_accuracy: 0.5333\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.2365 - accuracy: 0.5116 - val_loss: 1.2095 - val_accuracy: 0.5333\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 0s 376us/sample - loss: 1.2300 - accuracy: 0.5116 - val_loss: 1.2086 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 0s 372us/sample - loss: 1.2261 - accuracy: 0.5233 - val_loss: 1.2061 - val_accuracy: 0.5333\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 0s 364us/sample - loss: 1.2193 - accuracy: 0.5116 - val_loss: 1.2046 - val_accuracy: 0.5333\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.2135 - accuracy: 0.5116 - val_loss: 1.2042 - val_accuracy: 0.5111\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 1.2087 - accuracy: 0.5116 - val_loss: 1.2032 - val_accuracy: 0.5111\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 0s 363us/sample - loss: 1.2019 - accuracy: 0.5116 - val_loss: 1.2023 - val_accuracy: 0.5111\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 0s 365us/sample - loss: 1.1946 - accuracy: 0.5116 - val_loss: 1.2017 - val_accuracy: 0.5111\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.1882 - accuracy: 0.5116 - val_loss: 1.2014 - val_accuracy: 0.5111\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 0s 387us/sample - loss: 1.1837 - accuracy: 0.5116 - val_loss: 1.2006 - val_accuracy: 0.5111\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.1796 - accuracy: 0.5233 - val_loss: 1.1999 - val_accuracy: 0.4667\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 0s 369us/sample - loss: 1.1729 - accuracy: 0.5233 - val_loss: 1.1991 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 0s 379us/sample - loss: 1.1664 - accuracy: 0.5233 - val_loss: 1.1987 - val_accuracy: 0.4889\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 0s 378us/sample - loss: 1.1611 - accuracy: 0.5349 - val_loss: 1.1982 - val_accuracy: 0.4889\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 0s 388us/sample - loss: 1.1565 - accuracy: 0.5349 - val_loss: 1.1975 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.1517 - accuracy: 0.5349 - val_loss: 1.1970 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 0s 357us/sample - loss: 1.1483 - accuracy: 0.5465 - val_loss: 1.1954 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 0s 355us/sample - loss: 1.1432 - accuracy: 0.5465 - val_loss: 1.1937 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.1389 - accuracy: 0.5465 - val_loss: 1.1932 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 0s 383us/sample - loss: 1.1348 - accuracy: 0.5581 - val_loss: 1.1925 - val_accuracy: 0.4889\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 0s 354us/sample - loss: 1.1310 - accuracy: 0.5814 - val_loss: 1.1916 - val_accuracy: 0.4889\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 0s 370us/sample - loss: 1.1282 - accuracy: 0.5814 - val_loss: 1.1900 - val_accuracy: 0.4889\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 0s 361us/sample - loss: 1.1240 - accuracy: 0.5930 - val_loss: 1.1882 - val_accuracy: 0.4889\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.1205 - accuracy: 0.6047 - val_loss: 1.1876 - val_accuracy: 0.4889\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 0s 359us/sample - loss: 1.1171 - accuracy: 0.6047 - val_loss: 1.1874 - val_accuracy: 0.4889\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.1141 - accuracy: 0.6047 - val_loss: 1.1875 - val_accuracy: 0.4889\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.1124 - accuracy: 0.6047 - val_loss: 1.1875 - val_accuracy: 0.4889\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 1.1089 - accuracy: 0.6047 - val_loss: 1.1876 - val_accuracy: 0.4889\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.1079 - accuracy: 0.6047 - val_loss: 1.1873 - val_accuracy: 0.4889\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 0s 370us/sample - loss: 1.1035 - accuracy: 0.6047 - val_loss: 1.1869 - val_accuracy: 0.4889\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.1015 - accuracy: 0.6047 - val_loss: 1.1863 - val_accuracy: 0.4889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5333333611488342</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-max_value: 8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-min_value: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-sampling: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-step: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-max_value: 8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-min_value: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-sampling: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-step: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23JI0eA1OFOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "243eba28-afdf-4b40-9982-f4ea27337712"
      },
      "source": [
        "tuner.search_space_summary()\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-max_value: 8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-min_value: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-sampling: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-step: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2eeOHoYbina",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#history_dict = history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDN2PrRc36l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tss7vRUEgAcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(all_acc_histories[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpKE3iTJBHzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#average_acc_history = [np.mean([x[i] for x in all_acc_histories]) for i in range(num_epochs)]\n",
        "##media per epoca degli score ottenuti per tutte le k-fold\n",
        "##per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\n",
        "##e si fa questo per tutte le epoche\n",
        "#average_loss_history = [np.mean([x[i] for x in all_loss_histories]) for i in range(num_epochs)]\n",
        "#average_val_acc_history = [np.mean([x[i] for x in all_val_acc_histories]) for i in range(num_epochs)]\n",
        "#average_val_loss_history = [np.mean([x[i] for x in all_val_loss_histories]) for i in range(num_epochs)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQrkCEMUD2RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(average_val_acc_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UhSxIaHtuO",
        "colab_type": "text"
      },
      "source": [
        "##Plotting training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zsienD5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJizyjnaIPhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, num_epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEHEYLgIQUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs, average_loss_history, 'bo', label='training loss')\n",
        "plt.plot(epochs, average_val_loss_history, 'b', label='validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc4wMjfI97j",
        "colab_type": "text"
      },
      "source": [
        "##Plotting train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi7VzbFIbtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs, average_acc_history, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, average_val_acc_history, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9RurwColqyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkgKUMeNlsg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMDZbXRUMocN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}