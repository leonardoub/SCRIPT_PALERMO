{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_optimization_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/Hyperparameter_optimization_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YN6Hc9lFNNk",
        "colab_type": "text"
      },
      "source": [
        "#Optimization of hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py6sopCQLbAy",
        "colab_type": "code",
        "outputId": "0a33dc85-6a41-4895-f0f7-39c9ac0147e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -U keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/93/5db8ac61f6547ce94b534a1cf614961a6e302559f0cdd1b37248052c9761/keras_tuner-1.0.0-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.17.4)\n",
            "Collecting tensorflow>=2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/44/4e8cc8c84cf235628ee919ba97ee029f2d080fa3573e26fe726973d004b4/tensorflow-2.1.0rc2-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (5.4.8)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (0.2.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0-beta1->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow>=2.0.0-beta1->keras-tuner) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=2.0.0-beta1->keras-tuner) (2.8.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0-beta1->keras-tuner) (3.1.0)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15354 sha256=2270dc56b756053b7856bd11645c9a63cc8b7517cec52d03a177822678cc7b1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built terminaltables\n",
            "\u001b[31mERROR: tensorflow 2.1.0rc2 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow, terminaltables, colorama, keras-tuner\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed colorama-0.4.3 google-auth-1.10.0 keras-tuner-1.0.0 tensorboard-2.1.0 tensorflow-2.1.0rc2 tensorflow-estimator-2.1.0 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck9uZtF_gzU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "4b8a8de1-e1e3-40db-c18f-e4805a11234f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-87QSVhqhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSbeCedhuxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbcwLGg3iNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQdR4izXiT0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5wIylYmsQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = df_test.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data_stand = train_data - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVOoNOvm0Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_stand = test_data - mean\n",
        "test_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00VohsAyokpq",
        "colab_type": "text"
      },
      "source": [
        "##Vettorizzare i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvS_9ISpxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={'adenocarcinoma':0, 'large cell':1, 'squamous cell carcinoma':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPW9U0XrWY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_dec = [word_index[label] for label in train_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4SBiKFQsKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels_dec = [word_index[label] for label in test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMbTYR7okJq",
        "colab_type": "code",
        "outputId": "b30b82df-e1fd-49ff-9edb-177ebb5a8828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Frv4FDNn6Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels_dec)\n",
        "one_hot_test_labels = to_categorical(test_labels_dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn0tkOGc3LKN",
        "colab_type": "text"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS76u6iu3Seg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjC4zqJ3bui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.9, svd_solver='full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLUCf9qX4p_e",
        "colab_type": "code",
        "outputId": "794f71bf-c5f6-4020-c135-0da04c444fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pca.fit(train_data_stand)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyaKgNZ44o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_pca = pca.transform(train_data_stand)\n",
        "test_data_stand_pca = pca.transform(test_data_stand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9C4nl05b_g",
        "colab_type": "code",
        "outputId": "81003d9d-4fa3-4d9d-dc45-c82bc225dae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_data_stand_pca.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSKvSu4s5ip",
        "colab_type": "text"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osgm8ZvLpZh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTbHiq0D-4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAzbu7P1VylY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqbUCK5wOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KutkQ9Noj5mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hp):\n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "#  model.add(layers.Dense(units=(hp.Int('units', min_value=3, max_value=8, step=1)), \n",
        "#                         activation='relu', input_shape=(9,)))\n",
        "\n",
        "  model.add(layers.Dense(6, activation='relu', input_shape=(9,)))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "#  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "  lr = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "  momentum = hp.Choice('momentum', [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "  model.compile(optimizer=SGD(learning_rate=lr, momentum=momentum), \n",
        "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIxDu50pBeiz",
        "colab_type": "text"
      },
      "source": [
        "#Stratified k-fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyLcvedUBpxA",
        "colab_type": "text"
      },
      "source": [
        "This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1apcZ19gFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBDM-PtBx5V",
        "colab_type": "code",
        "outputId": "0aa9c5a6-7764-495e-9118-6ace96dfe0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "skf.get_n_splits(train_data_stand_pca, train_labels_dec)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "5d189364-c961-4372-c95e-9db26ce8a7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for train_index, test_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  0   1   2   4   5   6   7   8   9  10  11  12  14  15  16  17  18  19\n",
            "  20  22  23  24  25  27  28  29  30  31  32  33  34  36  37  38  39  40\n",
            "  41  42  43  44  45  46  47  48  49  51  52  53  55  56  57  58  59  60\n",
            "  61  62  63  64  65  66  67  69  70  71  72  74  75  76  77  78  79  80\n",
            "  81  83  84  85  86  87  88  89  90  92  93  94  95  96  97  98  99 100\n",
            " 101 102 103 104 105 107 108 109 110 111 113 114 115 116 117 119 120 121\n",
            " 122 123 124 125 126 127 128 129] TEST: [  3  13  21  26  35  50  54  68  73  82  91 106 112 118 130]\n",
            "TRAIN: [  0   1   3   4   5   6   8   9  10  11  12  13  14  15  16  17  19  20\n",
            "  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
            "  39  40  41  42  44  45  46  48  49  50  51  52  53  54  55  56  57  58\n",
            "  59  60  62  63  64  65  66  67  68  69  71  72  73  75  76  77  78  79\n",
            "  80  81  82  83  84  85  86  87  88  89  90  91  92  94  95  96  97  98\n",
            " 100 101 102 103 104 105 106 107 109 110 111 112 113 115 116 117 118 120\n",
            " 121 122 124 125 126 127 128 129 130] TEST: [  2   7  18  43  47  61  70  74  93  99 108 114 119 123]\n",
            "TRAIN: [  0   1   2   3   4   5   7   8   9  11  12  13  14  15  16  17  18  19\n",
            "  20  21  22  23  24  25  26  27  28  29  30  32  33  34  35  36  37  38\n",
            "  39  40  41  42  43  44  45  46  47  48  50  51  52  53  54  56  57  58\n",
            "  59  60  61  62  63  65  66  67  68  69  70  72  73  74  76  77  78  79\n",
            "  80  81  82  83  84  85  87  88  89  90  91  92  93  96  97  98  99 100\n",
            " 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 117 118 119\n",
            " 120 121 122 123 124 125 127 128 130] TEST: [  6  10  31  49  55  64  71  75  86  94  95 116 126 129]\n",
            "TRAIN: [  0   2   3   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19\n",
            "  20  21  22  23  24  25  26  27  29  30  31  33  34  35  36  37  38  39\n",
            "  40  41  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
            "  59  60  61  62  63  64  65  66  68  70  71  73  74  75  76  77  78  79\n",
            "  80  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
            "  99 100 101 102 105 106 107 108 109 111 112 113 114 115 116 117 118 119\n",
            " 120 122 123 124 125 126 127 129 130] TEST: [  1   4  28  32  42  67  69  72  81 103 104 110 121 128]\n",
            "TRAIN: [  1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18  20\n",
            "  21  23  24  25  26  27  28  29  30  31  32  33  34  35  36  38  39  40\n",
            "  42  43  44  45  46  47  48  49  50  51  53  54  55  57  58  59  60  61\n",
            "  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  80\n",
            "  81  82  83  84  85  86  87  90  91  92  93  94  95  96  97  98  99 100\n",
            " 101 102 103 104 105 106 108 109 110 111 112 113 114 115 116 117 118 119\n",
            " 121 122 123 124 125 126 127 128 129 130] TEST: [  0  14  19  22  37  41  52  56  79  88  89 107 120]\n",
            "TRAIN: [  0   1   2   3   4   5   6   7   8  10  11  12  13  14  16  17  18  19\n",
            "  20  21  22  23  25  26  27  28  29  30  31  32  34  35  36  37  38  39\n",
            "  41  42  43  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60\n",
            "  61  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
            "  80  81  82  84  85  86  87  88  89  90  91  92  93  94  95  96  99 100\n",
            " 101 102 103 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
            " 121 122 123 124 125 126 127 128 129 130] TEST: [  9  15  24  33  40  51  59  62  83  97  98 113 117]\n",
            "TRAIN: [  0   1   2   3   4   5   6   7   9  10  11  12  13  14  15  18  19  20\n",
            "  21  22  24  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
            "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
            "  59  61  62  64  65  66  67  68  69  70  71  72  73  74  75  76  79  81\n",
            "  82  83  84  85  86  87  88  89  91  92  93  94  95  96  97  98  99 100\n",
            " 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
            " 119 120 121 123 124 125 126 127 128 129 130] TEST: [  8  16  17  23  25  60  63  77  78  80  90 122]\n",
            "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  30  31  32  33  34  35  36  37\n",
            "  39  40  41  42  43  44  45  47  49  50  51  52  53  54  55  56  58  59\n",
            "  60  61  62  63  64  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
            "  79  80  81  82  83  85  86  87  88  89  90  91  92  93  94  95  96  97\n",
            "  98  99 100 102 103 104 106 107 108 109 110 111 112 113 114 115 116 117\n",
            " 118 119 120 121 122 123 124 126 128 129 130] TEST: [ 12  29  38  46  48  57  65  84 101 105 125 127]\n",
            "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18\n",
            "  19  21  22  23  24  25  26  27  28  29  31  32  33  34  35  36  37  38\n",
            "  40  41  42  43  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
            "  60  61  62  63  64  65  67  68  69  70  71  72  73  74  75  76  77  78\n",
            "  79  80  81  82  83  84  85  86  88  89  90  91  93  94  95  96  97  98\n",
            "  99 101 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
            " 119 120 121 122 123 125 126 127 128 129 130] TEST: [ 11  20  30  39  44  45  66  87  92 100 102 124]\n",
            "TRAIN: [  0   1   2   3   4   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  28  29  30  31  32  33  35  37  38  39\n",
            "  40  41  42  43  44  45  46  47  48  49  50  51  52  54  55  56  57  59\n",
            "  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  77  78\n",
            "  79  80  81  82  83  84  86  87  88  89  90  91  92  93  94  95  97  98\n",
            "  99 100 101 102 103 104 105 106 107 108 110 112 113 114 116 117 118 119\n",
            " 120 121 122 123 124 125 126 127 128 129 130] TEST: [  5  27  34  36  53  58  76  85  96 109 111 115]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgdGK-8FK-U_",
        "colab_type": "code",
        "outputId": "8ce1f869-c376-483d-e5e2-3cf83a36c6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels_dec[125]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJg0XD4Shhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Sq8r9GEPx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "#  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "#  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "\n",
        "#  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "#  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "#  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "#  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        "#  model = build_model()\n",
        "#  model.fit(partial_train_data, one_hot_partial_train_targets, epochs = num_epochs, batch_size=1)\n",
        "\n",
        "#  val_loss, val_accuracy = model.evaluate(val_data, one_hot_val_targets)\n",
        "#  all_scores.append(val_accuracy)\n",
        "#I parametri per la valutazione vengono calcolati una volta per ogni k-fold, per ogni set di validazione, quindi k volte"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X5B3lasRcsR",
        "colab_type": "text"
      },
      "source": [
        "C'è un problema: keras.utils.to_categorical produces a one-hot encoded class vector, i.e. the multilabel-indicator mentioned in the error message. StratifiedKFold is not designed to work with such input; i.e. your y must be a 1-D array of your class labels.\n",
        "Essentially, what you have to do is simply to invert the order of the operations: split first (using your intial y_train), and convert to_categorical afterwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yP9-PE1Wjz-",
        "colab_type": "text"
      },
      "source": [
        "#Keras tuner RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8a1I3yU9FS",
        "colab_type": "code",
        "outputId": "702a005d-1b8e-494e-ce1c-a30c0b7f2176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 50\n",
        "#all_acc_histories = []\n",
        "#all_loss_histories = []\n",
        "#all_val_acc_histories = []\n",
        "#all_val_loss_histories = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        " \n",
        "  tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=10, \n",
        "                       executions_per_trial=3, directory='/content/my_dir', project_name='helloworld')\n",
        "  \n",
        "  tuner.search_space_summary()\n",
        "\n",
        "  tuner.search(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=10)\n",
        "  \n",
        "\n",
        "#  acc_history = history.history['acc']\n",
        "#  all_acc_histories.append(acc_history)\n",
        "\n",
        "#  loss_history = history.history['loss']\n",
        "#  all_loss_histories.append(loss_history)\n",
        "\n",
        "#  acc_val_history = history.history['val_acc']\n",
        "#  all_val_acc_histories.append(acc_val_history)\n",
        "\n",
        "#  loss_val_history = history.history['val_loss']\n",
        "#  all_val_loss_histories.append(loss_val_history)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali è una lista lunga num_epochs,\n",
        "#ogni elemento può essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 3.1082 - accuracy: 0.3362 - val_loss: 2.6273 - val_accuracy: 0.2667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 448us/sample - loss: 1.9073 - accuracy: 0.3534 - val_loss: 2.0746 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.3860 - accuracy: 0.3362 - val_loss: 1.7900 - val_accuracy: 0.2000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 349us/sample - loss: 1.1637 - accuracy: 0.5000 - val_loss: 1.6338 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.0665 - accuracy: 0.5431 - val_loss: 1.6176 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 327us/sample - loss: 1.0330 - accuracy: 0.5517 - val_loss: 1.5898 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.0048 - accuracy: 0.5517 - val_loss: 1.5896 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 387us/sample - loss: 0.9686 - accuracy: 0.5862 - val_loss: 1.5457 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 340us/sample - loss: 0.9554 - accuracy: 0.5948 - val_loss: 1.5402 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.9360 - accuracy: 0.6121 - val_loss: 1.5416 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 334us/sample - loss: 0.9231 - accuracy: 0.5862 - val_loss: 1.5602 - val_accuracy: 0.4667\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 0.9058 - accuracy: 0.6121 - val_loss: 1.5518 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.8971 - accuracy: 0.6207 - val_loss: 1.5353 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 333us/sample - loss: 0.8851 - accuracy: 0.6293 - val_loss: 1.5583 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8695 - accuracy: 0.6466 - val_loss: 1.5594 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.8654 - accuracy: 0.6638 - val_loss: 1.5271 - val_accuracy: 0.4000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 0.8622 - accuracy: 0.6552 - val_loss: 1.5627 - val_accuracy: 0.4000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 0.8538 - accuracy: 0.6466 - val_loss: 1.5910 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.8462 - accuracy: 0.6810 - val_loss: 1.5687 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.8487 - accuracy: 0.6552 - val_loss: 1.5574 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.8423 - accuracy: 0.6466 - val_loss: 1.5065 - val_accuracy: 0.4667\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.8348 - accuracy: 0.6724 - val_loss: 1.5830 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 0.8288 - accuracy: 0.6897 - val_loss: 1.5571 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.8237 - accuracy: 0.6810 - val_loss: 1.5382 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8185 - accuracy: 0.6810 - val_loss: 1.5618 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 376us/sample - loss: 0.8156 - accuracy: 0.6810 - val_loss: 1.5451 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 383us/sample - loss: 0.8172 - accuracy: 0.6810 - val_loss: 1.5491 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 336us/sample - loss: 0.8093 - accuracy: 0.6810 - val_loss: 1.5998 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 365us/sample - loss: 0.8076 - accuracy: 0.6983 - val_loss: 1.6355 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 328us/sample - loss: 0.8015 - accuracy: 0.6897 - val_loss: 1.6311 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 0.7975 - accuracy: 0.6638 - val_loss: 1.6258 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 0.7921 - accuracy: 0.6810 - val_loss: 1.6483 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 0.7917 - accuracy: 0.6810 - val_loss: 1.6808 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 337us/sample - loss: 0.7889 - accuracy: 0.6983 - val_loss: 1.6358 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 328us/sample - loss: 0.7844 - accuracy: 0.6983 - val_loss: 1.6820 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 0.7819 - accuracy: 0.6897 - val_loss: 1.6304 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 0.7803 - accuracy: 0.6983 - val_loss: 1.6712 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 0.7787 - accuracy: 0.6983 - val_loss: 1.6698 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 0.7757 - accuracy: 0.6983 - val_loss: 1.6870 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.7770 - accuracy: 0.6897 - val_loss: 1.6745 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.7732 - accuracy: 0.6897 - val_loss: 1.7136 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 0.7706 - accuracy: 0.6983 - val_loss: 1.7073 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 0.7678 - accuracy: 0.6983 - val_loss: 1.6983 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 321us/sample - loss: 0.7633 - accuracy: 0.6983 - val_loss: 1.7904 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.7640 - accuracy: 0.6983 - val_loss: 1.7512 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.7596 - accuracy: 0.7069 - val_loss: 1.7450 - val_accuracy: 0.4667\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 327us/sample - loss: 0.7568 - accuracy: 0.7155 - val_loss: 1.7657 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 378us/sample - loss: 0.7575 - accuracy: 0.6983 - val_loss: 1.7799 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 0.7535 - accuracy: 0.7069 - val_loss: 1.7495 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 345us/sample - loss: 0.7511 - accuracy: 0.6983 - val_loss: 1.7888 - val_accuracy: 0.4667\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.1915 - accuracy: 0.4655 - val_loss: 1.8212 - val_accuracy: 0.4667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 334us/sample - loss: 1.5116 - accuracy: 0.4914 - val_loss: 1.6419 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 1.2994 - accuracy: 0.5086 - val_loss: 1.5529 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 333us/sample - loss: 1.2274 - accuracy: 0.5172 - val_loss: 1.5017 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 1.1640 - accuracy: 0.5345 - val_loss: 1.5141 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 342us/sample - loss: 1.1164 - accuracy: 0.5259 - val_loss: 1.4743 - val_accuracy: 0.4667\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 1.0830 - accuracy: 0.5172 - val_loss: 1.4446 - val_accuracy: 0.4667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 1.0488 - accuracy: 0.5517 - val_loss: 1.4635 - val_accuracy: 0.4667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 1.0237 - accuracy: 0.5948 - val_loss: 1.4268 - val_accuracy: 0.4667\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 388us/sample - loss: 1.0067 - accuracy: 0.5776 - val_loss: 1.4445 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 430us/sample - loss: 0.9864 - accuracy: 0.6121 - val_loss: 1.4167 - val_accuracy: 0.5333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 415us/sample - loss: 0.9647 - accuracy: 0.6121 - val_loss: 1.4181 - val_accuracy: 0.5333\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 371us/sample - loss: 0.9611 - accuracy: 0.5776 - val_loss: 1.4113 - val_accuracy: 0.5333\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 345us/sample - loss: 0.9453 - accuracy: 0.6121 - val_loss: 1.4033 - val_accuracy: 0.5333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 0.9397 - accuracy: 0.6121 - val_loss: 1.3966 - val_accuracy: 0.5333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.9294 - accuracy: 0.5862 - val_loss: 1.3861 - val_accuracy: 0.5333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.9250 - accuracy: 0.6466 - val_loss: 1.3925 - val_accuracy: 0.5333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 368us/sample - loss: 0.9145 - accuracy: 0.6207 - val_loss: 1.3756 - val_accuracy: 0.5333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 353us/sample - loss: 0.9081 - accuracy: 0.6121 - val_loss: 1.3669 - val_accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 332us/sample - loss: 0.9005 - accuracy: 0.6207 - val_loss: 1.3532 - val_accuracy: 0.6000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.8945 - accuracy: 0.6121 - val_loss: 1.3547 - val_accuracy: 0.6000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 321us/sample - loss: 0.8916 - accuracy: 0.6466 - val_loss: 1.3341 - val_accuracy: 0.6000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 0.8863 - accuracy: 0.6379 - val_loss: 1.3345 - val_accuracy: 0.6000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 0.8818 - accuracy: 0.6466 - val_loss: 1.3103 - val_accuracy: 0.6000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 366us/sample - loss: 0.8797 - accuracy: 0.6379 - val_loss: 1.3121 - val_accuracy: 0.6000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8693 - accuracy: 0.6466 - val_loss: 1.2968 - val_accuracy: 0.6000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8698 - accuracy: 0.6379 - val_loss: 1.3019 - val_accuracy: 0.6000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 0.8635 - accuracy: 0.6466 - val_loss: 1.2918 - val_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 0.8610 - accuracy: 0.6379 - val_loss: 1.2906 - val_accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.8561 - accuracy: 0.6379 - val_loss: 1.2838 - val_accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 0.8538 - accuracy: 0.6552 - val_loss: 1.3051 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 340us/sample - loss: 0.8486 - accuracy: 0.6724 - val_loss: 1.3086 - val_accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 0.8456 - accuracy: 0.6466 - val_loss: 1.3322 - val_accuracy: 0.6000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.8404 - accuracy: 0.6379 - val_loss: 1.3150 - val_accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 0.8392 - accuracy: 0.6552 - val_loss: 1.3090 - val_accuracy: 0.6000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 0.8361 - accuracy: 0.6466 - val_loss: 1.3083 - val_accuracy: 0.6000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 394us/sample - loss: 0.8338 - accuracy: 0.6638 - val_loss: 1.2897 - val_accuracy: 0.6000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 356us/sample - loss: 0.8306 - accuracy: 0.6638 - val_loss: 1.2743 - val_accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 372us/sample - loss: 0.8281 - accuracy: 0.6724 - val_loss: 1.2897 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 368us/sample - loss: 0.8278 - accuracy: 0.6724 - val_loss: 1.2858 - val_accuracy: 0.6000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 321us/sample - loss: 0.8284 - accuracy: 0.6983 - val_loss: 1.2914 - val_accuracy: 0.6000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 359us/sample - loss: 0.8242 - accuracy: 0.6638 - val_loss: 1.2930 - val_accuracy: 0.6000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 0.8171 - accuracy: 0.6810 - val_loss: 1.2914 - val_accuracy: 0.6000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 373us/sample - loss: 0.8177 - accuracy: 0.6724 - val_loss: 1.3070 - val_accuracy: 0.6000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 338us/sample - loss: 0.8184 - accuracy: 0.6897 - val_loss: 1.3128 - val_accuracy: 0.6000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 0.8167 - accuracy: 0.6638 - val_loss: 1.2985 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8129 - accuracy: 0.6897 - val_loss: 1.2990 - val_accuracy: 0.5333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 0.8128 - accuracy: 0.6724 - val_loss: 1.3161 - val_accuracy: 0.5333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 0.8120 - accuracy: 0.6983 - val_loss: 1.3270 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.8115 - accuracy: 0.6897 - val_loss: 1.3307 - val_accuracy: 0.5333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.5572 - accuracy: 0.2759 - val_loss: 2.4430 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 364us/sample - loss: 1.5439 - accuracy: 0.3707 - val_loss: 2.0371 - val_accuracy: 0.4667\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.2253 - accuracy: 0.4741 - val_loss: 1.8489 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.0808 - accuracy: 0.5259 - val_loss: 1.7279 - val_accuracy: 0.4667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 1.0101 - accuracy: 0.5345 - val_loss: 1.7044 - val_accuracy: 0.4667\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.9699 - accuracy: 0.5517 - val_loss: 1.6471 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.9361 - accuracy: 0.5776 - val_loss: 1.6186 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 0.9272 - accuracy: 0.5862 - val_loss: 1.6003 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.9104 - accuracy: 0.6034 - val_loss: 1.5698 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 0.9058 - accuracy: 0.5948 - val_loss: 1.5686 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 376us/sample - loss: 0.9017 - accuracy: 0.6034 - val_loss: 1.5557 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8953 - accuracy: 0.6207 - val_loss: 1.5787 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 0.8928 - accuracy: 0.6207 - val_loss: 1.5621 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.8835 - accuracy: 0.6293 - val_loss: 1.5615 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.8813 - accuracy: 0.6207 - val_loss: 1.5332 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8795 - accuracy: 0.6121 - val_loss: 1.5409 - val_accuracy: 0.4000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 0.8741 - accuracy: 0.6293 - val_loss: 1.5424 - val_accuracy: 0.4000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8743 - accuracy: 0.6293 - val_loss: 1.5150 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 0.8710 - accuracy: 0.6293 - val_loss: 1.5295 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8693 - accuracy: 0.6293 - val_loss: 1.5116 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8677 - accuracy: 0.6121 - val_loss: 1.5206 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 0.8636 - accuracy: 0.6379 - val_loss: 1.5199 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.8584 - accuracy: 0.6293 - val_loss: 1.5160 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 0.8617 - accuracy: 0.6293 - val_loss: 1.4999 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8602 - accuracy: 0.6293 - val_loss: 1.5227 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.8554 - accuracy: 0.6121 - val_loss: 1.5102 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8533 - accuracy: 0.6293 - val_loss: 1.5173 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 391us/sample - loss: 0.8482 - accuracy: 0.6293 - val_loss: 1.5065 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 0.8479 - accuracy: 0.6293 - val_loss: 1.5137 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 0.8491 - accuracy: 0.6293 - val_loss: 1.5274 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 251us/sample - loss: 0.8467 - accuracy: 0.6293 - val_loss: 1.5111 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 0.8458 - accuracy: 0.6293 - val_loss: 1.5167 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.8410 - accuracy: 0.6207 - val_loss: 1.5409 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.8378 - accuracy: 0.6466 - val_loss: 1.5443 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 337us/sample - loss: 0.8399 - accuracy: 0.6379 - val_loss: 1.5321 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.8375 - accuracy: 0.6379 - val_loss: 1.5419 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.8370 - accuracy: 0.6466 - val_loss: 1.5599 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 0.8365 - accuracy: 0.6293 - val_loss: 1.5564 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.8311 - accuracy: 0.6379 - val_loss: 1.5523 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.8345 - accuracy: 0.6379 - val_loss: 1.5455 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 0.8315 - accuracy: 0.6379 - val_loss: 1.5445 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 0.8281 - accuracy: 0.6466 - val_loss: 1.5190 - val_accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.8271 - accuracy: 0.6379 - val_loss: 1.5725 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.8268 - accuracy: 0.6379 - val_loss: 1.5928 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.8237 - accuracy: 0.6379 - val_loss: 1.5277 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 0.8277 - accuracy: 0.6379 - val_loss: 1.5422 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 339us/sample - loss: 0.8232 - accuracy: 0.6466 - val_loss: 1.5622 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.8210 - accuracy: 0.6466 - val_loss: 1.5447 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 0.8207 - accuracy: 0.6379 - val_loss: 1.5798 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 0.8229 - accuracy: 0.6466 - val_loss: 1.5663 - val_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5111111402511597</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.2536 - accuracy: 0.4828 - val_loss: 1.3014 - val_accuracy: 0.2667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 373us/sample - loss: 1.1082 - accuracy: 0.5259 - val_loss: 1.2594 - val_accuracy: 0.5333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.0482 - accuracy: 0.5259 - val_loss: 1.2127 - val_accuracy: 0.5333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 1.0203 - accuracy: 0.5259 - val_loss: 1.2120 - val_accuracy: 0.5333\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 0.9720 - accuracy: 0.5517 - val_loss: 1.1914 - val_accuracy: 0.5333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 338us/sample - loss: 0.9538 - accuracy: 0.5517 - val_loss: 1.1648 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 356us/sample - loss: 0.9513 - accuracy: 0.5603 - val_loss: 1.1454 - val_accuracy: 0.5333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.9315 - accuracy: 0.5776 - val_loss: 1.1316 - val_accuracy: 0.5333\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.9190 - accuracy: 0.5862 - val_loss: 1.1136 - val_accuracy: 0.5333\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.9130 - accuracy: 0.5776 - val_loss: 1.0747 - val_accuracy: 0.5333\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 339us/sample - loss: 0.9040 - accuracy: 0.5948 - val_loss: 1.0401 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.9002 - accuracy: 0.5862 - val_loss: 1.0624 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 0.8914 - accuracy: 0.6207 - val_loss: 1.0744 - val_accuracy: 0.5333\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 0.8917 - accuracy: 0.6121 - val_loss: 1.0763 - val_accuracy: 0.5333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.8912 - accuracy: 0.5948 - val_loss: 1.0604 - val_accuracy: 0.6000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 0.8923 - accuracy: 0.5948 - val_loss: 1.0442 - val_accuracy: 0.6000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.8922 - accuracy: 0.6121 - val_loss: 1.0823 - val_accuracy: 0.6000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8866 - accuracy: 0.5948 - val_loss: 1.0581 - val_accuracy: 0.6000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8873 - accuracy: 0.6034 - val_loss: 1.0860 - val_accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 0.8902 - accuracy: 0.5862 - val_loss: 1.0359 - val_accuracy: 0.6000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8969 - accuracy: 0.6034 - val_loss: 1.0459 - val_accuracy: 0.6000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 0.8842 - accuracy: 0.6034 - val_loss: 1.0471 - val_accuracy: 0.6000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8780 - accuracy: 0.5862 - val_loss: 1.0469 - val_accuracy: 0.6000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 400us/sample - loss: 0.8752 - accuracy: 0.6207 - val_loss: 1.0524 - val_accuracy: 0.6000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 339us/sample - loss: 0.8757 - accuracy: 0.5862 - val_loss: 1.0416 - val_accuracy: 0.6000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.8750 - accuracy: 0.6034 - val_loss: 1.0316 - val_accuracy: 0.6000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8691 - accuracy: 0.6034 - val_loss: 1.0409 - val_accuracy: 0.6000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.8771 - accuracy: 0.5948 - val_loss: 1.0137 - val_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8605 - accuracy: 0.6121 - val_loss: 1.0354 - val_accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 376us/sample - loss: 0.8593 - accuracy: 0.6121 - val_loss: 1.0344 - val_accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 0.8545 - accuracy: 0.6207 - val_loss: 1.0608 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 0.8489 - accuracy: 0.6034 - val_loss: 1.0537 - val_accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.8511 - accuracy: 0.6034 - val_loss: 1.0606 - val_accuracy: 0.6000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.8501 - accuracy: 0.6293 - val_loss: 1.0554 - val_accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 0.8434 - accuracy: 0.6121 - val_loss: 1.0567 - val_accuracy: 0.6000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8467 - accuracy: 0.6034 - val_loss: 1.0355 - val_accuracy: 0.6000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 340us/sample - loss: 0.8511 - accuracy: 0.6121 - val_loss: 1.0517 - val_accuracy: 0.5333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 0.8462 - accuracy: 0.6034 - val_loss: 1.0518 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 0.8420 - accuracy: 0.6121 - val_loss: 1.0243 - val_accuracy: 0.5333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.8385 - accuracy: 0.5948 - val_loss: 1.0264 - val_accuracy: 0.5333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.8426 - accuracy: 0.6034 - val_loss: 1.0145 - val_accuracy: 0.5333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.8368 - accuracy: 0.6379 - val_loss: 1.0327 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.8305 - accuracy: 0.6034 - val_loss: 1.0224 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 352us/sample - loss: 0.8340 - accuracy: 0.6034 - val_loss: 1.0187 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.8254 - accuracy: 0.6034 - val_loss: 1.0424 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8262 - accuracy: 0.6121 - val_loss: 1.0270 - val_accuracy: 0.4667\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 0.8247 - accuracy: 0.6207 - val_loss: 1.0280 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.8196 - accuracy: 0.6121 - val_loss: 1.0250 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.8214 - accuracy: 0.6207 - val_loss: 1.0289 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 0.8215 - accuracy: 0.6207 - val_loss: 1.0542 - val_accuracy: 0.4000\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.4032 - accuracy: 0.3276 - val_loss: 1.2511 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 1.0398 - accuracy: 0.4741 - val_loss: 1.2451 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 0.9829 - accuracy: 0.4914 - val_loss: 1.2227 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 0.9738 - accuracy: 0.4828 - val_loss: 1.1902 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.9486 - accuracy: 0.5086 - val_loss: 1.1893 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 0.9218 - accuracy: 0.5431 - val_loss: 1.2325 - val_accuracy: 0.4667\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 0.9036 - accuracy: 0.5345 - val_loss: 1.2254 - val_accuracy: 0.4667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 0.8939 - accuracy: 0.5603 - val_loss: 1.2210 - val_accuracy: 0.4667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8945 - accuracy: 0.5603 - val_loss: 1.2110 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 363us/sample - loss: 0.8778 - accuracy: 0.5776 - val_loss: 1.2531 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8723 - accuracy: 0.6121 - val_loss: 1.2254 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8624 - accuracy: 0.6207 - val_loss: 1.2698 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8596 - accuracy: 0.6034 - val_loss: 1.2773 - val_accuracy: 0.4667\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.8512 - accuracy: 0.6121 - val_loss: 1.2974 - val_accuracy: 0.5333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.8449 - accuracy: 0.6034 - val_loss: 1.3035 - val_accuracy: 0.5333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.8365 - accuracy: 0.6379 - val_loss: 1.2885 - val_accuracy: 0.5333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.8352 - accuracy: 0.5948 - val_loss: 1.3149 - val_accuracy: 0.5333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 333us/sample - loss: 0.8333 - accuracy: 0.6207 - val_loss: 1.3585 - val_accuracy: 0.5333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 321us/sample - loss: 0.8243 - accuracy: 0.6379 - val_loss: 1.3866 - val_accuracy: 0.5333\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8253 - accuracy: 0.6121 - val_loss: 1.4128 - val_accuracy: 0.5333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 0.8230 - accuracy: 0.6293 - val_loss: 1.4056 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.8118 - accuracy: 0.6293 - val_loss: 1.4327 - val_accuracy: 0.5333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.8164 - accuracy: 0.6379 - val_loss: 1.4016 - val_accuracy: 0.4667\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 0.8097 - accuracy: 0.6121 - val_loss: 1.4322 - val_accuracy: 0.5333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.8055 - accuracy: 0.6207 - val_loss: 1.4539 - val_accuracy: 0.5333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8009 - accuracy: 0.6379 - val_loss: 1.4545 - val_accuracy: 0.5333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.7975 - accuracy: 0.6466 - val_loss: 1.4741 - val_accuracy: 0.5333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.7986 - accuracy: 0.6379 - val_loss: 1.5143 - val_accuracy: 0.5333\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.8064 - accuracy: 0.6293 - val_loss: 1.5109 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.7883 - accuracy: 0.6552 - val_loss: 1.5757 - val_accuracy: 0.5333\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 359us/sample - loss: 0.7876 - accuracy: 0.6552 - val_loss: 1.5490 - val_accuracy: 0.5333\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 0.7868 - accuracy: 0.6724 - val_loss: 1.5664 - val_accuracy: 0.5333\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 0.7807 - accuracy: 0.6638 - val_loss: 1.5971 - val_accuracy: 0.5333\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.7786 - accuracy: 0.6638 - val_loss: 1.6020 - val_accuracy: 0.5333\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.7771 - accuracy: 0.6379 - val_loss: 1.6535 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.7745 - accuracy: 0.6466 - val_loss: 1.5943 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.7681 - accuracy: 0.6724 - val_loss: 1.6262 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 331us/sample - loss: 0.7740 - accuracy: 0.6552 - val_loss: 1.6613 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.7629 - accuracy: 0.6724 - val_loss: 1.6782 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.7638 - accuracy: 0.6552 - val_loss: 1.6353 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 0.7686 - accuracy: 0.6466 - val_loss: 1.6324 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.7666 - accuracy: 0.6466 - val_loss: 1.6920 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 0.7551 - accuracy: 0.6552 - val_loss: 1.7132 - val_accuracy: 0.5333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.7527 - accuracy: 0.6638 - val_loss: 1.7413 - val_accuracy: 0.5333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.7495 - accuracy: 0.6638 - val_loss: 1.7144 - val_accuracy: 0.5333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.7490 - accuracy: 0.6552 - val_loss: 1.7318 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 359us/sample - loss: 0.7488 - accuracy: 0.6724 - val_loss: 1.7843 - val_accuracy: 0.5333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.7469 - accuracy: 0.6552 - val_loss: 1.7507 - val_accuracy: 0.5333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.7446 - accuracy: 0.6466 - val_loss: 1.7884 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 0.7398 - accuracy: 0.6638 - val_loss: 1.8354 - val_accuracy: 0.5333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.0111 - accuracy: 0.3362 - val_loss: 1.8054 - val_accuracy: 0.2667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 369us/sample - loss: 1.2545 - accuracy: 0.4483 - val_loss: 1.3318 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 371us/sample - loss: 1.0969 - accuracy: 0.5431 - val_loss: 1.1435 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 1.0279 - accuracy: 0.5000 - val_loss: 1.1030 - val_accuracy: 0.4667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.9911 - accuracy: 0.5345 - val_loss: 1.0875 - val_accuracy: 0.5333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.9670 - accuracy: 0.5431 - val_loss: 1.0568 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 0.9564 - accuracy: 0.5776 - val_loss: 1.0453 - val_accuracy: 0.5333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 0.9462 - accuracy: 0.5862 - val_loss: 1.0230 - val_accuracy: 0.5333\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.9419 - accuracy: 0.5517 - val_loss: 1.0445 - val_accuracy: 0.5333\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.9280 - accuracy: 0.5862 - val_loss: 1.0248 - val_accuracy: 0.5333\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 365us/sample - loss: 0.9301 - accuracy: 0.5862 - val_loss: 1.0314 - val_accuracy: 0.5333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 0.9132 - accuracy: 0.6034 - val_loss: 1.0389 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 0.9113 - accuracy: 0.5862 - val_loss: 1.0347 - val_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 0.9055 - accuracy: 0.5862 - val_loss: 1.0255 - val_accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 321us/sample - loss: 0.8978 - accuracy: 0.6034 - val_loss: 1.0099 - val_accuracy: 0.5333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 0.9014 - accuracy: 0.5948 - val_loss: 1.0204 - val_accuracy: 0.5333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 348us/sample - loss: 0.8947 - accuracy: 0.5603 - val_loss: 1.0157 - val_accuracy: 0.5333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.8940 - accuracy: 0.5776 - val_loss: 0.9958 - val_accuracy: 0.5333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 0.8865 - accuracy: 0.6034 - val_loss: 1.0221 - val_accuracy: 0.5333\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8808 - accuracy: 0.6034 - val_loss: 1.0310 - val_accuracy: 0.5333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.8781 - accuracy: 0.6121 - val_loss: 1.0340 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.8757 - accuracy: 0.5948 - val_loss: 1.0181 - val_accuracy: 0.5333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.8667 - accuracy: 0.6121 - val_loss: 1.0075 - val_accuracy: 0.5333\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.8626 - accuracy: 0.6293 - val_loss: 1.0158 - val_accuracy: 0.5333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 0.8671 - accuracy: 0.6207 - val_loss: 1.0451 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 0.8616 - accuracy: 0.5948 - val_loss: 1.0376 - val_accuracy: 0.4667\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.8566 - accuracy: 0.6034 - val_loss: 1.0266 - val_accuracy: 0.4667\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.8615 - accuracy: 0.6034 - val_loss: 1.0222 - val_accuracy: 0.4667\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 0.8521 - accuracy: 0.6207 - val_loss: 1.0247 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.8540 - accuracy: 0.6293 - val_loss: 1.0512 - val_accuracy: 0.4667\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 0.8502 - accuracy: 0.5948 - val_loss: 1.0334 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.8444 - accuracy: 0.6207 - val_loss: 1.0312 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.8443 - accuracy: 0.6207 - val_loss: 1.0588 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 366us/sample - loss: 0.8422 - accuracy: 0.6121 - val_loss: 1.0731 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 0.8409 - accuracy: 0.6121 - val_loss: 1.0475 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.8381 - accuracy: 0.6121 - val_loss: 1.0457 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 0.8335 - accuracy: 0.6207 - val_loss: 1.0581 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.8339 - accuracy: 0.5862 - val_loss: 1.0651 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.8298 - accuracy: 0.6034 - val_loss: 1.0668 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 0.8287 - accuracy: 0.6207 - val_loss: 1.0806 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 0.8298 - accuracy: 0.6034 - val_loss: 1.0656 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 0.8270 - accuracy: 0.6121 - val_loss: 1.0753 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 0.8249 - accuracy: 0.6121 - val_loss: 1.0935 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 0.8170 - accuracy: 0.6121 - val_loss: 1.0944 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8182 - accuracy: 0.6207 - val_loss: 1.0960 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 364us/sample - loss: 0.8215 - accuracy: 0.5948 - val_loss: 1.0965 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 329us/sample - loss: 0.8152 - accuracy: 0.6379 - val_loss: 1.1105 - val_accuracy: 0.5333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 0.8204 - accuracy: 0.5948 - val_loss: 1.1215 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8122 - accuracy: 0.6034 - val_loss: 1.0981 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.8178 - accuracy: 0.5948 - val_loss: 1.0913 - val_accuracy: 0.5333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.6</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5777778029441833</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.9030 - accuracy: 0.3103 - val_loss: 1.9749 - val_accuracy: 0.2667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 355us/sample - loss: 1.7212 - accuracy: 0.2931 - val_loss: 1.8019 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.5829 - accuracy: 0.3534 - val_loss: 1.6955 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.4854 - accuracy: 0.3534 - val_loss: 1.6033 - val_accuracy: 0.2667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.4167 - accuracy: 0.3276 - val_loss: 1.5414 - val_accuracy: 0.2667\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 1.3649 - accuracy: 0.3362 - val_loss: 1.4730 - val_accuracy: 0.2667\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 1.3278 - accuracy: 0.3362 - val_loss: 1.4204 - val_accuracy: 0.2667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.2927 - accuracy: 0.3448 - val_loss: 1.3893 - val_accuracy: 0.2667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 1.2648 - accuracy: 0.3534 - val_loss: 1.3602 - val_accuracy: 0.2667\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.2383 - accuracy: 0.3879 - val_loss: 1.3172 - val_accuracy: 0.2667\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 1.2129 - accuracy: 0.3966 - val_loss: 1.2858 - val_accuracy: 0.2667\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.1948 - accuracy: 0.4052 - val_loss: 1.2612 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.1727 - accuracy: 0.4397 - val_loss: 1.2448 - val_accuracy: 0.2667\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 1.1562 - accuracy: 0.4310 - val_loss: 1.2297 - val_accuracy: 0.2667\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.1401 - accuracy: 0.4397 - val_loss: 1.2185 - val_accuracy: 0.2667\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.1225 - accuracy: 0.4483 - val_loss: 1.1891 - val_accuracy: 0.2667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 250us/sample - loss: 1.1101 - accuracy: 0.4569 - val_loss: 1.1762 - val_accuracy: 0.2667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 1.0984 - accuracy: 0.4483 - val_loss: 1.1568 - val_accuracy: 0.2667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.0875 - accuracy: 0.4569 - val_loss: 1.1452 - val_accuracy: 0.2667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.0773 - accuracy: 0.4397 - val_loss: 1.1350 - val_accuracy: 0.2667\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 1.0659 - accuracy: 0.4655 - val_loss: 1.1236 - val_accuracy: 0.2667\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 402us/sample - loss: 1.0590 - accuracy: 0.4569 - val_loss: 1.1124 - val_accuracy: 0.2667\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 1.0489 - accuracy: 0.4569 - val_loss: 1.1055 - val_accuracy: 0.2667\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 1.0410 - accuracy: 0.4569 - val_loss: 1.1012 - val_accuracy: 0.2667\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 327us/sample - loss: 1.0347 - accuracy: 0.4655 - val_loss: 1.0949 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 1.0286 - accuracy: 0.4569 - val_loss: 1.0851 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.0204 - accuracy: 0.4569 - val_loss: 1.0806 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 1.0180 - accuracy: 0.4569 - val_loss: 1.0699 - val_accuracy: 0.2667\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 338us/sample - loss: 1.0085 - accuracy: 0.4741 - val_loss: 1.0741 - val_accuracy: 0.2667\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 1.0040 - accuracy: 0.4828 - val_loss: 1.0667 - val_accuracy: 0.2667\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.9994 - accuracy: 0.4828 - val_loss: 1.0675 - val_accuracy: 0.2667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.9940 - accuracy: 0.4914 - val_loss: 1.0582 - val_accuracy: 0.2667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 0.9906 - accuracy: 0.4828 - val_loss: 1.0524 - val_accuracy: 0.2667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 0.9849 - accuracy: 0.5000 - val_loss: 1.0550 - val_accuracy: 0.2667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 327us/sample - loss: 0.9813 - accuracy: 0.5259 - val_loss: 1.0532 - val_accuracy: 0.2667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 331us/sample - loss: 0.9776 - accuracy: 0.5172 - val_loss: 1.0541 - val_accuracy: 0.2667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.9735 - accuracy: 0.5259 - val_loss: 1.0435 - val_accuracy: 0.2667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 0.9701 - accuracy: 0.5172 - val_loss: 1.0446 - val_accuracy: 0.2667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 0.9666 - accuracy: 0.5259 - val_loss: 1.0431 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 385us/sample - loss: 0.9644 - accuracy: 0.5259 - val_loss: 1.0434 - val_accuracy: 0.2667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 0.9615 - accuracy: 0.5172 - val_loss: 1.0387 - val_accuracy: 0.2667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.9598 - accuracy: 0.5431 - val_loss: 1.0336 - val_accuracy: 0.2667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 0.9565 - accuracy: 0.5345 - val_loss: 1.0359 - val_accuracy: 0.2667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.9548 - accuracy: 0.5431 - val_loss: 1.0362 - val_accuracy: 0.2667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 0.9509 - accuracy: 0.5431 - val_loss: 1.0305 - val_accuracy: 0.2667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.9490 - accuracy: 0.5517 - val_loss: 1.0324 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 0.9462 - accuracy: 0.5431 - val_loss: 1.0319 - val_accuracy: 0.3333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.9451 - accuracy: 0.5431 - val_loss: 1.0264 - val_accuracy: 0.3333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.9419 - accuracy: 0.5603 - val_loss: 1.0288 - val_accuracy: 0.3333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 0.9406 - accuracy: 0.5345 - val_loss: 1.0293 - val_accuracy: 0.3333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 3.8928 - accuracy: 0.2328 - val_loss: 2.2983 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 327us/sample - loss: 2.8350 - accuracy: 0.2759 - val_loss: 1.9369 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 2.0253 - accuracy: 0.3276 - val_loss: 1.8394 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 1.5900 - accuracy: 0.3621 - val_loss: 1.8418 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 1.3974 - accuracy: 0.3793 - val_loss: 1.8311 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.3163 - accuracy: 0.4310 - val_loss: 1.7866 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 258us/sample - loss: 1.2775 - accuracy: 0.4483 - val_loss: 1.7391 - val_accuracy: 0.2667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.2460 - accuracy: 0.4741 - val_loss: 1.7050 - val_accuracy: 0.2667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.2252 - accuracy: 0.4828 - val_loss: 1.6916 - val_accuracy: 0.2667\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.2040 - accuracy: 0.4828 - val_loss: 1.6455 - val_accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 1.1833 - accuracy: 0.4914 - val_loss: 1.6220 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.1696 - accuracy: 0.4914 - val_loss: 1.5942 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.1525 - accuracy: 0.4914 - val_loss: 1.5830 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.1423 - accuracy: 0.4828 - val_loss: 1.5711 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 1.1309 - accuracy: 0.4741 - val_loss: 1.5674 - val_accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 1.1201 - accuracy: 0.4828 - val_loss: 1.5515 - val_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 252us/sample - loss: 1.1109 - accuracy: 0.4914 - val_loss: 1.5335 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 1.1027 - accuracy: 0.4914 - val_loss: 1.5114 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.0936 - accuracy: 0.4828 - val_loss: 1.5126 - val_accuracy: 0.3333\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.0836 - accuracy: 0.4914 - val_loss: 1.4993 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 1.0767 - accuracy: 0.4741 - val_loss: 1.4898 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 1.0678 - accuracy: 0.4741 - val_loss: 1.5011 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 1.0622 - accuracy: 0.4741 - val_loss: 1.4814 - val_accuracy: 0.3333\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.0537 - accuracy: 0.4828 - val_loss: 1.4754 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 1.0536 - accuracy: 0.4828 - val_loss: 1.4748 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.0410 - accuracy: 0.4914 - val_loss: 1.4491 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.0342 - accuracy: 0.4828 - val_loss: 1.4405 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.0254 - accuracy: 0.4914 - val_loss: 1.4445 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 1.0203 - accuracy: 0.5086 - val_loss: 1.4427 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 1.0168 - accuracy: 0.4914 - val_loss: 1.4422 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.0136 - accuracy: 0.5086 - val_loss: 1.4362 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.0071 - accuracy: 0.5086 - val_loss: 1.4256 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 1.0011 - accuracy: 0.5259 - val_loss: 1.4237 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.9967 - accuracy: 0.5172 - val_loss: 1.4298 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 336us/sample - loss: 0.9914 - accuracy: 0.5086 - val_loss: 1.4315 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.9871 - accuracy: 0.5086 - val_loss: 1.4283 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.9843 - accuracy: 0.5086 - val_loss: 1.4155 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 0.9798 - accuracy: 0.5259 - val_loss: 1.4174 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.9780 - accuracy: 0.5172 - val_loss: 1.3998 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 0.9735 - accuracy: 0.5172 - val_loss: 1.4128 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 0.9685 - accuracy: 0.5259 - val_loss: 1.4108 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 0.9649 - accuracy: 0.5431 - val_loss: 1.4050 - val_accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.9610 - accuracy: 0.5431 - val_loss: 1.4073 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 0.9586 - accuracy: 0.5517 - val_loss: 1.4140 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.9556 - accuracy: 0.5431 - val_loss: 1.4038 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.9521 - accuracy: 0.5690 - val_loss: 1.4060 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 0.9483 - accuracy: 0.5690 - val_loss: 1.4067 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 0.9465 - accuracy: 0.5690 - val_loss: 1.4048 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 0.9431 - accuracy: 0.5776 - val_loss: 1.4043 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 338us/sample - loss: 0.9408 - accuracy: 0.5690 - val_loss: 1.3977 - val_accuracy: 0.4000\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.7679 - accuracy: 0.3190 - val_loss: 1.1784 - val_accuracy: 0.4667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.5744 - accuracy: 0.3276 - val_loss: 1.0813 - val_accuracy: 0.4667\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 1.4292 - accuracy: 0.3621 - val_loss: 1.0226 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 1.3264 - accuracy: 0.3534 - val_loss: 0.9869 - val_accuracy: 0.4667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.2432 - accuracy: 0.3534 - val_loss: 0.9603 - val_accuracy: 0.4667\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.1890 - accuracy: 0.3534 - val_loss: 0.9503 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.1484 - accuracy: 0.3707 - val_loss: 0.9459 - val_accuracy: 0.4667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 1.1171 - accuracy: 0.3707 - val_loss: 0.9446 - val_accuracy: 0.4667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.0918 - accuracy: 0.3793 - val_loss: 0.9437 - val_accuracy: 0.4667\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 1.0715 - accuracy: 0.3621 - val_loss: 0.9475 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 1.0552 - accuracy: 0.3621 - val_loss: 0.9483 - val_accuracy: 0.4667\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 1.0457 - accuracy: 0.3621 - val_loss: 0.9633 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 1.0335 - accuracy: 0.3621 - val_loss: 0.9554 - val_accuracy: 0.4667\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.0237 - accuracy: 0.3707 - val_loss: 0.9614 - val_accuracy: 0.4667\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.0147 - accuracy: 0.3793 - val_loss: 0.9575 - val_accuracy: 0.4667\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.0082 - accuracy: 0.3793 - val_loss: 0.9579 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.0023 - accuracy: 0.3707 - val_loss: 0.9640 - val_accuracy: 0.4667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 0.9971 - accuracy: 0.3793 - val_loss: 0.9709 - val_accuracy: 0.4667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 0.9915 - accuracy: 0.3534 - val_loss: 0.9696 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 0.9880 - accuracy: 0.3448 - val_loss: 0.9737 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 0.9843 - accuracy: 0.3534 - val_loss: 0.9802 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 337us/sample - loss: 0.9814 - accuracy: 0.3793 - val_loss: 0.9719 - val_accuracy: 0.6000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.9759 - accuracy: 0.3966 - val_loss: 0.9832 - val_accuracy: 0.6000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.9724 - accuracy: 0.4483 - val_loss: 0.9873 - val_accuracy: 0.5333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.9694 - accuracy: 0.4483 - val_loss: 0.9878 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.9677 - accuracy: 0.4828 - val_loss: 0.9960 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 0.9648 - accuracy: 0.4655 - val_loss: 0.9953 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.9616 - accuracy: 0.4741 - val_loss: 0.9951 - val_accuracy: 0.3333\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 252us/sample - loss: 0.9589 - accuracy: 0.4741 - val_loss: 0.9979 - val_accuracy: 0.3333\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 0.9571 - accuracy: 0.4914 - val_loss: 1.0013 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.9542 - accuracy: 0.5000 - val_loss: 1.0007 - val_accuracy: 0.3333\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.9522 - accuracy: 0.4914 - val_loss: 1.0091 - val_accuracy: 0.3333\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.9498 - accuracy: 0.4914 - val_loss: 1.0129 - val_accuracy: 0.3333\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.9476 - accuracy: 0.5000 - val_loss: 1.0153 - val_accuracy: 0.3333\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 0.9447 - accuracy: 0.5000 - val_loss: 1.0168 - val_accuracy: 0.3333\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 0.9426 - accuracy: 0.4914 - val_loss: 1.0261 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 0.9405 - accuracy: 0.5000 - val_loss: 1.0327 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 0.9379 - accuracy: 0.5000 - val_loss: 1.0361 - val_accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.9363 - accuracy: 0.5000 - val_loss: 1.0436 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.9358 - accuracy: 0.5086 - val_loss: 1.0461 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 0.9342 - accuracy: 0.5259 - val_loss: 1.0484 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.9327 - accuracy: 0.5172 - val_loss: 1.0582 - val_accuracy: 0.3333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.9304 - accuracy: 0.5172 - val_loss: 1.0567 - val_accuracy: 0.3333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.9277 - accuracy: 0.5172 - val_loss: 1.0610 - val_accuracy: 0.3333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.9259 - accuracy: 0.5259 - val_loss: 1.0613 - val_accuracy: 0.3333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 238us/sample - loss: 0.9245 - accuracy: 0.5259 - val_loss: 1.0632 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.9229 - accuracy: 0.5172 - val_loss: 1.0652 - val_accuracy: 0.3333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 0.9234 - accuracy: 0.5259 - val_loss: 1.0676 - val_accuracy: 0.3333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 0.9214 - accuracy: 0.5172 - val_loss: 1.0722 - val_accuracy: 0.3333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 0.9200 - accuracy: 0.5172 - val_loss: 1.0723 - val_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.4444444477558136</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.2950 - accuracy: 0.4310 - val_loss: 2.3061 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 393us/sample - loss: 2.2829 - accuracy: 0.4397 - val_loss: 2.2925 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 381us/sample - loss: 2.2702 - accuracy: 0.4397 - val_loss: 2.2793 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 322us/sample - loss: 2.2579 - accuracy: 0.4397 - val_loss: 2.2654 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 2.2455 - accuracy: 0.4397 - val_loss: 2.2513 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 2.2335 - accuracy: 0.4397 - val_loss: 2.2370 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 2.2215 - accuracy: 0.4397 - val_loss: 2.2238 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 2.2091 - accuracy: 0.4397 - val_loss: 2.2098 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 2.1971 - accuracy: 0.4310 - val_loss: 2.1952 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 2.1854 - accuracy: 0.4224 - val_loss: 2.1814 - val_accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 2.1733 - accuracy: 0.4397 - val_loss: 2.1679 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 2.1616 - accuracy: 0.4483 - val_loss: 2.1538 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 2.1499 - accuracy: 0.4397 - val_loss: 2.1404 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 2.1385 - accuracy: 0.4483 - val_loss: 2.1268 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 2.1268 - accuracy: 0.4655 - val_loss: 2.1131 - val_accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 2.1147 - accuracy: 0.4655 - val_loss: 2.1003 - val_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 2.1031 - accuracy: 0.4655 - val_loss: 2.0858 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 2.0914 - accuracy: 0.4655 - val_loss: 2.0722 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 2.0799 - accuracy: 0.4655 - val_loss: 2.0587 - val_accuracy: 0.3333\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 2.0685 - accuracy: 0.4655 - val_loss: 2.0460 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 2.0567 - accuracy: 0.4655 - val_loss: 2.0319 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 2.0449 - accuracy: 0.4655 - val_loss: 2.0181 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 2.0338 - accuracy: 0.4655 - val_loss: 2.0052 - val_accuracy: 0.3333\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 2.0231 - accuracy: 0.4655 - val_loss: 1.9918 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 2.0119 - accuracy: 0.4655 - val_loss: 1.9799 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 2.0012 - accuracy: 0.4655 - val_loss: 1.9671 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 1.9901 - accuracy: 0.4655 - val_loss: 1.9547 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.9788 - accuracy: 0.4655 - val_loss: 1.9432 - val_accuracy: 0.3333\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.9676 - accuracy: 0.4655 - val_loss: 1.9300 - val_accuracy: 0.3333\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.9571 - accuracy: 0.4655 - val_loss: 1.9184 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 1.9469 - accuracy: 0.4655 - val_loss: 1.9068 - val_accuracy: 0.3333\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.9367 - accuracy: 0.4655 - val_loss: 1.8952 - val_accuracy: 0.3333\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 1.9268 - accuracy: 0.4655 - val_loss: 1.8836 - val_accuracy: 0.3333\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 1.9163 - accuracy: 0.4569 - val_loss: 1.8711 - val_accuracy: 0.3333\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.9064 - accuracy: 0.4569 - val_loss: 1.8599 - val_accuracy: 0.3333\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.8966 - accuracy: 0.4569 - val_loss: 1.8490 - val_accuracy: 0.3333\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 1.8869 - accuracy: 0.4569 - val_loss: 1.8376 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.8763 - accuracy: 0.4569 - val_loss: 1.8257 - val_accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 1.8667 - accuracy: 0.4569 - val_loss: 1.8147 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 1.8566 - accuracy: 0.4569 - val_loss: 1.8039 - val_accuracy: 0.3333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.8472 - accuracy: 0.4569 - val_loss: 1.7920 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.8376 - accuracy: 0.4569 - val_loss: 1.7818 - val_accuracy: 0.3333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 1.8278 - accuracy: 0.4569 - val_loss: 1.7708 - val_accuracy: 0.3333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.8182 - accuracy: 0.4569 - val_loss: 1.7596 - val_accuracy: 0.3333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 1.8088 - accuracy: 0.4569 - val_loss: 1.7491 - val_accuracy: 0.3333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.8001 - accuracy: 0.4483 - val_loss: 1.7394 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.7912 - accuracy: 0.4483 - val_loss: 1.7282 - val_accuracy: 0.3333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.7802 - accuracy: 0.4483 - val_loss: 1.7163 - val_accuracy: 0.3333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 349us/sample - loss: 1.7708 - accuracy: 0.4483 - val_loss: 1.7050 - val_accuracy: 0.3333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.7619 - accuracy: 0.4483 - val_loss: 1.6946 - val_accuracy: 0.3333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.9228 - accuracy: 0.3276 - val_loss: 1.6947 - val_accuracy: 0.6000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 2.8975 - accuracy: 0.3276 - val_loss: 1.6790 - val_accuracy: 0.6000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 2.8727 - accuracy: 0.3276 - val_loss: 1.6630 - val_accuracy: 0.6667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 2.8475 - accuracy: 0.3276 - val_loss: 1.6489 - val_accuracy: 0.6667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 2.8230 - accuracy: 0.3362 - val_loss: 1.6336 - val_accuracy: 0.6667\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 2.7975 - accuracy: 0.3362 - val_loss: 1.6181 - val_accuracy: 0.6667\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 2.7728 - accuracy: 0.3276 - val_loss: 1.6030 - val_accuracy: 0.6667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 329us/sample - loss: 2.7490 - accuracy: 0.3276 - val_loss: 1.5899 - val_accuracy: 0.6667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 2.7251 - accuracy: 0.3276 - val_loss: 1.5751 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 2.7022 - accuracy: 0.3276 - val_loss: 1.5617 - val_accuracy: 0.6667\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 2.6782 - accuracy: 0.3276 - val_loss: 1.5491 - val_accuracy: 0.6667\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 2.6547 - accuracy: 0.3276 - val_loss: 1.5357 - val_accuracy: 0.6667\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 2.6312 - accuracy: 0.3276 - val_loss: 1.5211 - val_accuracy: 0.6667\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 2.6089 - accuracy: 0.3276 - val_loss: 1.5094 - val_accuracy: 0.6667\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 2.5868 - accuracy: 0.3276 - val_loss: 1.4973 - val_accuracy: 0.6667\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 2.5645 - accuracy: 0.3362 - val_loss: 1.4846 - val_accuracy: 0.6667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 2.5422 - accuracy: 0.3362 - val_loss: 1.4740 - val_accuracy: 0.6667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 2.5205 - accuracy: 0.3362 - val_loss: 1.4619 - val_accuracy: 0.6667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 2.4978 - accuracy: 0.3362 - val_loss: 1.4498 - val_accuracy: 0.6667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 2.4762 - accuracy: 0.3362 - val_loss: 1.4380 - val_accuracy: 0.6667\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 245us/sample - loss: 2.4545 - accuracy: 0.3362 - val_loss: 1.4266 - val_accuracy: 0.6667\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 2.4336 - accuracy: 0.3448 - val_loss: 1.4158 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 2.4126 - accuracy: 0.3448 - val_loss: 1.4049 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 2.3926 - accuracy: 0.3448 - val_loss: 1.3946 - val_accuracy: 0.6667\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 2.3710 - accuracy: 0.3448 - val_loss: 1.3833 - val_accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 2.3508 - accuracy: 0.3448 - val_loss: 1.3724 - val_accuracy: 0.6667\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 2.3298 - accuracy: 0.3448 - val_loss: 1.3609 - val_accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 2.3092 - accuracy: 0.3448 - val_loss: 1.3503 - val_accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 2.2896 - accuracy: 0.3534 - val_loss: 1.3416 - val_accuracy: 0.6667\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 2.2705 - accuracy: 0.3534 - val_loss: 1.3321 - val_accuracy: 0.6667\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 2.2519 - accuracy: 0.3621 - val_loss: 1.3227 - val_accuracy: 0.6667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 240us/sample - loss: 2.2329 - accuracy: 0.3621 - val_loss: 1.3138 - val_accuracy: 0.6667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 249us/sample - loss: 2.2144 - accuracy: 0.3621 - val_loss: 1.3034 - val_accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 2.1961 - accuracy: 0.3621 - val_loss: 1.2943 - val_accuracy: 0.6667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 2.1781 - accuracy: 0.3621 - val_loss: 1.2855 - val_accuracy: 0.6667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 2.1600 - accuracy: 0.3621 - val_loss: 1.2769 - val_accuracy: 0.6667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 2.1432 - accuracy: 0.3621 - val_loss: 1.2693 - val_accuracy: 0.7333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 2.1273 - accuracy: 0.3621 - val_loss: 1.2613 - val_accuracy: 0.7333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 2.1101 - accuracy: 0.3621 - val_loss: 1.2532 - val_accuracy: 0.7333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 2.0940 - accuracy: 0.3621 - val_loss: 1.2450 - val_accuracy: 0.7333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 2.0780 - accuracy: 0.3621 - val_loss: 1.2375 - val_accuracy: 0.7333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 2.0627 - accuracy: 0.3707 - val_loss: 1.2295 - val_accuracy: 0.7333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 2.0463 - accuracy: 0.3793 - val_loss: 1.2234 - val_accuracy: 0.7333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 2.0315 - accuracy: 0.3793 - val_loss: 1.2165 - val_accuracy: 0.7333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 2.0171 - accuracy: 0.3793 - val_loss: 1.2091 - val_accuracy: 0.7333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 358us/sample - loss: 2.0024 - accuracy: 0.3793 - val_loss: 1.2024 - val_accuracy: 0.7333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.9883 - accuracy: 0.3793 - val_loss: 1.1961 - val_accuracy: 0.7333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.9746 - accuracy: 0.3793 - val_loss: 1.1903 - val_accuracy: 0.7333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 1.9609 - accuracy: 0.3879 - val_loss: 1.1842 - val_accuracy: 0.7333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.9469 - accuracy: 0.3879 - val_loss: 1.1782 - val_accuracy: 0.7333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.7171 - accuracy: 0.3017 - val_loss: 2.2869 - val_accuracy: 0.2000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 1.7092 - accuracy: 0.3017 - val_loss: 2.2735 - val_accuracy: 0.2000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.7012 - accuracy: 0.3017 - val_loss: 2.2605 - val_accuracy: 0.2000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.6934 - accuracy: 0.3017 - val_loss: 2.2487 - val_accuracy: 0.2000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.6856 - accuracy: 0.3017 - val_loss: 2.2363 - val_accuracy: 0.2000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.6780 - accuracy: 0.3017 - val_loss: 2.2239 - val_accuracy: 0.2000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 1.6699 - accuracy: 0.3017 - val_loss: 2.2114 - val_accuracy: 0.2000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.6625 - accuracy: 0.3103 - val_loss: 2.1985 - val_accuracy: 0.2000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.6545 - accuracy: 0.3103 - val_loss: 2.1861 - val_accuracy: 0.2000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 1.6472 - accuracy: 0.3103 - val_loss: 2.1748 - val_accuracy: 0.2000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 1.6401 - accuracy: 0.3190 - val_loss: 2.1626 - val_accuracy: 0.2000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 1.6328 - accuracy: 0.3190 - val_loss: 2.1515 - val_accuracy: 0.2000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 1.6255 - accuracy: 0.3190 - val_loss: 2.1403 - val_accuracy: 0.2000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 258us/sample - loss: 1.6185 - accuracy: 0.3190 - val_loss: 2.1290 - val_accuracy: 0.2000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.6114 - accuracy: 0.3190 - val_loss: 2.1170 - val_accuracy: 0.2000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 1.6045 - accuracy: 0.3190 - val_loss: 2.1059 - val_accuracy: 0.2000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 1.5972 - accuracy: 0.3276 - val_loss: 2.0945 - val_accuracy: 0.2000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 253us/sample - loss: 1.5904 - accuracy: 0.3362 - val_loss: 2.0828 - val_accuracy: 0.2000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.5837 - accuracy: 0.3362 - val_loss: 2.0726 - val_accuracy: 0.2000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 1.5770 - accuracy: 0.3362 - val_loss: 2.0612 - val_accuracy: 0.2000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.5704 - accuracy: 0.3362 - val_loss: 2.0511 - val_accuracy: 0.2000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.5640 - accuracy: 0.3362 - val_loss: 2.0406 - val_accuracy: 0.2000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.5576 - accuracy: 0.3362 - val_loss: 2.0295 - val_accuracy: 0.2000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 1.5510 - accuracy: 0.3362 - val_loss: 2.0192 - val_accuracy: 0.2000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 1.5445 - accuracy: 0.3362 - val_loss: 2.0078 - val_accuracy: 0.2000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.5381 - accuracy: 0.3362 - val_loss: 1.9978 - val_accuracy: 0.2000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.5317 - accuracy: 0.3362 - val_loss: 1.9871 - val_accuracy: 0.2000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 1.5252 - accuracy: 0.3362 - val_loss: 1.9754 - val_accuracy: 0.2000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 331us/sample - loss: 1.5191 - accuracy: 0.3362 - val_loss: 1.9656 - val_accuracy: 0.2000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.5129 - accuracy: 0.3362 - val_loss: 1.9552 - val_accuracy: 0.2000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 1.5070 - accuracy: 0.3362 - val_loss: 1.9464 - val_accuracy: 0.2000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 1.5011 - accuracy: 0.3362 - val_loss: 1.9360 - val_accuracy: 0.2000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 241us/sample - loss: 1.4951 - accuracy: 0.3362 - val_loss: 1.9268 - val_accuracy: 0.2000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.4894 - accuracy: 0.3362 - val_loss: 1.9172 - val_accuracy: 0.2000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 1.4835 - accuracy: 0.3362 - val_loss: 1.9072 - val_accuracy: 0.2000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 242us/sample - loss: 1.4778 - accuracy: 0.3362 - val_loss: 1.8979 - val_accuracy: 0.2000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.4722 - accuracy: 0.3362 - val_loss: 1.8890 - val_accuracy: 0.2667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 247us/sample - loss: 1.4667 - accuracy: 0.3448 - val_loss: 1.8785 - val_accuracy: 0.2667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 1.4611 - accuracy: 0.3448 - val_loss: 1.8697 - val_accuracy: 0.2667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.4558 - accuracy: 0.3448 - val_loss: 1.8616 - val_accuracy: 0.2667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.4503 - accuracy: 0.3448 - val_loss: 1.8515 - val_accuracy: 0.2667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 257us/sample - loss: 1.4448 - accuracy: 0.3362 - val_loss: 1.8433 - val_accuracy: 0.2667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 1.4396 - accuracy: 0.3362 - val_loss: 1.8342 - val_accuracy: 0.2667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 1.4346 - accuracy: 0.3362 - val_loss: 1.8256 - val_accuracy: 0.2667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 252us/sample - loss: 1.4294 - accuracy: 0.3362 - val_loss: 1.8171 - val_accuracy: 0.2667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.4243 - accuracy: 0.3362 - val_loss: 1.8084 - val_accuracy: 0.2667\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 1.4192 - accuracy: 0.3362 - val_loss: 1.7999 - val_accuracy: 0.2667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 1.4142 - accuracy: 0.3362 - val_loss: 1.7910 - val_accuracy: 0.2667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 1.4091 - accuracy: 0.3362 - val_loss: 1.7833 - val_accuracy: 0.2667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.4043 - accuracy: 0.3362 - val_loss: 1.7750 - val_accuracy: 0.2667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.5</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.4444444477558136</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.8068 - accuracy: 0.5000 - val_loss: 1.8400 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.2754 - accuracy: 0.4828 - val_loss: 1.5696 - val_accuracy: 0.2667\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 239us/sample - loss: 1.1000 - accuracy: 0.5086 - val_loss: 1.4236 - val_accuracy: 0.2667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 1.0330 - accuracy: 0.5431 - val_loss: 1.3841 - val_accuracy: 0.2667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.9907 - accuracy: 0.5603 - val_loss: 1.2818 - val_accuracy: 0.2667\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 0.9479 - accuracy: 0.5690 - val_loss: 1.3044 - val_accuracy: 0.2667\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.9240 - accuracy: 0.5948 - val_loss: 1.2825 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 338us/sample - loss: 0.9042 - accuracy: 0.6121 - val_loss: 1.2800 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.8953 - accuracy: 0.6121 - val_loss: 1.2505 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 239us/sample - loss: 0.8902 - accuracy: 0.6207 - val_loss: 1.3114 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 0.8845 - accuracy: 0.6207 - val_loss: 1.3416 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8759 - accuracy: 0.6293 - val_loss: 1.3303 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 363us/sample - loss: 0.8655 - accuracy: 0.6207 - val_loss: 1.3131 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 352us/sample - loss: 0.8585 - accuracy: 0.6552 - val_loss: 1.3538 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 0.8600 - accuracy: 0.6466 - val_loss: 1.3203 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.8543 - accuracy: 0.6466 - val_loss: 1.3531 - val_accuracy: 0.4000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.8558 - accuracy: 0.6379 - val_loss: 1.3254 - val_accuracy: 0.4000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.8473 - accuracy: 0.6379 - val_loss: 1.3449 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 337us/sample - loss: 0.8568 - accuracy: 0.6466 - val_loss: 1.3562 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.8486 - accuracy: 0.6552 - val_loss: 1.3743 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 0.8474 - accuracy: 0.6552 - val_loss: 1.3837 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.8371 - accuracy: 0.6552 - val_loss: 1.3800 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.8358 - accuracy: 0.6552 - val_loss: 1.3638 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 257us/sample - loss: 0.8438 - accuracy: 0.6379 - val_loss: 1.4099 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 327us/sample - loss: 0.8365 - accuracy: 0.6552 - val_loss: 1.4123 - val_accuracy: 0.4667\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 0.8367 - accuracy: 0.6379 - val_loss: 1.3582 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 0.8351 - accuracy: 0.6379 - val_loss: 1.3799 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 246us/sample - loss: 0.8293 - accuracy: 0.6466 - val_loss: 1.3175 - val_accuracy: 0.4667\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 0.8345 - accuracy: 0.6466 - val_loss: 1.3699 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.8244 - accuracy: 0.6379 - val_loss: 1.3944 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 0.8232 - accuracy: 0.6466 - val_loss: 1.4613 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 0.8307 - accuracy: 0.6552 - val_loss: 1.3821 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.8299 - accuracy: 0.6466 - val_loss: 1.3626 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 0.8306 - accuracy: 0.6379 - val_loss: 1.3537 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 328us/sample - loss: 0.8225 - accuracy: 0.6466 - val_loss: 1.3977 - val_accuracy: 0.5333\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 257us/sample - loss: 0.8214 - accuracy: 0.6466 - val_loss: 1.3858 - val_accuracy: 0.5333\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.8209 - accuracy: 0.6552 - val_loss: 1.3942 - val_accuracy: 0.5333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.8245 - accuracy: 0.6379 - val_loss: 1.4421 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 0.8192 - accuracy: 0.6293 - val_loss: 1.3675 - val_accuracy: 0.5333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.8146 - accuracy: 0.6552 - val_loss: 1.3698 - val_accuracy: 0.5333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 251us/sample - loss: 0.8133 - accuracy: 0.6466 - val_loss: 1.4200 - val_accuracy: 0.5333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 0.8119 - accuracy: 0.6293 - val_loss: 1.4040 - val_accuracy: 0.5333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.8070 - accuracy: 0.6724 - val_loss: 1.3456 - val_accuracy: 0.5333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 0.8088 - accuracy: 0.6552 - val_loss: 1.4040 - val_accuracy: 0.5333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8074 - accuracy: 0.6379 - val_loss: 1.4290 - val_accuracy: 0.5333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 0.8080 - accuracy: 0.6466 - val_loss: 1.4087 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 0.8033 - accuracy: 0.6810 - val_loss: 1.3728 - val_accuracy: 0.5333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.8032 - accuracy: 0.6379 - val_loss: 1.4343 - val_accuracy: 0.5333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 0.8012 - accuracy: 0.6638 - val_loss: 1.3211 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 0.8036 - accuracy: 0.6552 - val_loss: 1.3304 - val_accuracy: 0.4667\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.7250 - accuracy: 0.2069 - val_loss: 1.3676 - val_accuracy: 0.2667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.2545 - accuracy: 0.4828 - val_loss: 1.1904 - val_accuracy: 0.5333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 1.1118 - accuracy: 0.5690 - val_loss: 1.1234 - val_accuracy: 0.5333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 1.0424 - accuracy: 0.5862 - val_loss: 1.0696 - val_accuracy: 0.5333\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 392us/sample - loss: 0.9972 - accuracy: 0.5603 - val_loss: 1.0264 - val_accuracy: 0.6000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 0.9738 - accuracy: 0.5862 - val_loss: 1.0142 - val_accuracy: 0.6000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.9585 - accuracy: 0.5776 - val_loss: 0.9975 - val_accuracy: 0.6000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 0.9442 - accuracy: 0.5690 - val_loss: 0.9783 - val_accuracy: 0.6000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 0.9363 - accuracy: 0.5948 - val_loss: 0.9810 - val_accuracy: 0.6000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 0.9281 - accuracy: 0.6034 - val_loss: 0.9766 - val_accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 0.9208 - accuracy: 0.5948 - val_loss: 0.9627 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 241us/sample - loss: 0.9153 - accuracy: 0.5862 - val_loss: 0.9663 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 0.9067 - accuracy: 0.6207 - val_loss: 0.9774 - val_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8958 - accuracy: 0.6034 - val_loss: 0.9801 - val_accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 0.8920 - accuracy: 0.6121 - val_loss: 0.9752 - val_accuracy: 0.6000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.8858 - accuracy: 0.6207 - val_loss: 0.9759 - val_accuracy: 0.6000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.8793 - accuracy: 0.6034 - val_loss: 0.9925 - val_accuracy: 0.6000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 248us/sample - loss: 0.8757 - accuracy: 0.6293 - val_loss: 0.9990 - val_accuracy: 0.6000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8726 - accuracy: 0.6293 - val_loss: 0.9983 - val_accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 247us/sample - loss: 0.8668 - accuracy: 0.6293 - val_loss: 0.9960 - val_accuracy: 0.6000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 0.8633 - accuracy: 0.6207 - val_loss: 0.9912 - val_accuracy: 0.6000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 0.8666 - accuracy: 0.6207 - val_loss: 1.0063 - val_accuracy: 0.6000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 0.8598 - accuracy: 0.6379 - val_loss: 1.0100 - val_accuracy: 0.6000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 0.8571 - accuracy: 0.6293 - val_loss: 1.0108 - val_accuracy: 0.6000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 256us/sample - loss: 0.8575 - accuracy: 0.6379 - val_loss: 1.0094 - val_accuracy: 0.6000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 0.8524 - accuracy: 0.6379 - val_loss: 1.0061 - val_accuracy: 0.6000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 372us/sample - loss: 0.8514 - accuracy: 0.6379 - val_loss: 1.0094 - val_accuracy: 0.6000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.8536 - accuracy: 0.6207 - val_loss: 1.0039 - val_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.8503 - accuracy: 0.6207 - val_loss: 1.0017 - val_accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.8444 - accuracy: 0.6379 - val_loss: 1.0048 - val_accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.8441 - accuracy: 0.6379 - val_loss: 1.0191 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 0.8437 - accuracy: 0.6293 - val_loss: 1.0027 - val_accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.8412 - accuracy: 0.6121 - val_loss: 1.0042 - val_accuracy: 0.6000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.8382 - accuracy: 0.6379 - val_loss: 1.0108 - val_accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8373 - accuracy: 0.6466 - val_loss: 1.0225 - val_accuracy: 0.6000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.8336 - accuracy: 0.6379 - val_loss: 1.0351 - val_accuracy: 0.6000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.8387 - accuracy: 0.6207 - val_loss: 1.0341 - val_accuracy: 0.6000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.8372 - accuracy: 0.6379 - val_loss: 1.0359 - val_accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8345 - accuracy: 0.6293 - val_loss: 1.0435 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 0.8318 - accuracy: 0.6293 - val_loss: 1.0172 - val_accuracy: 0.5333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 0.8329 - accuracy: 0.6207 - val_loss: 1.0176 - val_accuracy: 0.5333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 258us/sample - loss: 0.8248 - accuracy: 0.6293 - val_loss: 1.0093 - val_accuracy: 0.5333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 0.8250 - accuracy: 0.6379 - val_loss: 1.0179 - val_accuracy: 0.5333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 0.8277 - accuracy: 0.6466 - val_loss: 1.0250 - val_accuracy: 0.5333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 0.8236 - accuracy: 0.6293 - val_loss: 1.0252 - val_accuracy: 0.5333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 0.8197 - accuracy: 0.6638 - val_loss: 1.0354 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 0.8243 - accuracy: 0.6466 - val_loss: 1.0374 - val_accuracy: 0.5333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.8197 - accuracy: 0.6379 - val_loss: 1.0402 - val_accuracy: 0.5333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 242us/sample - loss: 0.8162 - accuracy: 0.6466 - val_loss: 1.0451 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.8180 - accuracy: 0.6466 - val_loss: 1.0295 - val_accuracy: 0.5333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.6072 - accuracy: 0.2586 - val_loss: 1.5364 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 1.4775 - accuracy: 0.3362 - val_loss: 1.2357 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 1.2340 - accuracy: 0.3879 - val_loss: 1.1934 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 1.1142 - accuracy: 0.4741 - val_loss: 1.1282 - val_accuracy: 0.5333\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 1.0506 - accuracy: 0.5086 - val_loss: 1.1508 - val_accuracy: 0.6000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 1.0171 - accuracy: 0.5431 - val_loss: 1.1814 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 0.9735 - accuracy: 0.5776 - val_loss: 1.1171 - val_accuracy: 0.5333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.9507 - accuracy: 0.5776 - val_loss: 1.1682 - val_accuracy: 0.5333\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 0.9300 - accuracy: 0.5862 - val_loss: 1.1884 - val_accuracy: 0.5333\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.9106 - accuracy: 0.5517 - val_loss: 1.1350 - val_accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.9005 - accuracy: 0.5862 - val_loss: 1.1418 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8864 - accuracy: 0.6034 - val_loss: 1.1874 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.8828 - accuracy: 0.6207 - val_loss: 1.1712 - val_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 0.8696 - accuracy: 0.6207 - val_loss: 1.1906 - val_accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 0.8620 - accuracy: 0.6121 - val_loss: 1.1852 - val_accuracy: 0.6000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 0.8557 - accuracy: 0.6121 - val_loss: 1.1920 - val_accuracy: 0.6000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 329us/sample - loss: 0.8495 - accuracy: 0.6207 - val_loss: 1.2006 - val_accuracy: 0.6000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8463 - accuracy: 0.6379 - val_loss: 1.1656 - val_accuracy: 0.6000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.8420 - accuracy: 0.6207 - val_loss: 1.1654 - val_accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.8360 - accuracy: 0.6293 - val_loss: 1.1718 - val_accuracy: 0.6000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.8429 - accuracy: 0.6207 - val_loss: 1.2309 - val_accuracy: 0.6000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 0.8292 - accuracy: 0.6379 - val_loss: 1.2003 - val_accuracy: 0.6000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.8207 - accuracy: 0.6293 - val_loss: 1.1653 - val_accuracy: 0.6000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.8175 - accuracy: 0.6207 - val_loss: 1.2155 - val_accuracy: 0.6000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 0.8178 - accuracy: 0.6379 - val_loss: 1.1995 - val_accuracy: 0.6000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.8109 - accuracy: 0.6121 - val_loss: 1.2169 - val_accuracy: 0.6000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8050 - accuracy: 0.6379 - val_loss: 1.1570 - val_accuracy: 0.6000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.8110 - accuracy: 0.6379 - val_loss: 1.1629 - val_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8066 - accuracy: 0.6121 - val_loss: 1.2248 - val_accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.8054 - accuracy: 0.6293 - val_loss: 1.1994 - val_accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.7985 - accuracy: 0.6293 - val_loss: 1.2363 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 0.7967 - accuracy: 0.6379 - val_loss: 1.1966 - val_accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.7942 - accuracy: 0.6379 - val_loss: 1.2237 - val_accuracy: 0.6000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.7929 - accuracy: 0.6121 - val_loss: 1.2512 - val_accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 0.7908 - accuracy: 0.6379 - val_loss: 1.2543 - val_accuracy: 0.6000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.7843 - accuracy: 0.6293 - val_loss: 1.2017 - val_accuracy: 0.6000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 0.7853 - accuracy: 0.6293 - val_loss: 1.2429 - val_accuracy: 0.6000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.7858 - accuracy: 0.6293 - val_loss: 1.1956 - val_accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.7831 - accuracy: 0.6379 - val_loss: 1.2014 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 0.7793 - accuracy: 0.6293 - val_loss: 1.2254 - val_accuracy: 0.6000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.7764 - accuracy: 0.6379 - val_loss: 1.2286 - val_accuracy: 0.6000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 0.7787 - accuracy: 0.6207 - val_loss: 1.2141 - val_accuracy: 0.6000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 0.7729 - accuracy: 0.6293 - val_loss: 1.2567 - val_accuracy: 0.6000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 0.7764 - accuracy: 0.6379 - val_loss: 1.2378 - val_accuracy: 0.6000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 0.7762 - accuracy: 0.6552 - val_loss: 1.1975 - val_accuracy: 0.6000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.7717 - accuracy: 0.6552 - val_loss: 1.2437 - val_accuracy: 0.6000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 0.7659 - accuracy: 0.6466 - val_loss: 1.2708 - val_accuracy: 0.6000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 0.7665 - accuracy: 0.6466 - val_loss: 1.2293 - val_accuracy: 0.6000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 0.7731 - accuracy: 0.6379 - val_loss: 1.2681 - val_accuracy: 0.6000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 0.7631 - accuracy: 0.6552 - val_loss: 1.2434 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.5</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5777778029441833</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.0305 - accuracy: 0.3276 - val_loss: 2.4261 - val_accuracy: 0.0667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 378us/sample - loss: 1.9699 - accuracy: 0.3017 - val_loss: 2.3341 - val_accuracy: 0.1333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 420us/sample - loss: 1.9133 - accuracy: 0.3103 - val_loss: 2.2495 - val_accuracy: 0.2000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.8598 - accuracy: 0.3103 - val_loss: 2.1732 - val_accuracy: 0.2000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.8101 - accuracy: 0.3276 - val_loss: 2.0997 - val_accuracy: 0.2000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 1.7619 - accuracy: 0.3362 - val_loss: 2.0308 - val_accuracy: 0.2000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 329us/sample - loss: 1.7175 - accuracy: 0.3448 - val_loss: 1.9654 - val_accuracy: 0.2000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 328us/sample - loss: 1.6778 - accuracy: 0.3448 - val_loss: 1.9042 - val_accuracy: 0.2000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 1.6382 - accuracy: 0.3621 - val_loss: 1.8465 - val_accuracy: 0.2000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 1.6018 - accuracy: 0.3621 - val_loss: 1.7931 - val_accuracy: 0.2000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 1.5672 - accuracy: 0.3707 - val_loss: 1.7388 - val_accuracy: 0.2000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 322us/sample - loss: 1.5334 - accuracy: 0.3707 - val_loss: 1.6876 - val_accuracy: 0.2000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.5046 - accuracy: 0.3621 - val_loss: 1.6425 - val_accuracy: 0.2000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 362us/sample - loss: 1.4759 - accuracy: 0.3448 - val_loss: 1.6007 - val_accuracy: 0.2667\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 1.4493 - accuracy: 0.3448 - val_loss: 1.5584 - val_accuracy: 0.2667\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 1.4231 - accuracy: 0.3534 - val_loss: 1.5216 - val_accuracy: 0.2667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 1.4020 - accuracy: 0.3534 - val_loss: 1.4904 - val_accuracy: 0.2667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 343us/sample - loss: 1.3796 - accuracy: 0.3534 - val_loss: 1.4592 - val_accuracy: 0.2667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 348us/sample - loss: 1.3592 - accuracy: 0.3534 - val_loss: 1.4307 - val_accuracy: 0.2667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 383us/sample - loss: 1.3394 - accuracy: 0.3534 - val_loss: 1.4060 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 1.3222 - accuracy: 0.3621 - val_loss: 1.3836 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 1.3061 - accuracy: 0.3621 - val_loss: 1.3611 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 383us/sample - loss: 1.2894 - accuracy: 0.3621 - val_loss: 1.3404 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 337us/sample - loss: 1.2760 - accuracy: 0.3793 - val_loss: 1.3240 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.2628 - accuracy: 0.3621 - val_loss: 1.3078 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.2507 - accuracy: 0.3707 - val_loss: 1.2923 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 1.2404 - accuracy: 0.3793 - val_loss: 1.2797 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 1.2273 - accuracy: 0.3707 - val_loss: 1.2661 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.2168 - accuracy: 0.3793 - val_loss: 1.2530 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 1.2057 - accuracy: 0.3793 - val_loss: 1.2418 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.1967 - accuracy: 0.3793 - val_loss: 1.2306 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.1875 - accuracy: 0.3793 - val_loss: 1.2192 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.1781 - accuracy: 0.3879 - val_loss: 1.2093 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 1.1695 - accuracy: 0.3966 - val_loss: 1.2007 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.1612 - accuracy: 0.4052 - val_loss: 1.1908 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.1553 - accuracy: 0.3793 - val_loss: 1.1819 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.1476 - accuracy: 0.4052 - val_loss: 1.1755 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 331us/sample - loss: 1.1409 - accuracy: 0.3966 - val_loss: 1.1690 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 1.1354 - accuracy: 0.3966 - val_loss: 1.1630 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.1289 - accuracy: 0.3966 - val_loss: 1.1573 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 1.1232 - accuracy: 0.4052 - val_loss: 1.1515 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 1.1175 - accuracy: 0.4052 - val_loss: 1.1453 - val_accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 333us/sample - loss: 1.1125 - accuracy: 0.4310 - val_loss: 1.1400 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 1.1087 - accuracy: 0.4138 - val_loss: 1.1340 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.1036 - accuracy: 0.4310 - val_loss: 1.1285 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.0992 - accuracy: 0.4224 - val_loss: 1.1241 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.0953 - accuracy: 0.4310 - val_loss: 1.1186 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 1.0917 - accuracy: 0.4483 - val_loss: 1.1104 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.0865 - accuracy: 0.4483 - val_loss: 1.1039 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.0836 - accuracy: 0.4569 - val_loss: 1.0992 - val_accuracy: 0.4000\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.6998 - accuracy: 0.4741 - val_loss: 2.8069 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 2.5952 - accuracy: 0.4828 - val_loss: 2.7172 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 2.4930 - accuracy: 0.4828 - val_loss: 2.6287 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 2.3994 - accuracy: 0.4914 - val_loss: 2.5458 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 2.3068 - accuracy: 0.5000 - val_loss: 2.4700 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 351us/sample - loss: 2.2285 - accuracy: 0.5000 - val_loss: 2.3977 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 2.1538 - accuracy: 0.5000 - val_loss: 2.3302 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 328us/sample - loss: 2.0847 - accuracy: 0.4914 - val_loss: 2.2630 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 2.0124 - accuracy: 0.4914 - val_loss: 2.1969 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 333us/sample - loss: 1.9477 - accuracy: 0.4914 - val_loss: 2.1401 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.8881 - accuracy: 0.4914 - val_loss: 2.0889 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.8352 - accuracy: 0.4914 - val_loss: 2.0395 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.7805 - accuracy: 0.5000 - val_loss: 1.9916 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 1.7319 - accuracy: 0.5000 - val_loss: 1.9488 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.6856 - accuracy: 0.5000 - val_loss: 1.9107 - val_accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.6425 - accuracy: 0.5086 - val_loss: 1.8735 - val_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 253us/sample - loss: 1.6006 - accuracy: 0.4914 - val_loss: 1.8397 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 1.5627 - accuracy: 0.5000 - val_loss: 1.8100 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.5279 - accuracy: 0.4828 - val_loss: 1.7832 - val_accuracy: 0.3333\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 1.4948 - accuracy: 0.4914 - val_loss: 1.7570 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.4659 - accuracy: 0.5000 - val_loss: 1.7330 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 1.4373 - accuracy: 0.5000 - val_loss: 1.7117 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.4111 - accuracy: 0.5259 - val_loss: 1.6925 - val_accuracy: 0.3333\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 1.3884 - accuracy: 0.5259 - val_loss: 1.6762 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 258us/sample - loss: 1.3677 - accuracy: 0.5259 - val_loss: 1.6618 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 1.3482 - accuracy: 0.5259 - val_loss: 1.6482 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 1.3306 - accuracy: 0.5259 - val_loss: 1.6347 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 1.3135 - accuracy: 0.5259 - val_loss: 1.6229 - val_accuracy: 0.2667\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 1.2984 - accuracy: 0.5259 - val_loss: 1.6124 - val_accuracy: 0.2667\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.2829 - accuracy: 0.5259 - val_loss: 1.6050 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.2708 - accuracy: 0.5259 - val_loss: 1.5986 - val_accuracy: 0.3333\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 1.2578 - accuracy: 0.5172 - val_loss: 1.5920 - val_accuracy: 0.3333\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.2473 - accuracy: 0.5086 - val_loss: 1.5871 - val_accuracy: 0.3333\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.2369 - accuracy: 0.5172 - val_loss: 1.5832 - val_accuracy: 0.3333\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.2271 - accuracy: 0.5259 - val_loss: 1.5777 - val_accuracy: 0.3333\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.2160 - accuracy: 0.5259 - val_loss: 1.5699 - val_accuracy: 0.3333\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.2071 - accuracy: 0.5172 - val_loss: 1.5640 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 1.1981 - accuracy: 0.5172 - val_loss: 1.5581 - val_accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 1.1899 - accuracy: 0.5172 - val_loss: 1.5530 - val_accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.1820 - accuracy: 0.5259 - val_loss: 1.5491 - val_accuracy: 0.3333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.1752 - accuracy: 0.5172 - val_loss: 1.5461 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.1676 - accuracy: 0.5259 - val_loss: 1.5418 - val_accuracy: 0.3333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 1.1604 - accuracy: 0.5345 - val_loss: 1.5369 - val_accuracy: 0.3333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.1538 - accuracy: 0.5345 - val_loss: 1.5325 - val_accuracy: 0.3333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 1.1483 - accuracy: 0.5345 - val_loss: 1.5283 - val_accuracy: 0.3333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.1419 - accuracy: 0.5345 - val_loss: 1.5244 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.1366 - accuracy: 0.5431 - val_loss: 1.5216 - val_accuracy: 0.2667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 1.1321 - accuracy: 0.5431 - val_loss: 1.5178 - val_accuracy: 0.2667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 1.1260 - accuracy: 0.5517 - val_loss: 1.5140 - val_accuracy: 0.2667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 338us/sample - loss: 1.1212 - accuracy: 0.5431 - val_loss: 1.5106 - val_accuracy: 0.2667\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.0697 - accuracy: 0.3362 - val_loss: 1.5774 - val_accuracy: 0.2667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 357us/sample - loss: 1.9827 - accuracy: 0.3448 - val_loss: 1.5444 - val_accuracy: 0.2667\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 367us/sample - loss: 1.9020 - accuracy: 0.3448 - val_loss: 1.5138 - val_accuracy: 0.2667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 1.8308 - accuracy: 0.3534 - val_loss: 1.4851 - val_accuracy: 0.2667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.7639 - accuracy: 0.3448 - val_loss: 1.4564 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.7016 - accuracy: 0.3362 - val_loss: 1.4289 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 1.6475 - accuracy: 0.3362 - val_loss: 1.4061 - val_accuracy: 0.2667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 1.5988 - accuracy: 0.3534 - val_loss: 1.3865 - val_accuracy: 0.2000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.5511 - accuracy: 0.3621 - val_loss: 1.3670 - val_accuracy: 0.2000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 1.5083 - accuracy: 0.3621 - val_loss: 1.3477 - val_accuracy: 0.2000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 1.4717 - accuracy: 0.3707 - val_loss: 1.3304 - val_accuracy: 0.2000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 1.4396 - accuracy: 0.3707 - val_loss: 1.3149 - val_accuracy: 0.2000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 1.4090 - accuracy: 0.3707 - val_loss: 1.3002 - val_accuracy: 0.2000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 1.3828 - accuracy: 0.3793 - val_loss: 1.2884 - val_accuracy: 0.2000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 1.3596 - accuracy: 0.3879 - val_loss: 1.2788 - val_accuracy: 0.2000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 1.3389 - accuracy: 0.3966 - val_loss: 1.2702 - val_accuracy: 0.2000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 327us/sample - loss: 1.3198 - accuracy: 0.4224 - val_loss: 1.2621 - val_accuracy: 0.2000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 1.3035 - accuracy: 0.4224 - val_loss: 1.2529 - val_accuracy: 0.2000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 1.2861 - accuracy: 0.4397 - val_loss: 1.2454 - val_accuracy: 0.2000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.2720 - accuracy: 0.4483 - val_loss: 1.2382 - val_accuracy: 0.2000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.2606 - accuracy: 0.4655 - val_loss: 1.2313 - val_accuracy: 0.2000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 1.2490 - accuracy: 0.4655 - val_loss: 1.2253 - val_accuracy: 0.2000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 346us/sample - loss: 1.2376 - accuracy: 0.4655 - val_loss: 1.2196 - val_accuracy: 0.2000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.2268 - accuracy: 0.4741 - val_loss: 1.2129 - val_accuracy: 0.2000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.2176 - accuracy: 0.4655 - val_loss: 1.2065 - val_accuracy: 0.2000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.2083 - accuracy: 0.4741 - val_loss: 1.2011 - val_accuracy: 0.2000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.2005 - accuracy: 0.4741 - val_loss: 1.1959 - val_accuracy: 0.1333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 1.1924 - accuracy: 0.4741 - val_loss: 1.1908 - val_accuracy: 0.2000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 1.1854 - accuracy: 0.4741 - val_loss: 1.1876 - val_accuracy: 0.2000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.1770 - accuracy: 0.4741 - val_loss: 1.1829 - val_accuracy: 0.2000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.1713 - accuracy: 0.4741 - val_loss: 1.1781 - val_accuracy: 0.2667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.1651 - accuracy: 0.4741 - val_loss: 1.1745 - val_accuracy: 0.2667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.1588 - accuracy: 0.4828 - val_loss: 1.1719 - val_accuracy: 0.2667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.1527 - accuracy: 0.4828 - val_loss: 1.1689 - val_accuracy: 0.2667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 382us/sample - loss: 1.1471 - accuracy: 0.5086 - val_loss: 1.1651 - val_accuracy: 0.2667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 1.1427 - accuracy: 0.5086 - val_loss: 1.1620 - val_accuracy: 0.2667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 1.1375 - accuracy: 0.5086 - val_loss: 1.1602 - val_accuracy: 0.2667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 1.1334 - accuracy: 0.5086 - val_loss: 1.1580 - val_accuracy: 0.2667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.1287 - accuracy: 0.5086 - val_loss: 1.1549 - val_accuracy: 0.2667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 1.1246 - accuracy: 0.5086 - val_loss: 1.1524 - val_accuracy: 0.2667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 1.1197 - accuracy: 0.5172 - val_loss: 1.1491 - val_accuracy: 0.2667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.1154 - accuracy: 0.5517 - val_loss: 1.1467 - val_accuracy: 0.2667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 1.1119 - accuracy: 0.5431 - val_loss: 1.1447 - val_accuracy: 0.2667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 1.1075 - accuracy: 0.5517 - val_loss: 1.1431 - val_accuracy: 0.2667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 352us/sample - loss: 1.1048 - accuracy: 0.5517 - val_loss: 1.1423 - val_accuracy: 0.3333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 1.1004 - accuracy: 0.5431 - val_loss: 1.1411 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.0966 - accuracy: 0.5431 - val_loss: 1.1394 - val_accuracy: 0.3333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.0931 - accuracy: 0.5431 - val_loss: 1.1375 - val_accuracy: 0.3333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 1.0902 - accuracy: 0.5345 - val_loss: 1.1356 - val_accuracy: 0.3333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.0868 - accuracy: 0.5345 - val_loss: 1.1342 - val_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.3777777850627899</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.4655 - accuracy: 0.4138 - val_loss: 1.5566 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 1.4617 - accuracy: 0.4138 - val_loss: 1.5520 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 1.4583 - accuracy: 0.4138 - val_loss: 1.5477 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.4550 - accuracy: 0.4138 - val_loss: 1.5435 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.4516 - accuracy: 0.4138 - val_loss: 1.5394 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 1.4482 - accuracy: 0.4138 - val_loss: 1.5353 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.4450 - accuracy: 0.4138 - val_loss: 1.5312 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.4417 - accuracy: 0.4138 - val_loss: 1.5272 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.4384 - accuracy: 0.4138 - val_loss: 1.5232 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 1.4351 - accuracy: 0.4224 - val_loss: 1.5192 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 1.4320 - accuracy: 0.4224 - val_loss: 1.5153 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.4289 - accuracy: 0.4224 - val_loss: 1.5113 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.4256 - accuracy: 0.4224 - val_loss: 1.5072 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 353us/sample - loss: 1.4224 - accuracy: 0.4224 - val_loss: 1.5032 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 1.4192 - accuracy: 0.4224 - val_loss: 1.4993 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.4163 - accuracy: 0.4224 - val_loss: 1.4955 - val_accuracy: 0.4000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 1.4132 - accuracy: 0.4224 - val_loss: 1.4918 - val_accuracy: 0.4000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 1.4102 - accuracy: 0.4224 - val_loss: 1.4878 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.4070 - accuracy: 0.4138 - val_loss: 1.4838 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.4040 - accuracy: 0.4138 - val_loss: 1.4801 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.4011 - accuracy: 0.4138 - val_loss: 1.4765 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.3982 - accuracy: 0.4138 - val_loss: 1.4729 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.3955 - accuracy: 0.4138 - val_loss: 1.4692 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 1.3925 - accuracy: 0.4138 - val_loss: 1.4654 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 1.3897 - accuracy: 0.4138 - val_loss: 1.4619 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.3868 - accuracy: 0.4138 - val_loss: 1.4582 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.3839 - accuracy: 0.4138 - val_loss: 1.4545 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 239us/sample - loss: 1.3809 - accuracy: 0.4138 - val_loss: 1.4509 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.3783 - accuracy: 0.4138 - val_loss: 1.4475 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 1.3755 - accuracy: 0.4224 - val_loss: 1.4438 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 345us/sample - loss: 1.3727 - accuracy: 0.4310 - val_loss: 1.4401 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 1.3699 - accuracy: 0.4310 - val_loss: 1.4365 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.3671 - accuracy: 0.4310 - val_loss: 1.4331 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.3645 - accuracy: 0.4310 - val_loss: 1.4299 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 1.3620 - accuracy: 0.4310 - val_loss: 1.4267 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 321us/sample - loss: 1.3593 - accuracy: 0.4310 - val_loss: 1.4235 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.3568 - accuracy: 0.4310 - val_loss: 1.4202 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 1.3541 - accuracy: 0.4310 - val_loss: 1.4169 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 1.3518 - accuracy: 0.4310 - val_loss: 1.4137 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.3490 - accuracy: 0.4310 - val_loss: 1.4105 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.3465 - accuracy: 0.4310 - val_loss: 1.4072 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.3440 - accuracy: 0.4310 - val_loss: 1.4041 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.3415 - accuracy: 0.4310 - val_loss: 1.4013 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 1.3392 - accuracy: 0.4310 - val_loss: 1.3987 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.3370 - accuracy: 0.4310 - val_loss: 1.3960 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.3345 - accuracy: 0.4310 - val_loss: 1.3931 - val_accuracy: 0.4667\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.3321 - accuracy: 0.4310 - val_loss: 1.3904 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 1.3299 - accuracy: 0.4310 - val_loss: 1.3878 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 1.3276 - accuracy: 0.4310 - val_loss: 1.3850 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.3254 - accuracy: 0.4310 - val_loss: 1.3824 - val_accuracy: 0.4667\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.6113 - accuracy: 0.3017 - val_loss: 1.1505 - val_accuracy: 0.6667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 1.6057 - accuracy: 0.3103 - val_loss: 1.1500 - val_accuracy: 0.6667\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 1.6001 - accuracy: 0.3103 - val_loss: 1.1495 - val_accuracy: 0.6667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.5947 - accuracy: 0.3103 - val_loss: 1.1490 - val_accuracy: 0.6667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.5891 - accuracy: 0.3103 - val_loss: 1.1485 - val_accuracy: 0.6667\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 251us/sample - loss: 1.5837 - accuracy: 0.3103 - val_loss: 1.1481 - val_accuracy: 0.6667\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.5782 - accuracy: 0.3103 - val_loss: 1.1477 - val_accuracy: 0.6667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.5727 - accuracy: 0.3103 - val_loss: 1.1473 - val_accuracy: 0.6667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.5672 - accuracy: 0.3103 - val_loss: 1.1468 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 1.5620 - accuracy: 0.3103 - val_loss: 1.1465 - val_accuracy: 0.6667\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.5568 - accuracy: 0.3103 - val_loss: 1.1461 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 1.5518 - accuracy: 0.3190 - val_loss: 1.1457 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.5467 - accuracy: 0.3190 - val_loss: 1.1454 - val_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.5416 - accuracy: 0.3190 - val_loss: 1.1450 - val_accuracy: 0.5333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.5368 - accuracy: 0.3190 - val_loss: 1.1448 - val_accuracy: 0.5333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.5316 - accuracy: 0.3103 - val_loss: 1.1446 - val_accuracy: 0.5333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 1.5267 - accuracy: 0.3190 - val_loss: 1.1443 - val_accuracy: 0.5333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 1.5218 - accuracy: 0.3190 - val_loss: 1.1440 - val_accuracy: 0.5333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 1.5171 - accuracy: 0.3276 - val_loss: 1.1436 - val_accuracy: 0.5333\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.5123 - accuracy: 0.3276 - val_loss: 1.1431 - val_accuracy: 0.5333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.5075 - accuracy: 0.3276 - val_loss: 1.1428 - val_accuracy: 0.5333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.5024 - accuracy: 0.3276 - val_loss: 1.1426 - val_accuracy: 0.5333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.4978 - accuracy: 0.3276 - val_loss: 1.1425 - val_accuracy: 0.5333\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 342us/sample - loss: 1.4927 - accuracy: 0.3276 - val_loss: 1.1422 - val_accuracy: 0.5333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.4882 - accuracy: 0.3362 - val_loss: 1.1419 - val_accuracy: 0.5333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 1.4835 - accuracy: 0.3362 - val_loss: 1.1416 - val_accuracy: 0.5333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 1.4791 - accuracy: 0.3362 - val_loss: 1.1414 - val_accuracy: 0.5333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.4746 - accuracy: 0.3448 - val_loss: 1.1411 - val_accuracy: 0.5333\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 1.4702 - accuracy: 0.3448 - val_loss: 1.1408 - val_accuracy: 0.5333\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.4658 - accuracy: 0.3448 - val_loss: 1.1407 - val_accuracy: 0.5333\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 1.4615 - accuracy: 0.3448 - val_loss: 1.1406 - val_accuracy: 0.5333\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.4570 - accuracy: 0.3448 - val_loss: 1.1405 - val_accuracy: 0.5333\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.4529 - accuracy: 0.3448 - val_loss: 1.1402 - val_accuracy: 0.5333\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.4489 - accuracy: 0.3448 - val_loss: 1.1400 - val_accuracy: 0.5333\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.4446 - accuracy: 0.3448 - val_loss: 1.1397 - val_accuracy: 0.5333\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 331us/sample - loss: 1.4407 - accuracy: 0.3448 - val_loss: 1.1395 - val_accuracy: 0.5333\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.4367 - accuracy: 0.3448 - val_loss: 1.1392 - val_accuracy: 0.5333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 1.4327 - accuracy: 0.3448 - val_loss: 1.1388 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.4288 - accuracy: 0.3448 - val_loss: 1.1385 - val_accuracy: 0.5333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.4248 - accuracy: 0.3448 - val_loss: 1.1383 - val_accuracy: 0.5333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.4209 - accuracy: 0.3448 - val_loss: 1.1381 - val_accuracy: 0.5333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 1.4171 - accuracy: 0.3362 - val_loss: 1.1378 - val_accuracy: 0.5333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 1.4134 - accuracy: 0.3362 - val_loss: 1.1374 - val_accuracy: 0.5333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 1.4098 - accuracy: 0.3362 - val_loss: 1.1371 - val_accuracy: 0.5333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.4061 - accuracy: 0.3276 - val_loss: 1.1369 - val_accuracy: 0.5333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.4024 - accuracy: 0.3276 - val_loss: 1.1366 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.3989 - accuracy: 0.3276 - val_loss: 1.1363 - val_accuracy: 0.5333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 1.3954 - accuracy: 0.3276 - val_loss: 1.1361 - val_accuracy: 0.5333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.3919 - accuracy: 0.3362 - val_loss: 1.1357 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 1.3884 - accuracy: 0.3362 - val_loss: 1.1355 - val_accuracy: 0.5333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.8353 - accuracy: 0.3362 - val_loss: 1.5697 - val_accuracy: 0.4667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 2.8064 - accuracy: 0.3362 - val_loss: 1.5696 - val_accuracy: 0.4667\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 2.7774 - accuracy: 0.3362 - val_loss: 1.5695 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 2.7484 - accuracy: 0.3362 - val_loss: 1.5696 - val_accuracy: 0.4667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 2.7198 - accuracy: 0.3362 - val_loss: 1.5698 - val_accuracy: 0.4667\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 2.6912 - accuracy: 0.3362 - val_loss: 1.5702 - val_accuracy: 0.4667\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 2.6632 - accuracy: 0.3448 - val_loss: 1.5706 - val_accuracy: 0.4667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 2.6362 - accuracy: 0.3448 - val_loss: 1.5712 - val_accuracy: 0.4667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 2.6086 - accuracy: 0.3448 - val_loss: 1.5718 - val_accuracy: 0.4667\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 2.5813 - accuracy: 0.3362 - val_loss: 1.5722 - val_accuracy: 0.4667\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 2.5546 - accuracy: 0.3362 - val_loss: 1.5730 - val_accuracy: 0.4667\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 2.5287 - accuracy: 0.3362 - val_loss: 1.5739 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 2.5030 - accuracy: 0.3362 - val_loss: 1.5751 - val_accuracy: 0.4667\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 2.4777 - accuracy: 0.3276 - val_loss: 1.5765 - val_accuracy: 0.4667\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 2.4531 - accuracy: 0.3276 - val_loss: 1.5779 - val_accuracy: 0.4667\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 2.4281 - accuracy: 0.3362 - val_loss: 1.5794 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 2.4043 - accuracy: 0.3362 - val_loss: 1.5810 - val_accuracy: 0.4667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 2.3807 - accuracy: 0.3362 - val_loss: 1.5827 - val_accuracy: 0.4667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 2.3578 - accuracy: 0.3448 - val_loss: 1.5844 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 2.3350 - accuracy: 0.3448 - val_loss: 1.5863 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 2.3121 - accuracy: 0.3448 - val_loss: 1.5884 - val_accuracy: 0.4667\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 2.2896 - accuracy: 0.3448 - val_loss: 1.5908 - val_accuracy: 0.4667\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 2.2674 - accuracy: 0.3534 - val_loss: 1.5932 - val_accuracy: 0.4667\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 2.2459 - accuracy: 0.3621 - val_loss: 1.5957 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 2.2245 - accuracy: 0.3621 - val_loss: 1.5984 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 2.2037 - accuracy: 0.3621 - val_loss: 1.6011 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 2.1829 - accuracy: 0.3621 - val_loss: 1.6039 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 2.1630 - accuracy: 0.3621 - val_loss: 1.6067 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 258us/sample - loss: 2.1432 - accuracy: 0.3621 - val_loss: 1.6098 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 2.1240 - accuracy: 0.3621 - val_loss: 1.6128 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 2.1051 - accuracy: 0.3707 - val_loss: 1.6157 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 2.0866 - accuracy: 0.3793 - val_loss: 1.6187 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 2.0679 - accuracy: 0.3793 - val_loss: 1.6218 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 2.0503 - accuracy: 0.3793 - val_loss: 1.6251 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 2.0327 - accuracy: 0.3879 - val_loss: 1.6287 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 2.0144 - accuracy: 0.3879 - val_loss: 1.6322 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.9975 - accuracy: 0.3879 - val_loss: 1.6358 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.9809 - accuracy: 0.3793 - val_loss: 1.6393 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 1.9649 - accuracy: 0.3793 - val_loss: 1.6429 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.9487 - accuracy: 0.3793 - val_loss: 1.6473 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.9323 - accuracy: 0.3793 - val_loss: 1.6519 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.9170 - accuracy: 0.3793 - val_loss: 1.6563 - val_accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 341us/sample - loss: 1.9020 - accuracy: 0.3793 - val_loss: 1.6609 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 322us/sample - loss: 1.8870 - accuracy: 0.3793 - val_loss: 1.6655 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 1.8728 - accuracy: 0.3879 - val_loss: 1.6697 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 1.8588 - accuracy: 0.3966 - val_loss: 1.6741 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 294us/sample - loss: 1.8446 - accuracy: 0.3966 - val_loss: 1.6789 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.8308 - accuracy: 0.3966 - val_loss: 1.6839 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 1.8167 - accuracy: 0.4052 - val_loss: 1.6888 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.8039 - accuracy: 0.4052 - val_loss: 1.6937 - val_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5333333611488342</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.0112 - accuracy: 0.4310 - val_loss: 1.8158 - val_accuracy: 0.2667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 2.0048 - accuracy: 0.4310 - val_loss: 1.8110 - val_accuracy: 0.2667\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 593us/sample - loss: 1.9986 - accuracy: 0.4310 - val_loss: 1.8061 - val_accuracy: 0.2667\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 1.9926 - accuracy: 0.4310 - val_loss: 1.8013 - val_accuracy: 0.2667\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 1.9866 - accuracy: 0.4310 - val_loss: 1.7967 - val_accuracy: 0.2667\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.9807 - accuracy: 0.4310 - val_loss: 1.7919 - val_accuracy: 0.2667\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 257us/sample - loss: 1.9745 - accuracy: 0.4310 - val_loss: 1.7872 - val_accuracy: 0.2667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 251us/sample - loss: 1.9687 - accuracy: 0.4310 - val_loss: 1.7827 - val_accuracy: 0.2667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 344us/sample - loss: 1.9629 - accuracy: 0.4310 - val_loss: 1.7782 - val_accuracy: 0.2667\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.9571 - accuracy: 0.4310 - val_loss: 1.7736 - val_accuracy: 0.2667\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.9513 - accuracy: 0.4310 - val_loss: 1.7691 - val_accuracy: 0.2667\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.9455 - accuracy: 0.4310 - val_loss: 1.7647 - val_accuracy: 0.2667\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.9399 - accuracy: 0.4310 - val_loss: 1.7603 - val_accuracy: 0.2667\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.9343 - accuracy: 0.4310 - val_loss: 1.7559 - val_accuracy: 0.2667\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 1.9286 - accuracy: 0.4310 - val_loss: 1.7516 - val_accuracy: 0.2667\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 1.9231 - accuracy: 0.4310 - val_loss: 1.7473 - val_accuracy: 0.2667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.9176 - accuracy: 0.4310 - val_loss: 1.7431 - val_accuracy: 0.2667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 1.9123 - accuracy: 0.4310 - val_loss: 1.7389 - val_accuracy: 0.2667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.9068 - accuracy: 0.4224 - val_loss: 1.7346 - val_accuracy: 0.2667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.9013 - accuracy: 0.4224 - val_loss: 1.7304 - val_accuracy: 0.2667\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 1.8958 - accuracy: 0.4224 - val_loss: 1.7262 - val_accuracy: 0.2667\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 1.8902 - accuracy: 0.4224 - val_loss: 1.7221 - val_accuracy: 0.2667\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 358us/sample - loss: 1.8850 - accuracy: 0.4224 - val_loss: 1.7180 - val_accuracy: 0.2667\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.8796 - accuracy: 0.4224 - val_loss: 1.7139 - val_accuracy: 0.2667\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 1.8743 - accuracy: 0.4224 - val_loss: 1.7098 - val_accuracy: 0.2667\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 1.8691 - accuracy: 0.4224 - val_loss: 1.7059 - val_accuracy: 0.2667\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 1.8638 - accuracy: 0.4224 - val_loss: 1.7019 - val_accuracy: 0.2667\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.8586 - accuracy: 0.4224 - val_loss: 1.6980 - val_accuracy: 0.2667\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.8534 - accuracy: 0.4224 - val_loss: 1.6940 - val_accuracy: 0.2667\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 257us/sample - loss: 1.8483 - accuracy: 0.4224 - val_loss: 1.6902 - val_accuracy: 0.2667\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.8432 - accuracy: 0.4224 - val_loss: 1.6864 - val_accuracy: 0.2667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 257us/sample - loss: 1.8383 - accuracy: 0.4224 - val_loss: 1.6825 - val_accuracy: 0.2667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.8332 - accuracy: 0.4224 - val_loss: 1.6788 - val_accuracy: 0.2667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 1.8283 - accuracy: 0.4310 - val_loss: 1.6750 - val_accuracy: 0.2667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.8234 - accuracy: 0.4310 - val_loss: 1.6713 - val_accuracy: 0.2667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.8184 - accuracy: 0.4310 - val_loss: 1.6676 - val_accuracy: 0.2667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.8135 - accuracy: 0.4310 - val_loss: 1.6640 - val_accuracy: 0.2667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 1.8087 - accuracy: 0.4310 - val_loss: 1.6604 - val_accuracy: 0.2667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.8039 - accuracy: 0.4310 - val_loss: 1.6566 - val_accuracy: 0.2667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.7990 - accuracy: 0.4310 - val_loss: 1.6529 - val_accuracy: 0.2667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 1.7943 - accuracy: 0.4310 - val_loss: 1.6494 - val_accuracy: 0.2667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 1.7897 - accuracy: 0.4310 - val_loss: 1.6458 - val_accuracy: 0.2667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.7849 - accuracy: 0.4310 - val_loss: 1.6424 - val_accuracy: 0.2667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.7804 - accuracy: 0.4310 - val_loss: 1.6390 - val_accuracy: 0.2667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.7759 - accuracy: 0.4310 - val_loss: 1.6355 - val_accuracy: 0.2667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 1.7713 - accuracy: 0.4310 - val_loss: 1.6320 - val_accuracy: 0.2667\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 1.7665 - accuracy: 0.4310 - val_loss: 1.6287 - val_accuracy: 0.2667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.7622 - accuracy: 0.4310 - val_loss: 1.6255 - val_accuracy: 0.2000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.7577 - accuracy: 0.4310 - val_loss: 1.6222 - val_accuracy: 0.2000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 1.7533 - accuracy: 0.4310 - val_loss: 1.6189 - val_accuracy: 0.2000\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.6847 - accuracy: 0.2845 - val_loss: 1.2038 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.6808 - accuracy: 0.2845 - val_loss: 1.2036 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.6772 - accuracy: 0.2845 - val_loss: 1.2034 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 331us/sample - loss: 1.6736 - accuracy: 0.2845 - val_loss: 1.2032 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.6698 - accuracy: 0.2845 - val_loss: 1.2029 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.6661 - accuracy: 0.2845 - val_loss: 1.2028 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.6624 - accuracy: 0.2759 - val_loss: 1.2027 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 1.6589 - accuracy: 0.2759 - val_loss: 1.2026 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 1.6553 - accuracy: 0.2759 - val_loss: 1.2025 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 248us/sample - loss: 1.6517 - accuracy: 0.2759 - val_loss: 1.2023 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.6480 - accuracy: 0.2759 - val_loss: 1.2022 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.6445 - accuracy: 0.2759 - val_loss: 1.2019 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.6410 - accuracy: 0.2759 - val_loss: 1.2018 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.6372 - accuracy: 0.2759 - val_loss: 1.2016 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.6337 - accuracy: 0.2759 - val_loss: 1.2015 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 253us/sample - loss: 1.6302 - accuracy: 0.2759 - val_loss: 1.2014 - val_accuracy: 0.4000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.6268 - accuracy: 0.2759 - val_loss: 1.2013 - val_accuracy: 0.4000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 1.6232 - accuracy: 0.2759 - val_loss: 1.2013 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 1.6199 - accuracy: 0.2759 - val_loss: 1.2012 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.6165 - accuracy: 0.2759 - val_loss: 1.2011 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.6133 - accuracy: 0.2759 - val_loss: 1.2011 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 1.6099 - accuracy: 0.2759 - val_loss: 1.2010 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 244us/sample - loss: 1.6064 - accuracy: 0.2759 - val_loss: 1.2009 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 249us/sample - loss: 1.6033 - accuracy: 0.2759 - val_loss: 1.2009 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 1.5999 - accuracy: 0.2759 - val_loss: 1.2009 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.5967 - accuracy: 0.2759 - val_loss: 1.2008 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 258us/sample - loss: 1.5936 - accuracy: 0.2759 - val_loss: 1.2009 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.5904 - accuracy: 0.2759 - val_loss: 1.2009 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 1.5872 - accuracy: 0.2759 - val_loss: 1.2009 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 1.5839 - accuracy: 0.2759 - val_loss: 1.2010 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 257us/sample - loss: 1.5809 - accuracy: 0.2845 - val_loss: 1.2010 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 251us/sample - loss: 1.5779 - accuracy: 0.2845 - val_loss: 1.2010 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.5747 - accuracy: 0.2845 - val_loss: 1.2012 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 248us/sample - loss: 1.5718 - accuracy: 0.2845 - val_loss: 1.2013 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 1.5688 - accuracy: 0.2845 - val_loss: 1.2013 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 258us/sample - loss: 1.5658 - accuracy: 0.2845 - val_loss: 1.2014 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 1.5629 - accuracy: 0.2845 - val_loss: 1.2013 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 1.5601 - accuracy: 0.2845 - val_loss: 1.2015 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.5571 - accuracy: 0.2845 - val_loss: 1.2014 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.5543 - accuracy: 0.2845 - val_loss: 1.2016 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.5515 - accuracy: 0.2845 - val_loss: 1.2017 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 1.5487 - accuracy: 0.2845 - val_loss: 1.2018 - val_accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 253us/sample - loss: 1.5458 - accuracy: 0.2845 - val_loss: 1.2019 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.5431 - accuracy: 0.2845 - val_loss: 1.2019 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 1.5404 - accuracy: 0.2845 - val_loss: 1.2019 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.5376 - accuracy: 0.2845 - val_loss: 1.2021 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.5349 - accuracy: 0.2845 - val_loss: 1.2024 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.5321 - accuracy: 0.2845 - val_loss: 1.2027 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 248us/sample - loss: 1.5293 - accuracy: 0.2845 - val_loss: 1.2028 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 1.5266 - accuracy: 0.2845 - val_loss: 1.2030 - val_accuracy: 0.4000\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.6384 - accuracy: 0.4741 - val_loss: 2.0308 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 2.6297 - accuracy: 0.4741 - val_loss: 2.0259 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 2.6214 - accuracy: 0.4741 - val_loss: 2.0211 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 2.6129 - accuracy: 0.4741 - val_loss: 2.0161 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 2.6044 - accuracy: 0.4741 - val_loss: 2.0115 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 2.5960 - accuracy: 0.4741 - val_loss: 2.0070 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 2.5879 - accuracy: 0.4741 - val_loss: 2.0024 - val_accuracy: 0.4000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 2.5795 - accuracy: 0.4741 - val_loss: 1.9980 - val_accuracy: 0.4000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 2.5715 - accuracy: 0.4741 - val_loss: 1.9933 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 2.5631 - accuracy: 0.4741 - val_loss: 1.9888 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 2.5551 - accuracy: 0.4741 - val_loss: 1.9841 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 2.5469 - accuracy: 0.4741 - val_loss: 1.9796 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 2.5387 - accuracy: 0.4741 - val_loss: 1.9752 - val_accuracy: 0.4000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 2.5306 - accuracy: 0.4741 - val_loss: 1.9710 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 2.5228 - accuracy: 0.4741 - val_loss: 1.9666 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 2.5147 - accuracy: 0.4741 - val_loss: 1.9623 - val_accuracy: 0.4000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 2.5067 - accuracy: 0.4828 - val_loss: 1.9580 - val_accuracy: 0.4000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 2.4985 - accuracy: 0.4828 - val_loss: 1.9537 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 2.4908 - accuracy: 0.4914 - val_loss: 1.9495 - val_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 2.4830 - accuracy: 0.4914 - val_loss: 1.9454 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 2.4753 - accuracy: 0.4914 - val_loss: 1.9412 - val_accuracy: 0.4000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 2.4676 - accuracy: 0.4914 - val_loss: 1.9371 - val_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 2.4599 - accuracy: 0.4914 - val_loss: 1.9331 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 2.4525 - accuracy: 0.4914 - val_loss: 1.9290 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 2.4452 - accuracy: 0.4914 - val_loss: 1.9248 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 2.4374 - accuracy: 0.4914 - val_loss: 1.9209 - val_accuracy: 0.4000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 2.4300 - accuracy: 0.4914 - val_loss: 1.9169 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 2.4228 - accuracy: 0.4914 - val_loss: 1.9130 - val_accuracy: 0.4000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 2.4153 - accuracy: 0.4914 - val_loss: 1.9091 - val_accuracy: 0.4000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 2.4082 - accuracy: 0.4914 - val_loss: 1.9050 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 2.4005 - accuracy: 0.4828 - val_loss: 1.9012 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 2.3935 - accuracy: 0.4828 - val_loss: 1.8973 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 2.3863 - accuracy: 0.4914 - val_loss: 1.8935 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 2.3791 - accuracy: 0.4914 - val_loss: 1.8898 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 2.3723 - accuracy: 0.4914 - val_loss: 1.8862 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 2.3651 - accuracy: 0.4914 - val_loss: 1.8826 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 2.3583 - accuracy: 0.4914 - val_loss: 1.8791 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 2.3513 - accuracy: 0.5000 - val_loss: 1.8754 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 2.3441 - accuracy: 0.5000 - val_loss: 1.8717 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 2.3370 - accuracy: 0.5000 - val_loss: 1.8679 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 2.3301 - accuracy: 0.5000 - val_loss: 1.8643 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 2.3229 - accuracy: 0.5000 - val_loss: 1.8606 - val_accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 2.3159 - accuracy: 0.5000 - val_loss: 1.8570 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 2.3090 - accuracy: 0.5000 - val_loss: 1.8536 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 2.3023 - accuracy: 0.5000 - val_loss: 1.8501 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 2.2956 - accuracy: 0.5000 - val_loss: 1.8466 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 2.2888 - accuracy: 0.5000 - val_loss: 1.8433 - val_accuracy: 0.4000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 2.2823 - accuracy: 0.5000 - val_loss: 1.8400 - val_accuracy: 0.4000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 2.2758 - accuracy: 0.5000 - val_loss: 1.8367 - val_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 2.2693 - accuracy: 0.5000 - val_loss: 1.8334 - val_accuracy: 0.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.35555556416511536</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.3610 - accuracy: 0.3534 - val_loss: 1.2954 - val_accuracy: 0.2000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 1.3521 - accuracy: 0.3534 - val_loss: 1.2961 - val_accuracy: 0.2000\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 333us/sample - loss: 1.3437 - accuracy: 0.3707 - val_loss: 1.2967 - val_accuracy: 0.2000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.3353 - accuracy: 0.3621 - val_loss: 1.2970 - val_accuracy: 0.2000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 1.3276 - accuracy: 0.3793 - val_loss: 1.2975 - val_accuracy: 0.2000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 1.3205 - accuracy: 0.3793 - val_loss: 1.2987 - val_accuracy: 0.1333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.3126 - accuracy: 0.3793 - val_loss: 1.2990 - val_accuracy: 0.1333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 1.3059 - accuracy: 0.3793 - val_loss: 1.3010 - val_accuracy: 0.0667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 342us/sample - loss: 1.3000 - accuracy: 0.3793 - val_loss: 1.3028 - val_accuracy: 0.1333\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 252us/sample - loss: 1.2927 - accuracy: 0.3879 - val_loss: 1.3032 - val_accuracy: 0.1333\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.2868 - accuracy: 0.3879 - val_loss: 1.3046 - val_accuracy: 0.1333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 1.2809 - accuracy: 0.3879 - val_loss: 1.3057 - val_accuracy: 0.1333\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 1.2751 - accuracy: 0.3793 - val_loss: 1.3072 - val_accuracy: 0.1333\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 251us/sample - loss: 1.2695 - accuracy: 0.3793 - val_loss: 1.3088 - val_accuracy: 0.1333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 1.2642 - accuracy: 0.3879 - val_loss: 1.3107 - val_accuracy: 0.1333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 1.2586 - accuracy: 0.3879 - val_loss: 1.3123 - val_accuracy: 0.1333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.2530 - accuracy: 0.3966 - val_loss: 1.3140 - val_accuracy: 0.1333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 269us/sample - loss: 1.2479 - accuracy: 0.3879 - val_loss: 1.3165 - val_accuracy: 0.1333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.2431 - accuracy: 0.3879 - val_loss: 1.3187 - val_accuracy: 0.1333\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 1.2382 - accuracy: 0.3966 - val_loss: 1.3196 - val_accuracy: 0.1333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.2334 - accuracy: 0.3966 - val_loss: 1.3212 - val_accuracy: 0.1333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 1.2289 - accuracy: 0.3879 - val_loss: 1.3232 - val_accuracy: 0.1333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 468us/sample - loss: 1.2253 - accuracy: 0.3966 - val_loss: 1.3256 - val_accuracy: 0.1333\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.2207 - accuracy: 0.3966 - val_loss: 1.3259 - val_accuracy: 0.1333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.2166 - accuracy: 0.3966 - val_loss: 1.3269 - val_accuracy: 0.1333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.2126 - accuracy: 0.4052 - val_loss: 1.3278 - val_accuracy: 0.1333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 1.2085 - accuracy: 0.4052 - val_loss: 1.3296 - val_accuracy: 0.1333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 1.2046 - accuracy: 0.4138 - val_loss: 1.3305 - val_accuracy: 0.1333\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 1.2006 - accuracy: 0.4138 - val_loss: 1.3323 - val_accuracy: 0.1333\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 1.1969 - accuracy: 0.4138 - val_loss: 1.3344 - val_accuracy: 0.1333\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.1936 - accuracy: 0.4138 - val_loss: 1.3354 - val_accuracy: 0.1333\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.1895 - accuracy: 0.4138 - val_loss: 1.3367 - val_accuracy: 0.1333\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 281us/sample - loss: 1.1861 - accuracy: 0.4397 - val_loss: 1.3382 - val_accuracy: 0.1333\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 1.1829 - accuracy: 0.4397 - val_loss: 1.3385 - val_accuracy: 0.1333\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.1793 - accuracy: 0.4397 - val_loss: 1.3412 - val_accuracy: 0.1333\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 370us/sample - loss: 1.1760 - accuracy: 0.4397 - val_loss: 1.3418 - val_accuracy: 0.1333\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.1728 - accuracy: 0.4397 - val_loss: 1.3426 - val_accuracy: 0.1333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 1.1698 - accuracy: 0.4397 - val_loss: 1.3434 - val_accuracy: 0.1333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 1.1668 - accuracy: 0.4397 - val_loss: 1.3451 - val_accuracy: 0.1333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 1.1634 - accuracy: 0.4397 - val_loss: 1.3455 - val_accuracy: 0.1333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 1.1604 - accuracy: 0.4397 - val_loss: 1.3455 - val_accuracy: 0.1333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 1.1574 - accuracy: 0.4397 - val_loss: 1.3454 - val_accuracy: 0.1333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.1546 - accuracy: 0.4397 - val_loss: 1.3459 - val_accuracy: 0.1333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 303us/sample - loss: 1.1517 - accuracy: 0.4397 - val_loss: 1.3456 - val_accuracy: 0.1333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 343us/sample - loss: 1.1491 - accuracy: 0.4483 - val_loss: 1.3482 - val_accuracy: 0.1333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.1459 - accuracy: 0.4483 - val_loss: 1.3475 - val_accuracy: 0.1333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 1.1432 - accuracy: 0.4483 - val_loss: 1.3490 - val_accuracy: 0.1333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 1.1407 - accuracy: 0.4483 - val_loss: 1.3493 - val_accuracy: 0.1333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 1.1380 - accuracy: 0.4569 - val_loss: 1.3497 - val_accuracy: 0.1333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 1.1356 - accuracy: 0.4569 - val_loss: 1.3511 - val_accuracy: 0.1333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 2.8615 - accuracy: 0.2759 - val_loss: 2.4572 - val_accuracy: 0.1333\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 248us/sample - loss: 2.8314 - accuracy: 0.2759 - val_loss: 2.4340 - val_accuracy: 0.1333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 2.8017 - accuracy: 0.2845 - val_loss: 2.4108 - val_accuracy: 0.2000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 2.7698 - accuracy: 0.2845 - val_loss: 2.3890 - val_accuracy: 0.2000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 2.7407 - accuracy: 0.2845 - val_loss: 2.3664 - val_accuracy: 0.2000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 2.7126 - accuracy: 0.2845 - val_loss: 2.3455 - val_accuracy: 0.2000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 384us/sample - loss: 2.6850 - accuracy: 0.2931 - val_loss: 2.3259 - val_accuracy: 0.2000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 2.6569 - accuracy: 0.3017 - val_loss: 2.3045 - val_accuracy: 0.2000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 2.6306 - accuracy: 0.3017 - val_loss: 2.2850 - val_accuracy: 0.2000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 2.6043 - accuracy: 0.3103 - val_loss: 2.2651 - val_accuracy: 0.2000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 2.5790 - accuracy: 0.3103 - val_loss: 2.2442 - val_accuracy: 0.2000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 2.5541 - accuracy: 0.3103 - val_loss: 2.2251 - val_accuracy: 0.2000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 2.5299 - accuracy: 0.3276 - val_loss: 2.2064 - val_accuracy: 0.2000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 2.5060 - accuracy: 0.3362 - val_loss: 2.1851 - val_accuracy: 0.2000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 259us/sample - loss: 2.4828 - accuracy: 0.3362 - val_loss: 2.1681 - val_accuracy: 0.2000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 2.4601 - accuracy: 0.3362 - val_loss: 2.1514 - val_accuracy: 0.2000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 2.4394 - accuracy: 0.3362 - val_loss: 2.1338 - val_accuracy: 0.2000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 2.4187 - accuracy: 0.3448 - val_loss: 2.1156 - val_accuracy: 0.2000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 2.3979 - accuracy: 0.3448 - val_loss: 2.0963 - val_accuracy: 0.2000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 2.3781 - accuracy: 0.3448 - val_loss: 2.0775 - val_accuracy: 0.2000\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 2.3588 - accuracy: 0.3448 - val_loss: 2.0621 - val_accuracy: 0.2000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 2.3402 - accuracy: 0.3448 - val_loss: 2.0473 - val_accuracy: 0.2000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 249us/sample - loss: 2.3207 - accuracy: 0.3448 - val_loss: 2.0319 - val_accuracy: 0.2000\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 2.3025 - accuracy: 0.3448 - val_loss: 2.0139 - val_accuracy: 0.2000\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 2.2841 - accuracy: 0.3534 - val_loss: 1.9981 - val_accuracy: 0.2000\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 2.2667 - accuracy: 0.3621 - val_loss: 1.9858 - val_accuracy: 0.2000\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 2.2486 - accuracy: 0.3621 - val_loss: 1.9668 - val_accuracy: 0.2000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 2.2315 - accuracy: 0.3621 - val_loss: 1.9504 - val_accuracy: 0.2000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 2.2153 - accuracy: 0.3621 - val_loss: 1.9350 - val_accuracy: 0.2000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 370us/sample - loss: 2.1978 - accuracy: 0.3707 - val_loss: 1.9206 - val_accuracy: 0.2667\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 2.1820 - accuracy: 0.3793 - val_loss: 1.9078 - val_accuracy: 0.2667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 2.1662 - accuracy: 0.3793 - val_loss: 1.8943 - val_accuracy: 0.2667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 2.1508 - accuracy: 0.3793 - val_loss: 1.8788 - val_accuracy: 0.2667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 2.1356 - accuracy: 0.3879 - val_loss: 1.8661 - val_accuracy: 0.2667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 2.1203 - accuracy: 0.3879 - val_loss: 1.8511 - val_accuracy: 0.2667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 2.1059 - accuracy: 0.3793 - val_loss: 1.8397 - val_accuracy: 0.2667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 2.0916 - accuracy: 0.3793 - val_loss: 1.8276 - val_accuracy: 0.2667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 2.0763 - accuracy: 0.3793 - val_loss: 1.8124 - val_accuracy: 0.2667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 2.0626 - accuracy: 0.3707 - val_loss: 1.8003 - val_accuracy: 0.2667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 2.0501 - accuracy: 0.3793 - val_loss: 1.7874 - val_accuracy: 0.2667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 2.0369 - accuracy: 0.3793 - val_loss: 1.7749 - val_accuracy: 0.2667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 2.0239 - accuracy: 0.3793 - val_loss: 1.7625 - val_accuracy: 0.2667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 2.0121 - accuracy: 0.3879 - val_loss: 1.7509 - val_accuracy: 0.2667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 2.0000 - accuracy: 0.3879 - val_loss: 1.7397 - val_accuracy: 0.2667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 1.9880 - accuracy: 0.3879 - val_loss: 1.7312 - val_accuracy: 0.2667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.9760 - accuracy: 0.3879 - val_loss: 1.7176 - val_accuracy: 0.2667\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 1.9646 - accuracy: 0.3879 - val_loss: 1.7062 - val_accuracy: 0.2667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 312us/sample - loss: 1.9531 - accuracy: 0.3879 - val_loss: 1.6953 - val_accuracy: 0.2667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 251us/sample - loss: 1.9414 - accuracy: 0.4052 - val_loss: 1.6867 - val_accuracy: 0.2667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 1.9302 - accuracy: 0.4138 - val_loss: 1.6773 - val_accuracy: 0.2667\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 4.1498 - accuracy: 0.2586 - val_loss: 4.7595 - val_accuracy: 0.1333\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 4.0561 - accuracy: 0.2672 - val_loss: 4.6431 - val_accuracy: 0.1333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 3.9572 - accuracy: 0.2759 - val_loss: 4.5266 - val_accuracy: 0.1333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 3.8623 - accuracy: 0.2759 - val_loss: 4.4124 - val_accuracy: 0.1333\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 3.7688 - accuracy: 0.2759 - val_loss: 4.2998 - val_accuracy: 0.1333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 3.6810 - accuracy: 0.2759 - val_loss: 4.1920 - val_accuracy: 0.1333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 252us/sample - loss: 3.5938 - accuracy: 0.2759 - val_loss: 4.0965 - val_accuracy: 0.1333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 3.5121 - accuracy: 0.2759 - val_loss: 3.9956 - val_accuracy: 0.1333\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 266us/sample - loss: 3.4320 - accuracy: 0.2759 - val_loss: 3.8998 - val_accuracy: 0.1333\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 3.3523 - accuracy: 0.2759 - val_loss: 3.8048 - val_accuracy: 0.1333\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 238us/sample - loss: 3.2776 - accuracy: 0.2672 - val_loss: 3.7117 - val_accuracy: 0.1333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 3.2043 - accuracy: 0.2845 - val_loss: 3.6208 - val_accuracy: 0.1333\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 3.1315 - accuracy: 0.2931 - val_loss: 3.5372 - val_accuracy: 0.1333\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 3.0633 - accuracy: 0.3017 - val_loss: 3.4509 - val_accuracy: 0.1333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 2.9942 - accuracy: 0.3017 - val_loss: 3.3769 - val_accuracy: 0.1333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 2.9327 - accuracy: 0.3017 - val_loss: 3.2986 - val_accuracy: 0.1333\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 2.8664 - accuracy: 0.3017 - val_loss: 3.2295 - val_accuracy: 0.1333\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 2.8048 - accuracy: 0.2931 - val_loss: 3.1545 - val_accuracy: 0.1333\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 2.7433 - accuracy: 0.2931 - val_loss: 3.0864 - val_accuracy: 0.1333\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 267us/sample - loss: 2.6854 - accuracy: 0.3017 - val_loss: 3.0210 - val_accuracy: 0.1333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 2.6276 - accuracy: 0.3017 - val_loss: 2.9473 - val_accuracy: 0.1333\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 2.5714 - accuracy: 0.3190 - val_loss: 2.8826 - val_accuracy: 0.1333\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 2.5189 - accuracy: 0.3190 - val_loss: 2.8148 - val_accuracy: 0.1333\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 2.4637 - accuracy: 0.3276 - val_loss: 2.7567 - val_accuracy: 0.1333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 2.4141 - accuracy: 0.3190 - val_loss: 2.6905 - val_accuracy: 0.1333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 2.3656 - accuracy: 0.3190 - val_loss: 2.6308 - val_accuracy: 0.1333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 261us/sample - loss: 2.3188 - accuracy: 0.3190 - val_loss: 2.5787 - val_accuracy: 0.1333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 262us/sample - loss: 2.2761 - accuracy: 0.3190 - val_loss: 2.5218 - val_accuracy: 0.1333\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 2.2338 - accuracy: 0.3190 - val_loss: 2.4693 - val_accuracy: 0.1333\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 254us/sample - loss: 2.1921 - accuracy: 0.3276 - val_loss: 2.4178 - val_accuracy: 0.1333\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 2.1537 - accuracy: 0.3276 - val_loss: 2.3636 - val_accuracy: 0.1333\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 255us/sample - loss: 2.1164 - accuracy: 0.3276 - val_loss: 2.3150 - val_accuracy: 0.1333\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 328us/sample - loss: 2.0808 - accuracy: 0.3276 - val_loss: 2.2693 - val_accuracy: 0.1333\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 2.0470 - accuracy: 0.3362 - val_loss: 2.2288 - val_accuracy: 0.1333\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 2.0162 - accuracy: 0.3362 - val_loss: 2.1835 - val_accuracy: 0.1333\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 263us/sample - loss: 1.9845 - accuracy: 0.3362 - val_loss: 2.1450 - val_accuracy: 0.1333\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 1.9564 - accuracy: 0.3362 - val_loss: 2.1042 - val_accuracy: 0.1333\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 250us/sample - loss: 1.9287 - accuracy: 0.3362 - val_loss: 2.0672 - val_accuracy: 0.1333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 1.9007 - accuracy: 0.3362 - val_loss: 2.0299 - val_accuracy: 0.1333\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 249us/sample - loss: 1.8744 - accuracy: 0.3362 - val_loss: 1.9984 - val_accuracy: 0.1333\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 273us/sample - loss: 1.8491 - accuracy: 0.3448 - val_loss: 1.9617 - val_accuracy: 0.1333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 1.8242 - accuracy: 0.3448 - val_loss: 1.9311 - val_accuracy: 0.1333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 395us/sample - loss: 1.8014 - accuracy: 0.3448 - val_loss: 1.9017 - val_accuracy: 0.1333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 321us/sample - loss: 1.7787 - accuracy: 0.3448 - val_loss: 1.8735 - val_accuracy: 0.1333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 1.7578 - accuracy: 0.3448 - val_loss: 1.8458 - val_accuracy: 0.1333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 260us/sample - loss: 1.7367 - accuracy: 0.3448 - val_loss: 1.8217 - val_accuracy: 0.1333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 304us/sample - loss: 1.7170 - accuracy: 0.3448 - val_loss: 1.7997 - val_accuracy: 0.1333\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 1.6983 - accuracy: 0.3448 - val_loss: 1.7760 - val_accuracy: 0.2000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.6797 - accuracy: 0.3448 - val_loss: 1.7559 - val_accuracy: 0.2000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 1.6628 - accuracy: 0.3448 - val_loss: 1.7380 - val_accuracy: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.7</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.2222222238779068</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.9994 - accuracy: 0.3534 - val_loss: 1.2610 - val_accuracy: 0.4000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 1.5225 - accuracy: 0.4569 - val_loss: 1.2377 - val_accuracy: 0.2667\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 1.2778 - accuracy: 0.5172 - val_loss: 1.1701 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 1.1303 - accuracy: 0.5517 - val_loss: 1.1549 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 1.0715 - accuracy: 0.5431 - val_loss: 1.1865 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 1.0348 - accuracy: 0.5603 - val_loss: 1.2353 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 1.0217 - accuracy: 0.5345 - val_loss: 1.2242 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 264us/sample - loss: 1.0064 - accuracy: 0.5431 - val_loss: 1.2468 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 256us/sample - loss: 0.9943 - accuracy: 0.5862 - val_loss: 1.2508 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 345us/sample - loss: 0.9869 - accuracy: 0.5776 - val_loss: 1.2569 - val_accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 291us/sample - loss: 0.9792 - accuracy: 0.5603 - val_loss: 1.2758 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.9728 - accuracy: 0.5517 - val_loss: 1.2784 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 277us/sample - loss: 0.9660 - accuracy: 0.5690 - val_loss: 1.2641 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 0.9586 - accuracy: 0.5776 - val_loss: 1.2796 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 276us/sample - loss: 0.9574 - accuracy: 0.5603 - val_loss: 1.2858 - val_accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.9494 - accuracy: 0.5862 - val_loss: 1.2568 - val_accuracy: 0.2667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.9439 - accuracy: 0.5690 - val_loss: 1.2499 - val_accuracy: 0.2667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 301us/sample - loss: 0.9421 - accuracy: 0.5690 - val_loss: 1.2712 - val_accuracy: 0.2667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 0.9392 - accuracy: 0.5603 - val_loss: 1.2773 - val_accuracy: 0.2667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 0.9410 - accuracy: 0.5776 - val_loss: 1.2792 - val_accuracy: 0.2667\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 363us/sample - loss: 0.9362 - accuracy: 0.5862 - val_loss: 1.2700 - val_accuracy: 0.2667\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.9290 - accuracy: 0.5690 - val_loss: 1.2881 - val_accuracy: 0.2667\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.9336 - accuracy: 0.5776 - val_loss: 1.2900 - val_accuracy: 0.2667\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 0.9289 - accuracy: 0.6034 - val_loss: 1.2731 - val_accuracy: 0.2667\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.9240 - accuracy: 0.6034 - val_loss: 1.2683 - val_accuracy: 0.2667\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 321us/sample - loss: 0.9184 - accuracy: 0.6034 - val_loss: 1.2707 - val_accuracy: 0.2667\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.9172 - accuracy: 0.6034 - val_loss: 1.2732 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.9150 - accuracy: 0.6121 - val_loss: 1.2926 - val_accuracy: 0.2667\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.9210 - accuracy: 0.6034 - val_loss: 1.2660 - val_accuracy: 0.3333\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 336us/sample - loss: 0.9117 - accuracy: 0.6379 - val_loss: 1.2456 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 0.9099 - accuracy: 0.6207 - val_loss: 1.2475 - val_accuracy: 0.4000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 0.9089 - accuracy: 0.6293 - val_loss: 1.2509 - val_accuracy: 0.4000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.9026 - accuracy: 0.6293 - val_loss: 1.2516 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 329us/sample - loss: 0.9041 - accuracy: 0.6207 - val_loss: 1.2695 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 372us/sample - loss: 0.8970 - accuracy: 0.6121 - val_loss: 1.2588 - val_accuracy: 0.4667\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 0.8968 - accuracy: 0.6034 - val_loss: 1.2590 - val_accuracy: 0.4667\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 0.8967 - accuracy: 0.6121 - val_loss: 1.2700 - val_accuracy: 0.4667\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.8930 - accuracy: 0.6207 - val_loss: 1.2897 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 0.8919 - accuracy: 0.6207 - val_loss: 1.2635 - val_accuracy: 0.4667\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 0.8928 - accuracy: 0.6466 - val_loss: 1.2859 - val_accuracy: 0.4667\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.8903 - accuracy: 0.6379 - val_loss: 1.2897 - val_accuracy: 0.4667\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 295us/sample - loss: 0.8860 - accuracy: 0.6379 - val_loss: 1.2896 - val_accuracy: 0.4667\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.8838 - accuracy: 0.6293 - val_loss: 1.3053 - val_accuracy: 0.4667\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 0.8884 - accuracy: 0.6552 - val_loss: 1.2969 - val_accuracy: 0.4667\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 344us/sample - loss: 0.8803 - accuracy: 0.6552 - val_loss: 1.2727 - val_accuracy: 0.4667\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 369us/sample - loss: 0.8811 - accuracy: 0.6466 - val_loss: 1.2491 - val_accuracy: 0.4667\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 0.8821 - accuracy: 0.6466 - val_loss: 1.2450 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8757 - accuracy: 0.6552 - val_loss: 1.2584 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 0.8792 - accuracy: 0.6379 - val_loss: 1.2777 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 270us/sample - loss: 0.8783 - accuracy: 0.6638 - val_loss: 1.2668 - val_accuracy: 0.4667\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.6767 - accuracy: 0.4397 - val_loss: 1.3332 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 340us/sample - loss: 1.3826 - accuracy: 0.4483 - val_loss: 1.2053 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 1.2316 - accuracy: 0.4569 - val_loss: 1.1167 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 1.1492 - accuracy: 0.4569 - val_loss: 1.0647 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 1.0872 - accuracy: 0.5000 - val_loss: 1.0158 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 1.0423 - accuracy: 0.4828 - val_loss: 0.9937 - val_accuracy: 0.4000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 1.0163 - accuracy: 0.5086 - val_loss: 0.9910 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 359us/sample - loss: 0.9976 - accuracy: 0.5172 - val_loss: 0.9843 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 0.9786 - accuracy: 0.5259 - val_loss: 0.9758 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 0.9619 - accuracy: 0.5172 - val_loss: 0.9614 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.9531 - accuracy: 0.5431 - val_loss: 0.9748 - val_accuracy: 0.4000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 268us/sample - loss: 0.9436 - accuracy: 0.5431 - val_loss: 0.9840 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 265us/sample - loss: 0.9360 - accuracy: 0.5345 - val_loss: 0.9822 - val_accuracy: 0.4667\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 0.9321 - accuracy: 0.5345 - val_loss: 0.9823 - val_accuracy: 0.4667\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 347us/sample - loss: 0.9218 - accuracy: 0.5431 - val_loss: 0.9858 - val_accuracy: 0.4667\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 0.9173 - accuracy: 0.5603 - val_loss: 0.9866 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 298us/sample - loss: 0.9101 - accuracy: 0.5776 - val_loss: 0.9877 - val_accuracy: 0.4667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 271us/sample - loss: 0.9115 - accuracy: 0.5603 - val_loss: 0.9813 - val_accuracy: 0.4667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.9034 - accuracy: 0.5776 - val_loss: 0.9914 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 275us/sample - loss: 0.9101 - accuracy: 0.5776 - val_loss: 0.9983 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.8976 - accuracy: 0.5948 - val_loss: 1.0165 - val_accuracy: 0.4667\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.9010 - accuracy: 0.5862 - val_loss: 1.0044 - val_accuracy: 0.4667\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.8898 - accuracy: 0.5948 - val_loss: 1.0070 - val_accuracy: 0.4667\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 0.8893 - accuracy: 0.6034 - val_loss: 1.0140 - val_accuracy: 0.4667\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 341us/sample - loss: 0.8881 - accuracy: 0.6034 - val_loss: 1.0133 - val_accuracy: 0.5333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8849 - accuracy: 0.5948 - val_loss: 1.0121 - val_accuracy: 0.5333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 349us/sample - loss: 0.8910 - accuracy: 0.6034 - val_loss: 1.0066 - val_accuracy: 0.6000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 334us/sample - loss: 0.8853 - accuracy: 0.6034 - val_loss: 1.0059 - val_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 311us/sample - loss: 0.8858 - accuracy: 0.6121 - val_loss: 1.0168 - val_accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 282us/sample - loss: 0.8762 - accuracy: 0.6034 - val_loss: 1.0306 - val_accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8746 - accuracy: 0.6034 - val_loss: 1.0394 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 0.8743 - accuracy: 0.6121 - val_loss: 1.0425 - val_accuracy: 0.5333\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 0.8753 - accuracy: 0.6121 - val_loss: 1.0544 - val_accuracy: 0.5333\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.8718 - accuracy: 0.6121 - val_loss: 1.0379 - val_accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 302us/sample - loss: 0.8720 - accuracy: 0.6207 - val_loss: 1.0571 - val_accuracy: 0.5333\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 0.8721 - accuracy: 0.6121 - val_loss: 1.0523 - val_accuracy: 0.5333\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.8631 - accuracy: 0.6121 - val_loss: 1.0486 - val_accuracy: 0.6000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 0.8642 - accuracy: 0.6121 - val_loss: 1.0621 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 288us/sample - loss: 0.8636 - accuracy: 0.6207 - val_loss: 1.0396 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 279us/sample - loss: 0.8655 - accuracy: 0.6466 - val_loss: 1.0619 - val_accuracy: 0.6000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 0.8636 - accuracy: 0.6207 - val_loss: 1.0824 - val_accuracy: 0.5333\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 0.8624 - accuracy: 0.6293 - val_loss: 1.0833 - val_accuracy: 0.5333\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.8606 - accuracy: 0.6207 - val_loss: 1.0916 - val_accuracy: 0.5333\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8615 - accuracy: 0.6121 - val_loss: 1.0852 - val_accuracy: 0.5333\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 0.8603 - accuracy: 0.6034 - val_loss: 1.0668 - val_accuracy: 0.5333\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.8597 - accuracy: 0.6121 - val_loss: 1.0611 - val_accuracy: 0.5333\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.8575 - accuracy: 0.6293 - val_loss: 1.0857 - val_accuracy: 0.6000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 353us/sample - loss: 0.8599 - accuracy: 0.6121 - val_loss: 1.0886 - val_accuracy: 0.5333\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 0.8529 - accuracy: 0.6207 - val_loss: 1.0925 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 0.8544 - accuracy: 0.6207 - val_loss: 1.0930 - val_accuracy: 0.5333\n",
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 1.6160 - accuracy: 0.3362 - val_loss: 1.6015 - val_accuracy: 0.2667\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 1.3159 - accuracy: 0.4138 - val_loss: 1.4890 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 1.1837 - accuracy: 0.4655 - val_loss: 1.4764 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 409us/sample - loss: 1.1242 - accuracy: 0.4655 - val_loss: 1.4464 - val_accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 351us/sample - loss: 1.0744 - accuracy: 0.4828 - val_loss: 1.4494 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 1.0499 - accuracy: 0.4828 - val_loss: 1.4064 - val_accuracy: 0.5333\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 1.0267 - accuracy: 0.4828 - val_loss: 1.3966 - val_accuracy: 0.4667\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 1.0133 - accuracy: 0.4741 - val_loss: 1.3896 - val_accuracy: 0.4667\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 0.9847 - accuracy: 0.4828 - val_loss: 1.3801 - val_accuracy: 0.5333\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 283us/sample - loss: 0.9731 - accuracy: 0.4914 - val_loss: 1.3668 - val_accuracy: 0.5333\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 285us/sample - loss: 0.9620 - accuracy: 0.4828 - val_loss: 1.3492 - val_accuracy: 0.5333\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 410us/sample - loss: 0.9489 - accuracy: 0.5086 - val_loss: 1.3512 - val_accuracy: 0.4667\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 349us/sample - loss: 0.9426 - accuracy: 0.5086 - val_loss: 1.3273 - val_accuracy: 0.4667\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 0.9354 - accuracy: 0.5431 - val_loss: 1.2920 - val_accuracy: 0.5333\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.9257 - accuracy: 0.5517 - val_loss: 1.3129 - val_accuracy: 0.4667\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 0.9178 - accuracy: 0.5431 - val_loss: 1.3020 - val_accuracy: 0.4667\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.9116 - accuracy: 0.5517 - val_loss: 1.2946 - val_accuracy: 0.4667\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 300us/sample - loss: 0.9051 - accuracy: 0.5431 - val_loss: 1.3098 - val_accuracy: 0.4667\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 287us/sample - loss: 0.9005 - accuracy: 0.5603 - val_loss: 1.2954 - val_accuracy: 0.4667\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 331us/sample - loss: 0.8957 - accuracy: 0.5603 - val_loss: 1.2902 - val_accuracy: 0.4667\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 274us/sample - loss: 0.8866 - accuracy: 0.5603 - val_loss: 1.3121 - val_accuracy: 0.4667\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 0.8857 - accuracy: 0.5603 - val_loss: 1.2936 - val_accuracy: 0.4667\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 0.8816 - accuracy: 0.5948 - val_loss: 1.2602 - val_accuracy: 0.4667\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8778 - accuracy: 0.5776 - val_loss: 1.2821 - val_accuracy: 0.5333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 322us/sample - loss: 0.8762 - accuracy: 0.5603 - val_loss: 1.2714 - val_accuracy: 0.5333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 286us/sample - loss: 0.8720 - accuracy: 0.5690 - val_loss: 1.2597 - val_accuracy: 0.5333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 296us/sample - loss: 0.8695 - accuracy: 0.5862 - val_loss: 1.2622 - val_accuracy: 0.6000\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 309us/sample - loss: 0.8688 - accuracy: 0.5603 - val_loss: 1.2623 - val_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 316us/sample - loss: 0.8655 - accuracy: 0.5948 - val_loss: 1.2525 - val_accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 0.8634 - accuracy: 0.5862 - val_loss: 1.2509 - val_accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.8594 - accuracy: 0.5862 - val_loss: 1.2641 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 326us/sample - loss: 0.8595 - accuracy: 0.5862 - val_loss: 1.2509 - val_accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 322us/sample - loss: 0.8610 - accuracy: 0.5776 - val_loss: 1.2761 - val_accuracy: 0.6000\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 314us/sample - loss: 0.8553 - accuracy: 0.6034 - val_loss: 1.2522 - val_accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 317us/sample - loss: 0.8616 - accuracy: 0.6121 - val_loss: 1.2719 - val_accuracy: 0.6000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8522 - accuracy: 0.5948 - val_loss: 1.2613 - val_accuracy: 0.6000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 305us/sample - loss: 0.8499 - accuracy: 0.6034 - val_loss: 1.2803 - val_accuracy: 0.6000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8523 - accuracy: 0.6121 - val_loss: 1.3003 - val_accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 292us/sample - loss: 0.8472 - accuracy: 0.6121 - val_loss: 1.2961 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 280us/sample - loss: 0.8434 - accuracy: 0.6121 - val_loss: 1.2796 - val_accuracy: 0.6000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8412 - accuracy: 0.5948 - val_loss: 1.2775 - val_accuracy: 0.6000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 0.8387 - accuracy: 0.6121 - val_loss: 1.2911 - val_accuracy: 0.6000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 0.8403 - accuracy: 0.6207 - val_loss: 1.2737 - val_accuracy: 0.6000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 293us/sample - loss: 0.8364 - accuracy: 0.5948 - val_loss: 1.2806 - val_accuracy: 0.6000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 308us/sample - loss: 0.8386 - accuracy: 0.5948 - val_loss: 1.2650 - val_accuracy: 0.6000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 299us/sample - loss: 0.8373 - accuracy: 0.6034 - val_loss: 1.2782 - val_accuracy: 0.6000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 284us/sample - loss: 0.8343 - accuracy: 0.6034 - val_loss: 1.2913 - val_accuracy: 0.6000\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 289us/sample - loss: 0.8342 - accuracy: 0.6121 - val_loss: 1.2836 - val_accuracy: 0.6000\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 278us/sample - loss: 0.8361 - accuracy: 0.5862 - val_loss: 1.2969 - val_accuracy: 0.6000\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 272us/sample - loss: 0.8304 - accuracy: 0.6034 - val_loss: 1.2711 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-momentum: 0.2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5555555820465088</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "INFO:tensorflow:Reloading Oracle from /content/my_dir/helloworld/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/my_dir/helloworld/tuner0.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23JI0eA1OFOX",
        "colab_type": "code",
        "outputId": "f9d98785-aaf8-4c7f-9333-7260aba443e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "tuner.search_space_summary()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">momentum (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ZP8M6DreMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "dbd36ebf-7ed7-4bba-b610-90458814deee"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Results in /content/my_dir/helloworld</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.5777778029441833</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.5777778029441833</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.5555555820465088</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.5333333611488342</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.5111111402511597</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.4444444477558136</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.4444444477558136</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.3777777850627899</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.35555556416511536</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.2222222238779068</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKoSdUynrlpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41122290-083c-4af4-c805-198a6635a776"
      },
      "source": [
        "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.01, 'momentum': 0.6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SZaHuo_rpgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = tuner.get_best_models()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHQqYcPDsGI4",
        "colab_type": "text"
      },
      "source": [
        "##Train the best model RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "00b20d76-a9de-4563-a80d-82965d5607ed",
        "id": "sH1B0fhOsNSD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#num_epochs = 50\n",
        "all_acc_histories_RS = []\n",
        "all_loss_histories_RS = []\n",
        "all_val_acc_histories_RS = []\n",
        "all_val_loss_histories_RS = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        " \n",
        "  history_RS = best_model.fit(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=8)\n",
        "  \n",
        "  acc_history_RS = history_RS.history['accuracy']\n",
        "  all_acc_histories_RS.append(acc_history_RS)\n",
        "\n",
        "  loss_history_RS = history_RS.history['loss']\n",
        "  all_loss_histories_RS.append(loss_history_RS)\n",
        "\n",
        "  acc_val_history_RS = history_RS.history['val_accuracy']\n",
        "  all_val_acc_histories_RS.append(acc_val_history_RS)\n",
        "\n",
        "  loss_val_history_RS = history_RS.history['val_loss']\n",
        "  all_val_loss_histories_RS.append(loss_val_history_RS)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali è una lista lunga num_epochs,\n",
        "#ogni elemento può essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 116 samples, validate on 15 samples\n",
            "Epoch 1/50\n",
            "116/116 [==============================] - 0s 3ms/sample - loss: 0.8978 - accuracy: 0.5862 - val_loss: 1.0708 - val_accuracy: 0.6000\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 0.9028 - accuracy: 0.6121 - val_loss: 1.1250 - val_accuracy: 0.5333\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 0.8955 - accuracy: 0.6034 - val_loss: 1.0634 - val_accuracy: 0.6000\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 0s 323us/sample - loss: 0.9088 - accuracy: 0.5948 - val_loss: 1.0643 - val_accuracy: 0.6000\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 0s 320us/sample - loss: 0.8996 - accuracy: 0.5948 - val_loss: 1.0793 - val_accuracy: 0.5333\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 0s 339us/sample - loss: 0.8949 - accuracy: 0.5948 - val_loss: 1.0412 - val_accuracy: 0.6000\n",
            "Epoch 7/50\n",
            "116/116 [==============================] - 0s 351us/sample - loss: 0.8962 - accuracy: 0.5862 - val_loss: 1.0141 - val_accuracy: 0.6000\n",
            "Epoch 8/50\n",
            "116/116 [==============================] - 0s 364us/sample - loss: 0.8894 - accuracy: 0.5862 - val_loss: 1.0133 - val_accuracy: 0.6000\n",
            "Epoch 9/50\n",
            "116/116 [==============================] - 0s 390us/sample - loss: 0.8936 - accuracy: 0.5603 - val_loss: 1.0160 - val_accuracy: 0.6000\n",
            "Epoch 10/50\n",
            "116/116 [==============================] - 0s 355us/sample - loss: 0.8954 - accuracy: 0.5948 - val_loss: 1.0345 - val_accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 0.8888 - accuracy: 0.5776 - val_loss: 1.0526 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "116/116 [==============================] - 0s 342us/sample - loss: 0.8858 - accuracy: 0.6034 - val_loss: 1.0614 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "116/116 [==============================] - 0s 341us/sample - loss: 0.8902 - accuracy: 0.5862 - val_loss: 1.0512 - val_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 0.8833 - accuracy: 0.5603 - val_loss: 1.0404 - val_accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "116/116 [==============================] - 0s 336us/sample - loss: 0.8759 - accuracy: 0.6034 - val_loss: 1.0257 - val_accuracy: 0.6000\n",
            "Epoch 16/50\n",
            "116/116 [==============================] - 0s 354us/sample - loss: 0.8714 - accuracy: 0.5690 - val_loss: 1.0304 - val_accuracy: 0.6000\n",
            "Epoch 17/50\n",
            "116/116 [==============================] - 0s 329us/sample - loss: 0.8793 - accuracy: 0.6034 - val_loss: 1.0087 - val_accuracy: 0.6000\n",
            "Epoch 18/50\n",
            "116/116 [==============================] - 0s 290us/sample - loss: 0.8678 - accuracy: 0.6034 - val_loss: 1.0170 - val_accuracy: 0.6000\n",
            "Epoch 19/50\n",
            "116/116 [==============================] - 0s 306us/sample - loss: 0.8672 - accuracy: 0.5862 - val_loss: 1.0119 - val_accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "116/116 [==============================] - 0s 307us/sample - loss: 0.8523 - accuracy: 0.5948 - val_loss: 1.0104 - val_accuracy: 0.5333\n",
            "Epoch 21/50\n",
            "116/116 [==============================] - 0s 328us/sample - loss: 0.8577 - accuracy: 0.5862 - val_loss: 1.0183 - val_accuracy: 0.6000\n",
            "Epoch 22/50\n",
            "116/116 [==============================] - 0s 313us/sample - loss: 0.8540 - accuracy: 0.6034 - val_loss: 1.0527 - val_accuracy: 0.6000\n",
            "Epoch 23/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.8502 - accuracy: 0.6121 - val_loss: 0.9972 - val_accuracy: 0.5333\n",
            "Epoch 24/50\n",
            "116/116 [==============================] - 0s 401us/sample - loss: 0.8537 - accuracy: 0.5862 - val_loss: 1.0110 - val_accuracy: 0.5333\n",
            "Epoch 25/50\n",
            "116/116 [==============================] - 0s 349us/sample - loss: 0.8424 - accuracy: 0.6207 - val_loss: 1.0230 - val_accuracy: 0.5333\n",
            "Epoch 26/50\n",
            "116/116 [==============================] - 0s 340us/sample - loss: 0.8423 - accuracy: 0.6034 - val_loss: 0.9940 - val_accuracy: 0.5333\n",
            "Epoch 27/50\n",
            "116/116 [==============================] - 0s 352us/sample - loss: 0.8436 - accuracy: 0.6207 - val_loss: 1.0059 - val_accuracy: 0.5333\n",
            "Epoch 28/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.8391 - accuracy: 0.6034 - val_loss: 0.9942 - val_accuracy: 0.5333\n",
            "Epoch 29/50\n",
            "116/116 [==============================] - 0s 331us/sample - loss: 0.8461 - accuracy: 0.6121 - val_loss: 0.9975 - val_accuracy: 0.4667\n",
            "Epoch 30/50\n",
            "116/116 [==============================] - 0s 325us/sample - loss: 0.8346 - accuracy: 0.6293 - val_loss: 1.0127 - val_accuracy: 0.4667\n",
            "Epoch 31/50\n",
            "116/116 [==============================] - 0s 338us/sample - loss: 0.8316 - accuracy: 0.6293 - val_loss: 0.9856 - val_accuracy: 0.4667\n",
            "Epoch 32/50\n",
            "116/116 [==============================] - 0s 333us/sample - loss: 0.8294 - accuracy: 0.6207 - val_loss: 0.9754 - val_accuracy: 0.4667\n",
            "Epoch 33/50\n",
            "116/116 [==============================] - 0s 354us/sample - loss: 0.8286 - accuracy: 0.6207 - val_loss: 0.9638 - val_accuracy: 0.4667\n",
            "Epoch 34/50\n",
            "116/116 [==============================] - 0s 338us/sample - loss: 0.8266 - accuracy: 0.6379 - val_loss: 0.9571 - val_accuracy: 0.4667\n",
            "Epoch 35/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 0.8230 - accuracy: 0.6207 - val_loss: 1.0373 - val_accuracy: 0.4000\n",
            "Epoch 36/50\n",
            "116/116 [==============================] - 0s 332us/sample - loss: 0.8185 - accuracy: 0.6293 - val_loss: 1.0474 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "116/116 [==============================] - 0s 324us/sample - loss: 0.8141 - accuracy: 0.6293 - val_loss: 1.0374 - val_accuracy: 0.4000\n",
            "Epoch 38/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.8190 - accuracy: 0.6034 - val_loss: 1.0506 - val_accuracy: 0.4000\n",
            "Epoch 39/50\n",
            "116/116 [==============================] - 0s 297us/sample - loss: 0.8090 - accuracy: 0.6207 - val_loss: 1.0377 - val_accuracy: 0.4000\n",
            "Epoch 40/50\n",
            "116/116 [==============================] - 0s 349us/sample - loss: 0.8099 - accuracy: 0.6379 - val_loss: 1.0485 - val_accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "116/116 [==============================] - 0s 318us/sample - loss: 0.8044 - accuracy: 0.6293 - val_loss: 1.0639 - val_accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 0.8080 - accuracy: 0.6293 - val_loss: 1.0310 - val_accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "116/116 [==============================] - 0s 315us/sample - loss: 0.7988 - accuracy: 0.6466 - val_loss: 1.0140 - val_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "116/116 [==============================] - 0s 333us/sample - loss: 0.8056 - accuracy: 0.6466 - val_loss: 1.0346 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "116/116 [==============================] - 0s 340us/sample - loss: 0.7954 - accuracy: 0.6293 - val_loss: 1.0609 - val_accuracy: 0.4000\n",
            "Epoch 46/50\n",
            "116/116 [==============================] - 0s 354us/sample - loss: 0.7931 - accuracy: 0.6552 - val_loss: 1.0354 - val_accuracy: 0.4000\n",
            "Epoch 47/50\n",
            "116/116 [==============================] - 0s 310us/sample - loss: 0.7952 - accuracy: 0.6293 - val_loss: 1.0717 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "116/116 [==============================] - 0s 330us/sample - loss: 0.7946 - accuracy: 0.6466 - val_loss: 1.0401 - val_accuracy: 0.4667\n",
            "Epoch 49/50\n",
            "116/116 [==============================] - 0s 335us/sample - loss: 0.7953 - accuracy: 0.6379 - val_loss: 1.0286 - val_accuracy: 0.4667\n",
            "Epoch 50/50\n",
            "116/116 [==============================] - 0s 319us/sample - loss: 0.8001 - accuracy: 0.6810 - val_loss: 1.0679 - val_accuracy: 0.4667\n",
            "Train on 117 samples, validate on 14 samples\n",
            "Epoch 1/50\n",
            "117/117 [==============================] - 0s 374us/sample - loss: 0.8276 - accuracy: 0.5983 - val_loss: 0.7442 - val_accuracy: 0.5714\n",
            "Epoch 2/50\n",
            "117/117 [==============================] - 0s 325us/sample - loss: 0.8175 - accuracy: 0.6239 - val_loss: 0.7463 - val_accuracy: 0.6429\n",
            "Epoch 3/50\n",
            "117/117 [==============================] - 0s 326us/sample - loss: 0.8108 - accuracy: 0.6325 - val_loss: 0.7597 - val_accuracy: 0.5714\n",
            "Epoch 4/50\n",
            "117/117 [==============================] - 0s 334us/sample - loss: 0.8133 - accuracy: 0.6410 - val_loss: 0.7598 - val_accuracy: 0.6429\n",
            "Epoch 5/50\n",
            "117/117 [==============================] - 0s 302us/sample - loss: 0.7964 - accuracy: 0.6154 - val_loss: 0.7763 - val_accuracy: 0.5714\n",
            "Epoch 6/50\n",
            "117/117 [==============================] - 0s 293us/sample - loss: 0.7999 - accuracy: 0.6239 - val_loss: 0.7740 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "117/117 [==============================] - 0s 496us/sample - loss: 0.7967 - accuracy: 0.6325 - val_loss: 0.7937 - val_accuracy: 0.5714\n",
            "Epoch 8/50\n",
            "117/117 [==============================] - 0s 351us/sample - loss: 0.7948 - accuracy: 0.6239 - val_loss: 0.7887 - val_accuracy: 0.6429\n",
            "Epoch 9/50\n",
            "117/117 [==============================] - 0s 369us/sample - loss: 0.7975 - accuracy: 0.6581 - val_loss: 0.7918 - val_accuracy: 0.6429\n",
            "Epoch 10/50\n",
            "117/117 [==============================] - 0s 353us/sample - loss: 0.7864 - accuracy: 0.6581 - val_loss: 0.7854 - val_accuracy: 0.6429\n",
            "Epoch 11/50\n",
            "117/117 [==============================] - 0s 342us/sample - loss: 0.7845 - accuracy: 0.6496 - val_loss: 0.7832 - val_accuracy: 0.6429\n",
            "Epoch 12/50\n",
            "117/117 [==============================] - 0s 324us/sample - loss: 0.7841 - accuracy: 0.6410 - val_loss: 0.8183 - val_accuracy: 0.5714\n",
            "Epoch 13/50\n",
            "117/117 [==============================] - 0s 328us/sample - loss: 0.7831 - accuracy: 0.6581 - val_loss: 0.8004 - val_accuracy: 0.5714\n",
            "Epoch 14/50\n",
            "117/117 [==============================] - 0s 317us/sample - loss: 0.7777 - accuracy: 0.6667 - val_loss: 0.8101 - val_accuracy: 0.5714\n",
            "Epoch 15/50\n",
            "117/117 [==============================] - 0s 351us/sample - loss: 0.7863 - accuracy: 0.6325 - val_loss: 0.7891 - val_accuracy: 0.7143\n",
            "Epoch 16/50\n",
            "117/117 [==============================] - 0s 338us/sample - loss: 0.7853 - accuracy: 0.6410 - val_loss: 0.8038 - val_accuracy: 0.5714\n",
            "Epoch 17/50\n",
            "117/117 [==============================] - 0s 371us/sample - loss: 0.7707 - accuracy: 0.6581 - val_loss: 0.7848 - val_accuracy: 0.6429\n",
            "Epoch 18/50\n",
            "117/117 [==============================] - 0s 353us/sample - loss: 0.7767 - accuracy: 0.6410 - val_loss: 0.8090 - val_accuracy: 0.5714\n",
            "Epoch 19/50\n",
            "117/117 [==============================] - 0s 317us/sample - loss: 0.7688 - accuracy: 0.6581 - val_loss: 0.7997 - val_accuracy: 0.6429\n",
            "Epoch 20/50\n",
            "117/117 [==============================] - 0s 320us/sample - loss: 0.7715 - accuracy: 0.6496 - val_loss: 0.8011 - val_accuracy: 0.6429\n",
            "Epoch 21/50\n",
            "117/117 [==============================] - 0s 318us/sample - loss: 0.7664 - accuracy: 0.6410 - val_loss: 0.7883 - val_accuracy: 0.6429\n",
            "Epoch 22/50\n",
            "117/117 [==============================] - 0s 281us/sample - loss: 0.7576 - accuracy: 0.6496 - val_loss: 0.8017 - val_accuracy: 0.5714\n",
            "Epoch 23/50\n",
            "117/117 [==============================] - 0s 342us/sample - loss: 0.7600 - accuracy: 0.6496 - val_loss: 0.7892 - val_accuracy: 0.6429\n",
            "Epoch 24/50\n",
            "117/117 [==============================] - 0s 318us/sample - loss: 0.7632 - accuracy: 0.6581 - val_loss: 0.7932 - val_accuracy: 0.6429\n",
            "Epoch 25/50\n",
            "117/117 [==============================] - 0s 328us/sample - loss: 0.7651 - accuracy: 0.6410 - val_loss: 0.7834 - val_accuracy: 0.6429\n",
            "Epoch 26/50\n",
            "117/117 [==============================] - 0s 337us/sample - loss: 0.7527 - accuracy: 0.6496 - val_loss: 0.8113 - val_accuracy: 0.5714\n",
            "Epoch 27/50\n",
            "117/117 [==============================] - 0s 341us/sample - loss: 0.7529 - accuracy: 0.6581 - val_loss: 0.8040 - val_accuracy: 0.6429\n",
            "Epoch 28/50\n",
            "117/117 [==============================] - 0s 323us/sample - loss: 0.7517 - accuracy: 0.6838 - val_loss: 0.8002 - val_accuracy: 0.5714\n",
            "Epoch 29/50\n",
            "117/117 [==============================] - 0s 347us/sample - loss: 0.7459 - accuracy: 0.6667 - val_loss: 0.8193 - val_accuracy: 0.5714\n",
            "Epoch 30/50\n",
            "117/117 [==============================] - 0s 308us/sample - loss: 0.7490 - accuracy: 0.6667 - val_loss: 0.7956 - val_accuracy: 0.6429\n",
            "Epoch 31/50\n",
            "117/117 [==============================] - 0s 352us/sample - loss: 0.7569 - accuracy: 0.6667 - val_loss: 0.8116 - val_accuracy: 0.5714\n",
            "Epoch 32/50\n",
            "117/117 [==============================] - 0s 327us/sample - loss: 0.7585 - accuracy: 0.6752 - val_loss: 0.8183 - val_accuracy: 0.5714\n",
            "Epoch 33/50\n",
            "117/117 [==============================] - 0s 325us/sample - loss: 0.7478 - accuracy: 0.6752 - val_loss: 0.8181 - val_accuracy: 0.6429\n",
            "Epoch 34/50\n",
            "117/117 [==============================] - 0s 313us/sample - loss: 0.7447 - accuracy: 0.7094 - val_loss: 0.8054 - val_accuracy: 0.6429\n",
            "Epoch 35/50\n",
            "117/117 [==============================] - 0s 340us/sample - loss: 0.7350 - accuracy: 0.6752 - val_loss: 0.8166 - val_accuracy: 0.6429\n",
            "Epoch 36/50\n",
            "117/117 [==============================] - 0s 326us/sample - loss: 0.7412 - accuracy: 0.6581 - val_loss: 0.8458 - val_accuracy: 0.5714\n",
            "Epoch 37/50\n",
            "117/117 [==============================] - 0s 323us/sample - loss: 0.7454 - accuracy: 0.6838 - val_loss: 0.8050 - val_accuracy: 0.6429\n",
            "Epoch 38/50\n",
            "117/117 [==============================] - 0s 318us/sample - loss: 0.7359 - accuracy: 0.6667 - val_loss: 0.8136 - val_accuracy: 0.6429\n",
            "Epoch 39/50\n",
            "117/117 [==============================] - 0s 321us/sample - loss: 0.7391 - accuracy: 0.6923 - val_loss: 0.8265 - val_accuracy: 0.6429\n",
            "Epoch 40/50\n",
            "117/117 [==============================] - 0s 331us/sample - loss: 0.7350 - accuracy: 0.6923 - val_loss: 0.8309 - val_accuracy: 0.5714\n",
            "Epoch 41/50\n",
            "117/117 [==============================] - 0s 368us/sample - loss: 0.7382 - accuracy: 0.7179 - val_loss: 0.8452 - val_accuracy: 0.5714\n",
            "Epoch 42/50\n",
            "117/117 [==============================] - 0s 386us/sample - loss: 0.7416 - accuracy: 0.6667 - val_loss: 0.8156 - val_accuracy: 0.6429\n",
            "Epoch 43/50\n",
            "117/117 [==============================] - 0s 315us/sample - loss: 0.7361 - accuracy: 0.6752 - val_loss: 0.8342 - val_accuracy: 0.5714\n",
            "Epoch 44/50\n",
            "117/117 [==============================] - 0s 317us/sample - loss: 0.7440 - accuracy: 0.6667 - val_loss: 0.8340 - val_accuracy: 0.5714\n",
            "Epoch 45/50\n",
            "117/117 [==============================] - 0s 322us/sample - loss: 0.7404 - accuracy: 0.6667 - val_loss: 0.8307 - val_accuracy: 0.6429\n",
            "Epoch 46/50\n",
            "117/117 [==============================] - 0s 319us/sample - loss: 0.7312 - accuracy: 0.7009 - val_loss: 0.8547 - val_accuracy: 0.5714\n",
            "Epoch 47/50\n",
            "117/117 [==============================] - 0s 354us/sample - loss: 0.7338 - accuracy: 0.6667 - val_loss: 0.8216 - val_accuracy: 0.6429\n",
            "Epoch 48/50\n",
            "117/117 [==============================] - 0s 335us/sample - loss: 0.7283 - accuracy: 0.6752 - val_loss: 0.8543 - val_accuracy: 0.5714\n",
            "Epoch 49/50\n",
            "117/117 [==============================] - 0s 341us/sample - loss: 0.7313 - accuracy: 0.6752 - val_loss: 0.8638 - val_accuracy: 0.5714\n",
            "Epoch 50/50\n",
            "117/117 [==============================] - 0s 326us/sample - loss: 0.7310 - accuracy: 0.6752 - val_loss: 0.8667 - val_accuracy: 0.5714\n",
            "Train on 117 samples, validate on 14 samples\n",
            "Epoch 1/50\n",
            "117/117 [==============================] - 0s 330us/sample - loss: 0.7284 - accuracy: 0.6838 - val_loss: 0.8592 - val_accuracy: 0.5714\n",
            "Epoch 2/50\n",
            "117/117 [==============================] - 0s 367us/sample - loss: 0.7213 - accuracy: 0.6667 - val_loss: 0.8966 - val_accuracy: 0.5714\n",
            "Epoch 3/50\n",
            "117/117 [==============================] - 0s 344us/sample - loss: 0.7179 - accuracy: 0.6923 - val_loss: 0.9236 - val_accuracy: 0.6429\n",
            "Epoch 4/50\n",
            "117/117 [==============================] - 0s 335us/sample - loss: 0.7152 - accuracy: 0.6667 - val_loss: 0.8948 - val_accuracy: 0.6429\n",
            "Epoch 5/50\n",
            "117/117 [==============================] - 0s 376us/sample - loss: 0.7176 - accuracy: 0.6838 - val_loss: 0.9277 - val_accuracy: 0.5714\n",
            "Epoch 6/50\n",
            "117/117 [==============================] - 0s 338us/sample - loss: 0.7147 - accuracy: 0.7009 - val_loss: 0.9286 - val_accuracy: 0.6429\n",
            "Epoch 7/50\n",
            "117/117 [==============================] - 0s 384us/sample - loss: 0.7170 - accuracy: 0.6752 - val_loss: 0.9848 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "117/117 [==============================] - 0s 340us/sample - loss: 0.7065 - accuracy: 0.6667 - val_loss: 0.9514 - val_accuracy: 0.5714\n",
            "Epoch 9/50\n",
            "117/117 [==============================] - 0s 364us/sample - loss: 0.6891 - accuracy: 0.6923 - val_loss: 0.9974 - val_accuracy: 0.5714\n",
            "Epoch 10/50\n",
            "117/117 [==============================] - 0s 312us/sample - loss: 0.7137 - accuracy: 0.7009 - val_loss: 0.9833 - val_accuracy: 0.5714\n",
            "Epoch 11/50\n",
            "117/117 [==============================] - 0s 352us/sample - loss: 0.6989 - accuracy: 0.6581 - val_loss: 0.9944 - val_accuracy: 0.5714\n",
            "Epoch 12/50\n",
            "117/117 [==============================] - 0s 333us/sample - loss: 0.7071 - accuracy: 0.6838 - val_loss: 1.0677 - val_accuracy: 0.5714\n",
            "Epoch 13/50\n",
            "117/117 [==============================] - 0s 373us/sample - loss: 0.6973 - accuracy: 0.6667 - val_loss: 1.0243 - val_accuracy: 0.5714\n",
            "Epoch 14/50\n",
            "117/117 [==============================] - 0s 339us/sample - loss: 0.6938 - accuracy: 0.7009 - val_loss: 1.0344 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "117/117 [==============================] - 0s 348us/sample - loss: 0.6846 - accuracy: 0.6752 - val_loss: 1.0151 - val_accuracy: 0.5714\n",
            "Epoch 16/50\n",
            "117/117 [==============================] - 0s 318us/sample - loss: 0.7013 - accuracy: 0.6923 - val_loss: 1.0485 - val_accuracy: 0.5714\n",
            "Epoch 17/50\n",
            "117/117 [==============================] - 0s 317us/sample - loss: 0.6897 - accuracy: 0.6923 - val_loss: 1.0385 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "117/117 [==============================] - 0s 319us/sample - loss: 0.7015 - accuracy: 0.6838 - val_loss: 1.0621 - val_accuracy: 0.4286\n",
            "Epoch 19/50\n",
            "117/117 [==============================] - 0s 324us/sample - loss: 0.6849 - accuracy: 0.6923 - val_loss: 1.0794 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "117/117 [==============================] - 0s 335us/sample - loss: 0.6841 - accuracy: 0.6923 - val_loss: 1.0840 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "117/117 [==============================] - 0s 354us/sample - loss: 0.6799 - accuracy: 0.6923 - val_loss: 1.0895 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "117/117 [==============================] - 0s 311us/sample - loss: 0.6863 - accuracy: 0.7094 - val_loss: 1.1142 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "117/117 [==============================] - 0s 300us/sample - loss: 0.6793 - accuracy: 0.7009 - val_loss: 1.1114 - val_accuracy: 0.4286\n",
            "Epoch 24/50\n",
            "117/117 [==============================] - 0s 354us/sample - loss: 0.6871 - accuracy: 0.7009 - val_loss: 1.1325 - val_accuracy: 0.4286\n",
            "Epoch 25/50\n",
            "117/117 [==============================] - 0s 339us/sample - loss: 0.6852 - accuracy: 0.7009 - val_loss: 1.0958 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "117/117 [==============================] - 0s 347us/sample - loss: 0.6958 - accuracy: 0.7094 - val_loss: 1.1615 - val_accuracy: 0.4286\n",
            "Epoch 27/50\n",
            "117/117 [==============================] - 0s 321us/sample - loss: 0.7038 - accuracy: 0.6752 - val_loss: 1.1454 - val_accuracy: 0.4286\n",
            "Epoch 28/50\n",
            "117/117 [==============================] - 0s 347us/sample - loss: 0.6893 - accuracy: 0.7009 - val_loss: 1.1757 - val_accuracy: 0.4286\n",
            "Epoch 29/50\n",
            "117/117 [==============================] - 0s 325us/sample - loss: 0.6756 - accuracy: 0.7009 - val_loss: 1.1548 - val_accuracy: 0.4286\n",
            "Epoch 30/50\n",
            "117/117 [==============================] - 0s 315us/sample - loss: 0.6678 - accuracy: 0.7265 - val_loss: 1.1698 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "117/117 [==============================] - 0s 388us/sample - loss: 0.6863 - accuracy: 0.6667 - val_loss: 1.1770 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "117/117 [==============================] - 0s 316us/sample - loss: 0.6827 - accuracy: 0.6923 - val_loss: 1.2418 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "117/117 [==============================] - 0s 339us/sample - loss: 0.6688 - accuracy: 0.7009 - val_loss: 1.1521 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "117/117 [==============================] - 0s 347us/sample - loss: 0.6636 - accuracy: 0.7265 - val_loss: 1.1845 - val_accuracy: 0.4286\n",
            "Epoch 35/50\n",
            "117/117 [==============================] - 0s 352us/sample - loss: 0.6668 - accuracy: 0.7009 - val_loss: 1.1641 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "117/117 [==============================] - 0s 453us/sample - loss: 0.7114 - accuracy: 0.7094 - val_loss: 1.2125 - val_accuracy: 0.4286\n",
            "Epoch 37/50\n",
            "117/117 [==============================] - 0s 337us/sample - loss: 0.6654 - accuracy: 0.7607 - val_loss: 1.1958 - val_accuracy: 0.4286\n",
            "Epoch 38/50\n",
            "117/117 [==============================] - 0s 329us/sample - loss: 0.6629 - accuracy: 0.7009 - val_loss: 1.2244 - val_accuracy: 0.4286\n",
            "Epoch 39/50\n",
            "117/117 [==============================] - 0s 334us/sample - loss: 0.6709 - accuracy: 0.7265 - val_loss: 1.2114 - val_accuracy: 0.4286\n",
            "Epoch 40/50\n",
            "117/117 [==============================] - 0s 305us/sample - loss: 0.6722 - accuracy: 0.7094 - val_loss: 1.2485 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "117/117 [==============================] - 0s 305us/sample - loss: 0.6744 - accuracy: 0.7094 - val_loss: 1.2149 - val_accuracy: 0.4286\n",
            "Epoch 42/50\n",
            "117/117 [==============================] - 0s 308us/sample - loss: 0.6664 - accuracy: 0.6838 - val_loss: 1.2240 - val_accuracy: 0.4286\n",
            "Epoch 43/50\n",
            "117/117 [==============================] - 0s 313us/sample - loss: 0.6486 - accuracy: 0.6667 - val_loss: 1.3003 - val_accuracy: 0.4286\n",
            "Epoch 44/50\n",
            "117/117 [==============================] - 0s 319us/sample - loss: 0.6991 - accuracy: 0.6667 - val_loss: 1.2982 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "117/117 [==============================] - 0s 307us/sample - loss: 0.6593 - accuracy: 0.7179 - val_loss: 1.2298 - val_accuracy: 0.4286\n",
            "Epoch 46/50\n",
            "117/117 [==============================] - 0s 318us/sample - loss: 0.6809 - accuracy: 0.6581 - val_loss: 1.2491 - val_accuracy: 0.4286\n",
            "Epoch 47/50\n",
            "117/117 [==============================] - 0s 342us/sample - loss: 0.6592 - accuracy: 0.6752 - val_loss: 1.3042 - val_accuracy: 0.4286\n",
            "Epoch 48/50\n",
            "117/117 [==============================] - 0s 322us/sample - loss: 0.6590 - accuracy: 0.6923 - val_loss: 1.2929 - val_accuracy: 0.4286\n",
            "Epoch 49/50\n",
            "117/117 [==============================] - 0s 347us/sample - loss: 0.6478 - accuracy: 0.7179 - val_loss: 1.2689 - val_accuracy: 0.4286\n",
            "Epoch 50/50\n",
            "117/117 [==============================] - 0s 363us/sample - loss: 0.6488 - accuracy: 0.7094 - val_loss: 1.3921 - val_accuracy: 0.5000\n",
            "Train on 117 samples, validate on 14 samples\n",
            "Epoch 1/50\n",
            "117/117 [==============================] - 0s 334us/sample - loss: 0.7300 - accuracy: 0.6838 - val_loss: 0.7200 - val_accuracy: 0.6429\n",
            "Epoch 2/50\n",
            "117/117 [==============================] - 0s 457us/sample - loss: 0.7090 - accuracy: 0.6923 - val_loss: 0.7916 - val_accuracy: 0.6429\n",
            "Epoch 3/50\n",
            "117/117 [==============================] - 0s 357us/sample - loss: 0.7006 - accuracy: 0.6838 - val_loss: 0.8216 - val_accuracy: 0.6429\n",
            "Epoch 4/50\n",
            "117/117 [==============================] - 0s 363us/sample - loss: 0.7025 - accuracy: 0.7094 - val_loss: 0.8104 - val_accuracy: 0.5714\n",
            "Epoch 5/50\n",
            "117/117 [==============================] - 0s 312us/sample - loss: 0.6937 - accuracy: 0.6923 - val_loss: 0.8806 - val_accuracy: 0.6429\n",
            "Epoch 6/50\n",
            "117/117 [==============================] - 0s 307us/sample - loss: 0.6933 - accuracy: 0.6838 - val_loss: 0.8574 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "117/117 [==============================] - 0s 328us/sample - loss: 0.7035 - accuracy: 0.6752 - val_loss: 0.8855 - val_accuracy: 0.6429\n",
            "Epoch 8/50\n",
            "117/117 [==============================] - 0s 351us/sample - loss: 0.7101 - accuracy: 0.6667 - val_loss: 0.8684 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "117/117 [==============================] - 0s 311us/sample - loss: 0.7107 - accuracy: 0.6838 - val_loss: 0.8581 - val_accuracy: 0.5714\n",
            "Epoch 10/50\n",
            "117/117 [==============================] - 0s 339us/sample - loss: 0.6891 - accuracy: 0.7094 - val_loss: 0.8454 - val_accuracy: 0.6429\n",
            "Epoch 11/50\n",
            "117/117 [==============================] - 0s 311us/sample - loss: 0.6946 - accuracy: 0.7265 - val_loss: 0.8797 - val_accuracy: 0.6429\n",
            "Epoch 12/50\n",
            "117/117 [==============================] - 0s 351us/sample - loss: 0.6807 - accuracy: 0.6923 - val_loss: 0.8856 - val_accuracy: 0.5714\n",
            "Epoch 13/50\n",
            "117/117 [==============================] - 0s 311us/sample - loss: 0.6976 - accuracy: 0.6838 - val_loss: 0.8855 - val_accuracy: 0.6429\n",
            "Epoch 14/50\n",
            "117/117 [==============================] - 0s 283us/sample - loss: 0.6812 - accuracy: 0.6923 - val_loss: 0.9131 - val_accuracy: 0.5714\n",
            "Epoch 15/50\n",
            "117/117 [==============================] - 0s 328us/sample - loss: 0.6858 - accuracy: 0.6923 - val_loss: 0.9215 - val_accuracy: 0.6429\n",
            "Epoch 16/50\n",
            "117/117 [==============================] - 0s 304us/sample - loss: 0.6938 - accuracy: 0.6838 - val_loss: 0.9187 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "117/117 [==============================] - 0s 331us/sample - loss: 0.6941 - accuracy: 0.6581 - val_loss: 0.9437 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "117/117 [==============================] - 0s 316us/sample - loss: 0.7113 - accuracy: 0.6838 - val_loss: 0.9173 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "117/117 [==============================] - 0s 299us/sample - loss: 0.6859 - accuracy: 0.6752 - val_loss: 0.9141 - val_accuracy: 0.6429\n",
            "Epoch 20/50\n",
            "117/117 [==============================] - 0s 349us/sample - loss: 0.6916 - accuracy: 0.6923 - val_loss: 0.9059 - val_accuracy: 0.6429\n",
            "Epoch 21/50\n",
            "117/117 [==============================] - 0s 322us/sample - loss: 0.6965 - accuracy: 0.6923 - val_loss: 0.8980 - val_accuracy: 0.6429\n",
            "Epoch 22/50\n",
            "117/117 [==============================] - 0s 327us/sample - loss: 0.6792 - accuracy: 0.7179 - val_loss: 0.9278 - val_accuracy: 0.6429\n",
            "Epoch 23/50\n",
            "117/117 [==============================] - 0s 327us/sample - loss: 0.6900 - accuracy: 0.6752 - val_loss: 0.9210 - val_accuracy: 0.5714\n",
            "Epoch 24/50\n",
            "117/117 [==============================] - 0s 327us/sample - loss: 0.6948 - accuracy: 0.7265 - val_loss: 0.9175 - val_accuracy: 0.6429\n",
            "Epoch 25/50\n",
            "117/117 [==============================] - 0s 321us/sample - loss: 0.6842 - accuracy: 0.6838 - val_loss: 0.9467 - val_accuracy: 0.6429\n",
            "Epoch 26/50\n",
            "117/117 [==============================] - 0s 342us/sample - loss: 0.6870 - accuracy: 0.6667 - val_loss: 0.9280 - val_accuracy: 0.5714\n",
            "Epoch 27/50\n",
            "117/117 [==============================] - 0s 323us/sample - loss: 0.6869 - accuracy: 0.6923 - val_loss: 0.9387 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "117/117 [==============================] - 0s 315us/sample - loss: 0.6853 - accuracy: 0.6325 - val_loss: 0.9310 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "117/117 [==============================] - 0s 300us/sample - loss: 0.6795 - accuracy: 0.6923 - val_loss: 0.9600 - val_accuracy: 0.6429\n",
            "Epoch 30/50\n",
            "117/117 [==============================] - 0s 309us/sample - loss: 0.6788 - accuracy: 0.7094 - val_loss: 0.9812 - val_accuracy: 0.6429\n",
            "Epoch 31/50\n",
            "117/117 [==============================] - 0s 313us/sample - loss: 0.6847 - accuracy: 0.6838 - val_loss: 0.9378 - val_accuracy: 0.5714\n",
            "Epoch 32/50\n",
            "117/117 [==============================] - 0s 312us/sample - loss: 0.6843 - accuracy: 0.7265 - val_loss: 0.9426 - val_accuracy: 0.6429\n",
            "Epoch 33/50\n",
            "117/117 [==============================] - 0s 375us/sample - loss: 0.7018 - accuracy: 0.6667 - val_loss: 0.9912 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "117/117 [==============================] - 0s 334us/sample - loss: 0.6827 - accuracy: 0.6923 - val_loss: 0.9722 - val_accuracy: 0.6429\n",
            "Epoch 35/50\n",
            "117/117 [==============================] - 0s 336us/sample - loss: 0.6759 - accuracy: 0.6752 - val_loss: 0.9654 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "117/117 [==============================] - 0s 326us/sample - loss: 0.6767 - accuracy: 0.7094 - val_loss: 0.9949 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "117/117 [==============================] - 0s 301us/sample - loss: 0.6884 - accuracy: 0.7009 - val_loss: 0.9911 - val_accuracy: 0.6429\n",
            "Epoch 38/50\n",
            "117/117 [==============================] - 0s 343us/sample - loss: 0.6717 - accuracy: 0.6923 - val_loss: 1.0433 - val_accuracy: 0.4286\n",
            "Epoch 39/50\n",
            "117/117 [==============================] - 0s 295us/sample - loss: 0.6764 - accuracy: 0.7179 - val_loss: 0.9818 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "117/117 [==============================] - 0s 341us/sample - loss: 0.6691 - accuracy: 0.6838 - val_loss: 0.9811 - val_accuracy: 0.6429\n",
            "Epoch 41/50\n",
            "117/117 [==============================] - 0s 351us/sample - loss: 0.6822 - accuracy: 0.6667 - val_loss: 1.0198 - val_accuracy: 0.5714\n",
            "Epoch 42/50\n",
            "117/117 [==============================] - 0s 333us/sample - loss: 0.6808 - accuracy: 0.6581 - val_loss: 0.9886 - val_accuracy: 0.6429\n",
            "Epoch 43/50\n",
            "117/117 [==============================] - 0s 317us/sample - loss: 0.6730 - accuracy: 0.6923 - val_loss: 0.9834 - val_accuracy: 0.6429\n",
            "Epoch 44/50\n",
            "117/117 [==============================] - 0s 319us/sample - loss: 0.6643 - accuracy: 0.7009 - val_loss: 1.0121 - val_accuracy: 0.6429\n",
            "Epoch 45/50\n",
            "117/117 [==============================] - 0s 308us/sample - loss: 0.6827 - accuracy: 0.6581 - val_loss: 0.9880 - val_accuracy: 0.6429\n",
            "Epoch 46/50\n",
            "117/117 [==============================] - 0s 381us/sample - loss: 0.6951 - accuracy: 0.6838 - val_loss: 0.9758 - val_accuracy: 0.6429\n",
            "Epoch 47/50\n",
            "117/117 [==============================] - 0s 352us/sample - loss: 0.6830 - accuracy: 0.6581 - val_loss: 0.9860 - val_accuracy: 0.5714\n",
            "Epoch 48/50\n",
            "117/117 [==============================] - 0s 336us/sample - loss: 0.6927 - accuracy: 0.6581 - val_loss: 1.0029 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "117/117 [==============================] - 0s 312us/sample - loss: 0.6930 - accuracy: 0.6752 - val_loss: 1.0431 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "117/117 [==============================] - 0s 301us/sample - loss: 0.6793 - accuracy: 0.7009 - val_loss: 1.0253 - val_accuracy: 0.5714\n",
            "Train on 118 samples, validate on 13 samples\n",
            "Epoch 1/50\n",
            "118/118 [==============================] - 0s 307us/sample - loss: 0.7258 - accuracy: 0.6525 - val_loss: 0.5886 - val_accuracy: 0.6923\n",
            "Epoch 2/50\n",
            "118/118 [==============================] - 0s 348us/sample - loss: 0.6985 - accuracy: 0.6441 - val_loss: 0.7167 - val_accuracy: 0.6923\n",
            "Epoch 3/50\n",
            "118/118 [==============================] - 0s 368us/sample - loss: 0.7264 - accuracy: 0.6610 - val_loss: 0.7215 - val_accuracy: 0.6923\n",
            "Epoch 4/50\n",
            "118/118 [==============================] - 0s 314us/sample - loss: 0.6971 - accuracy: 0.6864 - val_loss: 0.7958 - val_accuracy: 0.6154\n",
            "Epoch 5/50\n",
            "118/118 [==============================] - 0s 411us/sample - loss: 0.7085 - accuracy: 0.6864 - val_loss: 0.7736 - val_accuracy: 0.6154\n",
            "Epoch 6/50\n",
            "118/118 [==============================] - 0s 386us/sample - loss: 0.6981 - accuracy: 0.7034 - val_loss: 0.7817 - val_accuracy: 0.7692\n",
            "Epoch 7/50\n",
            "118/118 [==============================] - 0s 386us/sample - loss: 0.6902 - accuracy: 0.7119 - val_loss: 0.8245 - val_accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "118/118 [==============================] - 0s 327us/sample - loss: 0.6787 - accuracy: 0.6864 - val_loss: 0.8422 - val_accuracy: 0.6923\n",
            "Epoch 9/50\n",
            "118/118 [==============================] - 0s 288us/sample - loss: 0.6912 - accuracy: 0.6780 - val_loss: 0.9570 - val_accuracy: 0.6154\n",
            "Epoch 10/50\n",
            "118/118 [==============================] - 0s 328us/sample - loss: 0.6872 - accuracy: 0.6695 - val_loss: 0.9072 - val_accuracy: 0.6154\n",
            "Epoch 11/50\n",
            "118/118 [==============================] - 0s 325us/sample - loss: 0.6699 - accuracy: 0.7288 - val_loss: 0.9831 - val_accuracy: 0.6154\n",
            "Epoch 12/50\n",
            "118/118 [==============================] - 0s 267us/sample - loss: 0.6794 - accuracy: 0.6695 - val_loss: 1.0503 - val_accuracy: 0.6154\n",
            "Epoch 13/50\n",
            "118/118 [==============================] - 0s 312us/sample - loss: 0.6551 - accuracy: 0.7119 - val_loss: 1.0692 - val_accuracy: 0.6154\n",
            "Epoch 14/50\n",
            "118/118 [==============================] - 0s 379us/sample - loss: 0.6538 - accuracy: 0.7288 - val_loss: 1.0750 - val_accuracy: 0.6154\n",
            "Epoch 15/50\n",
            "118/118 [==============================] - 0s 303us/sample - loss: 0.6621 - accuracy: 0.6949 - val_loss: 1.1122 - val_accuracy: 0.6154\n",
            "Epoch 16/50\n",
            "118/118 [==============================] - 0s 303us/sample - loss: 0.6590 - accuracy: 0.7288 - val_loss: 1.0777 - val_accuracy: 0.6154\n",
            "Epoch 17/50\n",
            "118/118 [==============================] - 0s 315us/sample - loss: 0.6548 - accuracy: 0.6610 - val_loss: 1.0572 - val_accuracy: 0.6154\n",
            "Epoch 18/50\n",
            "118/118 [==============================] - 0s 325us/sample - loss: 0.6518 - accuracy: 0.7203 - val_loss: 1.1754 - val_accuracy: 0.6154\n",
            "Epoch 19/50\n",
            "118/118 [==============================] - 0s 333us/sample - loss: 0.6535 - accuracy: 0.7034 - val_loss: 1.1456 - val_accuracy: 0.6154\n",
            "Epoch 20/50\n",
            "118/118 [==============================] - 0s 295us/sample - loss: 0.6350 - accuracy: 0.7542 - val_loss: 1.2286 - val_accuracy: 0.6923\n",
            "Epoch 21/50\n",
            "118/118 [==============================] - 0s 294us/sample - loss: 0.6704 - accuracy: 0.7119 - val_loss: 1.2794 - val_accuracy: 0.6154\n",
            "Epoch 22/50\n",
            "118/118 [==============================] - 0s 336us/sample - loss: 0.6465 - accuracy: 0.7373 - val_loss: 1.2931 - val_accuracy: 0.6154\n",
            "Epoch 23/50\n",
            "118/118 [==============================] - 0s 299us/sample - loss: 0.6371 - accuracy: 0.7373 - val_loss: 1.2630 - val_accuracy: 0.6154\n",
            "Epoch 24/50\n",
            "118/118 [==============================] - 0s 285us/sample - loss: 0.6574 - accuracy: 0.7034 - val_loss: 1.3636 - val_accuracy: 0.5385\n",
            "Epoch 25/50\n",
            "118/118 [==============================] - 0s 294us/sample - loss: 0.6492 - accuracy: 0.7203 - val_loss: 1.3796 - val_accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "118/118 [==============================] - 0s 324us/sample - loss: 0.6530 - accuracy: 0.6864 - val_loss: 1.2416 - val_accuracy: 0.6154\n",
            "Epoch 27/50\n",
            "118/118 [==============================] - 0s 281us/sample - loss: 0.6622 - accuracy: 0.6949 - val_loss: 1.2922 - val_accuracy: 0.5385\n",
            "Epoch 28/50\n",
            "118/118 [==============================] - 0s 299us/sample - loss: 0.6455 - accuracy: 0.6949 - val_loss: 1.2674 - val_accuracy: 0.6154\n",
            "Epoch 29/50\n",
            "118/118 [==============================] - 0s 365us/sample - loss: 0.6475 - accuracy: 0.7288 - val_loss: 1.3513 - val_accuracy: 0.5385\n",
            "Epoch 30/50\n",
            "118/118 [==============================] - 0s 299us/sample - loss: 0.6544 - accuracy: 0.7034 - val_loss: 1.3048 - val_accuracy: 0.6154\n",
            "Epoch 31/50\n",
            "118/118 [==============================] - 0s 308us/sample - loss: 0.6481 - accuracy: 0.7034 - val_loss: 1.4068 - val_accuracy: 0.5385\n",
            "Epoch 32/50\n",
            "118/118 [==============================] - 0s 294us/sample - loss: 0.6367 - accuracy: 0.7458 - val_loss: 1.3228 - val_accuracy: 0.6154\n",
            "Epoch 33/50\n",
            "118/118 [==============================] - 0s 281us/sample - loss: 0.6359 - accuracy: 0.6949 - val_loss: 1.3998 - val_accuracy: 0.5385\n",
            "Epoch 34/50\n",
            "118/118 [==============================] - 0s 334us/sample - loss: 0.6399 - accuracy: 0.7458 - val_loss: 1.3583 - val_accuracy: 0.5385\n",
            "Epoch 35/50\n",
            "118/118 [==============================] - 0s 303us/sample - loss: 0.6378 - accuracy: 0.7288 - val_loss: 1.3654 - val_accuracy: 0.6154\n",
            "Epoch 36/50\n",
            "118/118 [==============================] - 0s 309us/sample - loss: 0.6294 - accuracy: 0.7203 - val_loss: 1.3842 - val_accuracy: 0.5385\n",
            "Epoch 37/50\n",
            "118/118 [==============================] - 0s 297us/sample - loss: 0.6217 - accuracy: 0.7288 - val_loss: 1.4501 - val_accuracy: 0.5385\n",
            "Epoch 38/50\n",
            "118/118 [==============================] - 0s 338us/sample - loss: 0.6449 - accuracy: 0.7288 - val_loss: 1.3612 - val_accuracy: 0.6154\n",
            "Epoch 39/50\n",
            "118/118 [==============================] - 0s 316us/sample - loss: 0.6479 - accuracy: 0.6949 - val_loss: 1.3577 - val_accuracy: 0.5385\n",
            "Epoch 40/50\n",
            "118/118 [==============================] - 0s 329us/sample - loss: 0.6557 - accuracy: 0.6949 - val_loss: 1.3971 - val_accuracy: 0.6154\n",
            "Epoch 41/50\n",
            "118/118 [==============================] - 0s 314us/sample - loss: 0.6337 - accuracy: 0.7288 - val_loss: 1.3663 - val_accuracy: 0.6154\n",
            "Epoch 42/50\n",
            "118/118 [==============================] - 0s 334us/sample - loss: 0.6224 - accuracy: 0.7542 - val_loss: 1.4301 - val_accuracy: 0.5385\n",
            "Epoch 43/50\n",
            "118/118 [==============================] - 0s 261us/sample - loss: 0.6350 - accuracy: 0.7542 - val_loss: 1.5071 - val_accuracy: 0.5385\n",
            "Epoch 44/50\n",
            "118/118 [==============================] - 0s 284us/sample - loss: 0.6242 - accuracy: 0.7373 - val_loss: 1.4190 - val_accuracy: 0.5385\n",
            "Epoch 45/50\n",
            "118/118 [==============================] - 0s 290us/sample - loss: 0.6281 - accuracy: 0.7119 - val_loss: 1.3952 - val_accuracy: 0.6923\n",
            "Epoch 46/50\n",
            "118/118 [==============================] - 0s 305us/sample - loss: 0.6312 - accuracy: 0.7627 - val_loss: 1.3920 - val_accuracy: 0.6923\n",
            "Epoch 47/50\n",
            "118/118 [==============================] - 0s 289us/sample - loss: 0.6133 - accuracy: 0.7458 - val_loss: 1.4284 - val_accuracy: 0.6154\n",
            "Epoch 48/50\n",
            "118/118 [==============================] - 0s 343us/sample - loss: 0.6295 - accuracy: 0.7288 - val_loss: 1.5246 - val_accuracy: 0.5385\n",
            "Epoch 49/50\n",
            "118/118 [==============================] - 0s 340us/sample - loss: 0.6203 - accuracy: 0.7542 - val_loss: 1.4666 - val_accuracy: 0.5385\n",
            "Epoch 50/50\n",
            "118/118 [==============================] - 0s 320us/sample - loss: 0.6071 - accuracy: 0.7288 - val_loss: 1.5194 - val_accuracy: 0.5385\n",
            "Train on 118 samples, validate on 13 samples\n",
            "Epoch 1/50\n",
            "118/118 [==============================] - 0s 355us/sample - loss: 0.7274 - accuracy: 0.6864 - val_loss: 0.5566 - val_accuracy: 0.7692\n",
            "Epoch 2/50\n",
            "118/118 [==============================] - 0s 314us/sample - loss: 0.6921 - accuracy: 0.7288 - val_loss: 0.6244 - val_accuracy: 0.7692\n",
            "Epoch 3/50\n",
            "118/118 [==============================] - 0s 359us/sample - loss: 0.7213 - accuracy: 0.7119 - val_loss: 0.6738 - val_accuracy: 0.6923\n",
            "Epoch 4/50\n",
            "118/118 [==============================] - 0s 327us/sample - loss: 0.6847 - accuracy: 0.7119 - val_loss: 0.7101 - val_accuracy: 0.6923\n",
            "Epoch 5/50\n",
            "118/118 [==============================] - 0s 314us/sample - loss: 0.6783 - accuracy: 0.7458 - val_loss: 0.7496 - val_accuracy: 0.6923\n",
            "Epoch 6/50\n",
            "118/118 [==============================] - 0s 310us/sample - loss: 0.6836 - accuracy: 0.7034 - val_loss: 0.8211 - val_accuracy: 0.6154\n",
            "Epoch 7/50\n",
            "118/118 [==============================] - 0s 295us/sample - loss: 0.6764 - accuracy: 0.7458 - val_loss: 0.7663 - val_accuracy: 0.6154\n",
            "Epoch 8/50\n",
            "118/118 [==============================] - 0s 304us/sample - loss: 0.6628 - accuracy: 0.7373 - val_loss: 0.8617 - val_accuracy: 0.6154\n",
            "Epoch 9/50\n",
            "118/118 [==============================] - 0s 332us/sample - loss: 0.6613 - accuracy: 0.7458 - val_loss: 0.8697 - val_accuracy: 0.6154\n",
            "Epoch 10/50\n",
            "118/118 [==============================] - 0s 291us/sample - loss: 0.6616 - accuracy: 0.7373 - val_loss: 0.8836 - val_accuracy: 0.6154\n",
            "Epoch 11/50\n",
            "118/118 [==============================] - 0s 303us/sample - loss: 0.6583 - accuracy: 0.7458 - val_loss: 0.9042 - val_accuracy: 0.5385\n",
            "Epoch 12/50\n",
            "118/118 [==============================] - 0s 338us/sample - loss: 0.6588 - accuracy: 0.7542 - val_loss: 0.9282 - val_accuracy: 0.5385\n",
            "Epoch 13/50\n",
            "118/118 [==============================] - 0s 319us/sample - loss: 0.6576 - accuracy: 0.7458 - val_loss: 0.9368 - val_accuracy: 0.6154\n",
            "Epoch 14/50\n",
            "118/118 [==============================] - 0s 299us/sample - loss: 0.6709 - accuracy: 0.7627 - val_loss: 0.9244 - val_accuracy: 0.5385\n",
            "Epoch 15/50\n",
            "118/118 [==============================] - 0s 313us/sample - loss: 0.6732 - accuracy: 0.7542 - val_loss: 1.0607 - val_accuracy: 0.4615\n",
            "Epoch 16/50\n",
            "118/118 [==============================] - 0s 284us/sample - loss: 0.6604 - accuracy: 0.7458 - val_loss: 1.0467 - val_accuracy: 0.5385\n",
            "Epoch 17/50\n",
            "118/118 [==============================] - 0s 287us/sample - loss: 0.6624 - accuracy: 0.7373 - val_loss: 1.0423 - val_accuracy: 0.5385\n",
            "Epoch 18/50\n",
            "118/118 [==============================] - 0s 307us/sample - loss: 0.6337 - accuracy: 0.7542 - val_loss: 1.0786 - val_accuracy: 0.5385\n",
            "Epoch 19/50\n",
            "118/118 [==============================] - 0s 303us/sample - loss: 0.6407 - accuracy: 0.7458 - val_loss: 1.1342 - val_accuracy: 0.5385\n",
            "Epoch 20/50\n",
            "118/118 [==============================] - 0s 298us/sample - loss: 0.6353 - accuracy: 0.7797 - val_loss: 1.1241 - val_accuracy: 0.5385\n",
            "Epoch 21/50\n",
            "118/118 [==============================] - 0s 325us/sample - loss: 0.6842 - accuracy: 0.7288 - val_loss: 1.0364 - val_accuracy: 0.5385\n",
            "Epoch 22/50\n",
            "118/118 [==============================] - 0s 308us/sample - loss: 0.6377 - accuracy: 0.7373 - val_loss: 1.1097 - val_accuracy: 0.5385\n",
            "Epoch 23/50\n",
            "118/118 [==============================] - 0s 319us/sample - loss: 0.6545 - accuracy: 0.7373 - val_loss: 1.1256 - val_accuracy: 0.5385\n",
            "Epoch 24/50\n",
            "118/118 [==============================] - 0s 414us/sample - loss: 0.6486 - accuracy: 0.7203 - val_loss: 1.1228 - val_accuracy: 0.5385\n",
            "Epoch 25/50\n",
            "118/118 [==============================] - 0s 456us/sample - loss: 0.6303 - accuracy: 0.7627 - val_loss: 1.1422 - val_accuracy: 0.4615\n",
            "Epoch 26/50\n",
            "118/118 [==============================] - 0s 328us/sample - loss: 0.6285 - accuracy: 0.7458 - val_loss: 1.2301 - val_accuracy: 0.4615\n",
            "Epoch 27/50\n",
            "118/118 [==============================] - 0s 314us/sample - loss: 0.6423 - accuracy: 0.7373 - val_loss: 1.1523 - val_accuracy: 0.5385\n",
            "Epoch 28/50\n",
            "118/118 [==============================] - 0s 350us/sample - loss: 0.6307 - accuracy: 0.7373 - val_loss: 1.1667 - val_accuracy: 0.5385\n",
            "Epoch 29/50\n",
            "118/118 [==============================] - 0s 338us/sample - loss: 0.6485 - accuracy: 0.7373 - val_loss: 1.1631 - val_accuracy: 0.5385\n",
            "Epoch 30/50\n",
            "118/118 [==============================] - 0s 327us/sample - loss: 0.6470 - accuracy: 0.7373 - val_loss: 1.1421 - val_accuracy: 0.5385\n",
            "Epoch 31/50\n",
            "118/118 [==============================] - 0s 327us/sample - loss: 0.6312 - accuracy: 0.7288 - val_loss: 1.1826 - val_accuracy: 0.5385\n",
            "Epoch 32/50\n",
            "118/118 [==============================] - 0s 348us/sample - loss: 0.6479 - accuracy: 0.7542 - val_loss: 1.2150 - val_accuracy: 0.5385\n",
            "Epoch 33/50\n",
            "118/118 [==============================] - 0s 293us/sample - loss: 0.6225 - accuracy: 0.7373 - val_loss: 1.2681 - val_accuracy: 0.4615\n",
            "Epoch 34/50\n",
            "118/118 [==============================] - 0s 327us/sample - loss: 0.6286 - accuracy: 0.7627 - val_loss: 1.2569 - val_accuracy: 0.4615\n",
            "Epoch 35/50\n",
            "118/118 [==============================] - 0s 309us/sample - loss: 0.6260 - accuracy: 0.7373 - val_loss: 1.3282 - val_accuracy: 0.6154\n",
            "Epoch 36/50\n",
            "118/118 [==============================] - 0s 300us/sample - loss: 0.6360 - accuracy: 0.7542 - val_loss: 1.2270 - val_accuracy: 0.4615\n",
            "Epoch 37/50\n",
            "118/118 [==============================] - 0s 308us/sample - loss: 0.6286 - accuracy: 0.7288 - val_loss: 1.2534 - val_accuracy: 0.5385\n",
            "Epoch 38/50\n",
            "118/118 [==============================] - 0s 301us/sample - loss: 0.6142 - accuracy: 0.7458 - val_loss: 1.2610 - val_accuracy: 0.5385\n",
            "Epoch 39/50\n",
            "118/118 [==============================] - 0s 303us/sample - loss: 0.6462 - accuracy: 0.7373 - val_loss: 1.2478 - val_accuracy: 0.5385\n",
            "Epoch 40/50\n",
            "118/118 [==============================] - 0s 298us/sample - loss: 0.6204 - accuracy: 0.7542 - val_loss: 1.3423 - val_accuracy: 0.4615\n",
            "Epoch 41/50\n",
            "118/118 [==============================] - 0s 303us/sample - loss: 0.6207 - accuracy: 0.7458 - val_loss: 1.2223 - val_accuracy: 0.5385\n",
            "Epoch 42/50\n",
            "118/118 [==============================] - 0s 299us/sample - loss: 0.6446 - accuracy: 0.7288 - val_loss: 1.2554 - val_accuracy: 0.5385\n",
            "Epoch 43/50\n",
            "118/118 [==============================] - 0s 298us/sample - loss: 0.6457 - accuracy: 0.7373 - val_loss: 1.3658 - val_accuracy: 0.5385\n",
            "Epoch 44/50\n",
            "118/118 [==============================] - 0s 313us/sample - loss: 0.6318 - accuracy: 0.7797 - val_loss: 1.3375 - val_accuracy: 0.4615\n",
            "Epoch 45/50\n",
            "118/118 [==============================] - 0s 297us/sample - loss: 0.6343 - accuracy: 0.7458 - val_loss: 1.2694 - val_accuracy: 0.4615\n",
            "Epoch 46/50\n",
            "118/118 [==============================] - 0s 293us/sample - loss: 0.6221 - accuracy: 0.7373 - val_loss: 1.3863 - val_accuracy: 0.4615\n",
            "Epoch 47/50\n",
            "118/118 [==============================] - 0s 305us/sample - loss: 0.6289 - accuracy: 0.7373 - val_loss: 1.2802 - val_accuracy: 0.4615\n",
            "Epoch 48/50\n",
            "118/118 [==============================] - 0s 311us/sample - loss: 0.6126 - accuracy: 0.7458 - val_loss: 1.3216 - val_accuracy: 0.5385\n",
            "Epoch 49/50\n",
            "118/118 [==============================] - 0s 315us/sample - loss: 0.6193 - accuracy: 0.7458 - val_loss: 1.3273 - val_accuracy: 0.5385\n",
            "Epoch 50/50\n",
            "118/118 [==============================] - 0s 312us/sample - loss: 0.6436 - accuracy: 0.7373 - val_loss: 1.3729 - val_accuracy: 0.4615\n",
            "Train on 119 samples, validate on 12 samples\n",
            "Epoch 1/50\n",
            "119/119 [==============================] - 0s 301us/sample - loss: 0.7367 - accuracy: 0.7059 - val_loss: 0.5617 - val_accuracy: 0.8333\n",
            "Epoch 2/50\n",
            "119/119 [==============================] - 0s 276us/sample - loss: 0.6595 - accuracy: 0.7311 - val_loss: 0.6887 - val_accuracy: 0.8333\n",
            "Epoch 3/50\n",
            "119/119 [==============================] - 0s 321us/sample - loss: 0.6650 - accuracy: 0.7479 - val_loss: 0.7060 - val_accuracy: 0.8333\n",
            "Epoch 4/50\n",
            "119/119 [==============================] - 0s 309us/sample - loss: 0.6615 - accuracy: 0.7563 - val_loss: 0.6947 - val_accuracy: 0.8333\n",
            "Epoch 5/50\n",
            "119/119 [==============================] - 0s 350us/sample - loss: 0.6397 - accuracy: 0.7563 - val_loss: 0.8391 - val_accuracy: 0.8333\n",
            "Epoch 6/50\n",
            "119/119 [==============================] - 0s 326us/sample - loss: 0.6524 - accuracy: 0.7311 - val_loss: 0.6512 - val_accuracy: 0.9167\n",
            "Epoch 7/50\n",
            "119/119 [==============================] - 0s 317us/sample - loss: 0.6442 - accuracy: 0.6975 - val_loss: 0.6273 - val_accuracy: 0.8333\n",
            "Epoch 8/50\n",
            "119/119 [==============================] - 0s 286us/sample - loss: 0.6704 - accuracy: 0.6723 - val_loss: 0.8647 - val_accuracy: 0.8333\n",
            "Epoch 9/50\n",
            "119/119 [==============================] - 0s 363us/sample - loss: 0.6332 - accuracy: 0.7563 - val_loss: 0.6601 - val_accuracy: 0.8333\n",
            "Epoch 10/50\n",
            "119/119 [==============================] - 0s 274us/sample - loss: 0.6465 - accuracy: 0.7059 - val_loss: 0.7770 - val_accuracy: 0.8333\n",
            "Epoch 11/50\n",
            "119/119 [==============================] - 0s 300us/sample - loss: 0.6320 - accuracy: 0.7311 - val_loss: 0.8111 - val_accuracy: 0.8333\n",
            "Epoch 12/50\n",
            "119/119 [==============================] - 0s 290us/sample - loss: 0.6243 - accuracy: 0.7479 - val_loss: 0.9030 - val_accuracy: 0.8333\n",
            "Epoch 13/50\n",
            "119/119 [==============================] - 0s 293us/sample - loss: 0.6247 - accuracy: 0.7647 - val_loss: 0.6970 - val_accuracy: 0.8333\n",
            "Epoch 14/50\n",
            "119/119 [==============================] - 0s 300us/sample - loss: 0.6265 - accuracy: 0.7731 - val_loss: 0.7908 - val_accuracy: 0.8333\n",
            "Epoch 15/50\n",
            "119/119 [==============================] - 0s 313us/sample - loss: 0.6337 - accuracy: 0.7479 - val_loss: 0.8366 - val_accuracy: 0.8333\n",
            "Epoch 16/50\n",
            "119/119 [==============================] - 0s 331us/sample - loss: 0.6319 - accuracy: 0.7479 - val_loss: 0.8826 - val_accuracy: 0.8333\n",
            "Epoch 17/50\n",
            "119/119 [==============================] - 0s 308us/sample - loss: 0.6429 - accuracy: 0.7311 - val_loss: 0.7758 - val_accuracy: 0.8333\n",
            "Epoch 18/50\n",
            "119/119 [==============================] - 0s 299us/sample - loss: 0.6246 - accuracy: 0.7479 - val_loss: 0.7719 - val_accuracy: 0.8333\n",
            "Epoch 19/50\n",
            "119/119 [==============================] - 0s 297us/sample - loss: 0.6261 - accuracy: 0.7059 - val_loss: 0.6921 - val_accuracy: 0.8333\n",
            "Epoch 20/50\n",
            "119/119 [==============================] - 0s 310us/sample - loss: 0.6298 - accuracy: 0.7395 - val_loss: 0.9042 - val_accuracy: 0.8333\n",
            "Epoch 21/50\n",
            "119/119 [==============================] - 0s 311us/sample - loss: 0.6201 - accuracy: 0.7395 - val_loss: 0.7392 - val_accuracy: 0.8333\n",
            "Epoch 22/50\n",
            "119/119 [==============================] - 0s 325us/sample - loss: 0.6395 - accuracy: 0.7479 - val_loss: 0.8376 - val_accuracy: 0.8333\n",
            "Epoch 23/50\n",
            "119/119 [==============================] - 0s 356us/sample - loss: 0.5994 - accuracy: 0.7395 - val_loss: 0.7387 - val_accuracy: 0.8333\n",
            "Epoch 24/50\n",
            "119/119 [==============================] - 0s 319us/sample - loss: 0.6239 - accuracy: 0.7311 - val_loss: 0.8172 - val_accuracy: 0.8333\n",
            "Epoch 25/50\n",
            "119/119 [==============================] - 0s 327us/sample - loss: 0.6008 - accuracy: 0.7647 - val_loss: 0.7337 - val_accuracy: 0.9167\n",
            "Epoch 26/50\n",
            "119/119 [==============================] - 0s 320us/sample - loss: 0.6139 - accuracy: 0.7479 - val_loss: 0.7993 - val_accuracy: 0.8333\n",
            "Epoch 27/50\n",
            "119/119 [==============================] - 0s 308us/sample - loss: 0.6068 - accuracy: 0.7563 - val_loss: 0.8296 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "119/119 [==============================] - 0s 339us/sample - loss: 0.6396 - accuracy: 0.7395 - val_loss: 0.8242 - val_accuracy: 0.8333\n",
            "Epoch 29/50\n",
            "119/119 [==============================] - 0s 363us/sample - loss: 0.6182 - accuracy: 0.7563 - val_loss: 0.7643 - val_accuracy: 0.8333\n",
            "Epoch 30/50\n",
            "119/119 [==============================] - 0s 325us/sample - loss: 0.6076 - accuracy: 0.7395 - val_loss: 0.7619 - val_accuracy: 0.9167\n",
            "Epoch 31/50\n",
            "119/119 [==============================] - 0s 299us/sample - loss: 0.6212 - accuracy: 0.7395 - val_loss: 0.8408 - val_accuracy: 0.8333\n",
            "Epoch 32/50\n",
            "119/119 [==============================] - 0s 359us/sample - loss: 0.6033 - accuracy: 0.7395 - val_loss: 0.9457 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "119/119 [==============================] - 0s 312us/sample - loss: 0.6250 - accuracy: 0.7395 - val_loss: 0.7974 - val_accuracy: 0.8333\n",
            "Epoch 34/50\n",
            "119/119 [==============================] - 0s 292us/sample - loss: 0.6184 - accuracy: 0.7395 - val_loss: 0.8413 - val_accuracy: 0.8333\n",
            "Epoch 35/50\n",
            "119/119 [==============================] - 0s 325us/sample - loss: 0.6032 - accuracy: 0.7647 - val_loss: 0.8676 - val_accuracy: 0.7500\n",
            "Epoch 36/50\n",
            "119/119 [==============================] - 0s 350us/sample - loss: 0.6121 - accuracy: 0.7143 - val_loss: 0.8372 - val_accuracy: 0.7500\n",
            "Epoch 37/50\n",
            "119/119 [==============================] - 0s 315us/sample - loss: 0.6172 - accuracy: 0.7647 - val_loss: 0.7999 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "119/119 [==============================] - 0s 315us/sample - loss: 0.6012 - accuracy: 0.7815 - val_loss: 0.8058 - val_accuracy: 0.8333\n",
            "Epoch 39/50\n",
            "119/119 [==============================] - 0s 294us/sample - loss: 0.5925 - accuracy: 0.7647 - val_loss: 0.7880 - val_accuracy: 0.8333\n",
            "Epoch 40/50\n",
            "119/119 [==============================] - 0s 312us/sample - loss: 0.6223 - accuracy: 0.7815 - val_loss: 0.8498 - val_accuracy: 0.8333\n",
            "Epoch 41/50\n",
            "119/119 [==============================] - 0s 318us/sample - loss: 0.6086 - accuracy: 0.7395 - val_loss: 0.9378 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "119/119 [==============================] - 0s 325us/sample - loss: 0.6158 - accuracy: 0.7479 - val_loss: 0.7590 - val_accuracy: 0.7500\n",
            "Epoch 43/50\n",
            "119/119 [==============================] - 0s 319us/sample - loss: 0.6323 - accuracy: 0.7311 - val_loss: 0.8654 - val_accuracy: 0.7500\n",
            "Epoch 44/50\n",
            "119/119 [==============================] - 0s 326us/sample - loss: 0.6180 - accuracy: 0.7395 - val_loss: 0.9063 - val_accuracy: 0.7500\n",
            "Epoch 45/50\n",
            "119/119 [==============================] - 0s 307us/sample - loss: 0.6413 - accuracy: 0.6975 - val_loss: 0.9428 - val_accuracy: 0.7500\n",
            "Epoch 46/50\n",
            "119/119 [==============================] - 0s 350us/sample - loss: 0.6019 - accuracy: 0.7227 - val_loss: 0.8435 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "119/119 [==============================] - 0s 326us/sample - loss: 0.6076 - accuracy: 0.7563 - val_loss: 0.7827 - val_accuracy: 0.8333\n",
            "Epoch 48/50\n",
            "119/119 [==============================] - 0s 304us/sample - loss: 0.6074 - accuracy: 0.7395 - val_loss: 0.8502 - val_accuracy: 0.7500\n",
            "Epoch 49/50\n",
            "119/119 [==============================] - 0s 302us/sample - loss: 0.6009 - accuracy: 0.7563 - val_loss: 0.9735 - val_accuracy: 0.7500\n",
            "Epoch 50/50\n",
            "119/119 [==============================] - 0s 306us/sample - loss: 0.6339 - accuracy: 0.7227 - val_loss: 0.9692 - val_accuracy: 0.7500\n",
            "Train on 119 samples, validate on 12 samples\n",
            "Epoch 1/50\n",
            "119/119 [==============================] - 0s 335us/sample - loss: 0.6594 - accuracy: 0.7479 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
            "Epoch 2/50\n",
            "119/119 [==============================] - 0s 331us/sample - loss: 0.6387 - accuracy: 0.7395 - val_loss: 0.4573 - val_accuracy: 0.8333\n",
            "Epoch 3/50\n",
            "119/119 [==============================] - 0s 308us/sample - loss: 0.6363 - accuracy: 0.7395 - val_loss: 0.4912 - val_accuracy: 0.8333\n",
            "Epoch 4/50\n",
            "119/119 [==============================] - 0s 307us/sample - loss: 0.6509 - accuracy: 0.7395 - val_loss: 0.5371 - val_accuracy: 0.9167\n",
            "Epoch 5/50\n",
            "119/119 [==============================] - 0s 334us/sample - loss: 0.6239 - accuracy: 0.7563 - val_loss: 0.4846 - val_accuracy: 0.8333\n",
            "Epoch 6/50\n",
            "119/119 [==============================] - 0s 305us/sample - loss: 0.6538 - accuracy: 0.6975 - val_loss: 0.5487 - val_accuracy: 0.9167\n",
            "Epoch 7/50\n",
            "119/119 [==============================] - 0s 303us/sample - loss: 0.6190 - accuracy: 0.7479 - val_loss: 0.4936 - val_accuracy: 0.8333\n",
            "Epoch 8/50\n",
            "119/119 [==============================] - 0s 292us/sample - loss: 0.6223 - accuracy: 0.7395 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 9/50\n",
            "119/119 [==============================] - 0s 314us/sample - loss: 0.6081 - accuracy: 0.7395 - val_loss: 0.5745 - val_accuracy: 0.8333\n",
            "Epoch 10/50\n",
            "119/119 [==============================] - 0s 327us/sample - loss: 0.6076 - accuracy: 0.7647 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 11/50\n",
            "119/119 [==============================] - 0s 318us/sample - loss: 0.6116 - accuracy: 0.7311 - val_loss: 0.5511 - val_accuracy: 0.7500\n",
            "Epoch 12/50\n",
            "119/119 [==============================] - 0s 330us/sample - loss: 0.6038 - accuracy: 0.7311 - val_loss: 0.5585 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "119/119 [==============================] - 0s 309us/sample - loss: 0.6021 - accuracy: 0.7479 - val_loss: 0.5558 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "119/119 [==============================] - 0s 316us/sample - loss: 0.6298 - accuracy: 0.7227 - val_loss: 0.5576 - val_accuracy: 0.8333\n",
            "Epoch 15/50\n",
            "119/119 [==============================] - 0s 331us/sample - loss: 0.6376 - accuracy: 0.7479 - val_loss: 0.6587 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "119/119 [==============================] - 0s 304us/sample - loss: 0.6203 - accuracy: 0.7731 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "119/119 [==============================] - 0s 339us/sample - loss: 0.6271 - accuracy: 0.7479 - val_loss: 0.6446 - val_accuracy: 0.5833\n",
            "Epoch 18/50\n",
            "119/119 [==============================] - 0s 317us/sample - loss: 0.6057 - accuracy: 0.7479 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "119/119 [==============================] - 0s 329us/sample - loss: 0.6184 - accuracy: 0.7311 - val_loss: 0.6095 - val_accuracy: 0.6667\n",
            "Epoch 20/50\n",
            "119/119 [==============================] - 0s 300us/sample - loss: 0.6214 - accuracy: 0.7647 - val_loss: 0.5941 - val_accuracy: 0.6667\n",
            "Epoch 21/50\n",
            "119/119 [==============================] - 0s 296us/sample - loss: 0.5940 - accuracy: 0.7647 - val_loss: 0.8051 - val_accuracy: 0.6667\n",
            "Epoch 22/50\n",
            "119/119 [==============================] - 0s 304us/sample - loss: 0.6121 - accuracy: 0.7395 - val_loss: 0.6676 - val_accuracy: 0.7500\n",
            "Epoch 23/50\n",
            "119/119 [==============================] - 0s 374us/sample - loss: 0.6213 - accuracy: 0.7227 - val_loss: 0.6999 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "119/119 [==============================] - 0s 287us/sample - loss: 0.6024 - accuracy: 0.7815 - val_loss: 0.6716 - val_accuracy: 0.6667\n",
            "Epoch 25/50\n",
            "119/119 [==============================] - 0s 317us/sample - loss: 0.6201 - accuracy: 0.7563 - val_loss: 0.7320 - val_accuracy: 0.5833\n",
            "Epoch 26/50\n",
            "119/119 [==============================] - 0s 295us/sample - loss: 0.6055 - accuracy: 0.7563 - val_loss: 0.6229 - val_accuracy: 0.6667\n",
            "Epoch 27/50\n",
            "119/119 [==============================] - 0s 295us/sample - loss: 0.6082 - accuracy: 0.7059 - val_loss: 0.6780 - val_accuracy: 0.5833\n",
            "Epoch 28/50\n",
            "119/119 [==============================] - 0s 310us/sample - loss: 0.6117 - accuracy: 0.7479 - val_loss: 0.7021 - val_accuracy: 0.5833\n",
            "Epoch 29/50\n",
            "119/119 [==============================] - 0s 311us/sample - loss: 0.5998 - accuracy: 0.7647 - val_loss: 0.6228 - val_accuracy: 0.6667\n",
            "Epoch 30/50\n",
            "119/119 [==============================] - 0s 309us/sample - loss: 0.6080 - accuracy: 0.7227 - val_loss: 0.6369 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "119/119 [==============================] - 0s 288us/sample - loss: 0.5900 - accuracy: 0.7731 - val_loss: 0.6860 - val_accuracy: 0.8333\n",
            "Epoch 32/50\n",
            "119/119 [==============================] - 0s 308us/sample - loss: 0.5944 - accuracy: 0.7479 - val_loss: 0.7386 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "119/119 [==============================] - 0s 314us/sample - loss: 0.5984 - accuracy: 0.7899 - val_loss: 0.6514 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "119/119 [==============================] - 0s 319us/sample - loss: 0.5963 - accuracy: 0.7815 - val_loss: 0.6380 - val_accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "119/119 [==============================] - 0s 341us/sample - loss: 0.5900 - accuracy: 0.7395 - val_loss: 0.6450 - val_accuracy: 0.7500\n",
            "Epoch 36/50\n",
            "119/119 [==============================] - 0s 377us/sample - loss: 0.6019 - accuracy: 0.7731 - val_loss: 0.6835 - val_accuracy: 0.7500\n",
            "Epoch 37/50\n",
            "119/119 [==============================] - 0s 396us/sample - loss: 0.6179 - accuracy: 0.7563 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
            "Epoch 38/50\n",
            "119/119 [==============================] - 0s 331us/sample - loss: 0.6085 - accuracy: 0.7563 - val_loss: 0.7651 - val_accuracy: 0.5833\n",
            "Epoch 39/50\n",
            "119/119 [==============================] - 0s 345us/sample - loss: 0.5939 - accuracy: 0.7311 - val_loss: 0.7297 - val_accuracy: 0.5833\n",
            "Epoch 40/50\n",
            "119/119 [==============================] - 0s 359us/sample - loss: 0.5942 - accuracy: 0.7563 - val_loss: 0.6595 - val_accuracy: 0.8333\n",
            "Epoch 41/50\n",
            "119/119 [==============================] - 0s 358us/sample - loss: 0.5906 - accuracy: 0.7479 - val_loss: 0.6870 - val_accuracy: 0.6667\n",
            "Epoch 42/50\n",
            "119/119 [==============================] - 0s 325us/sample - loss: 0.5874 - accuracy: 0.7815 - val_loss: 0.7727 - val_accuracy: 0.6667\n",
            "Epoch 43/50\n",
            "119/119 [==============================] - 0s 318us/sample - loss: 0.6294 - accuracy: 0.7731 - val_loss: 0.6280 - val_accuracy: 0.7500\n",
            "Epoch 44/50\n",
            "119/119 [==============================] - 0s 328us/sample - loss: 0.6092 - accuracy: 0.7395 - val_loss: 0.6590 - val_accuracy: 0.7500\n",
            "Epoch 45/50\n",
            "119/119 [==============================] - 0s 330us/sample - loss: 0.5839 - accuracy: 0.7983 - val_loss: 0.8128 - val_accuracy: 0.6667\n",
            "Epoch 46/50\n",
            "119/119 [==============================] - 0s 377us/sample - loss: 0.6453 - accuracy: 0.7479 - val_loss: 0.6704 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "119/119 [==============================] - 0s 337us/sample - loss: 0.6150 - accuracy: 0.7899 - val_loss: 0.6814 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "119/119 [==============================] - 0s 323us/sample - loss: 0.6242 - accuracy: 0.7563 - val_loss: 0.7411 - val_accuracy: 0.5833\n",
            "Epoch 49/50\n",
            "119/119 [==============================] - 0s 303us/sample - loss: 0.6028 - accuracy: 0.7479 - val_loss: 0.6847 - val_accuracy: 0.6667\n",
            "Epoch 50/50\n",
            "119/119 [==============================] - 0s 295us/sample - loss: 0.5850 - accuracy: 0.7563 - val_loss: 0.7306 - val_accuracy: 0.6667\n",
            "Train on 119 samples, validate on 12 samples\n",
            "Epoch 1/50\n",
            "119/119 [==============================] - 0s 346us/sample - loss: 0.6093 - accuracy: 0.7227 - val_loss: 0.6990 - val_accuracy: 0.7500\n",
            "Epoch 2/50\n",
            "119/119 [==============================] - 0s 385us/sample - loss: 0.5965 - accuracy: 0.7479 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
            "Epoch 3/50\n",
            "119/119 [==============================] - 0s 291us/sample - loss: 0.5875 - accuracy: 0.7479 - val_loss: 0.5972 - val_accuracy: 0.5833\n",
            "Epoch 4/50\n",
            "119/119 [==============================] - 0s 312us/sample - loss: 0.5968 - accuracy: 0.7395 - val_loss: 0.6537 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "119/119 [==============================] - 0s 303us/sample - loss: 0.5959 - accuracy: 0.7311 - val_loss: 0.6218 - val_accuracy: 0.6667\n",
            "Epoch 6/50\n",
            "119/119 [==============================] - 0s 307us/sample - loss: 0.5882 - accuracy: 0.7647 - val_loss: 0.6500 - val_accuracy: 0.5833\n",
            "Epoch 7/50\n",
            "119/119 [==============================] - 0s 275us/sample - loss: 0.5985 - accuracy: 0.7563 - val_loss: 0.7181 - val_accuracy: 0.6667\n",
            "Epoch 8/50\n",
            "119/119 [==============================] - 0s 322us/sample - loss: 0.5927 - accuracy: 0.7563 - val_loss: 0.6348 - val_accuracy: 0.6667\n",
            "Epoch 9/50\n",
            "119/119 [==============================] - 0s 304us/sample - loss: 0.6046 - accuracy: 0.7563 - val_loss: 0.6341 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "119/119 [==============================] - 0s 298us/sample - loss: 0.5932 - accuracy: 0.7395 - val_loss: 0.6756 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "119/119 [==============================] - 0s 285us/sample - loss: 0.6597 - accuracy: 0.7479 - val_loss: 0.7753 - val_accuracy: 0.7500\n",
            "Epoch 12/50\n",
            "119/119 [==============================] - 0s 300us/sample - loss: 0.5845 - accuracy: 0.7899 - val_loss: 0.7280 - val_accuracy: 0.6667\n",
            "Epoch 13/50\n",
            "119/119 [==============================] - 0s 364us/sample - loss: 0.5848 - accuracy: 0.7815 - val_loss: 0.6881 - val_accuracy: 0.5833\n",
            "Epoch 14/50\n",
            "119/119 [==============================] - 0s 295us/sample - loss: 0.5857 - accuracy: 0.7731 - val_loss: 0.6847 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "119/119 [==============================] - 0s 293us/sample - loss: 0.6046 - accuracy: 0.7311 - val_loss: 0.8233 - val_accuracy: 0.6667\n",
            "Epoch 16/50\n",
            "119/119 [==============================] - 0s 293us/sample - loss: 0.6120 - accuracy: 0.7395 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
            "Epoch 17/50\n",
            "119/119 [==============================] - 0s 307us/sample - loss: 0.5892 - accuracy: 0.7815 - val_loss: 0.6733 - val_accuracy: 0.5833\n",
            "Epoch 18/50\n",
            "119/119 [==============================] - 0s 317us/sample - loss: 0.5827 - accuracy: 0.7731 - val_loss: 0.7608 - val_accuracy: 0.5833\n",
            "Epoch 19/50\n",
            "119/119 [==============================] - 0s 317us/sample - loss: 0.6044 - accuracy: 0.7563 - val_loss: 0.7781 - val_accuracy: 0.6667\n",
            "Epoch 20/50\n",
            "119/119 [==============================] - 0s 312us/sample - loss: 0.5896 - accuracy: 0.7815 - val_loss: 0.7244 - val_accuracy: 0.6667\n",
            "Epoch 21/50\n",
            "119/119 [==============================] - 0s 316us/sample - loss: 0.5809 - accuracy: 0.7899 - val_loss: 0.7082 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "119/119 [==============================] - 0s 292us/sample - loss: 0.5730 - accuracy: 0.7647 - val_loss: 0.7400 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "119/119 [==============================] - 0s 300us/sample - loss: 0.6113 - accuracy: 0.7563 - val_loss: 0.7459 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "119/119 [==============================] - 0s 328us/sample - loss: 0.5860 - accuracy: 0.7731 - val_loss: 0.7720 - val_accuracy: 0.5833\n",
            "Epoch 25/50\n",
            "119/119 [==============================] - 0s 300us/sample - loss: 0.5769 - accuracy: 0.7647 - val_loss: 0.7921 - val_accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "119/119 [==============================] - 0s 306us/sample - loss: 0.5867 - accuracy: 0.7731 - val_loss: 0.7472 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "119/119 [==============================] - 0s 306us/sample - loss: 0.6016 - accuracy: 0.7479 - val_loss: 0.8897 - val_accuracy: 0.5833\n",
            "Epoch 28/50\n",
            "119/119 [==============================] - 0s 315us/sample - loss: 0.5766 - accuracy: 0.7647 - val_loss: 0.9074 - val_accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "119/119 [==============================] - 0s 323us/sample - loss: 0.5600 - accuracy: 0.7731 - val_loss: 0.9213 - val_accuracy: 0.5833\n",
            "Epoch 30/50\n",
            "119/119 [==============================] - 0s 343us/sample - loss: 0.5995 - accuracy: 0.7647 - val_loss: 0.7508 - val_accuracy: 0.5833\n",
            "Epoch 31/50\n",
            "119/119 [==============================] - 0s 306us/sample - loss: 0.5725 - accuracy: 0.7563 - val_loss: 0.7861 - val_accuracy: 0.5833\n",
            "Epoch 32/50\n",
            "119/119 [==============================] - 0s 358us/sample - loss: 0.6247 - accuracy: 0.7311 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "119/119 [==============================] - 0s 331us/sample - loss: 0.5694 - accuracy: 0.7731 - val_loss: 0.7924 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "119/119 [==============================] - 0s 323us/sample - loss: 0.5672 - accuracy: 0.7899 - val_loss: 0.9101 - val_accuracy: 0.5833\n",
            "Epoch 35/50\n",
            "119/119 [==============================] - 0s 313us/sample - loss: 0.5916 - accuracy: 0.7647 - val_loss: 0.7415 - val_accuracy: 0.5833\n",
            "Epoch 36/50\n",
            "119/119 [==============================] - 0s 301us/sample - loss: 0.5709 - accuracy: 0.7899 - val_loss: 0.8614 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "119/119 [==============================] - 0s 299us/sample - loss: 0.5723 - accuracy: 0.7731 - val_loss: 0.7091 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "119/119 [==============================] - 0s 351us/sample - loss: 0.5951 - accuracy: 0.7479 - val_loss: 0.8286 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "119/119 [==============================] - 0s 304us/sample - loss: 0.5969 - accuracy: 0.7311 - val_loss: 0.8480 - val_accuracy: 0.5833\n",
            "Epoch 40/50\n",
            "119/119 [==============================] - 0s 324us/sample - loss: 0.5737 - accuracy: 0.7983 - val_loss: 0.8369 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "119/119 [==============================] - 0s 353us/sample - loss: 0.5570 - accuracy: 0.7479 - val_loss: 0.7616 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "119/119 [==============================] - 0s 333us/sample - loss: 0.5633 - accuracy: 0.7815 - val_loss: 0.7153 - val_accuracy: 0.5833\n",
            "Epoch 43/50\n",
            "119/119 [==============================] - 0s 310us/sample - loss: 0.5711 - accuracy: 0.7815 - val_loss: 0.7772 - val_accuracy: 0.6667\n",
            "Epoch 44/50\n",
            "119/119 [==============================] - 0s 291us/sample - loss: 0.5719 - accuracy: 0.7479 - val_loss: 0.7738 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "119/119 [==============================] - 0s 285us/sample - loss: 0.5568 - accuracy: 0.7983 - val_loss: 0.7943 - val_accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "119/119 [==============================] - 0s 290us/sample - loss: 0.5531 - accuracy: 0.7899 - val_loss: 0.8741 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "119/119 [==============================] - 0s 303us/sample - loss: 0.5662 - accuracy: 0.7899 - val_loss: 0.8811 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "119/119 [==============================] - 0s 277us/sample - loss: 0.5532 - accuracy: 0.7815 - val_loss: 0.8171 - val_accuracy: 0.5833\n",
            "Epoch 49/50\n",
            "119/119 [==============================] - 0s 356us/sample - loss: 0.5441 - accuracy: 0.7899 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "119/119 [==============================] - 0s 284us/sample - loss: 0.5711 - accuracy: 0.7647 - val_loss: 0.6764 - val_accuracy: 0.5833\n",
            "Train on 119 samples, validate on 12 samples\n",
            "Epoch 1/50\n",
            "119/119 [==============================] - 0s 296us/sample - loss: 0.6376 - accuracy: 0.7227 - val_loss: 0.3571 - val_accuracy: 0.8333\n",
            "Epoch 2/50\n",
            "119/119 [==============================] - 0s 348us/sample - loss: 0.6423 - accuracy: 0.7143 - val_loss: 0.4115 - val_accuracy: 0.8333\n",
            "Epoch 3/50\n",
            "119/119 [==============================] - 0s 306us/sample - loss: 0.6144 - accuracy: 0.7311 - val_loss: 0.4263 - val_accuracy: 0.8333\n",
            "Epoch 4/50\n",
            "119/119 [==============================] - 0s 297us/sample - loss: 0.5902 - accuracy: 0.7563 - val_loss: 0.4479 - val_accuracy: 0.8333\n",
            "Epoch 5/50\n",
            "119/119 [==============================] - 0s 291us/sample - loss: 0.6061 - accuracy: 0.7227 - val_loss: 0.4648 - val_accuracy: 0.8333\n",
            "Epoch 6/50\n",
            "119/119 [==============================] - 0s 305us/sample - loss: 0.6033 - accuracy: 0.7395 - val_loss: 0.4580 - val_accuracy: 0.8333\n",
            "Epoch 7/50\n",
            "119/119 [==============================] - 0s 268us/sample - loss: 0.6099 - accuracy: 0.7647 - val_loss: 0.4405 - val_accuracy: 0.7500\n",
            "Epoch 8/50\n",
            "119/119 [==============================] - 0s 334us/sample - loss: 0.5875 - accuracy: 0.7311 - val_loss: 0.5400 - val_accuracy: 0.8333\n",
            "Epoch 9/50\n",
            "119/119 [==============================] - 0s 337us/sample - loss: 0.6181 - accuracy: 0.7479 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
            "Epoch 10/50\n",
            "119/119 [==============================] - 0s 307us/sample - loss: 0.5911 - accuracy: 0.7563 - val_loss: 0.4796 - val_accuracy: 0.7500\n",
            "Epoch 11/50\n",
            "119/119 [==============================] - 0s 300us/sample - loss: 0.6117 - accuracy: 0.7143 - val_loss: 0.5113 - val_accuracy: 0.8333\n",
            "Epoch 12/50\n",
            "119/119 [==============================] - 0s 311us/sample - loss: 0.6424 - accuracy: 0.7227 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "119/119 [==============================] - 0s 285us/sample - loss: 0.6001 - accuracy: 0.7647 - val_loss: 0.4573 - val_accuracy: 0.8333\n",
            "Epoch 14/50\n",
            "119/119 [==============================] - 0s 315us/sample - loss: 0.5785 - accuracy: 0.7647 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 15/50\n",
            "119/119 [==============================] - 0s 304us/sample - loss: 0.5867 - accuracy: 0.7563 - val_loss: 0.5332 - val_accuracy: 0.8333\n",
            "Epoch 16/50\n",
            "119/119 [==============================] - 0s 281us/sample - loss: 0.6050 - accuracy: 0.7395 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "119/119 [==============================] - 0s 283us/sample - loss: 0.5989 - accuracy: 0.7815 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
            "Epoch 18/50\n",
            "119/119 [==============================] - 0s 309us/sample - loss: 0.5816 - accuracy: 0.7479 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "119/119 [==============================] - 0s 301us/sample - loss: 0.5683 - accuracy: 0.7815 - val_loss: 0.4656 - val_accuracy: 0.8333\n",
            "Epoch 20/50\n",
            "119/119 [==============================] - 0s 307us/sample - loss: 0.6090 - accuracy: 0.7647 - val_loss: 0.5206 - val_accuracy: 0.8333\n",
            "Epoch 21/50\n",
            "119/119 [==============================] - 0s 304us/sample - loss: 0.5974 - accuracy: 0.7647 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
            "Epoch 22/50\n",
            "119/119 [==============================] - 0s 306us/sample - loss: 0.5846 - accuracy: 0.7563 - val_loss: 0.5794 - val_accuracy: 0.7500\n",
            "Epoch 23/50\n",
            "119/119 [==============================] - 0s 336us/sample - loss: 0.6216 - accuracy: 0.7731 - val_loss: 0.5347 - val_accuracy: 0.8333\n",
            "Epoch 24/50\n",
            "119/119 [==============================] - 0s 356us/sample - loss: 0.6154 - accuracy: 0.7479 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
            "Epoch 25/50\n",
            "119/119 [==============================] - 0s 296us/sample - loss: 0.5779 - accuracy: 0.7479 - val_loss: 0.5870 - val_accuracy: 0.8333\n",
            "Epoch 26/50\n",
            "119/119 [==============================] - 0s 312us/sample - loss: 0.6137 - accuracy: 0.7479 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
            "Epoch 27/50\n",
            "119/119 [==============================] - 0s 308us/sample - loss: 0.5816 - accuracy: 0.7815 - val_loss: 0.4752 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "119/119 [==============================] - 0s 292us/sample - loss: 0.6052 - accuracy: 0.7563 - val_loss: 0.6434 - val_accuracy: 0.7500\n",
            "Epoch 29/50\n",
            "119/119 [==============================] - 0s 293us/sample - loss: 0.6027 - accuracy: 0.7731 - val_loss: 0.5336 - val_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "119/119 [==============================] - 0s 273us/sample - loss: 0.5797 - accuracy: 0.7395 - val_loss: 0.6153 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "119/119 [==============================] - 0s 283us/sample - loss: 0.5952 - accuracy: 0.7479 - val_loss: 0.5537 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "119/119 [==============================] - 0s 294us/sample - loss: 0.5762 - accuracy: 0.7479 - val_loss: 0.5863 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "119/119 [==============================] - 0s 291us/sample - loss: 0.6016 - accuracy: 0.7563 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "119/119 [==============================] - 0s 294us/sample - loss: 0.5886 - accuracy: 0.7479 - val_loss: 0.5872 - val_accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "119/119 [==============================] - 0s 381us/sample - loss: 0.5800 - accuracy: 0.7647 - val_loss: 0.6276 - val_accuracy: 0.7500\n",
            "Epoch 36/50\n",
            "119/119 [==============================] - 0s 334us/sample - loss: 0.5707 - accuracy: 0.7479 - val_loss: 0.5679 - val_accuracy: 0.7500\n",
            "Epoch 37/50\n",
            "119/119 [==============================] - 0s 335us/sample - loss: 0.6216 - accuracy: 0.7227 - val_loss: 0.5863 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "119/119 [==============================] - 0s 349us/sample - loss: 0.5725 - accuracy: 0.7731 - val_loss: 0.6315 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "119/119 [==============================] - 0s 322us/sample - loss: 0.6012 - accuracy: 0.7395 - val_loss: 0.5815 - val_accuracy: 0.5833\n",
            "Epoch 40/50\n",
            "119/119 [==============================] - 0s 337us/sample - loss: 0.5787 - accuracy: 0.7899 - val_loss: 0.6873 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "119/119 [==============================] - 0s 328us/sample - loss: 0.5709 - accuracy: 0.7899 - val_loss: 0.6514 - val_accuracy: 0.6667\n",
            "Epoch 42/50\n",
            "119/119 [==============================] - 0s 325us/sample - loss: 0.5882 - accuracy: 0.7563 - val_loss: 0.6074 - val_accuracy: 0.7500\n",
            "Epoch 43/50\n",
            "119/119 [==============================] - 0s 316us/sample - loss: 0.5839 - accuracy: 0.7731 - val_loss: 0.6122 - val_accuracy: 0.7500\n",
            "Epoch 44/50\n",
            "119/119 [==============================] - 0s 323us/sample - loss: 0.5853 - accuracy: 0.7143 - val_loss: 0.6397 - val_accuracy: 0.7500\n",
            "Epoch 45/50\n",
            "119/119 [==============================] - 0s 346us/sample - loss: 0.6001 - accuracy: 0.7227 - val_loss: 0.7460 - val_accuracy: 0.7500\n",
            "Epoch 46/50\n",
            "119/119 [==============================] - 0s 311us/sample - loss: 0.5820 - accuracy: 0.7731 - val_loss: 0.6721 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "119/119 [==============================] - 0s 328us/sample - loss: 0.5720 - accuracy: 0.7731 - val_loss: 0.6164 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "119/119 [==============================] - 0s 455us/sample - loss: 0.5842 - accuracy: 0.7311 - val_loss: 0.6808 - val_accuracy: 0.7500\n",
            "Epoch 49/50\n",
            "119/119 [==============================] - 0s 355us/sample - loss: 0.6194 - accuracy: 0.7395 - val_loss: 0.6384 - val_accuracy: 0.6667\n",
            "Epoch 50/50\n",
            "119/119 [==============================] - 0s 348us/sample - loss: 0.5945 - accuracy: 0.7395 - val_loss: 0.5656 - val_accuracy: 0.7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2eeOHoYbina",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history_RS.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDN2PrRc36l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb846197-b74b-473e-c642-f39d4cd2eaad"
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UhSxIaHtuO",
        "colab_type": "text"
      },
      "source": [
        "##Plotting training and validation loss RandomSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zsienD5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJizyjnaIPhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, num_epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z_pSVTWwtybS",
        "colab": {}
      },
      "source": [
        "average_acc_history_RS = [np.mean([x[i] for x in all_acc_histories_RS]) for i in range(num_epochs)]\n",
        "average_loss_history_RS = [np.mean([x[i] for x in all_loss_histories_RS]) for i in range(num_epochs)]\n",
        "average_val_acc_history_RS = [np.mean([x[i] for x in all_val_acc_histories_RS]) for i in range(num_epochs)]\n",
        "average_val_loss_history_RS = [np.mean([x[i] for x in all_val_loss_histories_RS]) for i in range(num_epochs)]\n",
        "#media per epoca degli score ottenuti per tutte le k-fold\n",
        "#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\n",
        "#e si fa questo per tutte le epoche"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEHEYLgIQUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "c8895b48-daad-4227-ff10-c26b6e36383e"
      },
      "source": [
        "plt.plot(epochs, average_loss_history_RS, 'bo', label='training loss')\n",
        "plt.plot(epochs, average_val_loss_history_RS, 'b', label='validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe4b27270b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMMYY45cFCGOMMX5ZgDDGGOPX/wMWALyOMQNdGwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc4wMjfI97j",
        "colab_type": "text"
      },
      "source": [
        "##Plotting train and validation accuracy RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi7VzbFIbtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "562b15ff-802f-4a65-a9e0-faa3d4022f71"
      },
      "source": [
        "plt.plot(epochs, average_acc_history_RS, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, average_val_acc_history_RS, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend() "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe4b15e26a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}