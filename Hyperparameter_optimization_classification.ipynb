{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_optimization_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/Hyperparameter_optimization_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YN6Hc9lFNNk",
        "colab_type": "text"
      },
      "source": [
        "#Optimization of hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py6sopCQLbAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U keras-tuner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck9uZtF_gzU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "97ddad86-5359-4d0b-afa9-e375e7b40977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-87QSVhqhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSbeCedhuxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbcwLGg3iNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQdR4izXiT0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5wIylYmsQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = df_test.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data_stand = train_data - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVOoNOvm0Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_stand = test_data - mean\n",
        "test_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00VohsAyokpq",
        "colab_type": "text"
      },
      "source": [
        "##Vettorizzare i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvS_9ISpxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={'adenocarcinoma':0, 'large cell':1, 'squamous cell carcinoma':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPW9U0XrWY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_dec = [word_index[label] for label in train_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4SBiKFQsKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels_dec = [word_index[label] for label in test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMbTYR7okJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a2e59c52-b578-465c-ee78-b86a0b42abd7"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Frv4FDNn6Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels_dec)\n",
        "one_hot_test_labels = to_categorical(test_labels_dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn0tkOGc3LKN",
        "colab_type": "text"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS76u6iu3Seg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjC4zqJ3bui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.9, svd_solver='full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLUCf9qX4p_e",
        "colab_type": "code",
        "outputId": "36e50f3e-f7a2-4f5f-a566-dd5600e2d576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pca.fit(train_data_stand)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyaKgNZ44o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_pca = pca.transform(train_data_stand)\n",
        "test_data_stand_pca = pca.transform(test_data_stand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9C4nl05b_g",
        "colab_type": "code",
        "outputId": "abf327e9-f61b-40e0-dc8d-12484e64d979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_data_stand_pca.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSKvSu4s5ip",
        "colab_type": "text"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osgm8ZvLpZh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTbHiq0D-4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAzbu7P1VylY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqbUCK5wOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KutkQ9Noj5mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hp):\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(layers.Dense(units=(hp.Int('units', min_value=3, max_value=8, step=1)), \n",
        "                         activation='relu', input_shape=(9,)))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIxDu50pBeiz",
        "colab_type": "text"
      },
      "source": [
        "#Stratified k-fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyLcvedUBpxA",
        "colab_type": "text"
      },
      "source": [
        "This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1apcZ19gFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBDM-PtBx5V",
        "colab_type": "code",
        "outputId": "4fb74193-7436-45b2-eb2b-f7eb3f485aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "skf.get_n_splits(train_data_stand_pca, train_labels_dec)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "5c8d6a36-058e-4903-a637-0c467afba584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "for train_index, test_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  0   1   4   5   8   9  11  12  14  15  16  17  19  20  22  23  24  25\n",
            "  27  29  30  33  34  36  37  38  39  40  41  42  44  45  46  48  51  52\n",
            "  53  56  57  58  59  60  62  63  65  66  67  69  72  76  77  78  79  80\n",
            "  81  83  84  85  87  88  89  90  92  96  97  98 100 101 102 103 104 105\n",
            " 107 109 110 111 113 115 117 120 121 122 124 125 127 128] TEST: [  2   3   6   7  10  13  18  21  26  28  31  32  35  43  47  49  50  54\n",
            "  55  61  64  68  70  71  73  74  75  82  86  91  93  94  95  99 106 108\n",
            " 112 114 116 118 119 123 126 129 130]\n",
            "TRAIN: [  2   3   5   6   7   8   9  10  11  12  13  18  20  21  25  26  27  28\n",
            "  29  30  31  32  34  35  36  38  39  43  44  45  46  47  48  49  50  53\n",
            "  54  55  57  58  61  63  64  65  66  68  70  71  73  74  75  76  78  82\n",
            "  84  85  86  87  90  91  92  93  94  95  96  99 100 101 102 105 106 108\n",
            " 109 111 112 114 115 116 118 119 122 123 124 125 126 127 129 130] TEST: [  0   1   4  14  15  16  17  19  22  23  24  33  37  40  41  42  51  52\n",
            "  56  59  60  62  67  69  72  77  79  80  81  83  88  89  97  98 103 104\n",
            " 107 110 113 117 120 121 128]\n",
            "TRAIN: [  0   1   2   3   4   6   7  10  13  14  15  16  17  18  19  21  22  23\n",
            "  24  26  28  31  32  33  35  37  40  41  42  43  47  49  50  51  52  54\n",
            "  55  56  59  60  61  62  64  67  68  69  70  71  72  73  74  75  77  79\n",
            "  80  81  82  83  86  88  89  91  93  94  95  97  98  99 103 104 106 107\n",
            " 108 110 112 113 114 116 117 118 119 120 121 123 126 128 129 130] TEST: [  5   8   9  11  12  20  25  27  29  30  34  36  38  39  44  45  46  48\n",
            "  53  57  58  63  65  66  76  78  84  85  87  90  92  96 100 101 102 105\n",
            " 109 111 115 122 124 125 127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgdGK-8FK-U_",
        "colab_type": "code",
        "outputId": "c9a5c15d-df44-4264-901c-3201e22ef983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels_dec[125]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJg0XD4Shhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Sq8r9GEPx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "#  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "#  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "\n",
        "#  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "#  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "#  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "#  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        "#  model = build_model()\n",
        "#  model.fit(partial_train_data, one_hot_partial_train_targets, epochs = num_epochs, batch_size=1)\n",
        "\n",
        "#  val_loss, val_accuracy = model.evaluate(val_data, one_hot_val_targets)\n",
        "#  all_scores.append(val_accuracy)\n",
        "#I parametri per la valutazione vengono calcolati una volta per ogni k-fold, per ogni set di validazione, quindi k volte"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X5B3lasRcsR",
        "colab_type": "text"
      },
      "source": [
        "C'è un problema: keras.utils.to_categorical produces a one-hot encoded class vector, i.e. the multilabel-indicator mentioned in the error message. StratifiedKFold is not designed to work with such input; i.e. your y must be a 1-D array of your class labels.\n",
        "Essentially, what you have to do is simply to invert the order of the operations: split first (using your intial y_train), and convert to_categorical afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8a1I3yU9FS",
        "colab_type": "code",
        "outputId": "de686349-92d7-4929-9450-ca062ef74ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 100\n",
        "all_acc_histories = []\n",
        "all_loss_histories = []\n",
        "all_val_acc_histories = []\n",
        "all_val_loss_histories = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        " \n",
        "  tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=5, \n",
        "                       executions_per_trial=3, directory='/content/my_dir', project_name='helloworld')\n",
        "  \n",
        "  tuner.search_space_summary()\n",
        "\n",
        "  tuner.search(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=10)\n",
        "  \n",
        "\n",
        "  acc_history = history.history['acc']\n",
        "  all_acc_histories.append(acc_history)\n",
        "\n",
        "  loss_history = history.history['loss']\n",
        "  all_loss_histories.append(loss_history)\n",
        "\n",
        "  acc_val_history = history.history['val_acc']\n",
        "  all_val_acc_histories.append(acc_val_history)\n",
        "\n",
        "  loss_val_history = history.history['val_loss']\n",
        "  all_val_loss_histories.append(loss_val_history)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali è una lista lunga num_epochs,\n",
        "#ogni elemento può essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-max_value: 8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-min_value: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-sampling: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-step: 1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 5ms/sample - loss: 1.9087 - accuracy: 0.4884 - val_loss: 1.5371 - val_accuracy: 0.4889\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.8097 - accuracy: 0.4884 - val_loss: 1.4844 - val_accuracy: 0.4889\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 553us/sample - loss: 1.7185 - accuracy: 0.4884 - val_loss: 1.4369 - val_accuracy: 0.4889\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 1.6400 - accuracy: 0.5000 - val_loss: 1.3978 - val_accuracy: 0.4889\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 496us/sample - loss: 1.5714 - accuracy: 0.5000 - val_loss: 1.3632 - val_accuracy: 0.4444\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 845us/sample - loss: 1.5149 - accuracy: 0.4884 - val_loss: 1.3333 - val_accuracy: 0.4444\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 579us/sample - loss: 1.4645 - accuracy: 0.5116 - val_loss: 1.3070 - val_accuracy: 0.4444\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.4197 - accuracy: 0.5116 - val_loss: 1.2880 - val_accuracy: 0.4222\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.3803 - accuracy: 0.5581 - val_loss: 1.2706 - val_accuracy: 0.4222\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.3434 - accuracy: 0.5814 - val_loss: 1.2545 - val_accuracy: 0.4222\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 509us/sample - loss: 1.3111 - accuracy: 0.5814 - val_loss: 1.2397 - val_accuracy: 0.4222\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 572us/sample - loss: 1.2800 - accuracy: 0.5814 - val_loss: 1.2253 - val_accuracy: 0.4222\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 548us/sample - loss: 1.2517 - accuracy: 0.5814 - val_loss: 1.2126 - val_accuracy: 0.4444\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 1.2283 - accuracy: 0.6047 - val_loss: 1.2023 - val_accuracy: 0.4667\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 1.2046 - accuracy: 0.6047 - val_loss: 1.1928 - val_accuracy: 0.4667\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 525us/sample - loss: 1.1853 - accuracy: 0.6047 - val_loss: 1.1828 - val_accuracy: 0.4667\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 1.1657 - accuracy: 0.5930 - val_loss: 1.1745 - val_accuracy: 0.4667\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 526us/sample - loss: 1.1475 - accuracy: 0.5930 - val_loss: 1.1674 - val_accuracy: 0.4667\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 571us/sample - loss: 1.1291 - accuracy: 0.5930 - val_loss: 1.1601 - val_accuracy: 0.4667\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 1.1135 - accuracy: 0.5930 - val_loss: 1.1538 - val_accuracy: 0.4667\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 1.0997 - accuracy: 0.5930 - val_loss: 1.1471 - val_accuracy: 0.4667\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 565us/sample - loss: 1.0852 - accuracy: 0.5814 - val_loss: 1.1414 - val_accuracy: 0.4667\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.0733 - accuracy: 0.5814 - val_loss: 1.1362 - val_accuracy: 0.4667\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.0611 - accuracy: 0.5814 - val_loss: 1.1305 - val_accuracy: 0.4667\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.0508 - accuracy: 0.5814 - val_loss: 1.1259 - val_accuracy: 0.4444\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 1.0428 - accuracy: 0.5698 - val_loss: 1.1215 - val_accuracy: 0.4444\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.0338 - accuracy: 0.5698 - val_loss: 1.1171 - val_accuracy: 0.4444\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 1.0249 - accuracy: 0.5698 - val_loss: 1.1138 - val_accuracy: 0.4444\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.0177 - accuracy: 0.5581 - val_loss: 1.1109 - val_accuracy: 0.4444\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.0112 - accuracy: 0.5581 - val_loss: 1.1073 - val_accuracy: 0.4444\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.0054 - accuracy: 0.5581 - val_loss: 1.1046 - val_accuracy: 0.4667\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.0004 - accuracy: 0.5581 - val_loss: 1.1021 - val_accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9957 - accuracy: 0.5581 - val_loss: 1.0991 - val_accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 0.9890 - accuracy: 0.5581 - val_loss: 1.0963 - val_accuracy: 0.4889\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.9845 - accuracy: 0.5581 - val_loss: 1.0940 - val_accuracy: 0.4889\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9802 - accuracy: 0.5581 - val_loss: 1.0918 - val_accuracy: 0.4889\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 0.9762 - accuracy: 0.5581 - val_loss: 1.0893 - val_accuracy: 0.4889\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 553us/sample - loss: 0.9720 - accuracy: 0.5698 - val_loss: 1.0867 - val_accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.9689 - accuracy: 0.5698 - val_loss: 1.0847 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 0.9649 - accuracy: 0.5698 - val_loss: 1.0823 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 0.9617 - accuracy: 0.5698 - val_loss: 1.0802 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 0.9587 - accuracy: 0.5698 - val_loss: 1.0787 - val_accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9555 - accuracy: 0.5698 - val_loss: 1.0764 - val_accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 0.9529 - accuracy: 0.5581 - val_loss: 1.0743 - val_accuracy: 0.4667\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 0.9505 - accuracy: 0.5581 - val_loss: 1.0725 - val_accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 495us/sample - loss: 0.9487 - accuracy: 0.5581 - val_loss: 1.0708 - val_accuracy: 0.4667\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.9458 - accuracy: 0.5581 - val_loss: 1.0697 - val_accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 0.9437 - accuracy: 0.5465 - val_loss: 1.0680 - val_accuracy: 0.4667\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 0.9424 - accuracy: 0.5465 - val_loss: 1.0663 - val_accuracy: 0.4667\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 0.9397 - accuracy: 0.5465 - val_loss: 1.0654 - val_accuracy: 0.4667\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 0.9377 - accuracy: 0.5465 - val_loss: 1.0637 - val_accuracy: 0.4667\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9362 - accuracy: 0.5465 - val_loss: 1.0618 - val_accuracy: 0.4889\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 470us/sample - loss: 0.9349 - accuracy: 0.5465 - val_loss: 1.0603 - val_accuracy: 0.4889\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 0.9329 - accuracy: 0.5465 - val_loss: 1.0585 - val_accuracy: 0.4889\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.9319 - accuracy: 0.5465 - val_loss: 1.0566 - val_accuracy: 0.4889\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9296 - accuracy: 0.5465 - val_loss: 1.0550 - val_accuracy: 0.4889\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.9281 - accuracy: 0.5465 - val_loss: 1.0531 - val_accuracy: 0.4889\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 0.9266 - accuracy: 0.5465 - val_loss: 1.0518 - val_accuracy: 0.4889\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.9262 - accuracy: 0.5465 - val_loss: 1.0505 - val_accuracy: 0.4889\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 0.9240 - accuracy: 0.5465 - val_loss: 1.0496 - val_accuracy: 0.4889\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 0.9230 - accuracy: 0.5465 - val_loss: 1.0489 - val_accuracy: 0.4889\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 0.9219 - accuracy: 0.5465 - val_loss: 1.0483 - val_accuracy: 0.4889\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 0.9204 - accuracy: 0.5465 - val_loss: 1.0468 - val_accuracy: 0.4889\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 0.9198 - accuracy: 0.5465 - val_loss: 1.0454 - val_accuracy: 0.4889\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.9183 - accuracy: 0.5465 - val_loss: 1.0442 - val_accuracy: 0.4889\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.9172 - accuracy: 0.5465 - val_loss: 1.0437 - val_accuracy: 0.4889\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 0.9168 - accuracy: 0.5465 - val_loss: 1.0434 - val_accuracy: 0.4889\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9152 - accuracy: 0.5465 - val_loss: 1.0424 - val_accuracy: 0.4889\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 0.9143 - accuracy: 0.5465 - val_loss: 1.0418 - val_accuracy: 0.4889\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 0.9135 - accuracy: 0.5465 - val_loss: 1.0409 - val_accuracy: 0.4889\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.9125 - accuracy: 0.5465 - val_loss: 1.0401 - val_accuracy: 0.4889\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 0.9114 - accuracy: 0.5465 - val_loss: 1.0392 - val_accuracy: 0.4889\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.9105 - accuracy: 0.5349 - val_loss: 1.0384 - val_accuracy: 0.4889\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 405us/sample - loss: 0.9103 - accuracy: 0.5465 - val_loss: 1.0380 - val_accuracy: 0.4889\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 0.9094 - accuracy: 0.5465 - val_loss: 1.0372 - val_accuracy: 0.4889\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.9090 - accuracy: 0.5465 - val_loss: 1.0365 - val_accuracy: 0.4889\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.9083 - accuracy: 0.5581 - val_loss: 1.0354 - val_accuracy: 0.4889\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 0.9071 - accuracy: 0.5581 - val_loss: 1.0346 - val_accuracy: 0.4889\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 0.9057 - accuracy: 0.5581 - val_loss: 1.0336 - val_accuracy: 0.4889\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9050 - accuracy: 0.5465 - val_loss: 1.0330 - val_accuracy: 0.4889\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 0.9045 - accuracy: 0.5465 - val_loss: 1.0322 - val_accuracy: 0.4889\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 523us/sample - loss: 0.9037 - accuracy: 0.5465 - val_loss: 1.0315 - val_accuracy: 0.4889\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.9027 - accuracy: 0.5465 - val_loss: 1.0308 - val_accuracy: 0.4889\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 0.9021 - accuracy: 0.5465 - val_loss: 1.0302 - val_accuracy: 0.4889\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.9012 - accuracy: 0.5465 - val_loss: 1.0299 - val_accuracy: 0.4889\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 552us/sample - loss: 0.9006 - accuracy: 0.5465 - val_loss: 1.0295 - val_accuracy: 0.4889\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 525us/sample - loss: 0.9005 - accuracy: 0.5465 - val_loss: 1.0294 - val_accuracy: 0.4889\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 0.8991 - accuracy: 0.5465 - val_loss: 1.0287 - val_accuracy: 0.4889\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 0.8990 - accuracy: 0.5465 - val_loss: 1.0281 - val_accuracy: 0.4889\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.8974 - accuracy: 0.5465 - val_loss: 1.0280 - val_accuracy: 0.4889\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.8974 - accuracy: 0.5349 - val_loss: 1.0277 - val_accuracy: 0.4889\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 596us/sample - loss: 0.8960 - accuracy: 0.5349 - val_loss: 1.0275 - val_accuracy: 0.4889\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 0.8955 - accuracy: 0.5465 - val_loss: 1.0264 - val_accuracy: 0.4889\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 0.8953 - accuracy: 0.5465 - val_loss: 1.0253 - val_accuracy: 0.4889\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 493us/sample - loss: 0.8944 - accuracy: 0.5349 - val_loss: 1.0253 - val_accuracy: 0.4889\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.8932 - accuracy: 0.5465 - val_loss: 1.0253 - val_accuracy: 0.4889\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.8927 - accuracy: 0.5349 - val_loss: 1.0250 - val_accuracy: 0.4889\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.8920 - accuracy: 0.5349 - val_loss: 1.0255 - val_accuracy: 0.4889\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.8908 - accuracy: 0.5465 - val_loss: 1.0262 - val_accuracy: 0.4889\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 0.8903 - accuracy: 0.5349 - val_loss: 1.0266 - val_accuracy: 0.4889\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.4481 - accuracy: 0.2326 - val_loss: 2.8384 - val_accuracy: 0.3111\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 2.2533 - accuracy: 0.3256 - val_loss: 2.5979 - val_accuracy: 0.3111\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 2.0825 - accuracy: 0.3372 - val_loss: 2.3772 - val_accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.9306 - accuracy: 0.3488 - val_loss: 2.1909 - val_accuracy: 0.3556\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.8090 - accuracy: 0.3488 - val_loss: 2.0218 - val_accuracy: 0.3778\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.7005 - accuracy: 0.3372 - val_loss: 1.8773 - val_accuracy: 0.3778\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 1.6098 - accuracy: 0.3605 - val_loss: 1.7528 - val_accuracy: 0.3778\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.5326 - accuracy: 0.3953 - val_loss: 1.6447 - val_accuracy: 0.3778\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 495us/sample - loss: 1.4720 - accuracy: 0.4186 - val_loss: 1.5610 - val_accuracy: 0.3778\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 1.4205 - accuracy: 0.4419 - val_loss: 1.4961 - val_accuracy: 0.3778\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 1.3799 - accuracy: 0.4302 - val_loss: 1.4431 - val_accuracy: 0.4000\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.3462 - accuracy: 0.4419 - val_loss: 1.4039 - val_accuracy: 0.4000\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 513us/sample - loss: 1.3204 - accuracy: 0.4419 - val_loss: 1.3739 - val_accuracy: 0.4000\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.2965 - accuracy: 0.4302 - val_loss: 1.3495 - val_accuracy: 0.4000\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.2738 - accuracy: 0.4419 - val_loss: 1.3240 - val_accuracy: 0.3556\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.2528 - accuracy: 0.4419 - val_loss: 1.3025 - val_accuracy: 0.3778\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 524us/sample - loss: 1.2348 - accuracy: 0.4419 - val_loss: 1.2834 - val_accuracy: 0.3778\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 509us/sample - loss: 1.2181 - accuracy: 0.4419 - val_loss: 1.2676 - val_accuracy: 0.3778\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 551us/sample - loss: 1.2042 - accuracy: 0.4535 - val_loss: 1.2530 - val_accuracy: 0.3778\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.1895 - accuracy: 0.4535 - val_loss: 1.2407 - val_accuracy: 0.4000\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.1780 - accuracy: 0.4535 - val_loss: 1.2300 - val_accuracy: 0.4444\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.1672 - accuracy: 0.4535 - val_loss: 1.2209 - val_accuracy: 0.4444\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 495us/sample - loss: 1.1574 - accuracy: 0.4651 - val_loss: 1.2127 - val_accuracy: 0.4444\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1483 - accuracy: 0.4651 - val_loss: 1.2044 - val_accuracy: 0.4444\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.1387 - accuracy: 0.4651 - val_loss: 1.1971 - val_accuracy: 0.4444\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1292 - accuracy: 0.4651 - val_loss: 1.1896 - val_accuracy: 0.4667\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 392us/sample - loss: 1.1218 - accuracy: 0.4651 - val_loss: 1.1825 - val_accuracy: 0.4667\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 577us/sample - loss: 1.1131 - accuracy: 0.4767 - val_loss: 1.1757 - val_accuracy: 0.4667\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.1052 - accuracy: 0.4651 - val_loss: 1.1697 - val_accuracy: 0.4667\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 1.0991 - accuracy: 0.4767 - val_loss: 1.1640 - val_accuracy: 0.4667\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 517us/sample - loss: 1.0924 - accuracy: 0.4651 - val_loss: 1.1585 - val_accuracy: 0.4667\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0857 - accuracy: 0.4884 - val_loss: 1.1535 - val_accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.0804 - accuracy: 0.5000 - val_loss: 1.1497 - val_accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.0746 - accuracy: 0.4884 - val_loss: 1.1462 - val_accuracy: 0.4667\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.0709 - accuracy: 0.5000 - val_loss: 1.1427 - val_accuracy: 0.4667\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.0643 - accuracy: 0.4884 - val_loss: 1.1394 - val_accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 1.0597 - accuracy: 0.5000 - val_loss: 1.1362 - val_accuracy: 0.4444\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 529us/sample - loss: 1.0555 - accuracy: 0.5116 - val_loss: 1.1331 - val_accuracy: 0.4444\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.0507 - accuracy: 0.5000 - val_loss: 1.1302 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 491us/sample - loss: 1.0468 - accuracy: 0.5116 - val_loss: 1.1270 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.0428 - accuracy: 0.5116 - val_loss: 1.1243 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0393 - accuracy: 0.5116 - val_loss: 1.1218 - val_accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 1.0358 - accuracy: 0.5116 - val_loss: 1.1194 - val_accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0320 - accuracy: 0.5116 - val_loss: 1.1163 - val_accuracy: 0.4667\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 1.0287 - accuracy: 0.5116 - val_loss: 1.1140 - val_accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 1.0253 - accuracy: 0.5116 - val_loss: 1.1117 - val_accuracy: 0.4667\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 537us/sample - loss: 1.0226 - accuracy: 0.5116 - val_loss: 1.1091 - val_accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 489us/sample - loss: 1.0192 - accuracy: 0.5116 - val_loss: 1.1066 - val_accuracy: 0.4667\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 1.0177 - accuracy: 0.5116 - val_loss: 1.1047 - val_accuracy: 0.4667\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 1.0135 - accuracy: 0.5116 - val_loss: 1.1033 - val_accuracy: 0.4667\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 553us/sample - loss: 1.0109 - accuracy: 0.5116 - val_loss: 1.1014 - val_accuracy: 0.4667\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 1.0092 - accuracy: 0.5116 - val_loss: 1.1000 - val_accuracy: 0.4667\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 534us/sample - loss: 1.0062 - accuracy: 0.5116 - val_loss: 1.0983 - val_accuracy: 0.4667\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.0046 - accuracy: 0.5116 - val_loss: 1.0967 - val_accuracy: 0.4667\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.0028 - accuracy: 0.5116 - val_loss: 1.0949 - val_accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.0005 - accuracy: 0.5349 - val_loss: 1.0933 - val_accuracy: 0.4667\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 0.9979 - accuracy: 0.5233 - val_loss: 1.0919 - val_accuracy: 0.4889\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 0.9957 - accuracy: 0.5233 - val_loss: 1.0906 - val_accuracy: 0.4889\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.9935 - accuracy: 0.5116 - val_loss: 1.0890 - val_accuracy: 0.4889\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 0.9911 - accuracy: 0.5116 - val_loss: 1.0871 - val_accuracy: 0.4889\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 624us/sample - loss: 0.9901 - accuracy: 0.5233 - val_loss: 1.0850 - val_accuracy: 0.4889\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 0.9870 - accuracy: 0.5116 - val_loss: 1.0837 - val_accuracy: 0.4889\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 0.9843 - accuracy: 0.5116 - val_loss: 1.0820 - val_accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 0.9824 - accuracy: 0.5233 - val_loss: 1.0807 - val_accuracy: 0.4667\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 0.9807 - accuracy: 0.5116 - val_loss: 1.0794 - val_accuracy: 0.4667\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.9788 - accuracy: 0.5116 - val_loss: 1.0787 - val_accuracy: 0.4667\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.9770 - accuracy: 0.5233 - val_loss: 1.0777 - val_accuracy: 0.4667\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.9760 - accuracy: 0.5116 - val_loss: 1.0772 - val_accuracy: 0.4667\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 0.9737 - accuracy: 0.5116 - val_loss: 1.0762 - val_accuracy: 0.4889\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9720 - accuracy: 0.5233 - val_loss: 1.0752 - val_accuracy: 0.4889\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 509us/sample - loss: 0.9706 - accuracy: 0.5233 - val_loss: 1.0740 - val_accuracy: 0.4889\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 543us/sample - loss: 0.9689 - accuracy: 0.5116 - val_loss: 1.0726 - val_accuracy: 0.4889\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.9672 - accuracy: 0.5000 - val_loss: 1.0716 - val_accuracy: 0.4889\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 0.9660 - accuracy: 0.5000 - val_loss: 1.0707 - val_accuracy: 0.4889\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.9639 - accuracy: 0.5000 - val_loss: 1.0697 - val_accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 596us/sample - loss: 0.9627 - accuracy: 0.5116 - val_loss: 1.0687 - val_accuracy: 0.4667\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 0.9611 - accuracy: 0.5116 - val_loss: 1.0680 - val_accuracy: 0.4667\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.9603 - accuracy: 0.5000 - val_loss: 1.0668 - val_accuracy: 0.4667\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9600 - accuracy: 0.5000 - val_loss: 1.0657 - val_accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 0.9571 - accuracy: 0.5000 - val_loss: 1.0649 - val_accuracy: 0.4667\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.9562 - accuracy: 0.5000 - val_loss: 1.0643 - val_accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 0.9546 - accuracy: 0.5000 - val_loss: 1.0637 - val_accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 0.9542 - accuracy: 0.5000 - val_loss: 1.0629 - val_accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 0.9533 - accuracy: 0.5116 - val_loss: 1.0621 - val_accuracy: 0.4667\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 537us/sample - loss: 0.9522 - accuracy: 0.5233 - val_loss: 1.0613 - val_accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 0.9509 - accuracy: 0.5233 - val_loss: 1.0605 - val_accuracy: 0.4667\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 0.9493 - accuracy: 0.5116 - val_loss: 1.0598 - val_accuracy: 0.4667\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.9482 - accuracy: 0.5116 - val_loss: 1.0592 - val_accuracy: 0.4667\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 0.9480 - accuracy: 0.5233 - val_loss: 1.0587 - val_accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 557us/sample - loss: 0.9468 - accuracy: 0.5233 - val_loss: 1.0582 - val_accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 0.9463 - accuracy: 0.5116 - val_loss: 1.0582 - val_accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 0.9442 - accuracy: 0.5233 - val_loss: 1.0575 - val_accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 0.9438 - accuracy: 0.5116 - val_loss: 1.0563 - val_accuracy: 0.4667\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 0.9431 - accuracy: 0.5233 - val_loss: 1.0557 - val_accuracy: 0.4667\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 0.9419 - accuracy: 0.5116 - val_loss: 1.0552 - val_accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 0.9413 - accuracy: 0.5116 - val_loss: 1.0552 - val_accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 0.9395 - accuracy: 0.5233 - val_loss: 1.0545 - val_accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 0.9391 - accuracy: 0.5233 - val_loss: 1.0538 - val_accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.9373 - accuracy: 0.5233 - val_loss: 1.0533 - val_accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 525us/sample - loss: 0.9368 - accuracy: 0.5116 - val_loss: 1.0529 - val_accuracy: 0.4667\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.8138 - accuracy: 0.3837 - val_loss: 1.7040 - val_accuracy: 0.4222\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 2.6081 - accuracy: 0.3837 - val_loss: 1.6101 - val_accuracy: 0.4222\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 2.4243 - accuracy: 0.3837 - val_loss: 1.5261 - val_accuracy: 0.4222\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 2.2554 - accuracy: 0.3953 - val_loss: 1.4508 - val_accuracy: 0.4222\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 2.1039 - accuracy: 0.3837 - val_loss: 1.3822 - val_accuracy: 0.4667\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.9642 - accuracy: 0.3953 - val_loss: 1.3303 - val_accuracy: 0.4667\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 1.8350 - accuracy: 0.4070 - val_loss: 1.2836 - val_accuracy: 0.4444\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.7224 - accuracy: 0.4186 - val_loss: 1.2407 - val_accuracy: 0.4444\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.6162 - accuracy: 0.4186 - val_loss: 1.2026 - val_accuracy: 0.4444\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 516us/sample - loss: 1.5261 - accuracy: 0.4070 - val_loss: 1.1812 - val_accuracy: 0.4667\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.4538 - accuracy: 0.3721 - val_loss: 1.1673 - val_accuracy: 0.4667\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.3846 - accuracy: 0.4070 - val_loss: 1.1525 - val_accuracy: 0.4889\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.3295 - accuracy: 0.4070 - val_loss: 1.1374 - val_accuracy: 0.4667\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 1.2786 - accuracy: 0.4070 - val_loss: 1.1238 - val_accuracy: 0.4889\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.2323 - accuracy: 0.4302 - val_loss: 1.1130 - val_accuracy: 0.4889\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 1.1909 - accuracy: 0.4070 - val_loss: 1.1017 - val_accuracy: 0.4889\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.1458 - accuracy: 0.4070 - val_loss: 1.0914 - val_accuracy: 0.4889\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 633us/sample - loss: 1.1107 - accuracy: 0.4186 - val_loss: 1.0817 - val_accuracy: 0.5333\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 544us/sample - loss: 1.0800 - accuracy: 0.4070 - val_loss: 1.0721 - val_accuracy: 0.5556\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 1.0502 - accuracy: 0.4302 - val_loss: 1.0672 - val_accuracy: 0.5556\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.0255 - accuracy: 0.4419 - val_loss: 1.0644 - val_accuracy: 0.5556\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.0032 - accuracy: 0.4884 - val_loss: 1.0623 - val_accuracy: 0.5556\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.9860 - accuracy: 0.5000 - val_loss: 1.0601 - val_accuracy: 0.5556\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 0.9721 - accuracy: 0.5233 - val_loss: 1.0584 - val_accuracy: 0.5333\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 0.9586 - accuracy: 0.5233 - val_loss: 1.0580 - val_accuracy: 0.5111\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 0.9481 - accuracy: 0.5349 - val_loss: 1.0563 - val_accuracy: 0.5111\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.9386 - accuracy: 0.5349 - val_loss: 1.0540 - val_accuracy: 0.5111\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 588us/sample - loss: 0.9313 - accuracy: 0.5465 - val_loss: 1.0536 - val_accuracy: 0.5111\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9231 - accuracy: 0.5814 - val_loss: 1.0541 - val_accuracy: 0.5111\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9166 - accuracy: 0.5814 - val_loss: 1.0523 - val_accuracy: 0.5111\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 0.9121 - accuracy: 0.5814 - val_loss: 1.0520 - val_accuracy: 0.5111\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 0.9070 - accuracy: 0.5814 - val_loss: 1.0527 - val_accuracy: 0.4889\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9013 - accuracy: 0.5930 - val_loss: 1.0525 - val_accuracy: 0.4889\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 0.8961 - accuracy: 0.5930 - val_loss: 1.0542 - val_accuracy: 0.4889\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 0.8911 - accuracy: 0.5930 - val_loss: 1.0564 - val_accuracy: 0.4889\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 0.8870 - accuracy: 0.5930 - val_loss: 1.0575 - val_accuracy: 0.4889\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 564us/sample - loss: 0.8823 - accuracy: 0.5930 - val_loss: 1.0579 - val_accuracy: 0.4889\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 516us/sample - loss: 0.8788 - accuracy: 0.5930 - val_loss: 1.0609 - val_accuracy: 0.4889\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.8745 - accuracy: 0.5814 - val_loss: 1.0653 - val_accuracy: 0.5111\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.8704 - accuracy: 0.5814 - val_loss: 1.0670 - val_accuracy: 0.5111\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 0.8671 - accuracy: 0.5814 - val_loss: 1.0667 - val_accuracy: 0.5333\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 0.8645 - accuracy: 0.5814 - val_loss: 1.0673 - val_accuracy: 0.5333\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.8616 - accuracy: 0.5814 - val_loss: 1.0687 - val_accuracy: 0.5556\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.8583 - accuracy: 0.5930 - val_loss: 1.0700 - val_accuracy: 0.5556\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 0.8554 - accuracy: 0.5814 - val_loss: 1.0729 - val_accuracy: 0.5556\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 0.8528 - accuracy: 0.5930 - val_loss: 1.0751 - val_accuracy: 0.5556\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 0.8504 - accuracy: 0.5930 - val_loss: 1.0764 - val_accuracy: 0.5556\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.8484 - accuracy: 0.5930 - val_loss: 1.0780 - val_accuracy: 0.5556\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 0.8462 - accuracy: 0.5930 - val_loss: 1.0798 - val_accuracy: 0.5556\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 514us/sample - loss: 0.8455 - accuracy: 0.5930 - val_loss: 1.0810 - val_accuracy: 0.5556\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 0.8431 - accuracy: 0.5930 - val_loss: 1.0808 - val_accuracy: 0.5556\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.8415 - accuracy: 0.6047 - val_loss: 1.0808 - val_accuracy: 0.5556\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.8397 - accuracy: 0.6047 - val_loss: 1.0823 - val_accuracy: 0.5556\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 0.8381 - accuracy: 0.6047 - val_loss: 1.0806 - val_accuracy: 0.5556\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.8374 - accuracy: 0.6163 - val_loss: 1.0803 - val_accuracy: 0.5556\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.8353 - accuracy: 0.6163 - val_loss: 1.0822 - val_accuracy: 0.5556\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.8340 - accuracy: 0.6163 - val_loss: 1.0846 - val_accuracy: 0.5556\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.8327 - accuracy: 0.6163 - val_loss: 1.0870 - val_accuracy: 0.5333\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 0.8313 - accuracy: 0.6047 - val_loss: 1.0879 - val_accuracy: 0.5333\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.8301 - accuracy: 0.6163 - val_loss: 1.0890 - val_accuracy: 0.5333\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.8288 - accuracy: 0.6047 - val_loss: 1.0892 - val_accuracy: 0.5333\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.8274 - accuracy: 0.6163 - val_loss: 1.0900 - val_accuracy: 0.5333\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 0.8267 - accuracy: 0.6279 - val_loss: 1.0914 - val_accuracy: 0.5333\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.8252 - accuracy: 0.6279 - val_loss: 1.0917 - val_accuracy: 0.5333\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 0.8237 - accuracy: 0.6279 - val_loss: 1.0920 - val_accuracy: 0.5333\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.8230 - accuracy: 0.6279 - val_loss: 1.0918 - val_accuracy: 0.5333\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.8212 - accuracy: 0.6279 - val_loss: 1.0918 - val_accuracy: 0.5333\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 0.8206 - accuracy: 0.6279 - val_loss: 1.0936 - val_accuracy: 0.5333\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.8192 - accuracy: 0.6279 - val_loss: 1.0939 - val_accuracy: 0.5333\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.8177 - accuracy: 0.6395 - val_loss: 1.0946 - val_accuracy: 0.5556\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 0.8170 - accuracy: 0.6395 - val_loss: 1.0946 - val_accuracy: 0.5556\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 0.8161 - accuracy: 0.6395 - val_loss: 1.0949 - val_accuracy: 0.5556\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 0.8151 - accuracy: 0.6279 - val_loss: 1.0966 - val_accuracy: 0.5556\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.8147 - accuracy: 0.6279 - val_loss: 1.0972 - val_accuracy: 0.5556\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.8134 - accuracy: 0.6279 - val_loss: 1.0985 - val_accuracy: 0.5556\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.8124 - accuracy: 0.6395 - val_loss: 1.0986 - val_accuracy: 0.5556\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.8109 - accuracy: 0.6395 - val_loss: 1.0996 - val_accuracy: 0.5556\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 0.8100 - accuracy: 0.6395 - val_loss: 1.1001 - val_accuracy: 0.5556\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 0.8092 - accuracy: 0.6395 - val_loss: 1.1006 - val_accuracy: 0.5556\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 0.8083 - accuracy: 0.6395 - val_loss: 1.1020 - val_accuracy: 0.5556\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 0.8074 - accuracy: 0.6395 - val_loss: 1.1025 - val_accuracy: 0.5556\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 0.8067 - accuracy: 0.6395 - val_loss: 1.1034 - val_accuracy: 0.5556\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.8059 - accuracy: 0.6395 - val_loss: 1.1042 - val_accuracy: 0.5556\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.8054 - accuracy: 0.6395 - val_loss: 1.1061 - val_accuracy: 0.5333\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 0.8038 - accuracy: 0.6395 - val_loss: 1.1063 - val_accuracy: 0.5111\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 0.8038 - accuracy: 0.6395 - val_loss: 1.1072 - val_accuracy: 0.5111\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.8028 - accuracy: 0.6395 - val_loss: 1.1080 - val_accuracy: 0.5111\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 0.8019 - accuracy: 0.6395 - val_loss: 1.1085 - val_accuracy: 0.5111\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 0.8015 - accuracy: 0.6395 - val_loss: 1.1080 - val_accuracy: 0.5111\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.8009 - accuracy: 0.6512 - val_loss: 1.1083 - val_accuracy: 0.5111\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 0.7995 - accuracy: 0.6512 - val_loss: 1.1093 - val_accuracy: 0.5111\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 0.7994 - accuracy: 0.6512 - val_loss: 1.1098 - val_accuracy: 0.5111\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 0.7993 - accuracy: 0.6512 - val_loss: 1.1093 - val_accuracy: 0.5111\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 0.7982 - accuracy: 0.6512 - val_loss: 1.1102 - val_accuracy: 0.5111\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.7973 - accuracy: 0.6512 - val_loss: 1.1109 - val_accuracy: 0.5111\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 0.7975 - accuracy: 0.6512 - val_loss: 1.1115 - val_accuracy: 0.5111\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.7966 - accuracy: 0.6512 - val_loss: 1.1114 - val_accuracy: 0.5111\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 0.7960 - accuracy: 0.6512 - val_loss: 1.1115 - val_accuracy: 0.5333\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 0.7955 - accuracy: 0.6512 - val_loss: 1.1123 - val_accuracy: 0.5333\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 370us/sample - loss: 0.7951 - accuracy: 0.6512 - val_loss: 1.1130 - val_accuracy: 0.5333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 5</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5111110806465149</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 5ms/sample - loss: 2.1085 - accuracy: 0.2093 - val_loss: 2.1741 - val_accuracy: 0.2444\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 536us/sample - loss: 1.9811 - accuracy: 0.2326 - val_loss: 2.0780 - val_accuracy: 0.2667\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 390us/sample - loss: 1.8684 - accuracy: 0.2558 - val_loss: 1.9953 - val_accuracy: 0.2667\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.7772 - accuracy: 0.2674 - val_loss: 1.9192 - val_accuracy: 0.2667\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.6908 - accuracy: 0.2791 - val_loss: 1.8559 - val_accuracy: 0.2667\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 1.6225 - accuracy: 0.2907 - val_loss: 1.7989 - val_accuracy: 0.2444\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.5683 - accuracy: 0.3140 - val_loss: 1.7516 - val_accuracy: 0.2667\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.5217 - accuracy: 0.3140 - val_loss: 1.7110 - val_accuracy: 0.2667\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 529us/sample - loss: 1.4847 - accuracy: 0.3488 - val_loss: 1.6742 - val_accuracy: 0.2889\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 1.4523 - accuracy: 0.3605 - val_loss: 1.6407 - val_accuracy: 0.2889\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 1.4232 - accuracy: 0.3488 - val_loss: 1.6105 - val_accuracy: 0.2889\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 1.3980 - accuracy: 0.3721 - val_loss: 1.5822 - val_accuracy: 0.3111\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.3749 - accuracy: 0.3721 - val_loss: 1.5568 - val_accuracy: 0.3111\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.3550 - accuracy: 0.3837 - val_loss: 1.5330 - val_accuracy: 0.3111\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 515us/sample - loss: 1.3362 - accuracy: 0.3837 - val_loss: 1.5116 - val_accuracy: 0.3111\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 1.3182 - accuracy: 0.3721 - val_loss: 1.4906 - val_accuracy: 0.3333\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.3023 - accuracy: 0.3721 - val_loss: 1.4720 - val_accuracy: 0.3333\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 377us/sample - loss: 1.2865 - accuracy: 0.3837 - val_loss: 1.4548 - val_accuracy: 0.3333\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.2733 - accuracy: 0.3953 - val_loss: 1.4392 - val_accuracy: 0.2889\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.2610 - accuracy: 0.4070 - val_loss: 1.4235 - val_accuracy: 0.3111\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.2484 - accuracy: 0.3837 - val_loss: 1.4095 - val_accuracy: 0.3111\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.2373 - accuracy: 0.4070 - val_loss: 1.3956 - val_accuracy: 0.2889\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.2273 - accuracy: 0.4070 - val_loss: 1.3817 - val_accuracy: 0.3111\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.2160 - accuracy: 0.4186 - val_loss: 1.3703 - val_accuracy: 0.3111\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.2058 - accuracy: 0.4186 - val_loss: 1.3597 - val_accuracy: 0.3111\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 1.1974 - accuracy: 0.4302 - val_loss: 1.3487 - val_accuracy: 0.3111\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.1903 - accuracy: 0.4535 - val_loss: 1.3370 - val_accuracy: 0.3111\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 405us/sample - loss: 1.1838 - accuracy: 0.4535 - val_loss: 1.3262 - val_accuracy: 0.3111\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1726 - accuracy: 0.4535 - val_loss: 1.3172 - val_accuracy: 0.3333\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 1.1671 - accuracy: 0.4651 - val_loss: 1.3082 - val_accuracy: 0.3333\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 1.1584 - accuracy: 0.4651 - val_loss: 1.2990 - val_accuracy: 0.3111\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.1514 - accuracy: 0.4651 - val_loss: 1.2903 - val_accuracy: 0.3111\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 1.1449 - accuracy: 0.4767 - val_loss: 1.2821 - val_accuracy: 0.3333\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.1392 - accuracy: 0.4767 - val_loss: 1.2748 - val_accuracy: 0.3333\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 574us/sample - loss: 1.1336 - accuracy: 0.5000 - val_loss: 1.2667 - val_accuracy: 0.3556\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.1271 - accuracy: 0.5000 - val_loss: 1.2598 - val_accuracy: 0.3556\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.1206 - accuracy: 0.5000 - val_loss: 1.2531 - val_accuracy: 0.3556\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.1171 - accuracy: 0.5000 - val_loss: 1.2464 - val_accuracy: 0.3778\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 394us/sample - loss: 1.1111 - accuracy: 0.5000 - val_loss: 1.2401 - val_accuracy: 0.3778\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 1.1071 - accuracy: 0.5000 - val_loss: 1.2337 - val_accuracy: 0.3778\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.1012 - accuracy: 0.4884 - val_loss: 1.2277 - val_accuracy: 0.3778\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 1.0969 - accuracy: 0.4884 - val_loss: 1.2218 - val_accuracy: 0.3778\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.0928 - accuracy: 0.5000 - val_loss: 1.2158 - val_accuracy: 0.3778\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0895 - accuracy: 0.5000 - val_loss: 1.2098 - val_accuracy: 0.3778\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 1.0849 - accuracy: 0.5000 - val_loss: 1.2041 - val_accuracy: 0.3778\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.0794 - accuracy: 0.5000 - val_loss: 1.1986 - val_accuracy: 0.3778\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.0754 - accuracy: 0.4884 - val_loss: 1.1927 - val_accuracy: 0.3778\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 1.0718 - accuracy: 0.4884 - val_loss: 1.1870 - val_accuracy: 0.3778\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.0683 - accuracy: 0.5116 - val_loss: 1.1822 - val_accuracy: 0.3778\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.0670 - accuracy: 0.5000 - val_loss: 1.1780 - val_accuracy: 0.3778\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.0607 - accuracy: 0.5000 - val_loss: 1.1740 - val_accuracy: 0.3778\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.0583 - accuracy: 0.5000 - val_loss: 1.1696 - val_accuracy: 0.3778\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.0546 - accuracy: 0.5000 - val_loss: 1.1653 - val_accuracy: 0.3778\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 518us/sample - loss: 1.0525 - accuracy: 0.5116 - val_loss: 1.1606 - val_accuracy: 0.3778\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.0488 - accuracy: 0.5000 - val_loss: 1.1557 - val_accuracy: 0.3778\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.0456 - accuracy: 0.5000 - val_loss: 1.1526 - val_accuracy: 0.3778\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 1.0440 - accuracy: 0.5000 - val_loss: 1.1498 - val_accuracy: 0.3778\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.0423 - accuracy: 0.5000 - val_loss: 1.1468 - val_accuracy: 0.3778\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.0388 - accuracy: 0.5000 - val_loss: 1.1434 - val_accuracy: 0.3778\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.0359 - accuracy: 0.5000 - val_loss: 1.1399 - val_accuracy: 0.3778\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 1.0325 - accuracy: 0.5000 - val_loss: 1.1359 - val_accuracy: 0.3778\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.0300 - accuracy: 0.5000 - val_loss: 1.1322 - val_accuracy: 0.3556\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.0277 - accuracy: 0.5000 - val_loss: 1.1295 - val_accuracy: 0.3556\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.0265 - accuracy: 0.5116 - val_loss: 1.1271 - val_accuracy: 0.3556\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.0250 - accuracy: 0.5116 - val_loss: 1.1239 - val_accuracy: 0.3556\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 1.0224 - accuracy: 0.5116 - val_loss: 1.1210 - val_accuracy: 0.3556\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.0196 - accuracy: 0.5116 - val_loss: 1.1186 - val_accuracy: 0.3556\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 1.0178 - accuracy: 0.5116 - val_loss: 1.1165 - val_accuracy: 0.3556\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.0164 - accuracy: 0.5000 - val_loss: 1.1142 - val_accuracy: 0.3556\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.0145 - accuracy: 0.5116 - val_loss: 1.1116 - val_accuracy: 0.3556\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 1.0117 - accuracy: 0.5000 - val_loss: 1.1086 - val_accuracy: 0.3556\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 537us/sample - loss: 1.0100 - accuracy: 0.5116 - val_loss: 1.1066 - val_accuracy: 0.3556\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.0084 - accuracy: 0.5000 - val_loss: 1.1045 - val_accuracy: 0.3556\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.0079 - accuracy: 0.5000 - val_loss: 1.1024 - val_accuracy: 0.3556\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.0057 - accuracy: 0.5000 - val_loss: 1.0997 - val_accuracy: 0.3556\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.0033 - accuracy: 0.4884 - val_loss: 1.0972 - val_accuracy: 0.3556\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0025 - accuracy: 0.4767 - val_loss: 1.0955 - val_accuracy: 0.3556\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 1.0012 - accuracy: 0.4884 - val_loss: 1.0939 - val_accuracy: 0.3556\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.0001 - accuracy: 0.4884 - val_loss: 1.0925 - val_accuracy: 0.3556\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 0.9980 - accuracy: 0.4767 - val_loss: 1.0905 - val_accuracy: 0.3556\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9962 - accuracy: 0.4767 - val_loss: 1.0889 - val_accuracy: 0.3556\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.9961 - accuracy: 0.4767 - val_loss: 1.0876 - val_accuracy: 0.3556\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.9952 - accuracy: 0.4884 - val_loss: 1.0860 - val_accuracy: 0.3556\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 572us/sample - loss: 0.9934 - accuracy: 0.4884 - val_loss: 1.0840 - val_accuracy: 0.3556\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.9921 - accuracy: 0.4767 - val_loss: 1.0820 - val_accuracy: 0.3556\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 489us/sample - loss: 0.9903 - accuracy: 0.4884 - val_loss: 1.0808 - val_accuracy: 0.3556\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 0.9898 - accuracy: 0.4767 - val_loss: 1.0799 - val_accuracy: 0.3556\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 0.9890 - accuracy: 0.4884 - val_loss: 1.0791 - val_accuracy: 0.3556\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 0.9877 - accuracy: 0.4884 - val_loss: 1.0779 - val_accuracy: 0.3556\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 0.9861 - accuracy: 0.4884 - val_loss: 1.0766 - val_accuracy: 0.3556\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 0.9859 - accuracy: 0.4884 - val_loss: 1.0756 - val_accuracy: 0.3556\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 0.9847 - accuracy: 0.4884 - val_loss: 1.0740 - val_accuracy: 0.3556\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.9844 - accuracy: 0.4884 - val_loss: 1.0719 - val_accuracy: 0.3556\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9832 - accuracy: 0.4884 - val_loss: 1.0704 - val_accuracy: 0.3556\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.9813 - accuracy: 0.5000 - val_loss: 1.0690 - val_accuracy: 0.3556\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 0.9824 - accuracy: 0.5000 - val_loss: 1.0679 - val_accuracy: 0.3556\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 0.9794 - accuracy: 0.5000 - val_loss: 1.0668 - val_accuracy: 0.3556\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 0.9793 - accuracy: 0.5000 - val_loss: 1.0657 - val_accuracy: 0.3556\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 0.9779 - accuracy: 0.5000 - val_loss: 1.0647 - val_accuracy: 0.3556\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.9786 - accuracy: 0.5000 - val_loss: 1.0634 - val_accuracy: 0.3333\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.7773 - accuracy: 0.3721 - val_loss: 1.7236 - val_accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 2.6028 - accuracy: 0.3721 - val_loss: 1.6355 - val_accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 2.4314 - accuracy: 0.3605 - val_loss: 1.5595 - val_accuracy: 0.4000\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 2.2859 - accuracy: 0.3605 - val_loss: 1.4915 - val_accuracy: 0.4000\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 2.1520 - accuracy: 0.3605 - val_loss: 1.4270 - val_accuracy: 0.4000\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 2.0232 - accuracy: 0.3605 - val_loss: 1.3683 - val_accuracy: 0.4000\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 367us/sample - loss: 1.9117 - accuracy: 0.3605 - val_loss: 1.3154 - val_accuracy: 0.4000\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 537us/sample - loss: 1.8066 - accuracy: 0.3605 - val_loss: 1.2696 - val_accuracy: 0.4222\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.7119 - accuracy: 0.3605 - val_loss: 1.2291 - val_accuracy: 0.4222\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.6231 - accuracy: 0.3721 - val_loss: 1.1904 - val_accuracy: 0.4000\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.5354 - accuracy: 0.3721 - val_loss: 1.1558 - val_accuracy: 0.4000\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.4607 - accuracy: 0.3721 - val_loss: 1.1264 - val_accuracy: 0.3778\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 541us/sample - loss: 1.3934 - accuracy: 0.3721 - val_loss: 1.1034 - val_accuracy: 0.3778\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.3351 - accuracy: 0.3721 - val_loss: 1.0823 - val_accuracy: 0.3556\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 1.2777 - accuracy: 0.3721 - val_loss: 1.0639 - val_accuracy: 0.3333\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 1.2229 - accuracy: 0.3837 - val_loss: 1.0484 - val_accuracy: 0.3556\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.1762 - accuracy: 0.3837 - val_loss: 1.0359 - val_accuracy: 0.3556\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 1.1326 - accuracy: 0.3605 - val_loss: 1.0273 - val_accuracy: 0.3556\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 1.0981 - accuracy: 0.3721 - val_loss: 1.0206 - val_accuracy: 0.3556\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.0680 - accuracy: 0.3372 - val_loss: 1.0166 - val_accuracy: 0.3556\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.0431 - accuracy: 0.3488 - val_loss: 1.0133 - val_accuracy: 0.3778\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 489us/sample - loss: 1.0233 - accuracy: 0.3837 - val_loss: 1.0103 - val_accuracy: 0.4222\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 529us/sample - loss: 1.0071 - accuracy: 0.4419 - val_loss: 1.0076 - val_accuracy: 0.4667\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 529us/sample - loss: 0.9944 - accuracy: 0.4535 - val_loss: 1.0058 - val_accuracy: 0.4889\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 0.9838 - accuracy: 0.4535 - val_loss: 1.0048 - val_accuracy: 0.4889\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 0.9757 - accuracy: 0.4767 - val_loss: 1.0040 - val_accuracy: 0.4889\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 0.9702 - accuracy: 0.4884 - val_loss: 1.0034 - val_accuracy: 0.4889\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 389us/sample - loss: 0.9655 - accuracy: 0.4884 - val_loss: 1.0025 - val_accuracy: 0.4889\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 0.9619 - accuracy: 0.4884 - val_loss: 1.0018 - val_accuracy: 0.4889\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.9581 - accuracy: 0.4767 - val_loss: 1.0009 - val_accuracy: 0.4889\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 0.9557 - accuracy: 0.4767 - val_loss: 1.0000 - val_accuracy: 0.4889\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9528 - accuracy: 0.5000 - val_loss: 0.9991 - val_accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9511 - accuracy: 0.5116 - val_loss: 0.9983 - val_accuracy: 0.4444\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 0.9490 - accuracy: 0.4884 - val_loss: 0.9973 - val_accuracy: 0.4444\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9480 - accuracy: 0.5000 - val_loss: 0.9967 - val_accuracy: 0.4444\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 0.9469 - accuracy: 0.5000 - val_loss: 0.9961 - val_accuracy: 0.4444\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.9451 - accuracy: 0.5000 - val_loss: 0.9952 - val_accuracy: 0.4444\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9445 - accuracy: 0.5000 - val_loss: 0.9948 - val_accuracy: 0.4444\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 563us/sample - loss: 0.9433 - accuracy: 0.4884 - val_loss: 0.9942 - val_accuracy: 0.4444\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 0.9423 - accuracy: 0.4884 - val_loss: 0.9940 - val_accuracy: 0.4444\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 0.9419 - accuracy: 0.4767 - val_loss: 0.9939 - val_accuracy: 0.4444\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 0.9408 - accuracy: 0.4767 - val_loss: 0.9936 - val_accuracy: 0.4444\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 0.9394 - accuracy: 0.4767 - val_loss: 0.9935 - val_accuracy: 0.4444\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.9386 - accuracy: 0.4884 - val_loss: 0.9934 - val_accuracy: 0.4444\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9383 - accuracy: 0.4884 - val_loss: 0.9934 - val_accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 496us/sample - loss: 0.9372 - accuracy: 0.4884 - val_loss: 0.9933 - val_accuracy: 0.4667\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9372 - accuracy: 0.4884 - val_loss: 0.9932 - val_accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9358 - accuracy: 0.4884 - val_loss: 0.9931 - val_accuracy: 0.4667\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 0.9354 - accuracy: 0.4884 - val_loss: 0.9929 - val_accuracy: 0.4667\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.9351 - accuracy: 0.4884 - val_loss: 0.9931 - val_accuracy: 0.4667\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 0.9343 - accuracy: 0.4884 - val_loss: 0.9934 - val_accuracy: 0.4667\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 0.9335 - accuracy: 0.4884 - val_loss: 0.9935 - val_accuracy: 0.4667\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 504us/sample - loss: 0.9327 - accuracy: 0.4884 - val_loss: 0.9937 - val_accuracy: 0.4667\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.9320 - accuracy: 0.4767 - val_loss: 0.9941 - val_accuracy: 0.4667\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 0.9321 - accuracy: 0.4767 - val_loss: 0.9942 - val_accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 0.9313 - accuracy: 0.4767 - val_loss: 0.9940 - val_accuracy: 0.4667\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9310 - accuracy: 0.4767 - val_loss: 0.9936 - val_accuracy: 0.4667\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 0.9309 - accuracy: 0.4767 - val_loss: 0.9935 - val_accuracy: 0.4667\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.9296 - accuracy: 0.4767 - val_loss: 0.9937 - val_accuracy: 0.4667\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9298 - accuracy: 0.4884 - val_loss: 0.9938 - val_accuracy: 0.4667\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 0.9288 - accuracy: 0.4884 - val_loss: 0.9937 - val_accuracy: 0.4667\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.9287 - accuracy: 0.4884 - val_loss: 0.9937 - val_accuracy: 0.4667\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 0.9279 - accuracy: 0.4884 - val_loss: 0.9937 - val_accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9274 - accuracy: 0.4884 - val_loss: 0.9937 - val_accuracy: 0.4667\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 0.9272 - accuracy: 0.4884 - val_loss: 0.9936 - val_accuracy: 0.4667\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.9263 - accuracy: 0.4884 - val_loss: 0.9937 - val_accuracy: 0.4444\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 412us/sample - loss: 0.9260 - accuracy: 0.4884 - val_loss: 0.9939 - val_accuracy: 0.4444\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 0.9259 - accuracy: 0.4884 - val_loss: 0.9943 - val_accuracy: 0.4444\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 500us/sample - loss: 0.9254 - accuracy: 0.4884 - val_loss: 0.9945 - val_accuracy: 0.4667\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 0.9254 - accuracy: 0.4884 - val_loss: 0.9946 - val_accuracy: 0.4667\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 0.9244 - accuracy: 0.4884 - val_loss: 0.9946 - val_accuracy: 0.4667\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.9245 - accuracy: 0.4884 - val_loss: 0.9945 - val_accuracy: 0.4667\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9237 - accuracy: 0.4884 - val_loss: 0.9945 - val_accuracy: 0.4667\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 0.9238 - accuracy: 0.4884 - val_loss: 0.9946 - val_accuracy: 0.4667\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 0.9233 - accuracy: 0.4884 - val_loss: 0.9948 - val_accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.9234 - accuracy: 0.4884 - val_loss: 0.9951 - val_accuracy: 0.4667\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 0.9230 - accuracy: 0.5000 - val_loss: 0.9955 - val_accuracy: 0.4667\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9223 - accuracy: 0.5000 - val_loss: 0.9955 - val_accuracy: 0.4667\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 376us/sample - loss: 0.9220 - accuracy: 0.5000 - val_loss: 0.9955 - val_accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.9214 - accuracy: 0.5000 - val_loss: 0.9954 - val_accuracy: 0.4667\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 0.9214 - accuracy: 0.5000 - val_loss: 0.9953 - val_accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 0.9203 - accuracy: 0.5000 - val_loss: 0.9952 - val_accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 0.9202 - accuracy: 0.5000 - val_loss: 0.9954 - val_accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 0.9206 - accuracy: 0.5000 - val_loss: 0.9957 - val_accuracy: 0.4667\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.9195 - accuracy: 0.5000 - val_loss: 0.9959 - val_accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.9192 - accuracy: 0.5000 - val_loss: 0.9959 - val_accuracy: 0.4667\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.9191 - accuracy: 0.5000 - val_loss: 0.9959 - val_accuracy: 0.4667\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 0.9189 - accuracy: 0.5000 - val_loss: 0.9957 - val_accuracy: 0.4667\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 0.9185 - accuracy: 0.5000 - val_loss: 0.9956 - val_accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.9184 - accuracy: 0.5000 - val_loss: 0.9959 - val_accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9179 - accuracy: 0.5000 - val_loss: 0.9962 - val_accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 0.9176 - accuracy: 0.5000 - val_loss: 0.9965 - val_accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 529us/sample - loss: 0.9179 - accuracy: 0.5000 - val_loss: 0.9966 - val_accuracy: 0.4889\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 0.9178 - accuracy: 0.4884 - val_loss: 0.9964 - val_accuracy: 0.4889\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 548us/sample - loss: 0.9169 - accuracy: 0.5116 - val_loss: 0.9965 - val_accuracy: 0.5111\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.9176 - accuracy: 0.5000 - val_loss: 0.9967 - val_accuracy: 0.5111\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 0.9166 - accuracy: 0.5116 - val_loss: 0.9972 - val_accuracy: 0.5111\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 0.9162 - accuracy: 0.5233 - val_loss: 0.9973 - val_accuracy: 0.5111\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.9165 - accuracy: 0.5233 - val_loss: 0.9973 - val_accuracy: 0.5111\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 0.9159 - accuracy: 0.5116 - val_loss: 0.9973 - val_accuracy: 0.5111\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 5ms/sample - loss: 1.8362 - accuracy: 0.3605 - val_loss: 1.9172 - val_accuracy: 0.2889\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 1.7408 - accuracy: 0.3605 - val_loss: 1.8365 - val_accuracy: 0.2889\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 1.6591 - accuracy: 0.3488 - val_loss: 1.7674 - val_accuracy: 0.2889\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 518us/sample - loss: 1.5907 - accuracy: 0.3372 - val_loss: 1.7085 - val_accuracy: 0.3556\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.5303 - accuracy: 0.3488 - val_loss: 1.6519 - val_accuracy: 0.3778\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.4773 - accuracy: 0.3721 - val_loss: 1.6021 - val_accuracy: 0.3778\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 1.4314 - accuracy: 0.3721 - val_loss: 1.5571 - val_accuracy: 0.3556\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 1.3923 - accuracy: 0.3721 - val_loss: 1.5189 - val_accuracy: 0.3556\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.3597 - accuracy: 0.3721 - val_loss: 1.4872 - val_accuracy: 0.3556\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 1.3317 - accuracy: 0.3721 - val_loss: 1.4572 - val_accuracy: 0.3333\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 470us/sample - loss: 1.3068 - accuracy: 0.4070 - val_loss: 1.4275 - val_accuracy: 0.3333\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 531us/sample - loss: 1.2833 - accuracy: 0.3953 - val_loss: 1.4021 - val_accuracy: 0.3778\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 1.2637 - accuracy: 0.3953 - val_loss: 1.3796 - val_accuracy: 0.3556\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.2453 - accuracy: 0.4070 - val_loss: 1.3593 - val_accuracy: 0.3556\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 516us/sample - loss: 1.2309 - accuracy: 0.4070 - val_loss: 1.3407 - val_accuracy: 0.3778\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.2164 - accuracy: 0.4070 - val_loss: 1.3229 - val_accuracy: 0.3778\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.2027 - accuracy: 0.4070 - val_loss: 1.3066 - val_accuracy: 0.4000\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.1905 - accuracy: 0.4070 - val_loss: 1.2898 - val_accuracy: 0.4000\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1784 - accuracy: 0.4070 - val_loss: 1.2748 - val_accuracy: 0.4222\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 538us/sample - loss: 1.1684 - accuracy: 0.4070 - val_loss: 1.2610 - val_accuracy: 0.4222\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.1590 - accuracy: 0.4070 - val_loss: 1.2485 - val_accuracy: 0.4222\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.1496 - accuracy: 0.3953 - val_loss: 1.2357 - val_accuracy: 0.4444\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.1419 - accuracy: 0.4070 - val_loss: 1.2246 - val_accuracy: 0.4444\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.1345 - accuracy: 0.4070 - val_loss: 1.2145 - val_accuracy: 0.4444\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 510us/sample - loss: 1.1273 - accuracy: 0.4070 - val_loss: 1.2048 - val_accuracy: 0.4444\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 1.1208 - accuracy: 0.4070 - val_loss: 1.1955 - val_accuracy: 0.4444\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.1149 - accuracy: 0.4186 - val_loss: 1.1864 - val_accuracy: 0.4222\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1086 - accuracy: 0.4419 - val_loss: 1.1771 - val_accuracy: 0.4222\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.1043 - accuracy: 0.4302 - val_loss: 1.1695 - val_accuracy: 0.4222\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 1.0987 - accuracy: 0.4535 - val_loss: 1.1626 - val_accuracy: 0.4222\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.0939 - accuracy: 0.4535 - val_loss: 1.1551 - val_accuracy: 0.4000\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.0888 - accuracy: 0.4535 - val_loss: 1.1473 - val_accuracy: 0.4000\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 1.0845 - accuracy: 0.4535 - val_loss: 1.1406 - val_accuracy: 0.4000\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.0804 - accuracy: 0.4535 - val_loss: 1.1345 - val_accuracy: 0.4000\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 1.0763 - accuracy: 0.4535 - val_loss: 1.1291 - val_accuracy: 0.4000\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 489us/sample - loss: 1.0734 - accuracy: 0.4419 - val_loss: 1.1237 - val_accuracy: 0.4000\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 1.0708 - accuracy: 0.4535 - val_loss: 1.1195 - val_accuracy: 0.4000\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.0672 - accuracy: 0.4535 - val_loss: 1.1136 - val_accuracy: 0.4000\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.0637 - accuracy: 0.4651 - val_loss: 1.1084 - val_accuracy: 0.4000\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.0621 - accuracy: 0.4651 - val_loss: 1.1044 - val_accuracy: 0.4000\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.0590 - accuracy: 0.4767 - val_loss: 1.1008 - val_accuracy: 0.4000\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0558 - accuracy: 0.4651 - val_loss: 1.0976 - val_accuracy: 0.4444\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.0538 - accuracy: 0.4651 - val_loss: 1.0949 - val_accuracy: 0.4444\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 1.0511 - accuracy: 0.4535 - val_loss: 1.0916 - val_accuracy: 0.4444\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.0494 - accuracy: 0.4651 - val_loss: 1.0890 - val_accuracy: 0.4444\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.0486 - accuracy: 0.4884 - val_loss: 1.0849 - val_accuracy: 0.4444\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.0450 - accuracy: 0.4535 - val_loss: 1.0796 - val_accuracy: 0.4444\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0429 - accuracy: 0.4535 - val_loss: 1.0764 - val_accuracy: 0.4444\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.0404 - accuracy: 0.4767 - val_loss: 1.0745 - val_accuracy: 0.4444\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.0388 - accuracy: 0.4651 - val_loss: 1.0727 - val_accuracy: 0.4444\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.0373 - accuracy: 0.4767 - val_loss: 1.0706 - val_accuracy: 0.4444\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.0357 - accuracy: 0.4884 - val_loss: 1.0686 - val_accuracy: 0.4444\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.0334 - accuracy: 0.4651 - val_loss: 1.0671 - val_accuracy: 0.4444\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 1.0326 - accuracy: 0.4767 - val_loss: 1.0644 - val_accuracy: 0.4444\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0312 - accuracy: 0.4767 - val_loss: 1.0605 - val_accuracy: 0.4444\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.0289 - accuracy: 0.4767 - val_loss: 1.0581 - val_accuracy: 0.4444\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.0274 - accuracy: 0.4884 - val_loss: 1.0569 - val_accuracy: 0.4444\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.0262 - accuracy: 0.4767 - val_loss: 1.0561 - val_accuracy: 0.4444\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 1.0249 - accuracy: 0.4767 - val_loss: 1.0549 - val_accuracy: 0.4444\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.0236 - accuracy: 0.4767 - val_loss: 1.0535 - val_accuracy: 0.4444\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.0217 - accuracy: 0.4767 - val_loss: 1.0520 - val_accuracy: 0.4444\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.0209 - accuracy: 0.4767 - val_loss: 1.0507 - val_accuracy: 0.4444\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.0201 - accuracy: 0.4767 - val_loss: 1.0496 - val_accuracy: 0.4444\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.0180 - accuracy: 0.4767 - val_loss: 1.0489 - val_accuracy: 0.4444\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.0169 - accuracy: 0.4767 - val_loss: 1.0473 - val_accuracy: 0.4444\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.0164 - accuracy: 0.4767 - val_loss: 1.0462 - val_accuracy: 0.4444\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.0154 - accuracy: 0.4767 - val_loss: 1.0457 - val_accuracy: 0.4444\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 1.0139 - accuracy: 0.4767 - val_loss: 1.0450 - val_accuracy: 0.4444\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.0130 - accuracy: 0.4767 - val_loss: 1.0441 - val_accuracy: 0.4444\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 1.0116 - accuracy: 0.4767 - val_loss: 1.0437 - val_accuracy: 0.4444\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.0107 - accuracy: 0.4767 - val_loss: 1.0429 - val_accuracy: 0.4444\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.0105 - accuracy: 0.4767 - val_loss: 1.0421 - val_accuracy: 0.4444\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 1.0090 - accuracy: 0.4767 - val_loss: 1.0415 - val_accuracy: 0.4444\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.0082 - accuracy: 0.4767 - val_loss: 1.0408 - val_accuracy: 0.4444\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 508us/sample - loss: 1.0080 - accuracy: 0.4767 - val_loss: 1.0401 - val_accuracy: 0.4444\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 1.0068 - accuracy: 0.4767 - val_loss: 1.0386 - val_accuracy: 0.4444\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.0063 - accuracy: 0.4884 - val_loss: 1.0375 - val_accuracy: 0.4444\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.0053 - accuracy: 0.4884 - val_loss: 1.0369 - val_accuracy: 0.4444\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 1.0047 - accuracy: 0.4884 - val_loss: 1.0359 - val_accuracy: 0.4444\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.0035 - accuracy: 0.4884 - val_loss: 1.0359 - val_accuracy: 0.4444\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 1.0033 - accuracy: 0.4884 - val_loss: 1.0354 - val_accuracy: 0.4444\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.0020 - accuracy: 0.4884 - val_loss: 1.0347 - val_accuracy: 0.4444\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 1.0011 - accuracy: 0.4884 - val_loss: 1.0340 - val_accuracy: 0.4444\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 491us/sample - loss: 1.0002 - accuracy: 0.4884 - val_loss: 1.0331 - val_accuracy: 0.4444\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 0.9996 - accuracy: 0.4884 - val_loss: 1.0322 - val_accuracy: 0.4444\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.9995 - accuracy: 0.4884 - val_loss: 1.0318 - val_accuracy: 0.4444\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.9979 - accuracy: 0.4884 - val_loss: 1.0316 - val_accuracy: 0.4444\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 0.9977 - accuracy: 0.4884 - val_loss: 1.0312 - val_accuracy: 0.4444\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.9972 - accuracy: 0.4884 - val_loss: 1.0305 - val_accuracy: 0.4444\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 0.9961 - accuracy: 0.5000 - val_loss: 1.0299 - val_accuracy: 0.4444\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 0.9955 - accuracy: 0.4884 - val_loss: 1.0290 - val_accuracy: 0.4444\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 0.9950 - accuracy: 0.4884 - val_loss: 1.0285 - val_accuracy: 0.4444\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 0.9942 - accuracy: 0.4884 - val_loss: 1.0282 - val_accuracy: 0.4444\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 0.9934 - accuracy: 0.4884 - val_loss: 1.0277 - val_accuracy: 0.4444\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 0.9932 - accuracy: 0.4884 - val_loss: 1.0270 - val_accuracy: 0.4444\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 0.9930 - accuracy: 0.4884 - val_loss: 1.0256 - val_accuracy: 0.4444\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 0.9920 - accuracy: 0.4884 - val_loss: 1.0243 - val_accuracy: 0.4444\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 0.9913 - accuracy: 0.4884 - val_loss: 1.0242 - val_accuracy: 0.4444\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 0.9911 - accuracy: 0.4884 - val_loss: 1.0242 - val_accuracy: 0.4444\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 0.9900 - accuracy: 0.4884 - val_loss: 1.0243 - val_accuracy: 0.4444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.4444444477558136</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 5ms/sample - loss: 2.9254 - accuracy: 0.2558 - val_loss: 2.9534 - val_accuracy: 0.1556\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 713us/sample - loss: 2.6463 - accuracy: 0.2558 - val_loss: 2.6510 - val_accuracy: 0.1333\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 587us/sample - loss: 2.3960 - accuracy: 0.2558 - val_loss: 2.3960 - val_accuracy: 0.1778\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 504us/sample - loss: 2.1857 - accuracy: 0.2907 - val_loss: 2.1791 - val_accuracy: 0.1778\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 551us/sample - loss: 1.9964 - accuracy: 0.3372 - val_loss: 2.0031 - val_accuracy: 0.2222\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.8402 - accuracy: 0.3605 - val_loss: 1.8617 - val_accuracy: 0.2222\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 1.7048 - accuracy: 0.3721 - val_loss: 1.7513 - val_accuracy: 0.2000\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.5941 - accuracy: 0.3837 - val_loss: 1.6620 - val_accuracy: 0.2222\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 513us/sample - loss: 1.5029 - accuracy: 0.4070 - val_loss: 1.5922 - val_accuracy: 0.2444\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.4300 - accuracy: 0.4302 - val_loss: 1.5379 - val_accuracy: 0.2222\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.3668 - accuracy: 0.4535 - val_loss: 1.4934 - val_accuracy: 0.2444\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.3166 - accuracy: 0.4535 - val_loss: 1.4564 - val_accuracy: 0.2444\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 583us/sample - loss: 1.2762 - accuracy: 0.4651 - val_loss: 1.4245 - val_accuracy: 0.2667\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.2406 - accuracy: 0.4535 - val_loss: 1.3966 - val_accuracy: 0.2667\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.2115 - accuracy: 0.4535 - val_loss: 1.3720 - val_accuracy: 0.2667\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 1.1855 - accuracy: 0.4535 - val_loss: 1.3515 - val_accuracy: 0.2667\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.1636 - accuracy: 0.4535 - val_loss: 1.3333 - val_accuracy: 0.2667\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1439 - accuracy: 0.4535 - val_loss: 1.3176 - val_accuracy: 0.2667\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 632us/sample - loss: 1.1271 - accuracy: 0.4535 - val_loss: 1.3042 - val_accuracy: 0.2889\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 1.1128 - accuracy: 0.4535 - val_loss: 1.2931 - val_accuracy: 0.3111\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.0996 - accuracy: 0.4535 - val_loss: 1.2821 - val_accuracy: 0.3111\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 1.0864 - accuracy: 0.4419 - val_loss: 1.2710 - val_accuracy: 0.3556\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 572us/sample - loss: 1.0748 - accuracy: 0.4419 - val_loss: 1.2608 - val_accuracy: 0.3778\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 1.0652 - accuracy: 0.4419 - val_loss: 1.2513 - val_accuracy: 0.4222\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.0549 - accuracy: 0.4302 - val_loss: 1.2434 - val_accuracy: 0.4222\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 1.0455 - accuracy: 0.4302 - val_loss: 1.2358 - val_accuracy: 0.4222\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.0371 - accuracy: 0.4302 - val_loss: 1.2287 - val_accuracy: 0.4222\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.0295 - accuracy: 0.4419 - val_loss: 1.2220 - val_accuracy: 0.4222\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 1.0237 - accuracy: 0.4419 - val_loss: 1.2159 - val_accuracy: 0.4222\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 513us/sample - loss: 1.0165 - accuracy: 0.4535 - val_loss: 1.2107 - val_accuracy: 0.4222\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.0109 - accuracy: 0.4535 - val_loss: 1.2063 - val_accuracy: 0.4222\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 541us/sample - loss: 1.0062 - accuracy: 0.4535 - val_loss: 1.2022 - val_accuracy: 0.4444\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 1.0002 - accuracy: 0.4651 - val_loss: 1.1978 - val_accuracy: 0.4444\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 496us/sample - loss: 0.9959 - accuracy: 0.4651 - val_loss: 1.1928 - val_accuracy: 0.4444\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 0.9916 - accuracy: 0.4651 - val_loss: 1.1898 - val_accuracy: 0.4444\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9865 - accuracy: 0.4767 - val_loss: 1.1861 - val_accuracy: 0.4444\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 531us/sample - loss: 0.9815 - accuracy: 0.4884 - val_loss: 1.1825 - val_accuracy: 0.4667\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 0.9774 - accuracy: 0.5000 - val_loss: 1.1803 - val_accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 0.9750 - accuracy: 0.5116 - val_loss: 1.1778 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.9699 - accuracy: 0.5116 - val_loss: 1.1743 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 0.9662 - accuracy: 0.5233 - val_loss: 1.1714 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9640 - accuracy: 0.5233 - val_loss: 1.1692 - val_accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 0.9607 - accuracy: 0.5349 - val_loss: 1.1669 - val_accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 500us/sample - loss: 0.9575 - accuracy: 0.5349 - val_loss: 1.1639 - val_accuracy: 0.4667\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 404us/sample - loss: 0.9546 - accuracy: 0.5349 - val_loss: 1.1618 - val_accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 0.9511 - accuracy: 0.5465 - val_loss: 1.1598 - val_accuracy: 0.4444\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9485 - accuracy: 0.5465 - val_loss: 1.1575 - val_accuracy: 0.4444\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9464 - accuracy: 0.5698 - val_loss: 1.1554 - val_accuracy: 0.4444\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 0.9446 - accuracy: 0.5465 - val_loss: 1.1525 - val_accuracy: 0.4444\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 0.9401 - accuracy: 0.5814 - val_loss: 1.1501 - val_accuracy: 0.4444\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 0.9394 - accuracy: 0.5698 - val_loss: 1.1484 - val_accuracy: 0.4444\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 557us/sample - loss: 0.9363 - accuracy: 0.5814 - val_loss: 1.1466 - val_accuracy: 0.4222\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 0.9345 - accuracy: 0.5814 - val_loss: 1.1458 - val_accuracy: 0.4222\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 0.9311 - accuracy: 0.5814 - val_loss: 1.1448 - val_accuracy: 0.4222\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 0.9295 - accuracy: 0.5814 - val_loss: 1.1440 - val_accuracy: 0.4222\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 0.9269 - accuracy: 0.5814 - val_loss: 1.1421 - val_accuracy: 0.4222\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 610us/sample - loss: 0.9246 - accuracy: 0.5814 - val_loss: 1.1404 - val_accuracy: 0.4222\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 0.9232 - accuracy: 0.5814 - val_loss: 1.1383 - val_accuracy: 0.4222\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 0.9200 - accuracy: 0.5814 - val_loss: 1.1367 - val_accuracy: 0.4222\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.9190 - accuracy: 0.5814 - val_loss: 1.1362 - val_accuracy: 0.4222\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 521us/sample - loss: 0.9163 - accuracy: 0.5814 - val_loss: 1.1352 - val_accuracy: 0.4222\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 0.9150 - accuracy: 0.5814 - val_loss: 1.1342 - val_accuracy: 0.4222\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 0.9136 - accuracy: 0.5814 - val_loss: 1.1336 - val_accuracy: 0.4444\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 0.9107 - accuracy: 0.5930 - val_loss: 1.1323 - val_accuracy: 0.4444\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 0.9099 - accuracy: 0.5930 - val_loss: 1.1309 - val_accuracy: 0.4444\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 525us/sample - loss: 0.9080 - accuracy: 0.5930 - val_loss: 1.1299 - val_accuracy: 0.4444\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 535us/sample - loss: 0.9057 - accuracy: 0.5930 - val_loss: 1.1295 - val_accuracy: 0.4444\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 0.9038 - accuracy: 0.5930 - val_loss: 1.1290 - val_accuracy: 0.4444\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 0.9032 - accuracy: 0.6047 - val_loss: 1.1285 - val_accuracy: 0.4444\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 0.9004 - accuracy: 0.6163 - val_loss: 1.1283 - val_accuracy: 0.4444\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 0.8992 - accuracy: 0.6047 - val_loss: 1.1272 - val_accuracy: 0.4444\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.8984 - accuracy: 0.6047 - val_loss: 1.1265 - val_accuracy: 0.4444\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.8964 - accuracy: 0.6163 - val_loss: 1.1253 - val_accuracy: 0.4444\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 0.8946 - accuracy: 0.6047 - val_loss: 1.1232 - val_accuracy: 0.4444\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 0.8937 - accuracy: 0.6047 - val_loss: 1.1220 - val_accuracy: 0.4444\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.8911 - accuracy: 0.6047 - val_loss: 1.1208 - val_accuracy: 0.4444\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 385us/sample - loss: 0.8908 - accuracy: 0.6047 - val_loss: 1.1201 - val_accuracy: 0.4444\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 0.8880 - accuracy: 0.6047 - val_loss: 1.1199 - val_accuracy: 0.4444\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 587us/sample - loss: 0.8874 - accuracy: 0.6047 - val_loss: 1.1197 - val_accuracy: 0.4444\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 535us/sample - loss: 0.8859 - accuracy: 0.6047 - val_loss: 1.1192 - val_accuracy: 0.4444\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 0.8846 - accuracy: 0.5930 - val_loss: 1.1188 - val_accuracy: 0.4444\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 0.8835 - accuracy: 0.5930 - val_loss: 1.1180 - val_accuracy: 0.4444\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.8811 - accuracy: 0.6163 - val_loss: 1.1176 - val_accuracy: 0.4444\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.8800 - accuracy: 0.6047 - val_loss: 1.1172 - val_accuracy: 0.4444\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 0.8783 - accuracy: 0.6163 - val_loss: 1.1168 - val_accuracy: 0.4444\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.8771 - accuracy: 0.6047 - val_loss: 1.1151 - val_accuracy: 0.4444\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 0.8754 - accuracy: 0.6047 - val_loss: 1.1139 - val_accuracy: 0.4444\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.8732 - accuracy: 0.6047 - val_loss: 1.1143 - val_accuracy: 0.4444\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.8721 - accuracy: 0.6163 - val_loss: 1.1142 - val_accuracy: 0.4444\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.8696 - accuracy: 0.6047 - val_loss: 1.1138 - val_accuracy: 0.4222\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 496us/sample - loss: 0.8684 - accuracy: 0.6047 - val_loss: 1.1140 - val_accuracy: 0.4222\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.8664 - accuracy: 0.6047 - val_loss: 1.1140 - val_accuracy: 0.4222\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 554us/sample - loss: 0.8648 - accuracy: 0.6047 - val_loss: 1.1139 - val_accuracy: 0.4222\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 0.8628 - accuracy: 0.6047 - val_loss: 1.1139 - val_accuracy: 0.4000\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 0.8616 - accuracy: 0.6163 - val_loss: 1.1132 - val_accuracy: 0.4000\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 491us/sample - loss: 0.8603 - accuracy: 0.6163 - val_loss: 1.1123 - val_accuracy: 0.4000\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.8594 - accuracy: 0.6163 - val_loss: 1.1114 - val_accuracy: 0.4222\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 0.8575 - accuracy: 0.6279 - val_loss: 1.1113 - val_accuracy: 0.4000\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 0.8558 - accuracy: 0.6395 - val_loss: 1.1120 - val_accuracy: 0.4000\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.8542 - accuracy: 0.6279 - val_loss: 1.1125 - val_accuracy: 0.4000\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.6056 - accuracy: 0.3256 - val_loss: 2.9829 - val_accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 2.4129 - accuracy: 0.3140 - val_loss: 2.7804 - val_accuracy: 0.1556\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 2.2422 - accuracy: 0.3140 - val_loss: 2.6003 - val_accuracy: 0.1778\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 2.0960 - accuracy: 0.3372 - val_loss: 2.4468 - val_accuracy: 0.1778\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 1.9731 - accuracy: 0.3372 - val_loss: 2.3180 - val_accuracy: 0.2000\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 1.8697 - accuracy: 0.3488 - val_loss: 2.2047 - val_accuracy: 0.2222\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 529us/sample - loss: 1.7801 - accuracy: 0.3605 - val_loss: 2.1018 - val_accuracy: 0.2222\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.6967 - accuracy: 0.3605 - val_loss: 2.0134 - val_accuracy: 0.2444\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 1.6243 - accuracy: 0.3488 - val_loss: 1.9325 - val_accuracy: 0.2667\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 560us/sample - loss: 1.5563 - accuracy: 0.3721 - val_loss: 1.8583 - val_accuracy: 0.2667\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.4980 - accuracy: 0.3721 - val_loss: 1.7949 - val_accuracy: 0.3111\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.4465 - accuracy: 0.3953 - val_loss: 1.7406 - val_accuracy: 0.2889\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 1.4002 - accuracy: 0.4070 - val_loss: 1.6916 - val_accuracy: 0.3111\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 470us/sample - loss: 1.3603 - accuracy: 0.4186 - val_loss: 1.6478 - val_accuracy: 0.3111\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 505us/sample - loss: 1.3224 - accuracy: 0.4419 - val_loss: 1.6064 - val_accuracy: 0.3111\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.2896 - accuracy: 0.4302 - val_loss: 1.5714 - val_accuracy: 0.3111\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.2612 - accuracy: 0.4419 - val_loss: 1.5449 - val_accuracy: 0.3111\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 522us/sample - loss: 1.2338 - accuracy: 0.4419 - val_loss: 1.5181 - val_accuracy: 0.3111\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.2099 - accuracy: 0.4419 - val_loss: 1.4936 - val_accuracy: 0.3333\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.1883 - accuracy: 0.4419 - val_loss: 1.4723 - val_accuracy: 0.3556\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.1668 - accuracy: 0.4884 - val_loss: 1.4541 - val_accuracy: 0.3556\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.1494 - accuracy: 0.5000 - val_loss: 1.4386 - val_accuracy: 0.3778\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.1339 - accuracy: 0.5116 - val_loss: 1.4238 - val_accuracy: 0.4000\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.1166 - accuracy: 0.5116 - val_loss: 1.4084 - val_accuracy: 0.4000\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.1025 - accuracy: 0.5116 - val_loss: 1.3946 - val_accuracy: 0.4000\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.0884 - accuracy: 0.5116 - val_loss: 1.3813 - val_accuracy: 0.4222\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.0749 - accuracy: 0.5233 - val_loss: 1.3712 - val_accuracy: 0.4222\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.0644 - accuracy: 0.5233 - val_loss: 1.3606 - val_accuracy: 0.4667\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 470us/sample - loss: 1.0524 - accuracy: 0.5233 - val_loss: 1.3506 - val_accuracy: 0.4667\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 521us/sample - loss: 1.0418 - accuracy: 0.5233 - val_loss: 1.3410 - val_accuracy: 0.4667\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 1.0325 - accuracy: 0.5000 - val_loss: 1.3337 - val_accuracy: 0.4667\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0241 - accuracy: 0.5116 - val_loss: 1.3261 - val_accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.0164 - accuracy: 0.5233 - val_loss: 1.3187 - val_accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 1.0085 - accuracy: 0.5233 - val_loss: 1.3121 - val_accuracy: 0.4667\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 512us/sample - loss: 1.0026 - accuracy: 0.5233 - val_loss: 1.3061 - val_accuracy: 0.4667\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 0.9965 - accuracy: 0.5233 - val_loss: 1.3009 - val_accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9907 - accuracy: 0.5116 - val_loss: 1.2952 - val_accuracy: 0.4667\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 0.9848 - accuracy: 0.5116 - val_loss: 1.2894 - val_accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 0.9796 - accuracy: 0.5349 - val_loss: 1.2850 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 0.9743 - accuracy: 0.5465 - val_loss: 1.2819 - val_accuracy: 0.4444\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 502us/sample - loss: 0.9695 - accuracy: 0.5349 - val_loss: 1.2779 - val_accuracy: 0.4444\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 500us/sample - loss: 0.9658 - accuracy: 0.5465 - val_loss: 1.2738 - val_accuracy: 0.4444\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 550us/sample - loss: 0.9616 - accuracy: 0.5465 - val_loss: 1.2695 - val_accuracy: 0.4889\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 0.9576 - accuracy: 0.5581 - val_loss: 1.2666 - val_accuracy: 0.4889\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 530us/sample - loss: 0.9537 - accuracy: 0.5581 - val_loss: 1.2638 - val_accuracy: 0.4889\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 0.9496 - accuracy: 0.5581 - val_loss: 1.2605 - val_accuracy: 0.4889\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.9470 - accuracy: 0.5698 - val_loss: 1.2576 - val_accuracy: 0.4889\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9433 - accuracy: 0.5581 - val_loss: 1.2556 - val_accuracy: 0.4889\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 0.9394 - accuracy: 0.5698 - val_loss: 1.2536 - val_accuracy: 0.4889\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 0.9369 - accuracy: 0.5698 - val_loss: 1.2516 - val_accuracy: 0.4889\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 0.9335 - accuracy: 0.5698 - val_loss: 1.2493 - val_accuracy: 0.4889\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 0.9308 - accuracy: 0.5698 - val_loss: 1.2471 - val_accuracy: 0.4889\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 0.9276 - accuracy: 0.5698 - val_loss: 1.2446 - val_accuracy: 0.4889\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 0.9252 - accuracy: 0.5814 - val_loss: 1.2423 - val_accuracy: 0.4889\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 0.9230 - accuracy: 0.5581 - val_loss: 1.2414 - val_accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.9192 - accuracy: 0.5814 - val_loss: 1.2413 - val_accuracy: 0.4667\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.9166 - accuracy: 0.5930 - val_loss: 1.2392 - val_accuracy: 0.4667\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 0.9140 - accuracy: 0.5930 - val_loss: 1.2370 - val_accuracy: 0.4667\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 0.9113 - accuracy: 0.5930 - val_loss: 1.2350 - val_accuracy: 0.4667\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 595us/sample - loss: 0.9094 - accuracy: 0.5930 - val_loss: 1.2335 - val_accuracy: 0.4667\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9079 - accuracy: 0.5930 - val_loss: 1.2319 - val_accuracy: 0.4667\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 0.9055 - accuracy: 0.5930 - val_loss: 1.2312 - val_accuracy: 0.4667\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.9026 - accuracy: 0.5930 - val_loss: 1.2295 - val_accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 0.8998 - accuracy: 0.5930 - val_loss: 1.2286 - val_accuracy: 0.4667\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 502us/sample - loss: 0.8980 - accuracy: 0.5930 - val_loss: 1.2270 - val_accuracy: 0.4444\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 0.8956 - accuracy: 0.5930 - val_loss: 1.2249 - val_accuracy: 0.4444\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.8938 - accuracy: 0.5930 - val_loss: 1.2233 - val_accuracy: 0.4444\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.8913 - accuracy: 0.5930 - val_loss: 1.2215 - val_accuracy: 0.4444\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 0.8895 - accuracy: 0.6047 - val_loss: 1.2203 - val_accuracy: 0.4444\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 0.8891 - accuracy: 0.6047 - val_loss: 1.2186 - val_accuracy: 0.4444\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 0.8867 - accuracy: 0.6047 - val_loss: 1.2167 - val_accuracy: 0.4444\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.8844 - accuracy: 0.6047 - val_loss: 1.2154 - val_accuracy: 0.4444\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.8825 - accuracy: 0.5930 - val_loss: 1.2156 - val_accuracy: 0.4444\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.8796 - accuracy: 0.6047 - val_loss: 1.2157 - val_accuracy: 0.4667\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.8788 - accuracy: 0.6163 - val_loss: 1.2156 - val_accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 521us/sample - loss: 0.8771 - accuracy: 0.6279 - val_loss: 1.2153 - val_accuracy: 0.4667\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 0.8751 - accuracy: 0.6163 - val_loss: 1.2140 - val_accuracy: 0.4667\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.8735 - accuracy: 0.6395 - val_loss: 1.2132 - val_accuracy: 0.4667\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 0.8720 - accuracy: 0.6279 - val_loss: 1.2131 - val_accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.8704 - accuracy: 0.6395 - val_loss: 1.2113 - val_accuracy: 0.4667\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 0.8690 - accuracy: 0.6395 - val_loss: 1.2107 - val_accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 0.8676 - accuracy: 0.6395 - val_loss: 1.2099 - val_accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 0.8656 - accuracy: 0.6395 - val_loss: 1.2095 - val_accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.8645 - accuracy: 0.6395 - val_loss: 1.2089 - val_accuracy: 0.4667\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 718us/sample - loss: 0.8620 - accuracy: 0.6395 - val_loss: 1.2084 - val_accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 0.8607 - accuracy: 0.6395 - val_loss: 1.2084 - val_accuracy: 0.4667\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 0.8600 - accuracy: 0.6512 - val_loss: 1.2084 - val_accuracy: 0.4667\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 0.8592 - accuracy: 0.6279 - val_loss: 1.2092 - val_accuracy: 0.4667\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 0.8571 - accuracy: 0.6395 - val_loss: 1.2097 - val_accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 0.8561 - accuracy: 0.6395 - val_loss: 1.2095 - val_accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.8555 - accuracy: 0.6279 - val_loss: 1.2083 - val_accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.8532 - accuracy: 0.6395 - val_loss: 1.2077 - val_accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.8520 - accuracy: 0.6395 - val_loss: 1.2069 - val_accuracy: 0.4667\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.8506 - accuracy: 0.6395 - val_loss: 1.2067 - val_accuracy: 0.4667\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 0.8516 - accuracy: 0.6395 - val_loss: 1.2067 - val_accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 0.8479 - accuracy: 0.6395 - val_loss: 1.2057 - val_accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.8473 - accuracy: 0.6395 - val_loss: 1.2069 - val_accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 0.8456 - accuracy: 0.6395 - val_loss: 1.2077 - val_accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 0.8452 - accuracy: 0.6395 - val_loss: 1.2075 - val_accuracy: 0.4444\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 0.8431 - accuracy: 0.6395 - val_loss: 1.2072 - val_accuracy: 0.4444\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 5ms/sample - loss: 2.0089 - accuracy: 0.3256 - val_loss: 1.8736 - val_accuracy: 0.3778\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.9022 - accuracy: 0.3023 - val_loss: 1.7766 - val_accuracy: 0.3556\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.8066 - accuracy: 0.3023 - val_loss: 1.6953 - val_accuracy: 0.3556\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 1.7267 - accuracy: 0.3023 - val_loss: 1.6259 - val_accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.6523 - accuracy: 0.3023 - val_loss: 1.5658 - val_accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.5858 - accuracy: 0.3023 - val_loss: 1.5159 - val_accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.5274 - accuracy: 0.3023 - val_loss: 1.4774 - val_accuracy: 0.2889\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.4781 - accuracy: 0.2907 - val_loss: 1.4450 - val_accuracy: 0.2889\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 1.4321 - accuracy: 0.2907 - val_loss: 1.4186 - val_accuracy: 0.2889\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.3921 - accuracy: 0.3023 - val_loss: 1.3970 - val_accuracy: 0.2889\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.3576 - accuracy: 0.3023 - val_loss: 1.3799 - val_accuracy: 0.2889\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 405us/sample - loss: 1.3245 - accuracy: 0.3023 - val_loss: 1.3655 - val_accuracy: 0.2667\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 422us/sample - loss: 1.2987 - accuracy: 0.2907 - val_loss: 1.3526 - val_accuracy: 0.2889\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.2753 - accuracy: 0.2907 - val_loss: 1.3418 - val_accuracy: 0.3111\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 528us/sample - loss: 1.2540 - accuracy: 0.2907 - val_loss: 1.3322 - val_accuracy: 0.3111\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.2349 - accuracy: 0.3023 - val_loss: 1.3242 - val_accuracy: 0.2889\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 1.2188 - accuracy: 0.3140 - val_loss: 1.3165 - val_accuracy: 0.2889\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.2000 - accuracy: 0.3140 - val_loss: 1.3082 - val_accuracy: 0.2889\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.1868 - accuracy: 0.3140 - val_loss: 1.2998 - val_accuracy: 0.2889\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.1746 - accuracy: 0.3256 - val_loss: 1.2908 - val_accuracy: 0.2889\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 1.1633 - accuracy: 0.3372 - val_loss: 1.2832 - val_accuracy: 0.3111\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 1.1540 - accuracy: 0.3605 - val_loss: 1.2767 - val_accuracy: 0.2889\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1423 - accuracy: 0.3837 - val_loss: 1.2701 - val_accuracy: 0.2889\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.1335 - accuracy: 0.3837 - val_loss: 1.2648 - val_accuracy: 0.3111\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.1255 - accuracy: 0.3837 - val_loss: 1.2578 - val_accuracy: 0.3111\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.1161 - accuracy: 0.3488 - val_loss: 1.2514 - val_accuracy: 0.3333\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.1093 - accuracy: 0.3721 - val_loss: 1.2456 - val_accuracy: 0.3333\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.1006 - accuracy: 0.3837 - val_loss: 1.2391 - val_accuracy: 0.3556\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.0936 - accuracy: 0.3953 - val_loss: 1.2332 - val_accuracy: 0.3556\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.0864 - accuracy: 0.4302 - val_loss: 1.2274 - val_accuracy: 0.3778\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.0803 - accuracy: 0.4651 - val_loss: 1.2231 - val_accuracy: 0.3778\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.0745 - accuracy: 0.4767 - val_loss: 1.2199 - val_accuracy: 0.4000\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.0677 - accuracy: 0.4767 - val_loss: 1.2163 - val_accuracy: 0.4000\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 1.0632 - accuracy: 0.4767 - val_loss: 1.2121 - val_accuracy: 0.4000\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 1.0567 - accuracy: 0.4767 - val_loss: 1.2074 - val_accuracy: 0.4222\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 1.0511 - accuracy: 0.4767 - val_loss: 1.2034 - val_accuracy: 0.4222\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 1.0460 - accuracy: 0.4767 - val_loss: 1.1990 - val_accuracy: 0.4444\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.0416 - accuracy: 0.4884 - val_loss: 1.1963 - val_accuracy: 0.4889\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.0362 - accuracy: 0.4884 - val_loss: 1.1933 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.0327 - accuracy: 0.4884 - val_loss: 1.1897 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.0282 - accuracy: 0.4884 - val_loss: 1.1871 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.0230 - accuracy: 0.4884 - val_loss: 1.1837 - val_accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.0186 - accuracy: 0.5116 - val_loss: 1.1805 - val_accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 1.0157 - accuracy: 0.5116 - val_loss: 1.1762 - val_accuracy: 0.4667\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 1.0117 - accuracy: 0.5116 - val_loss: 1.1714 - val_accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.0079 - accuracy: 0.5116 - val_loss: 1.1689 - val_accuracy: 0.4444\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 495us/sample - loss: 1.0037 - accuracy: 0.5233 - val_loss: 1.1660 - val_accuracy: 0.4444\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 1.0001 - accuracy: 0.5233 - val_loss: 1.1628 - val_accuracy: 0.4222\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 547us/sample - loss: 0.9977 - accuracy: 0.5233 - val_loss: 1.1600 - val_accuracy: 0.4222\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.9937 - accuracy: 0.5233 - val_loss: 1.1585 - val_accuracy: 0.4222\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.9907 - accuracy: 0.5233 - val_loss: 1.1562 - val_accuracy: 0.4222\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9884 - accuracy: 0.5349 - val_loss: 1.1540 - val_accuracy: 0.4222\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9845 - accuracy: 0.5233 - val_loss: 1.1525 - val_accuracy: 0.4222\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 0.9815 - accuracy: 0.5349 - val_loss: 1.1517 - val_accuracy: 0.4222\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 0.9785 - accuracy: 0.5349 - val_loss: 1.1505 - val_accuracy: 0.4222\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 0.9747 - accuracy: 0.5581 - val_loss: 1.1492 - val_accuracy: 0.4444\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9721 - accuracy: 0.5465 - val_loss: 1.1458 - val_accuracy: 0.4667\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.9698 - accuracy: 0.5581 - val_loss: 1.1422 - val_accuracy: 0.4667\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.9674 - accuracy: 0.5581 - val_loss: 1.1387 - val_accuracy: 0.4667\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.9645 - accuracy: 0.5698 - val_loss: 1.1367 - val_accuracy: 0.4667\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9626 - accuracy: 0.5698 - val_loss: 1.1345 - val_accuracy: 0.4667\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 515us/sample - loss: 0.9589 - accuracy: 0.5698 - val_loss: 1.1337 - val_accuracy: 0.4667\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 0.9573 - accuracy: 0.5698 - val_loss: 1.1341 - val_accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 0.9559 - accuracy: 0.5581 - val_loss: 1.1318 - val_accuracy: 0.4667\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 0.9533 - accuracy: 0.5581 - val_loss: 1.1298 - val_accuracy: 0.4667\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 0.9507 - accuracy: 0.5930 - val_loss: 1.1285 - val_accuracy: 0.4444\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.9486 - accuracy: 0.5814 - val_loss: 1.1274 - val_accuracy: 0.4444\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 559us/sample - loss: 0.9476 - accuracy: 0.5814 - val_loss: 1.1266 - val_accuracy: 0.4444\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 0.9454 - accuracy: 0.5581 - val_loss: 1.1257 - val_accuracy: 0.4444\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.9438 - accuracy: 0.5814 - val_loss: 1.1237 - val_accuracy: 0.4444\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.9425 - accuracy: 0.5814 - val_loss: 1.1225 - val_accuracy: 0.4444\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 0.9402 - accuracy: 0.5814 - val_loss: 1.1223 - val_accuracy: 0.4444\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 0.9382 - accuracy: 0.5814 - val_loss: 1.1213 - val_accuracy: 0.4444\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.9370 - accuracy: 0.5814 - val_loss: 1.1203 - val_accuracy: 0.4444\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.9345 - accuracy: 0.5814 - val_loss: 1.1197 - val_accuracy: 0.4444\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9341 - accuracy: 0.5814 - val_loss: 1.1197 - val_accuracy: 0.4444\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.9314 - accuracy: 0.5814 - val_loss: 1.1199 - val_accuracy: 0.4444\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9306 - accuracy: 0.5814 - val_loss: 1.1189 - val_accuracy: 0.4444\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 0.9290 - accuracy: 0.5930 - val_loss: 1.1174 - val_accuracy: 0.4444\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.9284 - accuracy: 0.5814 - val_loss: 1.1154 - val_accuracy: 0.4444\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 0.9264 - accuracy: 0.5814 - val_loss: 1.1137 - val_accuracy: 0.4444\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.9246 - accuracy: 0.5814 - val_loss: 1.1119 - val_accuracy: 0.4444\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.9238 - accuracy: 0.5814 - val_loss: 1.1106 - val_accuracy: 0.4444\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9227 - accuracy: 0.5814 - val_loss: 1.1103 - val_accuracy: 0.4444\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 0.9221 - accuracy: 0.5814 - val_loss: 1.1092 - val_accuracy: 0.4444\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.9203 - accuracy: 0.5814 - val_loss: 1.1078 - val_accuracy: 0.4667\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9193 - accuracy: 0.5814 - val_loss: 1.1079 - val_accuracy: 0.4667\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 0.9180 - accuracy: 0.5814 - val_loss: 1.1075 - val_accuracy: 0.4667\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 0.9165 - accuracy: 0.5930 - val_loss: 1.1072 - val_accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 575us/sample - loss: 0.9158 - accuracy: 0.5930 - val_loss: 1.1070 - val_accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.9148 - accuracy: 0.5930 - val_loss: 1.1066 - val_accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 512us/sample - loss: 0.9138 - accuracy: 0.5814 - val_loss: 1.1048 - val_accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 618us/sample - loss: 0.9128 - accuracy: 0.5930 - val_loss: 1.1028 - val_accuracy: 0.4667\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 513us/sample - loss: 0.9115 - accuracy: 0.6047 - val_loss: 1.1016 - val_accuracy: 0.4667\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 547us/sample - loss: 0.9110 - accuracy: 0.5930 - val_loss: 1.1019 - val_accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.9093 - accuracy: 0.6047 - val_loss: 1.1032 - val_accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.9077 - accuracy: 0.6047 - val_loss: 1.1025 - val_accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 0.9070 - accuracy: 0.6047 - val_loss: 1.1018 - val_accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9065 - accuracy: 0.6047 - val_loss: 1.1019 - val_accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9053 - accuracy: 0.6047 - val_loss: 1.1023 - val_accuracy: 0.4667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 7</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.4814814627170563</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 5ms/sample - loss: 2.7410 - accuracy: 0.2558 - val_loss: 2.2713 - val_accuracy: 0.1556\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 2.5592 - accuracy: 0.2558 - val_loss: 2.1437 - val_accuracy: 0.1556\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 2.3953 - accuracy: 0.2558 - val_loss: 2.0338 - val_accuracy: 0.1556\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 2.2541 - accuracy: 0.2558 - val_loss: 1.9368 - val_accuracy: 0.1556\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 2.1251 - accuracy: 0.2558 - val_loss: 1.8509 - val_accuracy: 0.1556\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 2.0128 - accuracy: 0.2791 - val_loss: 1.7793 - val_accuracy: 0.1556\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 500us/sample - loss: 1.9151 - accuracy: 0.3140 - val_loss: 1.7119 - val_accuracy: 0.2000\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 513us/sample - loss: 1.8271 - accuracy: 0.3488 - val_loss: 1.6523 - val_accuracy: 0.2444\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.7491 - accuracy: 0.4070 - val_loss: 1.5987 - val_accuracy: 0.2444\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 558us/sample - loss: 1.6821 - accuracy: 0.4070 - val_loss: 1.5513 - val_accuracy: 0.2667\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.6213 - accuracy: 0.4070 - val_loss: 1.5098 - val_accuracy: 0.2667\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 526us/sample - loss: 1.5661 - accuracy: 0.4302 - val_loss: 1.4724 - val_accuracy: 0.2889\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.5174 - accuracy: 0.4302 - val_loss: 1.4414 - val_accuracy: 0.2889\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 519us/sample - loss: 1.4745 - accuracy: 0.4302 - val_loss: 1.4132 - val_accuracy: 0.3111\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 516us/sample - loss: 1.4345 - accuracy: 0.4302 - val_loss: 1.3883 - val_accuracy: 0.3556\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 1.3979 - accuracy: 0.4535 - val_loss: 1.3653 - val_accuracy: 0.3556\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 519us/sample - loss: 1.3661 - accuracy: 0.4535 - val_loss: 1.3446 - val_accuracy: 0.4222\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.3329 - accuracy: 0.4535 - val_loss: 1.3255 - val_accuracy: 0.4222\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.3034 - accuracy: 0.4651 - val_loss: 1.3086 - val_accuracy: 0.4222\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.2779 - accuracy: 0.4767 - val_loss: 1.2932 - val_accuracy: 0.4222\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 371us/sample - loss: 1.2520 - accuracy: 0.4651 - val_loss: 1.2791 - val_accuracy: 0.4222\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.2315 - accuracy: 0.4651 - val_loss: 1.2672 - val_accuracy: 0.4222\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 522us/sample - loss: 1.2124 - accuracy: 0.4651 - val_loss: 1.2560 - val_accuracy: 0.4444\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 568us/sample - loss: 1.1929 - accuracy: 0.4767 - val_loss: 1.2453 - val_accuracy: 0.4667\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.1750 - accuracy: 0.4767 - val_loss: 1.2357 - val_accuracy: 0.4667\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.1571 - accuracy: 0.4884 - val_loss: 1.2264 - val_accuracy: 0.4444\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.1422 - accuracy: 0.4884 - val_loss: 1.2181 - val_accuracy: 0.4444\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.1283 - accuracy: 0.5000 - val_loss: 1.2114 - val_accuracy: 0.4444\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.1154 - accuracy: 0.4884 - val_loss: 1.2054 - val_accuracy: 0.4444\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 1.1041 - accuracy: 0.5000 - val_loss: 1.1994 - val_accuracy: 0.4444\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.0933 - accuracy: 0.4884 - val_loss: 1.1942 - val_accuracy: 0.4444\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.0820 - accuracy: 0.4884 - val_loss: 1.1896 - val_accuracy: 0.4222\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.0731 - accuracy: 0.5000 - val_loss: 1.1853 - val_accuracy: 0.4444\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.0645 - accuracy: 0.5233 - val_loss: 1.1811 - val_accuracy: 0.4444\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 1.0547 - accuracy: 0.5233 - val_loss: 1.1772 - val_accuracy: 0.4444\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.0469 - accuracy: 0.5233 - val_loss: 1.1736 - val_accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.0394 - accuracy: 0.5116 - val_loss: 1.1700 - val_accuracy: 0.4667\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.0323 - accuracy: 0.5233 - val_loss: 1.1664 - val_accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 571us/sample - loss: 1.0254 - accuracy: 0.5349 - val_loss: 1.1637 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 1.0191 - accuracy: 0.5465 - val_loss: 1.1606 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 405us/sample - loss: 1.0123 - accuracy: 0.5465 - val_loss: 1.1576 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 527us/sample - loss: 1.0070 - accuracy: 0.5581 - val_loss: 1.1555 - val_accuracy: 0.4889\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 1.0010 - accuracy: 0.5581 - val_loss: 1.1533 - val_accuracy: 0.4889\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 0.9957 - accuracy: 0.5581 - val_loss: 1.1515 - val_accuracy: 0.4889\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.9909 - accuracy: 0.5698 - val_loss: 1.1498 - val_accuracy: 0.4889\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9866 - accuracy: 0.5814 - val_loss: 1.1476 - val_accuracy: 0.4889\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 0.9815 - accuracy: 0.5814 - val_loss: 1.1459 - val_accuracy: 0.4889\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 0.9774 - accuracy: 0.5814 - val_loss: 1.1442 - val_accuracy: 0.4889\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 493us/sample - loss: 0.9722 - accuracy: 0.5814 - val_loss: 1.1423 - val_accuracy: 0.4889\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 0.9682 - accuracy: 0.5814 - val_loss: 1.1406 - val_accuracy: 0.4889\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 540us/sample - loss: 0.9641 - accuracy: 0.5814 - val_loss: 1.1388 - val_accuracy: 0.4889\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 0.9603 - accuracy: 0.6047 - val_loss: 1.1371 - val_accuracy: 0.4889\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 0.9570 - accuracy: 0.6047 - val_loss: 1.1356 - val_accuracy: 0.4889\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.9535 - accuracy: 0.6047 - val_loss: 1.1343 - val_accuracy: 0.4889\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9494 - accuracy: 0.6047 - val_loss: 1.1331 - val_accuracy: 0.4889\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 0.9465 - accuracy: 0.6047 - val_loss: 1.1319 - val_accuracy: 0.4889\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 505us/sample - loss: 0.9432 - accuracy: 0.6047 - val_loss: 1.1309 - val_accuracy: 0.4889\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9402 - accuracy: 0.6163 - val_loss: 1.1297 - val_accuracy: 0.4889\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 0.9366 - accuracy: 0.6163 - val_loss: 1.1287 - val_accuracy: 0.4889\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 0.9339 - accuracy: 0.6163 - val_loss: 1.1275 - val_accuracy: 0.4889\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 0.9311 - accuracy: 0.6163 - val_loss: 1.1266 - val_accuracy: 0.4889\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.9281 - accuracy: 0.6163 - val_loss: 1.1253 - val_accuracy: 0.4889\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 0.9255 - accuracy: 0.6163 - val_loss: 1.1242 - val_accuracy: 0.4889\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 0.9228 - accuracy: 0.6279 - val_loss: 1.1233 - val_accuracy: 0.4889\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 396us/sample - loss: 0.9203 - accuracy: 0.6279 - val_loss: 1.1227 - val_accuracy: 0.4889\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 402us/sample - loss: 0.9184 - accuracy: 0.6279 - val_loss: 1.1219 - val_accuracy: 0.4889\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 0.9155 - accuracy: 0.6279 - val_loss: 1.1211 - val_accuracy: 0.4889\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 408us/sample - loss: 0.9133 - accuracy: 0.6279 - val_loss: 1.1204 - val_accuracy: 0.4889\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 0.9112 - accuracy: 0.6279 - val_loss: 1.1195 - val_accuracy: 0.4889\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9081 - accuracy: 0.6279 - val_loss: 1.1183 - val_accuracy: 0.4889\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.9061 - accuracy: 0.6279 - val_loss: 1.1174 - val_accuracy: 0.4889\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9042 - accuracy: 0.6279 - val_loss: 1.1166 - val_accuracy: 0.4889\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 0.9022 - accuracy: 0.6279 - val_loss: 1.1157 - val_accuracy: 0.4889\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 504us/sample - loss: 0.9004 - accuracy: 0.6163 - val_loss: 1.1150 - val_accuracy: 0.4889\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.8986 - accuracy: 0.6395 - val_loss: 1.1143 - val_accuracy: 0.4889\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.8969 - accuracy: 0.6395 - val_loss: 1.1133 - val_accuracy: 0.4889\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 522us/sample - loss: 0.8948 - accuracy: 0.6279 - val_loss: 1.1128 - val_accuracy: 0.4889\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 528us/sample - loss: 0.8929 - accuracy: 0.6279 - val_loss: 1.1122 - val_accuracy: 0.4889\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 533us/sample - loss: 0.8913 - accuracy: 0.6279 - val_loss: 1.1115 - val_accuracy: 0.4889\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 0.8900 - accuracy: 0.6279 - val_loss: 1.1107 - val_accuracy: 0.4889\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 0.8884 - accuracy: 0.6163 - val_loss: 1.1098 - val_accuracy: 0.4889\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 0.8867 - accuracy: 0.6163 - val_loss: 1.1092 - val_accuracy: 0.4889\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.8844 - accuracy: 0.6163 - val_loss: 1.1083 - val_accuracy: 0.4889\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 0.8834 - accuracy: 0.6163 - val_loss: 1.1077 - val_accuracy: 0.4889\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 539us/sample - loss: 0.8816 - accuracy: 0.6163 - val_loss: 1.1071 - val_accuracy: 0.4889\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 0.8796 - accuracy: 0.6163 - val_loss: 1.1067 - val_accuracy: 0.4889\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 0.8790 - accuracy: 0.6047 - val_loss: 1.1064 - val_accuracy: 0.4889\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.8772 - accuracy: 0.6163 - val_loss: 1.1058 - val_accuracy: 0.4889\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 0.8758 - accuracy: 0.6163 - val_loss: 1.1053 - val_accuracy: 0.4889\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 0.8743 - accuracy: 0.6047 - val_loss: 1.1047 - val_accuracy: 0.4889\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.8731 - accuracy: 0.5930 - val_loss: 1.1042 - val_accuracy: 0.4889\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.8724 - accuracy: 0.6047 - val_loss: 1.1037 - val_accuracy: 0.4889\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 0.8708 - accuracy: 0.6047 - val_loss: 1.1031 - val_accuracy: 0.4889\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 0.8698 - accuracy: 0.6047 - val_loss: 1.1027 - val_accuracy: 0.4889\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 0.8685 - accuracy: 0.6163 - val_loss: 1.1025 - val_accuracy: 0.4889\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 522us/sample - loss: 0.8669 - accuracy: 0.6047 - val_loss: 1.1021 - val_accuracy: 0.5111\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 0.8653 - accuracy: 0.6047 - val_loss: 1.1017 - val_accuracy: 0.5111\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 618us/sample - loss: 0.8643 - accuracy: 0.6279 - val_loss: 1.1011 - val_accuracy: 0.5111\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 0.8635 - accuracy: 0.6163 - val_loss: 1.1008 - val_accuracy: 0.5111\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 523us/sample - loss: 0.8620 - accuracy: 0.6163 - val_loss: 1.1005 - val_accuracy: 0.5111\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.4906 - accuracy: 0.2326 - val_loss: 1.7819 - val_accuracy: 0.1778\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 2.3019 - accuracy: 0.2209 - val_loss: 1.7185 - val_accuracy: 0.1333\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 495us/sample - loss: 2.1454 - accuracy: 0.2209 - val_loss: 1.6674 - val_accuracy: 0.1333\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 2.0116 - accuracy: 0.2326 - val_loss: 1.6202 - val_accuracy: 0.1556\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.8920 - accuracy: 0.2442 - val_loss: 1.5796 - val_accuracy: 0.1556\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 1.7970 - accuracy: 0.2674 - val_loss: 1.5438 - val_accuracy: 0.1778\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 1.7119 - accuracy: 0.2791 - val_loss: 1.5136 - val_accuracy: 0.2000\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.6411 - accuracy: 0.3023 - val_loss: 1.4866 - val_accuracy: 0.2000\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 1.5807 - accuracy: 0.2907 - val_loss: 1.4618 - val_accuracy: 0.2000\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.5245 - accuracy: 0.3256 - val_loss: 1.4384 - val_accuracy: 0.2222\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 1.4693 - accuracy: 0.2907 - val_loss: 1.4150 - val_accuracy: 0.2444\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 533us/sample - loss: 1.4183 - accuracy: 0.2791 - val_loss: 1.3933 - val_accuracy: 0.2667\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.3748 - accuracy: 0.2907 - val_loss: 1.3759 - val_accuracy: 0.2667\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.3350 - accuracy: 0.3140 - val_loss: 1.3612 - val_accuracy: 0.2444\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.3002 - accuracy: 0.3372 - val_loss: 1.3493 - val_accuracy: 0.2667\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.2677 - accuracy: 0.3488 - val_loss: 1.3376 - val_accuracy: 0.2889\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.2396 - accuracy: 0.3488 - val_loss: 1.3266 - val_accuracy: 0.2889\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.2122 - accuracy: 0.3605 - val_loss: 1.3151 - val_accuracy: 0.2889\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.1881 - accuracy: 0.3721 - val_loss: 1.3049 - val_accuracy: 0.2444\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 431us/sample - loss: 1.1664 - accuracy: 0.3953 - val_loss: 1.2956 - val_accuracy: 0.2444\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 508us/sample - loss: 1.1460 - accuracy: 0.3953 - val_loss: 1.2884 - val_accuracy: 0.2444\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 1.1280 - accuracy: 0.4302 - val_loss: 1.2821 - val_accuracy: 0.2667\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 1.1129 - accuracy: 0.4651 - val_loss: 1.2749 - val_accuracy: 0.2667\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.0981 - accuracy: 0.4651 - val_loss: 1.2689 - val_accuracy: 0.2667\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 542us/sample - loss: 1.0865 - accuracy: 0.4767 - val_loss: 1.2637 - val_accuracy: 0.2667\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.0734 - accuracy: 0.4884 - val_loss: 1.2578 - val_accuracy: 0.2667\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.0627 - accuracy: 0.5000 - val_loss: 1.2521 - val_accuracy: 0.2667\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.0541 - accuracy: 0.4884 - val_loss: 1.2482 - val_accuracy: 0.2667\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 514us/sample - loss: 1.0459 - accuracy: 0.4767 - val_loss: 1.2446 - val_accuracy: 0.2667\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.0389 - accuracy: 0.4651 - val_loss: 1.2403 - val_accuracy: 0.3111\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.0296 - accuracy: 0.4767 - val_loss: 1.2372 - val_accuracy: 0.3111\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.0233 - accuracy: 0.4767 - val_loss: 1.2352 - val_accuracy: 0.3111\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 1.0157 - accuracy: 0.4884 - val_loss: 1.2322 - val_accuracy: 0.3333\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 1.0093 - accuracy: 0.5000 - val_loss: 1.2288 - val_accuracy: 0.3556\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.0045 - accuracy: 0.5000 - val_loss: 1.2265 - val_accuracy: 0.3556\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 515us/sample - loss: 0.9982 - accuracy: 0.5000 - val_loss: 1.2249 - val_accuracy: 0.3556\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 0.9928 - accuracy: 0.5233 - val_loss: 1.2226 - val_accuracy: 0.3556\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 517us/sample - loss: 0.9883 - accuracy: 0.5233 - val_loss: 1.2205 - val_accuracy: 0.3556\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 0.9845 - accuracy: 0.5233 - val_loss: 1.2190 - val_accuracy: 0.3556\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9789 - accuracy: 0.5465 - val_loss: 1.2180 - val_accuracy: 0.3556\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 531us/sample - loss: 0.9755 - accuracy: 0.5581 - val_loss: 1.2160 - val_accuracy: 0.3778\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 529us/sample - loss: 0.9706 - accuracy: 0.5698 - val_loss: 1.2137 - val_accuracy: 0.3778\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 0.9685 - accuracy: 0.5581 - val_loss: 1.2125 - val_accuracy: 0.4000\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 0.9650 - accuracy: 0.5698 - val_loss: 1.2113 - val_accuracy: 0.4000\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.9605 - accuracy: 0.5698 - val_loss: 1.2093 - val_accuracy: 0.4000\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 0.9582 - accuracy: 0.5698 - val_loss: 1.2082 - val_accuracy: 0.4000\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 455us/sample - loss: 0.9544 - accuracy: 0.5698 - val_loss: 1.2072 - val_accuracy: 0.4000\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 0.9512 - accuracy: 0.5698 - val_loss: 1.2064 - val_accuracy: 0.4000\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 495us/sample - loss: 0.9473 - accuracy: 0.5698 - val_loss: 1.2060 - val_accuracy: 0.4000\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9452 - accuracy: 0.5814 - val_loss: 1.2049 - val_accuracy: 0.4000\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 0.9413 - accuracy: 0.5814 - val_loss: 1.2040 - val_accuracy: 0.4000\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 543us/sample - loss: 0.9390 - accuracy: 0.5814 - val_loss: 1.2030 - val_accuracy: 0.4000\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9371 - accuracy: 0.5930 - val_loss: 1.2023 - val_accuracy: 0.4000\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.9346 - accuracy: 0.5930 - val_loss: 1.2010 - val_accuracy: 0.4000\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.9310 - accuracy: 0.5930 - val_loss: 1.2010 - val_accuracy: 0.4000\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 0.9288 - accuracy: 0.6047 - val_loss: 1.2011 - val_accuracy: 0.4000\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 599us/sample - loss: 0.9268 - accuracy: 0.6047 - val_loss: 1.1998 - val_accuracy: 0.4000\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9242 - accuracy: 0.6163 - val_loss: 1.1990 - val_accuracy: 0.4222\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 0.9226 - accuracy: 0.6279 - val_loss: 1.1980 - val_accuracy: 0.4222\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 0.9195 - accuracy: 0.6279 - val_loss: 1.1964 - val_accuracy: 0.4222\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 0.9183 - accuracy: 0.6279 - val_loss: 1.1952 - val_accuracy: 0.4222\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.9160 - accuracy: 0.6279 - val_loss: 1.1956 - val_accuracy: 0.4444\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 0.9139 - accuracy: 0.6163 - val_loss: 1.1940 - val_accuracy: 0.4444\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 409us/sample - loss: 0.9113 - accuracy: 0.6395 - val_loss: 1.1927 - val_accuracy: 0.4444\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.9084 - accuracy: 0.6279 - val_loss: 1.1917 - val_accuracy: 0.4444\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 514us/sample - loss: 0.9073 - accuracy: 0.6395 - val_loss: 1.1920 - val_accuracy: 0.4444\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 0.9049 - accuracy: 0.6395 - val_loss: 1.1929 - val_accuracy: 0.4444\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 516us/sample - loss: 0.9029 - accuracy: 0.6512 - val_loss: 1.1935 - val_accuracy: 0.4444\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 0.9006 - accuracy: 0.6395 - val_loss: 1.1937 - val_accuracy: 0.4444\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.8989 - accuracy: 0.6395 - val_loss: 1.1935 - val_accuracy: 0.4444\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 628us/sample - loss: 0.8971 - accuracy: 0.6395 - val_loss: 1.1938 - val_accuracy: 0.4444\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 556us/sample - loss: 0.8959 - accuracy: 0.6628 - val_loss: 1.1944 - val_accuracy: 0.4444\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 545us/sample - loss: 0.8941 - accuracy: 0.6395 - val_loss: 1.1937 - val_accuracy: 0.4667\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 0.8926 - accuracy: 0.6279 - val_loss: 1.1931 - val_accuracy: 0.4667\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 0.8907 - accuracy: 0.6279 - val_loss: 1.1940 - val_accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 0.8888 - accuracy: 0.6279 - val_loss: 1.1944 - val_accuracy: 0.4667\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 0.8868 - accuracy: 0.6395 - val_loss: 1.1949 - val_accuracy: 0.4667\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 380us/sample - loss: 0.8855 - accuracy: 0.6279 - val_loss: 1.1948 - val_accuracy: 0.4667\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 0.8837 - accuracy: 0.6395 - val_loss: 1.1943 - val_accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.8822 - accuracy: 0.6395 - val_loss: 1.1945 - val_accuracy: 0.4667\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 0.8814 - accuracy: 0.6628 - val_loss: 1.1942 - val_accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 521us/sample - loss: 0.8795 - accuracy: 0.6628 - val_loss: 1.1950 - val_accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 391us/sample - loss: 0.8773 - accuracy: 0.6628 - val_loss: 1.1955 - val_accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 0.8754 - accuracy: 0.6628 - val_loss: 1.1953 - val_accuracy: 0.4667\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 0.8739 - accuracy: 0.6628 - val_loss: 1.1942 - val_accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 398us/sample - loss: 0.8731 - accuracy: 0.6628 - val_loss: 1.1935 - val_accuracy: 0.4667\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 0.8707 - accuracy: 0.6628 - val_loss: 1.1928 - val_accuracy: 0.4667\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 0.8693 - accuracy: 0.6744 - val_loss: 1.1932 - val_accuracy: 0.4667\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 0.8677 - accuracy: 0.6744 - val_loss: 1.1937 - val_accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.8661 - accuracy: 0.6628 - val_loss: 1.1945 - val_accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.8646 - accuracy: 0.6744 - val_loss: 1.1943 - val_accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 0.8628 - accuracy: 0.6744 - val_loss: 1.1936 - val_accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 0.8612 - accuracy: 0.6744 - val_loss: 1.1933 - val_accuracy: 0.4667\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 0.8603 - accuracy: 0.6628 - val_loss: 1.1940 - val_accuracy: 0.4667\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 0.8582 - accuracy: 0.6628 - val_loss: 1.1949 - val_accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.8575 - accuracy: 0.6512 - val_loss: 1.1956 - val_accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 0.8558 - accuracy: 0.6628 - val_loss: 1.1965 - val_accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 0.8542 - accuracy: 0.6628 - val_loss: 1.1973 - val_accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 0.8534 - accuracy: 0.6512 - val_loss: 1.1973 - val_accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.8519 - accuracy: 0.6512 - val_loss: 1.1977 - val_accuracy: 0.4667\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.2517 - accuracy: 0.3023 - val_loss: 1.7872 - val_accuracy: 0.3556\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 2.1362 - accuracy: 0.3140 - val_loss: 1.7227 - val_accuracy: 0.3778\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 2.0297 - accuracy: 0.3140 - val_loss: 1.6652 - val_accuracy: 0.3778\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.9339 - accuracy: 0.3256 - val_loss: 1.6148 - val_accuracy: 0.3778\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.8513 - accuracy: 0.3372 - val_loss: 1.5671 - val_accuracy: 0.3778\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.7780 - accuracy: 0.3488 - val_loss: 1.5232 - val_accuracy: 0.3778\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.7070 - accuracy: 0.3605 - val_loss: 1.4801 - val_accuracy: 0.3778\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 1.6462 - accuracy: 0.3605 - val_loss: 1.4431 - val_accuracy: 0.3778\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 403us/sample - loss: 1.5917 - accuracy: 0.3372 - val_loss: 1.4094 - val_accuracy: 0.3778\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.5415 - accuracy: 0.3372 - val_loss: 1.3793 - val_accuracy: 0.3778\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.4992 - accuracy: 0.3488 - val_loss: 1.3498 - val_accuracy: 0.3778\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.4583 - accuracy: 0.3721 - val_loss: 1.3253 - val_accuracy: 0.3778\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.4244 - accuracy: 0.3721 - val_loss: 1.3031 - val_accuracy: 0.4222\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.3941 - accuracy: 0.3837 - val_loss: 1.2833 - val_accuracy: 0.4222\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 1.3657 - accuracy: 0.4070 - val_loss: 1.2663 - val_accuracy: 0.4222\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.3431 - accuracy: 0.4186 - val_loss: 1.2508 - val_accuracy: 0.4444\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.3192 - accuracy: 0.4302 - val_loss: 1.2361 - val_accuracy: 0.4444\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.2987 - accuracy: 0.4419 - val_loss: 1.2237 - val_accuracy: 0.4444\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.2802 - accuracy: 0.4302 - val_loss: 1.2112 - val_accuracy: 0.4444\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 1.2637 - accuracy: 0.4535 - val_loss: 1.1997 - val_accuracy: 0.4444\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.2448 - accuracy: 0.4651 - val_loss: 1.1881 - val_accuracy: 0.4889\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.2311 - accuracy: 0.4767 - val_loss: 1.1779 - val_accuracy: 0.4889\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.2172 - accuracy: 0.4767 - val_loss: 1.1678 - val_accuracy: 0.4889\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.2043 - accuracy: 0.4767 - val_loss: 1.1592 - val_accuracy: 0.4889\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 1.1929 - accuracy: 0.4884 - val_loss: 1.1507 - val_accuracy: 0.4889\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.1808 - accuracy: 0.5233 - val_loss: 1.1436 - val_accuracy: 0.4667\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.1693 - accuracy: 0.5349 - val_loss: 1.1358 - val_accuracy: 0.4667\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 1.1596 - accuracy: 0.5349 - val_loss: 1.1287 - val_accuracy: 0.4444\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 519us/sample - loss: 1.1507 - accuracy: 0.5349 - val_loss: 1.1228 - val_accuracy: 0.4889\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 1.1394 - accuracy: 0.5465 - val_loss: 1.1169 - val_accuracy: 0.4889\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 1.1304 - accuracy: 0.5465 - val_loss: 1.1121 - val_accuracy: 0.4889\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 1.1233 - accuracy: 0.5465 - val_loss: 1.1067 - val_accuracy: 0.5111\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 521us/sample - loss: 1.1157 - accuracy: 0.5349 - val_loss: 1.1010 - val_accuracy: 0.4889\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 1.1071 - accuracy: 0.5349 - val_loss: 1.0948 - val_accuracy: 0.4889\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 468us/sample - loss: 1.1004 - accuracy: 0.5349 - val_loss: 1.0894 - val_accuracy: 0.4889\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 1.0936 - accuracy: 0.5233 - val_loss: 1.0852 - val_accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 1.0886 - accuracy: 0.5233 - val_loss: 1.0812 - val_accuracy: 0.4667\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 1.0809 - accuracy: 0.5233 - val_loss: 1.0771 - val_accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.0753 - accuracy: 0.5233 - val_loss: 1.0727 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.0711 - accuracy: 0.5233 - val_loss: 1.0686 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.0644 - accuracy: 0.5233 - val_loss: 1.0653 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 1.0598 - accuracy: 0.5233 - val_loss: 1.0625 - val_accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 1.0548 - accuracy: 0.5116 - val_loss: 1.0595 - val_accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.0496 - accuracy: 0.5116 - val_loss: 1.0562 - val_accuracy: 0.4889\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.0465 - accuracy: 0.5116 - val_loss: 1.0529 - val_accuracy: 0.4667\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.0413 - accuracy: 0.5116 - val_loss: 1.0500 - val_accuracy: 0.4667\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 400us/sample - loss: 1.0380 - accuracy: 0.5116 - val_loss: 1.0467 - val_accuracy: 0.4667\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 395us/sample - loss: 1.0330 - accuracy: 0.5116 - val_loss: 1.0444 - val_accuracy: 0.4667\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 505us/sample - loss: 1.0297 - accuracy: 0.5116 - val_loss: 1.0421 - val_accuracy: 0.4667\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.0267 - accuracy: 0.5116 - val_loss: 1.0398 - val_accuracy: 0.4667\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 1.0232 - accuracy: 0.5233 - val_loss: 1.0371 - val_accuracy: 0.4667\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.0195 - accuracy: 0.5233 - val_loss: 1.0348 - val_accuracy: 0.4667\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 1.0176 - accuracy: 0.5233 - val_loss: 1.0326 - val_accuracy: 0.4667\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.0134 - accuracy: 0.5233 - val_loss: 1.0302 - val_accuracy: 0.4667\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 537us/sample - loss: 1.0106 - accuracy: 0.5233 - val_loss: 1.0280 - val_accuracy: 0.4889\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 1.0085 - accuracy: 0.5349 - val_loss: 1.0259 - val_accuracy: 0.4889\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.0049 - accuracy: 0.5349 - val_loss: 1.0239 - val_accuracy: 0.4889\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.0020 - accuracy: 0.5349 - val_loss: 1.0217 - val_accuracy: 0.4889\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 0.9996 - accuracy: 0.5349 - val_loss: 1.0203 - val_accuracy: 0.4889\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9974 - accuracy: 0.5349 - val_loss: 1.0192 - val_accuracy: 0.4889\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9952 - accuracy: 0.5349 - val_loss: 1.0184 - val_accuracy: 0.4889\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.9929 - accuracy: 0.5581 - val_loss: 1.0172 - val_accuracy: 0.4889\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 0.9914 - accuracy: 0.5581 - val_loss: 1.0156 - val_accuracy: 0.4889\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 0.9879 - accuracy: 0.5465 - val_loss: 1.0145 - val_accuracy: 0.5111\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 489us/sample - loss: 0.9859 - accuracy: 0.5465 - val_loss: 1.0133 - val_accuracy: 0.5111\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 0.9836 - accuracy: 0.5465 - val_loss: 1.0121 - val_accuracy: 0.5111\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9824 - accuracy: 0.5465 - val_loss: 1.0104 - val_accuracy: 0.5111\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 566us/sample - loss: 0.9786 - accuracy: 0.5581 - val_loss: 1.0096 - val_accuracy: 0.5333\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 0.9777 - accuracy: 0.5698 - val_loss: 1.0088 - val_accuracy: 0.5333\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.9762 - accuracy: 0.5581 - val_loss: 1.0080 - val_accuracy: 0.5333\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 519us/sample - loss: 0.9741 - accuracy: 0.5814 - val_loss: 1.0068 - val_accuracy: 0.5333\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.9726 - accuracy: 0.5930 - val_loss: 1.0058 - val_accuracy: 0.5333\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 415us/sample - loss: 0.9712 - accuracy: 0.5930 - val_loss: 1.0049 - val_accuracy: 0.5333\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 0.9681 - accuracy: 0.5930 - val_loss: 1.0040 - val_accuracy: 0.5333\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 0.9669 - accuracy: 0.5930 - val_loss: 1.0030 - val_accuracy: 0.5333\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9646 - accuracy: 0.5930 - val_loss: 1.0020 - val_accuracy: 0.5333\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 0.9638 - accuracy: 0.5930 - val_loss: 1.0007 - val_accuracy: 0.5333\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 0.9610 - accuracy: 0.5930 - val_loss: 0.9993 - val_accuracy: 0.5333\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 0.9603 - accuracy: 0.5930 - val_loss: 0.9981 - val_accuracy: 0.5333\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 0.9578 - accuracy: 0.5930 - val_loss: 0.9972 - val_accuracy: 0.5333\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 0.9560 - accuracy: 0.5930 - val_loss: 0.9966 - val_accuracy: 0.5333\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 608us/sample - loss: 0.9553 - accuracy: 0.5930 - val_loss: 0.9958 - val_accuracy: 0.5556\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 0.9536 - accuracy: 0.5930 - val_loss: 0.9951 - val_accuracy: 0.5556\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 533us/sample - loss: 0.9519 - accuracy: 0.5814 - val_loss: 0.9946 - val_accuracy: 0.5778\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 470us/sample - loss: 0.9509 - accuracy: 0.5814 - val_loss: 0.9939 - val_accuracy: 0.5778\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 463us/sample - loss: 0.9490 - accuracy: 0.5814 - val_loss: 0.9936 - val_accuracy: 0.5778\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 0.9464 - accuracy: 0.5930 - val_loss: 0.9931 - val_accuracy: 0.5778\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 522us/sample - loss: 0.9442 - accuracy: 0.5698 - val_loss: 0.9928 - val_accuracy: 0.5778\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 0.9426 - accuracy: 0.5814 - val_loss: 0.9925 - val_accuracy: 0.5778\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 568us/sample - loss: 0.9407 - accuracy: 0.5930 - val_loss: 0.9920 - val_accuracy: 0.6000\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 548us/sample - loss: 0.9396 - accuracy: 0.5814 - val_loss: 0.9911 - val_accuracy: 0.6000\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9376 - accuracy: 0.5814 - val_loss: 0.9905 - val_accuracy: 0.6000\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 519us/sample - loss: 0.9365 - accuracy: 0.5814 - val_loss: 0.9899 - val_accuracy: 0.6000\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 0.9339 - accuracy: 0.5814 - val_loss: 0.9893 - val_accuracy: 0.6000\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9329 - accuracy: 0.5814 - val_loss: 0.9888 - val_accuracy: 0.6000\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 504us/sample - loss: 0.9321 - accuracy: 0.5814 - val_loss: 0.9883 - val_accuracy: 0.6000\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 570us/sample - loss: 0.9302 - accuracy: 0.5814 - val_loss: 0.9881 - val_accuracy: 0.6222\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 0.9282 - accuracy: 0.5814 - val_loss: 0.9876 - val_accuracy: 0.6222\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 522us/sample - loss: 0.9284 - accuracy: 0.5814 - val_loss: 0.9865 - val_accuracy: 0.6222\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 556us/sample - loss: 0.9263 - accuracy: 0.5814 - val_loss: 0.9855 - val_accuracy: 0.6222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5333333611488342</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 5ms/sample - loss: 2.3283 - accuracy: 0.3140 - val_loss: 1.6274 - val_accuracy: 0.4222\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 2.2019 - accuracy: 0.2907 - val_loss: 1.5777 - val_accuracy: 0.4000\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 2.1010 - accuracy: 0.2907 - val_loss: 1.5344 - val_accuracy: 0.3778\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 534us/sample - loss: 2.0066 - accuracy: 0.2791 - val_loss: 1.4984 - val_accuracy: 0.4000\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 495us/sample - loss: 1.9340 - accuracy: 0.3023 - val_loss: 1.4645 - val_accuracy: 0.4000\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 1.8684 - accuracy: 0.3023 - val_loss: 1.4335 - val_accuracy: 0.4000\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 516us/sample - loss: 1.8152 - accuracy: 0.3140 - val_loss: 1.4051 - val_accuracy: 0.4000\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 520us/sample - loss: 1.7634 - accuracy: 0.3488 - val_loss: 1.3801 - val_accuracy: 0.4000\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.7233 - accuracy: 0.3605 - val_loss: 1.3583 - val_accuracy: 0.4222\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 594us/sample - loss: 1.6845 - accuracy: 0.3837 - val_loss: 1.3406 - val_accuracy: 0.4444\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 467us/sample - loss: 1.6540 - accuracy: 0.4186 - val_loss: 1.3261 - val_accuracy: 0.4444\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.6265 - accuracy: 0.4419 - val_loss: 1.3124 - val_accuracy: 0.4444\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 525us/sample - loss: 1.6017 - accuracy: 0.4419 - val_loss: 1.3015 - val_accuracy: 0.4667\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 523us/sample - loss: 1.5780 - accuracy: 0.4302 - val_loss: 1.2914 - val_accuracy: 0.4667\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.5572 - accuracy: 0.4419 - val_loss: 1.2806 - val_accuracy: 0.4667\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 551us/sample - loss: 1.5356 - accuracy: 0.4302 - val_loss: 1.2708 - val_accuracy: 0.4889\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 1.5150 - accuracy: 0.4302 - val_loss: 1.2629 - val_accuracy: 0.4889\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 1.4962 - accuracy: 0.4419 - val_loss: 1.2560 - val_accuracy: 0.4889\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 1.4796 - accuracy: 0.4535 - val_loss: 1.2487 - val_accuracy: 0.4889\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.4601 - accuracy: 0.4535 - val_loss: 1.2416 - val_accuracy: 0.4889\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.4464 - accuracy: 0.4535 - val_loss: 1.2356 - val_accuracy: 0.4889\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.4302 - accuracy: 0.4535 - val_loss: 1.2293 - val_accuracy: 0.4889\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.4133 - accuracy: 0.4535 - val_loss: 1.2239 - val_accuracy: 0.4889\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 1.4024 - accuracy: 0.4535 - val_loss: 1.2186 - val_accuracy: 0.4889\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 554us/sample - loss: 1.3870 - accuracy: 0.4419 - val_loss: 1.2134 - val_accuracy: 0.4889\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.3733 - accuracy: 0.4302 - val_loss: 1.2094 - val_accuracy: 0.4889\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 1.3603 - accuracy: 0.4419 - val_loss: 1.2052 - val_accuracy: 0.4889\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 1.3460 - accuracy: 0.4419 - val_loss: 1.2019 - val_accuracy: 0.4889\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 1.3344 - accuracy: 0.4535 - val_loss: 1.1979 - val_accuracy: 0.4889\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 782us/sample - loss: 1.3219 - accuracy: 0.4419 - val_loss: 1.1942 - val_accuracy: 0.4889\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.3122 - accuracy: 0.4419 - val_loss: 1.1911 - val_accuracy: 0.4889\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.3010 - accuracy: 0.4535 - val_loss: 1.1883 - val_accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 1.2916 - accuracy: 0.4535 - val_loss: 1.1863 - val_accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 435us/sample - loss: 1.2821 - accuracy: 0.4419 - val_loss: 1.1842 - val_accuracy: 0.4667\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 519us/sample - loss: 1.2727 - accuracy: 0.4535 - val_loss: 1.1818 - val_accuracy: 0.4889\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 526us/sample - loss: 1.2644 - accuracy: 0.4651 - val_loss: 1.1796 - val_accuracy: 0.4889\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.2556 - accuracy: 0.4651 - val_loss: 1.1777 - val_accuracy: 0.4889\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 504us/sample - loss: 1.2473 - accuracy: 0.4651 - val_loss: 1.1762 - val_accuracy: 0.4889\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 1.2401 - accuracy: 0.4651 - val_loss: 1.1743 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.2315 - accuracy: 0.4767 - val_loss: 1.1730 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 1.2251 - accuracy: 0.4767 - val_loss: 1.1720 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 536us/sample - loss: 1.2168 - accuracy: 0.4767 - val_loss: 1.1718 - val_accuracy: 0.4444\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 1.2092 - accuracy: 0.4884 - val_loss: 1.1714 - val_accuracy: 0.4444\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 1.2026 - accuracy: 0.5000 - val_loss: 1.1711 - val_accuracy: 0.4444\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.1958 - accuracy: 0.5000 - val_loss: 1.1704 - val_accuracy: 0.4444\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 1.1888 - accuracy: 0.5000 - val_loss: 1.1699 - val_accuracy: 0.4444\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.1836 - accuracy: 0.5000 - val_loss: 1.1702 - val_accuracy: 0.4444\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 1.1773 - accuracy: 0.5000 - val_loss: 1.1700 - val_accuracy: 0.4444\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 1.1719 - accuracy: 0.5116 - val_loss: 1.1692 - val_accuracy: 0.4444\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.1658 - accuracy: 0.5116 - val_loss: 1.1685 - val_accuracy: 0.4444\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 537us/sample - loss: 1.1592 - accuracy: 0.5116 - val_loss: 1.1680 - val_accuracy: 0.4444\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 589us/sample - loss: 1.1543 - accuracy: 0.5116 - val_loss: 1.1677 - val_accuracy: 0.4667\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 551us/sample - loss: 1.1495 - accuracy: 0.5116 - val_loss: 1.1674 - val_accuracy: 0.4667\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 540us/sample - loss: 1.1442 - accuracy: 0.5000 - val_loss: 1.1674 - val_accuracy: 0.4667\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.1392 - accuracy: 0.5000 - val_loss: 1.1679 - val_accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.1340 - accuracy: 0.5116 - val_loss: 1.1681 - val_accuracy: 0.4889\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.1295 - accuracy: 0.5116 - val_loss: 1.1683 - val_accuracy: 0.4889\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.1250 - accuracy: 0.5116 - val_loss: 1.1688 - val_accuracy: 0.4889\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.1206 - accuracy: 0.5349 - val_loss: 1.1689 - val_accuracy: 0.4889\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.1162 - accuracy: 0.5116 - val_loss: 1.1692 - val_accuracy: 0.4889\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 1.1125 - accuracy: 0.5116 - val_loss: 1.1700 - val_accuracy: 0.4889\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.1094 - accuracy: 0.5116 - val_loss: 1.1705 - val_accuracy: 0.4889\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.1043 - accuracy: 0.5233 - val_loss: 1.1714 - val_accuracy: 0.4889\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.1002 - accuracy: 0.5233 - val_loss: 1.1721 - val_accuracy: 0.4889\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.0972 - accuracy: 0.5233 - val_loss: 1.1730 - val_accuracy: 0.4889\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 1.0932 - accuracy: 0.5233 - val_loss: 1.1737 - val_accuracy: 0.4889\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.0891 - accuracy: 0.5233 - val_loss: 1.1740 - val_accuracy: 0.4889\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0852 - accuracy: 0.5233 - val_loss: 1.1742 - val_accuracy: 0.4889\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 1.0824 - accuracy: 0.5233 - val_loss: 1.1746 - val_accuracy: 0.4889\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0782 - accuracy: 0.5233 - val_loss: 1.1753 - val_accuracy: 0.4889\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 429us/sample - loss: 1.0756 - accuracy: 0.5233 - val_loss: 1.1761 - val_accuracy: 0.4889\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.0726 - accuracy: 0.5233 - val_loss: 1.1773 - val_accuracy: 0.4889\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 476us/sample - loss: 1.0692 - accuracy: 0.5233 - val_loss: 1.1785 - val_accuracy: 0.4889\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 531us/sample - loss: 1.0654 - accuracy: 0.5233 - val_loss: 1.1790 - val_accuracy: 0.4889\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 507us/sample - loss: 1.0619 - accuracy: 0.5233 - val_loss: 1.1797 - val_accuracy: 0.4889\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 1.0594 - accuracy: 0.5233 - val_loss: 1.1809 - val_accuracy: 0.4889\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 485us/sample - loss: 1.0558 - accuracy: 0.5349 - val_loss: 1.1821 - val_accuracy: 0.4889\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.0532 - accuracy: 0.5349 - val_loss: 1.1832 - val_accuracy: 0.4889\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 472us/sample - loss: 1.0501 - accuracy: 0.5465 - val_loss: 1.1841 - val_accuracy: 0.4889\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.0470 - accuracy: 0.5465 - val_loss: 1.1853 - val_accuracy: 0.4889\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 413us/sample - loss: 1.0451 - accuracy: 0.5465 - val_loss: 1.1861 - val_accuracy: 0.4889\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 503us/sample - loss: 1.0416 - accuracy: 0.5465 - val_loss: 1.1864 - val_accuracy: 0.4889\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.0380 - accuracy: 0.5465 - val_loss: 1.1869 - val_accuracy: 0.4889\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 531us/sample - loss: 1.0356 - accuracy: 0.5465 - val_loss: 1.1873 - val_accuracy: 0.4889\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.0334 - accuracy: 0.5465 - val_loss: 1.1878 - val_accuracy: 0.4889\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 1.0309 - accuracy: 0.5465 - val_loss: 1.1883 - val_accuracy: 0.4667\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0282 - accuracy: 0.5465 - val_loss: 1.1886 - val_accuracy: 0.4667\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 1.0253 - accuracy: 0.5465 - val_loss: 1.1891 - val_accuracy: 0.4667\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 423us/sample - loss: 1.0234 - accuracy: 0.5465 - val_loss: 1.1896 - val_accuracy: 0.4667\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 437us/sample - loss: 1.0212 - accuracy: 0.5465 - val_loss: 1.1899 - val_accuracy: 0.4667\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.0186 - accuracy: 0.5465 - val_loss: 1.1899 - val_accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.0165 - accuracy: 0.5465 - val_loss: 1.1903 - val_accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.0140 - accuracy: 0.5465 - val_loss: 1.1908 - val_accuracy: 0.4667\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 519us/sample - loss: 1.0122 - accuracy: 0.5581 - val_loss: 1.1906 - val_accuracy: 0.4667\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 1.0100 - accuracy: 0.5581 - val_loss: 1.1911 - val_accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 1.0080 - accuracy: 0.5581 - val_loss: 1.1917 - val_accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 1.0063 - accuracy: 0.5581 - val_loss: 1.1916 - val_accuracy: 0.4444\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 1.0041 - accuracy: 0.5581 - val_loss: 1.1915 - val_accuracy: 0.4444\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.0021 - accuracy: 0.5581 - val_loss: 1.1911 - val_accuracy: 0.4444\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.0000 - accuracy: 0.5581 - val_loss: 1.1914 - val_accuracy: 0.4444\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 4ms/sample - loss: 2.7715 - accuracy: 0.1860 - val_loss: 2.6004 - val_accuracy: 0.2222\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 569us/sample - loss: 2.6289 - accuracy: 0.1860 - val_loss: 2.4978 - val_accuracy: 0.2222\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 2.5054 - accuracy: 0.1977 - val_loss: 2.4098 - val_accuracy: 0.2000\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 479us/sample - loss: 2.3973 - accuracy: 0.2093 - val_loss: 2.3304 - val_accuracy: 0.2000\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 2.3017 - accuracy: 0.2558 - val_loss: 2.2553 - val_accuracy: 0.2667\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 2.2180 - accuracy: 0.2791 - val_loss: 2.1869 - val_accuracy: 0.2889\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 2.1409 - accuracy: 0.3256 - val_loss: 2.1269 - val_accuracy: 0.2889\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 2.0766 - accuracy: 0.3837 - val_loss: 2.0699 - val_accuracy: 0.3556\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 2.0133 - accuracy: 0.4419 - val_loss: 2.0152 - val_accuracy: 0.4000\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.9551 - accuracy: 0.4419 - val_loss: 1.9633 - val_accuracy: 0.4222\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 393us/sample - loss: 1.8987 - accuracy: 0.4535 - val_loss: 1.9151 - val_accuracy: 0.4222\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 1.8482 - accuracy: 0.4651 - val_loss: 1.8675 - val_accuracy: 0.4222\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 1.7965 - accuracy: 0.4767 - val_loss: 1.8195 - val_accuracy: 0.4222\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 440us/sample - loss: 1.7501 - accuracy: 0.4767 - val_loss: 1.7760 - val_accuracy: 0.4222\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.7061 - accuracy: 0.4767 - val_loss: 1.7372 - val_accuracy: 0.4222\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 525us/sample - loss: 1.6663 - accuracy: 0.4767 - val_loss: 1.7046 - val_accuracy: 0.4222\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.6312 - accuracy: 0.4767 - val_loss: 1.6721 - val_accuracy: 0.4222\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 1.5953 - accuracy: 0.4767 - val_loss: 1.6403 - val_accuracy: 0.4222\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.5601 - accuracy: 0.4767 - val_loss: 1.6121 - val_accuracy: 0.4222\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 417us/sample - loss: 1.5303 - accuracy: 0.4767 - val_loss: 1.5859 - val_accuracy: 0.4222\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 470us/sample - loss: 1.5030 - accuracy: 0.4767 - val_loss: 1.5598 - val_accuracy: 0.4222\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.4759 - accuracy: 0.4767 - val_loss: 1.5373 - val_accuracy: 0.4222\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.4513 - accuracy: 0.4651 - val_loss: 1.5158 - val_accuracy: 0.4222\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.4293 - accuracy: 0.4651 - val_loss: 1.4969 - val_accuracy: 0.4222\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 406us/sample - loss: 1.4091 - accuracy: 0.4651 - val_loss: 1.4785 - val_accuracy: 0.4222\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 1.3907 - accuracy: 0.4767 - val_loss: 1.4613 - val_accuracy: 0.4222\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.3718 - accuracy: 0.4535 - val_loss: 1.4456 - val_accuracy: 0.4444\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.3546 - accuracy: 0.4535 - val_loss: 1.4305 - val_accuracy: 0.4444\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.3387 - accuracy: 0.4651 - val_loss: 1.4170 - val_accuracy: 0.4444\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.3225 - accuracy: 0.4651 - val_loss: 1.4034 - val_accuracy: 0.4667\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 421us/sample - loss: 1.3066 - accuracy: 0.4651 - val_loss: 1.3907 - val_accuracy: 0.4444\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 448us/sample - loss: 1.2931 - accuracy: 0.4651 - val_loss: 1.3787 - val_accuracy: 0.4444\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.2795 - accuracy: 0.4651 - val_loss: 1.3668 - val_accuracy: 0.4444\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.2661 - accuracy: 0.4535 - val_loss: 1.3553 - val_accuracy: 0.4444\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 1.2536 - accuracy: 0.4535 - val_loss: 1.3452 - val_accuracy: 0.4444\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.2409 - accuracy: 0.4535 - val_loss: 1.3345 - val_accuracy: 0.4444\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 1.2303 - accuracy: 0.4651 - val_loss: 1.3249 - val_accuracy: 0.4667\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 447us/sample - loss: 1.2183 - accuracy: 0.4651 - val_loss: 1.3155 - val_accuracy: 0.4667\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.2067 - accuracy: 0.4651 - val_loss: 1.3068 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.1965 - accuracy: 0.4651 - val_loss: 1.2987 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 397us/sample - loss: 1.1874 - accuracy: 0.4651 - val_loss: 1.2910 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 1.1781 - accuracy: 0.4767 - val_loss: 1.2832 - val_accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 419us/sample - loss: 1.1691 - accuracy: 0.4767 - val_loss: 1.2751 - val_accuracy: 0.4667\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.1589 - accuracy: 0.4767 - val_loss: 1.2675 - val_accuracy: 0.4889\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.1508 - accuracy: 0.4767 - val_loss: 1.2598 - val_accuracy: 0.4889\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 474us/sample - loss: 1.1397 - accuracy: 0.4884 - val_loss: 1.2519 - val_accuracy: 0.4889\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.1298 - accuracy: 0.4884 - val_loss: 1.2448 - val_accuracy: 0.4889\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.1206 - accuracy: 0.5000 - val_loss: 1.2387 - val_accuracy: 0.4889\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.1130 - accuracy: 0.5233 - val_loss: 1.2336 - val_accuracy: 0.4889\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.1064 - accuracy: 0.5233 - val_loss: 1.2283 - val_accuracy: 0.4889\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.1005 - accuracy: 0.5116 - val_loss: 1.2232 - val_accuracy: 0.4889\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 1.0953 - accuracy: 0.5349 - val_loss: 1.2184 - val_accuracy: 0.4889\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 537us/sample - loss: 1.0894 - accuracy: 0.5116 - val_loss: 1.2138 - val_accuracy: 0.4889\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.0844 - accuracy: 0.5233 - val_loss: 1.2097 - val_accuracy: 0.4444\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.0785 - accuracy: 0.5233 - val_loss: 1.2052 - val_accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.0739 - accuracy: 0.5349 - val_loss: 1.2010 - val_accuracy: 0.4667\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.0694 - accuracy: 0.5116 - val_loss: 1.1967 - val_accuracy: 0.4667\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 1.0633 - accuracy: 0.5349 - val_loss: 1.1928 - val_accuracy: 0.4889\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.0593 - accuracy: 0.5233 - val_loss: 1.1892 - val_accuracy: 0.4889\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 499us/sample - loss: 1.0545 - accuracy: 0.5116 - val_loss: 1.1855 - val_accuracy: 0.4889\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 1.0498 - accuracy: 0.5349 - val_loss: 1.1821 - val_accuracy: 0.4889\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0452 - accuracy: 0.5233 - val_loss: 1.1787 - val_accuracy: 0.4889\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 1.0418 - accuracy: 0.5465 - val_loss: 1.1758 - val_accuracy: 0.4889\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 1.0374 - accuracy: 0.5581 - val_loss: 1.1729 - val_accuracy: 0.4889\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 1.0352 - accuracy: 0.5581 - val_loss: 1.1699 - val_accuracy: 0.4889\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 401us/sample - loss: 1.0311 - accuracy: 0.5581 - val_loss: 1.1667 - val_accuracy: 0.4889\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 418us/sample - loss: 1.0284 - accuracy: 0.5581 - val_loss: 1.1637 - val_accuracy: 0.4889\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.0248 - accuracy: 0.5581 - val_loss: 1.1611 - val_accuracy: 0.4889\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 410us/sample - loss: 1.0218 - accuracy: 0.5465 - val_loss: 1.1589 - val_accuracy: 0.4889\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.0197 - accuracy: 0.5698 - val_loss: 1.1565 - val_accuracy: 0.4889\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 521us/sample - loss: 1.0151 - accuracy: 0.5698 - val_loss: 1.1539 - val_accuracy: 0.4889\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 446us/sample - loss: 1.0130 - accuracy: 0.5698 - val_loss: 1.1514 - val_accuracy: 0.4889\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 1.0092 - accuracy: 0.5581 - val_loss: 1.1491 - val_accuracy: 0.4889\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 1.0068 - accuracy: 0.5698 - val_loss: 1.1469 - val_accuracy: 0.4889\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 1.0043 - accuracy: 0.5698 - val_loss: 1.1448 - val_accuracy: 0.4889\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 523us/sample - loss: 1.0023 - accuracy: 0.5581 - val_loss: 1.1428 - val_accuracy: 0.5111\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.9992 - accuracy: 0.5465 - val_loss: 1.1411 - val_accuracy: 0.4889\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 0.9970 - accuracy: 0.5465 - val_loss: 1.1392 - val_accuracy: 0.4889\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 527us/sample - loss: 0.9940 - accuracy: 0.5465 - val_loss: 1.1373 - val_accuracy: 0.4889\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9922 - accuracy: 0.5581 - val_loss: 1.1354 - val_accuracy: 0.4889\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9901 - accuracy: 0.5581 - val_loss: 1.1333 - val_accuracy: 0.4889\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 462us/sample - loss: 0.9871 - accuracy: 0.5581 - val_loss: 1.1314 - val_accuracy: 0.4889\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 491us/sample - loss: 0.9864 - accuracy: 0.5581 - val_loss: 1.1301 - val_accuracy: 0.4889\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9829 - accuracy: 0.5581 - val_loss: 1.1283 - val_accuracy: 0.4889\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 0.9817 - accuracy: 0.5581 - val_loss: 1.1265 - val_accuracy: 0.4889\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 427us/sample - loss: 0.9796 - accuracy: 0.5581 - val_loss: 1.1249 - val_accuracy: 0.4889\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 0.9772 - accuracy: 0.5581 - val_loss: 1.1233 - val_accuracy: 0.4889\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 407us/sample - loss: 0.9745 - accuracy: 0.5581 - val_loss: 1.1219 - val_accuracy: 0.4889\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 0.9733 - accuracy: 0.5581 - val_loss: 1.1206 - val_accuracy: 0.4889\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 494us/sample - loss: 0.9712 - accuracy: 0.5581 - val_loss: 1.1193 - val_accuracy: 0.4889\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 0.9693 - accuracy: 0.5581 - val_loss: 1.1180 - val_accuracy: 0.4889\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9678 - accuracy: 0.5581 - val_loss: 1.1167 - val_accuracy: 0.4889\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 0.9654 - accuracy: 0.5581 - val_loss: 1.1156 - val_accuracy: 0.4889\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.9643 - accuracy: 0.5581 - val_loss: 1.1144 - val_accuracy: 0.4889\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 458us/sample - loss: 0.9625 - accuracy: 0.5581 - val_loss: 1.1132 - val_accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9610 - accuracy: 0.5465 - val_loss: 1.1118 - val_accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 456us/sample - loss: 0.9588 - accuracy: 0.5465 - val_loss: 1.1103 - val_accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 433us/sample - loss: 0.9573 - accuracy: 0.5581 - val_loss: 1.1090 - val_accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 0.9559 - accuracy: 0.5581 - val_loss: 1.1079 - val_accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.9537 - accuracy: 0.5581 - val_loss: 1.1067 - val_accuracy: 0.4667\n",
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 5ms/sample - loss: 2.5485 - accuracy: 0.3953 - val_loss: 3.1249 - val_accuracy: 0.3778\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 2.3833 - accuracy: 0.3953 - val_loss: 2.9253 - val_accuracy: 0.3778\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 509us/sample - loss: 2.2371 - accuracy: 0.3837 - val_loss: 2.7447 - val_accuracy: 0.4222\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 2.1084 - accuracy: 0.3721 - val_loss: 2.5828 - val_accuracy: 0.4222\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 478us/sample - loss: 1.9889 - accuracy: 0.3605 - val_loss: 2.4266 - val_accuracy: 0.4222\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 1.8788 - accuracy: 0.3605 - val_loss: 2.2888 - val_accuracy: 0.4444\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 487us/sample - loss: 1.7855 - accuracy: 0.3721 - val_loss: 2.1690 - val_accuracy: 0.4222\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 1.7051 - accuracy: 0.3721 - val_loss: 2.0638 - val_accuracy: 0.4444\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.6349 - accuracy: 0.4302 - val_loss: 1.9684 - val_accuracy: 0.4444\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 556us/sample - loss: 1.5716 - accuracy: 0.4302 - val_loss: 1.8838 - val_accuracy: 0.4444\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 436us/sample - loss: 1.5145 - accuracy: 0.4302 - val_loss: 1.8065 - val_accuracy: 0.4667\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.4656 - accuracy: 0.4419 - val_loss: 1.7404 - val_accuracy: 0.4667\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 470us/sample - loss: 1.4240 - accuracy: 0.4535 - val_loss: 1.6786 - val_accuracy: 0.4667\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 506us/sample - loss: 1.3847 - accuracy: 0.4535 - val_loss: 1.6219 - val_accuracy: 0.4667\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 1.3485 - accuracy: 0.4651 - val_loss: 1.5712 - val_accuracy: 0.4667\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 1.3184 - accuracy: 0.4884 - val_loss: 1.5265 - val_accuracy: 0.4667\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 434us/sample - loss: 1.2918 - accuracy: 0.4884 - val_loss: 1.4863 - val_accuracy: 0.4667\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 1.2689 - accuracy: 0.5000 - val_loss: 1.4526 - val_accuracy: 0.4667\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 1.2471 - accuracy: 0.4884 - val_loss: 1.4209 - val_accuracy: 0.4444\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 1.2274 - accuracy: 0.4884 - val_loss: 1.3919 - val_accuracy: 0.4444\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 1.2107 - accuracy: 0.4884 - val_loss: 1.3651 - val_accuracy: 0.4444\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 522us/sample - loss: 1.1945 - accuracy: 0.4884 - val_loss: 1.3405 - val_accuracy: 0.4222\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 1.1812 - accuracy: 0.5000 - val_loss: 1.3178 - val_accuracy: 0.4222\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 426us/sample - loss: 1.1664 - accuracy: 0.5000 - val_loss: 1.2982 - val_accuracy: 0.4222\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.1551 - accuracy: 0.5116 - val_loss: 1.2788 - val_accuracy: 0.4222\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.1432 - accuracy: 0.5116 - val_loss: 1.2617 - val_accuracy: 0.4000\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 518us/sample - loss: 1.1329 - accuracy: 0.5116 - val_loss: 1.2465 - val_accuracy: 0.4222\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.1241 - accuracy: 0.5233 - val_loss: 1.2325 - val_accuracy: 0.4222\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 420us/sample - loss: 1.1150 - accuracy: 0.5233 - val_loss: 1.2183 - val_accuracy: 0.4222\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 411us/sample - loss: 1.1054 - accuracy: 0.5233 - val_loss: 1.2041 - val_accuracy: 0.4222\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 1.0969 - accuracy: 0.5233 - val_loss: 1.1906 - val_accuracy: 0.4444\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 527us/sample - loss: 1.0878 - accuracy: 0.5233 - val_loss: 1.1770 - val_accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 432us/sample - loss: 1.0800 - accuracy: 0.5349 - val_loss: 1.1660 - val_accuracy: 0.4667\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 522us/sample - loss: 1.0732 - accuracy: 0.5349 - val_loss: 1.1559 - val_accuracy: 0.4667\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 562us/sample - loss: 1.0674 - accuracy: 0.5349 - val_loss: 1.1477 - val_accuracy: 0.4667\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 471us/sample - loss: 1.0619 - accuracy: 0.5349 - val_loss: 1.1420 - val_accuracy: 0.4667\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 441us/sample - loss: 1.0571 - accuracy: 0.5349 - val_loss: 1.1362 - val_accuracy: 0.4889\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 1.0526 - accuracy: 0.5349 - val_loss: 1.1301 - val_accuracy: 0.4889\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 430us/sample - loss: 1.0482 - accuracy: 0.5465 - val_loss: 1.1250 - val_accuracy: 0.4667\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 1.0442 - accuracy: 0.5465 - val_loss: 1.1201 - val_accuracy: 0.4667\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 469us/sample - loss: 1.0404 - accuracy: 0.5465 - val_loss: 1.1154 - val_accuracy: 0.4667\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 1.0365 - accuracy: 0.5698 - val_loss: 1.1111 - val_accuracy: 0.4667\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 481us/sample - loss: 1.0330 - accuracy: 0.5814 - val_loss: 1.1075 - val_accuracy: 0.4444\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 488us/sample - loss: 1.0295 - accuracy: 0.5814 - val_loss: 1.1032 - val_accuracy: 0.4444\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 1.0257 - accuracy: 0.5814 - val_loss: 1.0992 - val_accuracy: 0.4444\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 425us/sample - loss: 1.0229 - accuracy: 0.5930 - val_loss: 1.0961 - val_accuracy: 0.4444\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 1.0198 - accuracy: 0.5930 - val_loss: 1.0936 - val_accuracy: 0.4444\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 1.0169 - accuracy: 0.5930 - val_loss: 1.0902 - val_accuracy: 0.4444\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 482us/sample - loss: 1.0133 - accuracy: 0.5930 - val_loss: 1.0865 - val_accuracy: 0.4444\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 496us/sample - loss: 1.0103 - accuracy: 0.5930 - val_loss: 1.0838 - val_accuracy: 0.4667\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 452us/sample - loss: 1.0073 - accuracy: 0.5930 - val_loss: 1.0810 - val_accuracy: 0.4667\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 442us/sample - loss: 1.0046 - accuracy: 0.5930 - val_loss: 1.0785 - val_accuracy: 0.4667\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 0s 461us/sample - loss: 1.0024 - accuracy: 0.6047 - val_loss: 1.0761 - val_accuracy: 0.4667\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 0s 545us/sample - loss: 1.0003 - accuracy: 0.6047 - val_loss: 1.0741 - val_accuracy: 0.4667\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 0s 486us/sample - loss: 0.9976 - accuracy: 0.6047 - val_loss: 1.0723 - val_accuracy: 0.4667\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 0s 498us/sample - loss: 0.9956 - accuracy: 0.6047 - val_loss: 1.0711 - val_accuracy: 0.4667\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 0.9936 - accuracy: 0.6047 - val_loss: 1.0697 - val_accuracy: 0.4667\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 0s 497us/sample - loss: 0.9917 - accuracy: 0.6047 - val_loss: 1.0684 - val_accuracy: 0.4667\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 0s 477us/sample - loss: 0.9899 - accuracy: 0.6047 - val_loss: 1.0674 - val_accuracy: 0.4667\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 0s 528us/sample - loss: 0.9882 - accuracy: 0.6047 - val_loss: 1.0661 - val_accuracy: 0.4667\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9865 - accuracy: 0.6047 - val_loss: 1.0653 - val_accuracy: 0.4667\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 0s 454us/sample - loss: 0.9846 - accuracy: 0.6047 - val_loss: 1.0648 - val_accuracy: 0.4667\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9829 - accuracy: 0.6047 - val_loss: 1.0640 - val_accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 0s 515us/sample - loss: 0.9811 - accuracy: 0.6163 - val_loss: 1.0633 - val_accuracy: 0.4667\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 0s 457us/sample - loss: 0.9795 - accuracy: 0.6163 - val_loss: 1.0625 - val_accuracy: 0.4667\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 0s 459us/sample - loss: 0.9773 - accuracy: 0.6163 - val_loss: 1.0620 - val_accuracy: 0.4667\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 0s 444us/sample - loss: 0.9757 - accuracy: 0.6163 - val_loss: 1.0614 - val_accuracy: 0.4444\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 0.9742 - accuracy: 0.6163 - val_loss: 1.0607 - val_accuracy: 0.4444\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 0s 483us/sample - loss: 0.9724 - accuracy: 0.6163 - val_loss: 1.0603 - val_accuracy: 0.4444\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 0s 511us/sample - loss: 0.9707 - accuracy: 0.6163 - val_loss: 1.0596 - val_accuracy: 0.4444\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 0s 490us/sample - loss: 0.9692 - accuracy: 0.6163 - val_loss: 1.0588 - val_accuracy: 0.4444\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 0s 438us/sample - loss: 0.9678 - accuracy: 0.6163 - val_loss: 1.0586 - val_accuracy: 0.4667\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 0s 443us/sample - loss: 0.9664 - accuracy: 0.6163 - val_loss: 1.0585 - val_accuracy: 0.4667\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 0s 473us/sample - loss: 0.9652 - accuracy: 0.6163 - val_loss: 1.0583 - val_accuracy: 0.4667\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 0s 631us/sample - loss: 0.9639 - accuracy: 0.6163 - val_loss: 1.0581 - val_accuracy: 0.4667\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 0s 428us/sample - loss: 0.9624 - accuracy: 0.6163 - val_loss: 1.0575 - val_accuracy: 0.4667\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 0.9614 - accuracy: 0.6279 - val_loss: 1.0578 - val_accuracy: 0.4667\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 0s 492us/sample - loss: 0.9600 - accuracy: 0.6279 - val_loss: 1.0579 - val_accuracy: 0.4667\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 0s 480us/sample - loss: 0.9589 - accuracy: 0.6279 - val_loss: 1.0578 - val_accuracy: 0.4667\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 0s 465us/sample - loss: 0.9576 - accuracy: 0.6279 - val_loss: 1.0577 - val_accuracy: 0.4667\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 0s 460us/sample - loss: 0.9562 - accuracy: 0.6279 - val_loss: 1.0578 - val_accuracy: 0.4667\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 0s 464us/sample - loss: 0.9552 - accuracy: 0.6279 - val_loss: 1.0577 - val_accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 0s 450us/sample - loss: 0.9542 - accuracy: 0.6279 - val_loss: 1.0579 - val_accuracy: 0.4667\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 0s 504us/sample - loss: 0.9525 - accuracy: 0.6279 - val_loss: 1.0580 - val_accuracy: 0.4667\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 0s 491us/sample - loss: 0.9517 - accuracy: 0.6279 - val_loss: 1.0579 - val_accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "86/86 [==============================] - 0s 449us/sample - loss: 0.9503 - accuracy: 0.6279 - val_loss: 1.0580 - val_accuracy: 0.4889\n",
            "Epoch 87/100\n",
            "86/86 [==============================] - 0s 505us/sample - loss: 0.9490 - accuracy: 0.6279 - val_loss: 1.0583 - val_accuracy: 0.4889\n",
            "Epoch 88/100\n",
            "86/86 [==============================] - 0s 414us/sample - loss: 0.9481 - accuracy: 0.6279 - val_loss: 1.0584 - val_accuracy: 0.4889\n",
            "Epoch 89/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 0.9468 - accuracy: 0.6279 - val_loss: 1.0583 - val_accuracy: 0.4889\n",
            "Epoch 90/100\n",
            "86/86 [==============================] - 0s 451us/sample - loss: 0.9462 - accuracy: 0.6279 - val_loss: 1.0585 - val_accuracy: 0.4889\n",
            "Epoch 91/100\n",
            "86/86 [==============================] - 0s 484us/sample - loss: 0.9447 - accuracy: 0.6279 - val_loss: 1.0587 - val_accuracy: 0.4667\n",
            "Epoch 92/100\n",
            "86/86 [==============================] - 0s 445us/sample - loss: 0.9439 - accuracy: 0.6279 - val_loss: 1.0590 - val_accuracy: 0.4667\n",
            "Epoch 93/100\n",
            "86/86 [==============================] - 0s 453us/sample - loss: 0.9425 - accuracy: 0.6512 - val_loss: 1.0597 - val_accuracy: 0.4667\n",
            "Epoch 94/100\n",
            "86/86 [==============================] - 0s 399us/sample - loss: 0.9412 - accuracy: 0.6279 - val_loss: 1.0603 - val_accuracy: 0.4667\n",
            "Epoch 95/100\n",
            "86/86 [==============================] - 0s 416us/sample - loss: 0.9404 - accuracy: 0.6512 - val_loss: 1.0604 - val_accuracy: 0.4667\n",
            "Epoch 96/100\n",
            "86/86 [==============================] - 0s 475us/sample - loss: 0.9392 - accuracy: 0.6512 - val_loss: 1.0604 - val_accuracy: 0.4667\n",
            "Epoch 97/100\n",
            "86/86 [==============================] - 0s 424us/sample - loss: 0.9385 - accuracy: 0.6512 - val_loss: 1.0606 - val_accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "86/86 [==============================] - 0s 466us/sample - loss: 0.9371 - accuracy: 0.6395 - val_loss: 1.0607 - val_accuracy: 0.4667\n",
            "Epoch 99/100\n",
            "86/86 [==============================] - 0s 519us/sample - loss: 0.9362 - accuracy: 0.6395 - val_loss: 1.0608 - val_accuracy: 0.4667\n",
            "Epoch 100/100\n",
            "86/86 [==============================] - 0s 439us/sample - loss: 0.9351 - accuracy: 0.6395 - val_loss: 1.0611 - val_accuracy: 0.4667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.4962962865829468</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-2d55c9f9e3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0macc_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0mall_acc_histories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2eeOHoYbina",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDN2PrRc36l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tss7vRUEgAcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(all_acc_histories[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpKE3iTJBHzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_acc_history = [np.mean([x[i] for x in all_acc_histories]) for i in range(num_epochs)]\n",
        "#media per epoca degli score ottenuti per tutte le k-fold\n",
        "#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\n",
        "#e si fa questo per tutte le epoche\n",
        "average_loss_history = [np.mean([x[i] for x in all_loss_histories]) for i in range(num_epochs)]\n",
        "average_val_acc_history = [np.mean([x[i] for x in all_val_acc_histories]) for i in range(num_epochs)]\n",
        "average_val_loss_history = [np.mean([x[i] for x in all_val_loss_histories]) for i in range(num_epochs)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQrkCEMUD2RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(average_val_acc_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UhSxIaHtuO",
        "colab_type": "text"
      },
      "source": [
        "##Plotting training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zsienD5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJizyjnaIPhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, num_epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEHEYLgIQUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs, average_loss_history, 'bo', label='training loss')\n",
        "plt.plot(epochs, average_val_loss_history, 'b', label='validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc4wMjfI97j",
        "colab_type": "text"
      },
      "source": [
        "##Plotting train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi7VzbFIbtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs, average_acc_history, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, average_val_acc_history, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9RurwColqyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkgKUMeNlsg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}