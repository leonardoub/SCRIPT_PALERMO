{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Callbacks_Network_classification_histology.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/SCRIPT_PALERMO/blob/master/Callbacks_Network_classification_histology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo87xY_fffSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "5fab1494-7260-4689-c16c-1400919b84c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_path = '/gdrive/My Drive/AIM_PA/database_training2.csv'\n",
        "test_dataset_path = '/gdrive/My Drive/AIM_PA/database_nostro_without_nan.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(train_dataset_path)\n",
        "df_test = pd.read_csv(test_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-87QSVhqhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSbeCedhuxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.rename(columns={'Survival.time (months)':'Surv_time_months'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbcwLGg3iNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)\n",
        "df_test.rename(columns={'Overall.Stage':'Overall_Stage'}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQdR4izXiT0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = df_test.drop(['Histology', 'Surv_time_months', 'OS', 'deadstatus.event','Overall_Stage'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = df_train.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS5wIylYmsQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = df_test.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtPx7PMDnXM3",
        "colab_type": "text"
      },
      "source": [
        "##Z score dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4Qji2EnVV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data_stand = train_data - mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVOoNOvm0Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_stand = test_data - mean\n",
        "test_data_stand /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00VohsAyokpq",
        "colab_type": "text"
      },
      "source": [
        "##Vettorizzare i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvS_9ISpxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index={'adenocarcinoma':0, 'large cell':1, 'squamous cell carcinoma':2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPW9U0XrWY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_dec = [word_index[label] for label in train_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4SBiKFQsKFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels_dec = [word_index[label] for label in test_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMbTYR7okJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Frv4FDNn6Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels_dec)\n",
        "one_hot_test_labels = to_categorical(test_labels_dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn0tkOGc3LKN",
        "colab_type": "text"
      },
      "source": [
        "#PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS76u6iu3Seg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCjC4zqJ3bui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.9, svd_solver='full')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLUCf9qX4p_e",
        "colab_type": "code",
        "outputId": "8c8a8cf3-34a6-4552-ea0f-3b5eced9599d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pca.fit(train_data_stand)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
              "    svd_solver='full', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfyaKgNZ44o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_stand_pca = pca.transform(train_data_stand)\n",
        "test_data_stand_pca = pca.transform(test_data_stand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz9C4nl05b_g",
        "colab_type": "code",
        "outputId": "1050258d-e0ed-4fc0-e5b8-2c50ab77c0b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_stand_pca.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VVfbsnKS5CD1"
      },
      "source": [
        "#Building Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sDBPQTG05CEA",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s8BmvSBz5CER",
        "colab": {}
      },
      "source": [
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hc7nlRP95CEb",
        "colab": {}
      },
      "source": [
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r4G5Xx4c5CEk",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3naYmgFO5CEt",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(layers.Dense(6, activation='relu', input_shape=(9,)))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIxDu50pBeiz",
        "colab_type": "text"
      },
      "source": [
        "#Stratified k-fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyLcvedUBpxA",
        "colab_type": "text"
      },
      "source": [
        "This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1apcZ19gFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaBDM-PtBx5V",
        "colab_type": "code",
        "outputId": "5d74223b-d20b-42ac-9c4b-c7ee539eac51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "skf.get_n_splits(train_data_stand_pca, train_labels_dec)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-XQzPyD1gi",
        "colab_type": "code",
        "outputId": "dfcc9ed3-a988-4444-dcf1-02227293ad37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "for train_index, test_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [  0   1   4   5   8   9  11  12  14  15  16  17  19  20  22  23  24  25\n",
            "  27  29  30  33  34  36  37  38  39  40  41  42  44  45  46  48  51  52\n",
            "  53  56  57  58  59  60  62  63  65  66  67  69  72  76  77  78  79  80\n",
            "  81  83  84  85  87  88  89  90  92  96  97  98 100 101 102 103 104 105\n",
            " 107 109 110 111 113 115 117 120 121 122 124 125 127 128] TEST: [  2   3   6   7  10  13  18  21  26  28  31  32  35  43  47  49  50  54\n",
            "  55  61  64  68  70  71  73  74  75  82  86  91  93  94  95  99 106 108\n",
            " 112 114 116 118 119 123 126 129 130]\n",
            "TRAIN: [  2   3   5   6   7   8   9  10  11  12  13  18  20  21  25  26  27  28\n",
            "  29  30  31  32  34  35  36  38  39  43  44  45  46  47  48  49  50  53\n",
            "  54  55  57  58  61  63  64  65  66  68  70  71  73  74  75  76  78  82\n",
            "  84  85  86  87  90  91  92  93  94  95  96  99 100 101 102 105 106 108\n",
            " 109 111 112 114 115 116 118 119 122 123 124 125 126 127 129 130] TEST: [  0   1   4  14  15  16  17  19  22  23  24  33  37  40  41  42  51  52\n",
            "  56  59  60  62  67  69  72  77  79  80  81  83  88  89  97  98 103 104\n",
            " 107 110 113 117 120 121 128]\n",
            "TRAIN: [  0   1   2   3   4   6   7  10  13  14  15  16  17  18  19  21  22  23\n",
            "  24  26  28  31  32  33  35  37  40  41  42  43  47  49  50  51  52  54\n",
            "  55  56  59  60  61  62  64  67  68  69  70  71  72  73  74  75  77  79\n",
            "  80  81  82  83  86  88  89  91  93  94  95  97  98  99 103 104 106 107\n",
            " 108 110 112 113 114 116 117 118 119 120 121 123 126 128 129 130] TEST: [  5   8   9  11  12  20  25  27  29  30  34  36  38  39  44  45  46  48\n",
            "  53  57  58  63  65  66  76  78  84  85  87  90  92  96 100 101 102 105\n",
            " 109 111 115 122 124 125 127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgdGK-8FK-U_",
        "colab_type": "code",
        "outputId": "60947d4a-7481-477d-dcd2-edcb4486b91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels_dec[125]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJg0XD4Shhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Sq8r9GEPx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "#  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "#  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "\n",
        "#  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "#  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "#  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "#  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        "#  model = build_model()\n",
        "#  model.fit(partial_train_data, one_hot_partial_train_targets, epochs = num_epochs, batch_size=1)\n",
        "\n",
        "#  val_loss, val_accuracy = model.evaluate(val_data, one_hot_val_targets)\n",
        "#  all_scores.append(val_accuracy)\n",
        "#I parametri per la valutazione vengono calcolati una volta per ogni k-fold, per ogni set di validazione, quindi k volte"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X5B3lasRcsR",
        "colab_type": "text"
      },
      "source": [
        "C'è un problema: keras.utils.to_categorical produces a one-hot encoded class vector, i.e. the multilabel-indicator mentioned in the error message. StratifiedKFold is not designed to work with such input; i.e. your y must be a 1-D array of your class labels.\n",
        "Essentially, what you have to do is simply to invert the order of the operations: split first (using your intial y_train), and convert to_categorical afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clhXS8kJB591",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8a1I3yU9FS",
        "colab_type": "code",
        "outputId": "d7b0b736-f0ee-4c56-ea0a-e58980e8b187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 100\n",
        "all_acc_histories = []\n",
        "all_loss_histories = []\n",
        "all_val_acc_histories = []\n",
        "all_val_loss_histories = []\n",
        "\n",
        "for train_index, val_index in skf.split(train_data_stand_pca, train_labels_dec):\n",
        " \n",
        "  partial_train_data = np.array([train_data_stand_pca[i] for i in train_index])\n",
        "  partial_train_targets = np.array([train_labels_dec[i] for i in train_index])\n",
        "  \n",
        "  val_data = np.array([train_data_stand_pca[i] for i in val_index])\n",
        "  val_targets = np.array([train_labels_dec[i] for i in val_index])\n",
        "\n",
        "  one_hot_partial_train_targets = to_categorical(partial_train_targets)\n",
        "  one_hot_val_targets = to_categorical(val_targets)\n",
        "\n",
        "  model = build_model()\n",
        "\n",
        "  callbacks_list = [keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=10),\n",
        "                    keras.callbacks.EarlyStopping(monitor='acc', patience=10)]\n",
        "  history = model.fit(partial_train_data, one_hot_partial_train_targets, validation_data=(val_data, one_hot_val_targets), \n",
        "                      epochs=num_epochs, batch_size=10, callbacks=callbacks_list)\n",
        "  \n",
        "  acc_history = history.history['acc']\n",
        "  all_acc_histories.append(acc_history)\n",
        "\n",
        "  loss_history = history.history['loss']\n",
        "  all_loss_histories.append(loss_history)\n",
        "\n",
        "  acc_val_history = history.history['val_acc']\n",
        "  all_val_acc_histories.append(acc_val_history)\n",
        "\n",
        "  loss_val_history = history.history['val_loss']\n",
        "  all_val_loss_histories.append(loss_val_history)\n",
        "  \n",
        "\n",
        "#I parametri per la valutazione vengono calcolati per ogni epoca, quindi num_epochs volte. \n",
        "#Il tutto viene ripetuto un numero di volte pari a n_splits.\n",
        "#Si ottiene una lista con n_splits elementi ciascuno dei quali è una lista lunga num_epochs,\n",
        "#ogni elemento può essere uno fra questi: dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) "
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 45 samples\n",
            "Epoch 1/100\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 2.7944 - acc: 0.2791 - val_loss: 2.4592 - val_acc: 0.3556\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 0s 184us/step - loss: 2.6193 - acc: 0.2907 - val_loss: 2.3846 - val_acc: 0.4222\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 0s 197us/step - loss: 2.4535 - acc: 0.3140 - val_loss: 2.3150 - val_acc: 0.4222\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 0s 187us/step - loss: 2.3169 - acc: 0.3256 - val_loss: 2.2516 - val_acc: 0.4222\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 0s 193us/step - loss: 2.2078 - acc: 0.3488 - val_loss: 2.1946 - val_acc: 0.4222\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 0s 235us/step - loss: 2.1146 - acc: 0.3605 - val_loss: 2.1413 - val_acc: 0.4444\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 0s 187us/step - loss: 2.0374 - acc: 0.3488 - val_loss: 2.0891 - val_acc: 0.4222\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 0s 208us/step - loss: 1.9687 - acc: 0.3721 - val_loss: 2.0385 - val_acc: 0.4000\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 0s 249us/step - loss: 1.9068 - acc: 0.3721 - val_loss: 1.9955 - val_acc: 0.4000\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 0s 247us/step - loss: 1.8559 - acc: 0.3837 - val_loss: 1.9563 - val_acc: 0.3778\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 0s 217us/step - loss: 1.8083 - acc: 0.3953 - val_loss: 1.9216 - val_acc: 0.3778\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 0s 191us/step - loss: 1.7671 - acc: 0.3953 - val_loss: 1.8894 - val_acc: 0.3778\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 0s 209us/step - loss: 1.7285 - acc: 0.4070 - val_loss: 1.8562 - val_acc: 0.3778\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 0s 254us/step - loss: 1.6934 - acc: 0.4186 - val_loss: 1.8251 - val_acc: 0.3778\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 0s 225us/step - loss: 1.6601 - acc: 0.4419 - val_loss: 1.7960 - val_acc: 0.3778\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 0s 186us/step - loss: 1.6260 - acc: 0.4419 - val_loss: 1.7682 - val_acc: 0.3778\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 0s 248us/step - loss: 1.5965 - acc: 0.4535 - val_loss: 1.7461 - val_acc: 0.3778\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 0s 291us/step - loss: 1.5708 - acc: 0.4419 - val_loss: 1.7237 - val_acc: 0.3778\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 0s 229us/step - loss: 1.5452 - acc: 0.4419 - val_loss: 1.7023 - val_acc: 0.3556\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 0s 203us/step - loss: 1.5234 - acc: 0.4419 - val_loss: 1.6848 - val_acc: 0.3556\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 0s 207us/step - loss: 1.5011 - acc: 0.4535 - val_loss: 1.6662 - val_acc: 0.3556\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 0s 217us/step - loss: 1.4802 - acc: 0.4651 - val_loss: 1.6497 - val_acc: 0.3778\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 0s 203us/step - loss: 1.4611 - acc: 0.4651 - val_loss: 1.6333 - val_acc: 0.4000\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 0s 241us/step - loss: 1.4420 - acc: 0.4535 - val_loss: 1.6167 - val_acc: 0.4222\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 0s 203us/step - loss: 1.4244 - acc: 0.4535 - val_loss: 1.6018 - val_acc: 0.4222\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 0s 211us/step - loss: 1.4078 - acc: 0.4535 - val_loss: 1.5875 - val_acc: 0.4222\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 0s 213us/step - loss: 1.3923 - acc: 0.4651 - val_loss: 1.5757 - val_acc: 0.4222\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 0s 237us/step - loss: 1.3782 - acc: 0.4767 - val_loss: 1.5641 - val_acc: 0.4222\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 0s 251us/step - loss: 1.3642 - acc: 0.4651 - val_loss: 1.5515 - val_acc: 0.4222\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 0s 216us/step - loss: 1.3515 - acc: 0.4651 - val_loss: 1.5412 - val_acc: 0.4222\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 0s 207us/step - loss: 1.3396 - acc: 0.4651 - val_loss: 1.5300 - val_acc: 0.4222\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 0s 222us/step - loss: 1.3276 - acc: 0.4651 - val_loss: 1.5186 - val_acc: 0.4222\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 0s 221us/step - loss: 1.3162 - acc: 0.4651 - val_loss: 1.5071 - val_acc: 0.4222\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 0s 218us/step - loss: 1.3048 - acc: 0.4651 - val_loss: 1.4975 - val_acc: 0.4222\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 0s 254us/step - loss: 1.2945 - acc: 0.4767 - val_loss: 1.4881 - val_acc: 0.4222\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 0s 233us/step - loss: 1.2848 - acc: 0.4767 - val_loss: 1.4790 - val_acc: 0.4222\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 0s 245us/step - loss: 1.2741 - acc: 0.4767 - val_loss: 1.4703 - val_acc: 0.4000\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 0s 239us/step - loss: 1.2651 - acc: 0.4884 - val_loss: 1.4621 - val_acc: 0.4000\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 0s 239us/step - loss: 1.2566 - acc: 0.4884 - val_loss: 1.4551 - val_acc: 0.4000\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 0s 217us/step - loss: 1.2477 - acc: 0.5000 - val_loss: 1.4472 - val_acc: 0.4000\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 0s 227us/step - loss: 1.2390 - acc: 0.5116 - val_loss: 1.4397 - val_acc: 0.4000\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 0s 222us/step - loss: 1.2311 - acc: 0.5116 - val_loss: 1.4336 - val_acc: 0.4222\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 0s 216us/step - loss: 1.2238 - acc: 0.5000 - val_loss: 1.4268 - val_acc: 0.4000\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 0s 217us/step - loss: 1.2168 - acc: 0.5000 - val_loss: 1.4211 - val_acc: 0.4222\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 0s 227us/step - loss: 1.2091 - acc: 0.5000 - val_loss: 1.4145 - val_acc: 0.4444\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 0s 220us/step - loss: 1.2023 - acc: 0.5000 - val_loss: 1.4080 - val_acc: 0.4444\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 0s 231us/step - loss: 1.1966 - acc: 0.5000 - val_loss: 1.4027 - val_acc: 0.4444\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 0s 237us/step - loss: 1.1892 - acc: 0.5000 - val_loss: 1.3967 - val_acc: 0.4444\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 0s 259us/step - loss: 1.1827 - acc: 0.5000 - val_loss: 1.3906 - val_acc: 0.4444\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 0s 231us/step - loss: 1.1761 - acc: 0.5000 - val_loss: 1.3849 - val_acc: 0.4444\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 0s 233us/step - loss: 1.1704 - acc: 0.5000 - val_loss: 1.3804 - val_acc: 0.4444\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 0s 234us/step - loss: 1.1645 - acc: 0.5000 - val_loss: 1.3760 - val_acc: 0.4444\n",
            "Train on 88 samples, validate on 43 samples\n",
            "Epoch 1/100\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 2.0360 - acc: 0.4545 - val_loss: 2.1264 - val_acc: 0.4651\n",
            "Epoch 2/100\n",
            "88/88 [==============================] - 0s 193us/step - loss: 1.9301 - acc: 0.4545 - val_loss: 2.0095 - val_acc: 0.4884\n",
            "Epoch 3/100\n",
            "88/88 [==============================] - 0s 214us/step - loss: 1.8312 - acc: 0.4659 - val_loss: 1.9081 - val_acc: 0.4884\n",
            "Epoch 4/100\n",
            "88/88 [==============================] - 0s 199us/step - loss: 1.7410 - acc: 0.4773 - val_loss: 1.8182 - val_acc: 0.4884\n",
            "Epoch 5/100\n",
            "88/88 [==============================] - 0s 200us/step - loss: 1.6645 - acc: 0.4886 - val_loss: 1.7356 - val_acc: 0.5349\n",
            "Epoch 6/100\n",
            "88/88 [==============================] - 0s 178us/step - loss: 1.5951 - acc: 0.4659 - val_loss: 1.6619 - val_acc: 0.5349\n",
            "Epoch 7/100\n",
            "88/88 [==============================] - 0s 226us/step - loss: 1.5366 - acc: 0.4545 - val_loss: 1.5943 - val_acc: 0.5116\n",
            "Epoch 8/100\n",
            "88/88 [==============================] - 0s 220us/step - loss: 1.4844 - acc: 0.4545 - val_loss: 1.5365 - val_acc: 0.5116\n",
            "Epoch 9/100\n",
            "88/88 [==============================] - 0s 176us/step - loss: 1.4344 - acc: 0.4545 - val_loss: 1.4890 - val_acc: 0.5116\n",
            "Epoch 10/100\n",
            "88/88 [==============================] - 0s 195us/step - loss: 1.3935 - acc: 0.4773 - val_loss: 1.4434 - val_acc: 0.5116\n",
            "Epoch 11/100\n",
            "88/88 [==============================] - 0s 199us/step - loss: 1.3568 - acc: 0.4773 - val_loss: 1.4053 - val_acc: 0.5349\n",
            "Epoch 12/100\n",
            "88/88 [==============================] - 0s 190us/step - loss: 1.3245 - acc: 0.4773 - val_loss: 1.3720 - val_acc: 0.5581\n",
            "Epoch 13/100\n",
            "88/88 [==============================] - 0s 213us/step - loss: 1.2935 - acc: 0.4773 - val_loss: 1.3430 - val_acc: 0.5581\n",
            "Epoch 14/100\n",
            "88/88 [==============================] - 0s 198us/step - loss: 1.2666 - acc: 0.4773 - val_loss: 1.3168 - val_acc: 0.5581\n",
            "Epoch 15/100\n",
            "88/88 [==============================] - 0s 207us/step - loss: 1.2430 - acc: 0.4659 - val_loss: 1.2928 - val_acc: 0.5581\n",
            "Train on 88 samples, validate on 43 samples\n",
            "Epoch 1/100\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 3.2284 - acc: 0.3864 - val_loss: 3.1288 - val_acc: 0.4186\n",
            "Epoch 2/100\n",
            "88/88 [==============================] - 0s 204us/step - loss: 3.0750 - acc: 0.3750 - val_loss: 3.0008 - val_acc: 0.4186\n",
            "Epoch 3/100\n",
            "88/88 [==============================] - 0s 219us/step - loss: 2.9347 - acc: 0.3750 - val_loss: 2.8838 - val_acc: 0.4186\n",
            "Epoch 4/100\n",
            "88/88 [==============================] - 0s 205us/step - loss: 2.8037 - acc: 0.3864 - val_loss: 2.7686 - val_acc: 0.4186\n",
            "Epoch 5/100\n",
            "88/88 [==============================] - 0s 232us/step - loss: 2.6824 - acc: 0.3864 - val_loss: 2.6667 - val_acc: 0.4186\n",
            "Epoch 6/100\n",
            "88/88 [==============================] - 0s 225us/step - loss: 2.5664 - acc: 0.3864 - val_loss: 2.5677 - val_acc: 0.4186\n",
            "Epoch 7/100\n",
            "88/88 [==============================] - 0s 207us/step - loss: 2.4635 - acc: 0.3864 - val_loss: 2.4775 - val_acc: 0.4186\n",
            "Epoch 8/100\n",
            "88/88 [==============================] - 0s 234us/step - loss: 2.3633 - acc: 0.3864 - val_loss: 2.3916 - val_acc: 0.4186\n",
            "Epoch 9/100\n",
            "88/88 [==============================] - 0s 190us/step - loss: 2.2728 - acc: 0.3864 - val_loss: 2.3082 - val_acc: 0.4186\n",
            "Epoch 10/100\n",
            "88/88 [==============================] - 0s 239us/step - loss: 2.1855 - acc: 0.3864 - val_loss: 2.2329 - val_acc: 0.4419\n",
            "Epoch 11/100\n",
            "88/88 [==============================] - 0s 202us/step - loss: 2.1071 - acc: 0.3977 - val_loss: 2.1639 - val_acc: 0.4186\n",
            "Epoch 12/100\n",
            "88/88 [==============================] - 0s 212us/step - loss: 2.0306 - acc: 0.3977 - val_loss: 2.0949 - val_acc: 0.4186\n",
            "Epoch 13/100\n",
            "88/88 [==============================] - 0s 206us/step - loss: 1.9610 - acc: 0.4091 - val_loss: 2.0310 - val_acc: 0.4186\n",
            "Epoch 14/100\n",
            "88/88 [==============================] - 0s 221us/step - loss: 1.8968 - acc: 0.4091 - val_loss: 1.9716 - val_acc: 0.4186\n",
            "Epoch 15/100\n",
            "88/88 [==============================] - 0s 202us/step - loss: 1.8345 - acc: 0.4091 - val_loss: 1.9136 - val_acc: 0.4186\n",
            "Epoch 16/100\n",
            "88/88 [==============================] - 0s 218us/step - loss: 1.7757 - acc: 0.3977 - val_loss: 1.8575 - val_acc: 0.4186\n",
            "Epoch 17/100\n",
            "88/88 [==============================] - 0s 205us/step - loss: 1.7197 - acc: 0.3977 - val_loss: 1.8066 - val_acc: 0.4186\n",
            "Epoch 18/100\n",
            "88/88 [==============================] - 0s 220us/step - loss: 1.6687 - acc: 0.3977 - val_loss: 1.7567 - val_acc: 0.4186\n",
            "Epoch 19/100\n",
            "88/88 [==============================] - 0s 240us/step - loss: 1.6184 - acc: 0.3977 - val_loss: 1.7105 - val_acc: 0.3953\n",
            "Epoch 20/100\n",
            "88/88 [==============================] - 0s 221us/step - loss: 1.5725 - acc: 0.3977 - val_loss: 1.6658 - val_acc: 0.3953\n",
            "Epoch 21/100\n",
            "88/88 [==============================] - 0s 193us/step - loss: 1.5281 - acc: 0.3977 - val_loss: 1.6247 - val_acc: 0.3953\n",
            "Epoch 22/100\n",
            "88/88 [==============================] - 0s 200us/step - loss: 1.4894 - acc: 0.3977 - val_loss: 1.5846 - val_acc: 0.3953\n",
            "Epoch 23/100\n",
            "88/88 [==============================] - 0s 199us/step - loss: 1.4493 - acc: 0.3977 - val_loss: 1.5485 - val_acc: 0.3953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2eeOHoYbina",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDN2PrRc36l",
        "colab_type": "code",
        "outputId": "7295fc06-806b-4485-ef5c-d8fb9304e69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc', 'lr'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tss7vRUEgAcz",
        "colab_type": "code",
        "outputId": "d5443296-b56f-44e9-d516-821c5e014bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_acc_histories[2])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpKE3iTJBHzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "ec061192-f52f-4e91-cdf4-6d70cf12e560"
      },
      "source": [
        "average_acc_history = [np.mean([x[i] for x in all_acc_histories]) for i in range(num_epochs)]\n",
        "#media per epoca degli score ottenuti per tutte le k-fold\n",
        "#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\n",
        "#e si fa questo per tutte le epoche\n",
        "average_loss_history = [np.mean([x[i] for x in all_loss_histories]) for i in range(num_epochs)]\n",
        "average_val_acc_history = [np.mean([x[i] for x in all_val_acc_histories]) for i in range(num_epochs)]\n",
        "average_val_loss_history = [np.mean([x[i] for x in all_val_loss_histories]) for i in range(num_epochs)]\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-5f1375ebaf5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maverage_acc_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_acc_histories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#media per epoca degli score ottenuti per tutte le k-fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#e si fa questo per tutte le epoche\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maverage_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_loss_histories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-5f1375ebaf5c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maverage_acc_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_acc_histories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#media per epoca degli score ottenuti per tutte le k-fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#e si fa questo per tutte le epoche\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maverage_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_loss_histories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-5f1375ebaf5c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maverage_acc_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_acc_histories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#media per epoca degli score ottenuti per tutte le k-fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#per ogni k-fold di fanno num_epoch epoche, la media viene fatta prendendo gli score di tutti i k-fold relativi ad una data epoca,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#e si fa questo per tutte le epoche\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maverage_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_loss_histories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQrkCEMUD2RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(average_val_acc_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9UhSxIaHtuO",
        "colab_type": "text"
      },
      "source": [
        "##Plotting training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6zsienD5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJizyjnaIPhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, num_epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEHEYLgIQUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs, average_loss_history, 'bo', label='training loss')\n",
        "plt.plot(epochs, average_val_loss_history, 'b', label='validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc4wMjfI97j",
        "colab_type": "text"
      },
      "source": [
        "##Plotting train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi7VzbFIbtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs, average_acc_history, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, average_val_acc_history, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJTbHiq0D-4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwM6YMqsxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAzbu7P1VylY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyqbUCK5wOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OAEgN31tHVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(layers.Dense(6, activation='relu', input_shape=(9,)))\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "  sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}